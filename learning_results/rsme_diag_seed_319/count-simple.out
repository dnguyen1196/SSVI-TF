Generating synthetic  count valued data ... 
Generating synthetic  count valued data took:  8.775056838989258
max_count =  16  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       56.06      3.8316     3.8524     0.3162     0.2942    58922.43   47591.14    0.0001  
   100       250.67     3.8558     3.8862     0.2789     0.2237    57808.84   46686.84     0.0    
   150       438.44     3.8784     3.9063     0.2549     0.1798    56986.22   46017.67    0.0001  
   200       626.21     3.897      3.9264      0.22      0.1468    56345.68   45495.36     0.0    
   250       821.11     3.9082     3.9423     0.1999     0.1297    55816.28   45063.54     0.0    
   300      1016.06     3.9267     3.9534     0.1914     0.1067    55381.55   44708.25     0.0    
   350      1211.07     3.9379     3.9644     0.1794     0.0987    55007.55   44402.9      0.0    
   400      1406.39     3.9492     3.9779     0.1824     0.086     54685.35   44139.53     0.0    
   450      1601.65     3.9604     3.9871     0.1606     0.0795    54399.75   43906.38     0.0    
   500      1796.77     3.9683      4.0       0.153       0.07     54145.99   43699.29     0.0    
   550      1993.46     3.9746     4.0047     0.164      0.0631    53920.32   43515.18     0.0    
   600      2188.52     3.9839     4.0127     0.1551     0.0601    53716.16   43348.95     0.0    
   650      2383.47     3.9908     4.0214     0.1523     0.0552    53533.35   43199.88     0.0    
   700      2578.43     3.9966     4.0262     0.1366     0.0519    53364.5    43062.46     0.0    
   750      2773.38     4.002      4.032      0.1315     0.0508    53211.4    42937.85     0.0    
   800       2968.4     4.0049     4.0358     0.1199     0.0479    53071.35   42824.02     0.0    
   850      3163.71     4.0126     4.0428     0.1191     0.0436    52938.31   42715.66     0.0    
   900      3358.67     4.0154     4.0473     0.1188     0.0408    52817.16   42617.22     0.0    
   950      3553.61     4.0213     4.0513     0.1086     0.0382    52704.55   42525.85     0.0    
   1000     3752.09     4.0261     4.0529     0.1123     0.0385    52599.9    42440.82     0.0    
   1050     3947.13     4.0302     4.0576     0.1047     0.0344    52502.86   42362.21     0.0    
   1100     4142.16     4.0336     4.0617     0.1103     0.0353    52413.61   42289.93     0.0    
   1150     4337.07     4.0378     4.066      0.1005     0.0321    52331.73   42223.57     0.0    
   1200     4532.01     4.0389     4.0675     0.1081     0.0303    52255.14   42161.49     0.0    
   1250     4727.07     4.042      4.0702     0.1099     0.029     52183.72   42103.77     0.0    
   1300     4922.01     4.0426     4.073      0.1072     0.0283    52117.95   42050.52     0.0    
   1350     5116.92     4.0448     4.0743     0.1035     0.0274    52057.86   42002.11     0.0    
   1400     5311.86     4.0443     4.0732     0.1161     0.0269    52004.03   41958.67     0.0    
   1450     5510.96     4.0462     4.0753     0.1094     0.0257    51955.55   41919.41     0.0    
   1500     5705.74     4.0426     4.0742     0.122      0.0246    51913.27   41885.42     0.0    
   1550     5900.67     4.0381     4.0677     0.1232     0.023     51874.03   41853.68     0.0    
   1600     6095.64     4.0264     4.0574     0.1342     0.0242    51836.4    41823.63     0.0    
   1650     6290.63     4.0093      4.04      0.1448     0.0222    51800.59   41795.62     0.0    
   1700     6485.62     3.9814     4.0152     0.1674     0.0225    51764.46   41768.36     0.0    
   1750      6680.4     3.9395     3.9669     0.1855     0.0221    51739.19   41750.67     0.0    
   1800     6875.32     3.8745     3.9057     0.2017     0.0208    51744.65   41759.71     0.0    
   1850     7070.13     3.7824     3.8107     0.2185     0.0198    51820.34   41827.63     0.0    
   1900     7267.81     3.6459     3.6773     0.2366     0.0196    52016.15   41993.4      0.0    
   1950     7461.73     3.4766     3.4986     0.2477     0.0182    52391.56   42301.94     0.0    
   2000     7655.51     3.2527     3.2788     0.2451     0.017     52953.16   42752.72     0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       55.87      3.8185     3.8374     0.1523     0.1976    59654.74   96527.89     0.0    
   100       310.93     3.8398     3.8556     0.1521     0.1631    58890.85   95279.66     0.0    
   150       565.9      3.848      3.8697     0.1223     0.1342    58241.77   94218.64     0.0    
   200       820.85     3.8685     3.8831     0.1398     0.1214    57677.02   93293.79     0.0    
   250      1075.63     3.8796     3.8958     0.1403     0.1118    57188.37   92492.84     0.0    
   300      1332.02     3.8872     3.9055     0.1121     0.1015    56756.8    91784.85     0.0    
   350      1586.92     3.8957     3.9185     0.1064     0.0883    56378.33   91163.58     0.0    
   400      1841.79     3.9114     3.9319     0.1168     0.084     56033.39   90597.55     0.0    
   450      2096.52     3.9241     3.9405     0.1206     0.0773    55725.18   90090.82     0.0    
   500      2351.43     3.9282     3.9459     0.1018     0.0731    55445.71   89631.83     0.0    
   550      2607.04     3.9398     3.9559     0.0958     0.0679    55189.18   89210.28     0.0    
   600      2861.93     3.9471     3.9648     0.0939     0.0657    54956.73   88828.23     0.0    
   650      3118.45     3.9529     3.9705     0.0812     0.0593    54741.21   88473.94     0.0    
   700      3373.26     3.9595     3.9792     0.0791     0.0554    54540.7    88144.07     0.0    
   750      3627.99     3.9671     3.9851     0.0828     0.051     54355.79   87840.5      0.0    
   800      3883.35     3.9721     3.9897     0.0893     0.0488    54183.24   87557.0      0.0    
   850       4138.2     3.9775     3.9965     0.0777     0.0484    54018.89   87287.29     0.0    
   900      4392.94     3.9807     4.004      0.0816     0.0456    53868.89   87041.14     0.0    
   950      4647.73     3.9898     4.0078     0.0781     0.0423    53725.57   86806.04     0.0    
   1000     4906.15     3.9955     4.0121     0.0685     0.0408    53590.34   86584.22     0.0    
   1050     5160.87     3.9986     4.017      0.0718     0.0415    53464.18   86377.43     0.0    
   1100     5416.27     4.0001     4.0235     0.0729     0.0389    53344.53   86181.24     0.0    
   1150      5671.2     4.0072     4.026      0.0665     0.0364    53230.35   85993.97     0.0    
   1200     5926.07     4.0097     4.0293     0.0667     0.0358    53122.55   85817.36     0.0    
   1250     6180.93     4.0158     4.0357     0.0685     0.0345    53020.74   85650.65     0.0    
   1300     6435.67     4.0174     4.0373     0.0743     0.0314    52923.45   85491.32     0.0    
   1350     6693.85     4.019      4.0422     0.0615     0.0305    52831.65   85341.14     0.0    
   1400     6948.75     4.0254     4.0477     0.0731     0.0305    52744.09   85197.82     0.0    
   1450      7203.6     4.0297     4.0498     0.0658     0.0282    52660.06   85060.39     0.0    
   1500     7458.57     4.0347     4.0525     0.0675     0.0274    52580.04   84929.56     0.0    
   1550     7713.46     4.0374     4.0547     0.0638     0.0272    52502.85   84803.35     0.0    
   1600     7969.01     4.0405     4.0605     0.0578     0.0268    52430.08   84684.28     0.0    
   1650     8223.98     4.0413     4.0638      0.06      0.025     52360.7    84571.03     0.0    
   1700     8480.08     4.0432     4.0651     0.0633     0.0241    52294.02   84462.07     0.0    
   1750      8735.4     4.0498     4.0691     0.0644     0.0249    52229.93   84357.37     0.0    
   1800     8990.89     4.0519     4.0727     0.0579     0.0241    52170.02   84259.6      0.0    
   1850     9247.23     4.0539     4.072      0.062      0.023     52111.82   84164.45     0.0    
   1900     9502.87     4.0558     4.0747     0.0574     0.0212    52056.4    84073.94     0.0    
   1950     9758.39     4.058      4.0775     0.0644     0.0218    52003.19   83986.94     0.0    
   2000     10013.87    4.0602     4.0804     0.0547     0.0201    51952.29   83903.73     0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       57.75      3.8139     3.8263     0.1322     0.1408    59911.26  144831.43     0.0    
   100       375.14     3.8331     3.8405     0.1163     0.1255    59332.16  143420.53     0.0    
   150       692.1      3.8349     3.8524     0.1113     0.119     58816.31  142162.83     0.0    
   200      1008.86     3.8545     3.8656     0.1119     0.1038    58349.51  141024.78     0.0    
   250      1325.89     3.864      3.8761     0.1194     0.0949    57924.39  139987.58     0.0    
   300      1642.51     3.8697     3.8864     0.1102     0.0904    57537.11  139042.19     0.0    
   350      1962.09     3.8802     3.894      0.1025     0.084     57180.8   138173.01     0.0    
   400       2279.2     3.8911     3.9029     0.0934     0.0789    56857.92  137384.48     0.0    
   450      2596.33     3.9009     3.9104     0.0926     0.0707    56560.44  136656.89     0.0    
   500      2913.05     3.9068     3.9211     0.0849     0.0682    56285.58  135984.91     0.0    
   550      3229.23     3.9154     3.9279     0.0933     0.0637    56032.96  135366.41     0.0    
   600      3545.22     3.9215     3.9341     0.0881     0.0586    55793.62   134780.8     0.0    
   650       3862.0      3.93      3.9415     0.0858     0.0591    55574.06  134243.58     0.0    
   700       4177.7     3.933      3.9494     0.0775     0.0548    55369.03  133741.97     0.0    
   750      4494.97     3.9373     3.9563     0.089      0.0541    55177.54   133273.3     0.0    
   800       4812.4     3.9466     3.9604     0.0833     0.0485    54996.82   132830.9     0.0    
   850      5129.93     3.9545     3.9662     0.0814     0.0495    54826.21  132413.34     0.0    
   900      5449.93     3.9611     3.9719     0.0884     0.0444    54664.72  132017.96     0.0    
   950      5766.59     3.9621     3.9763     0.0779     0.0438    54511.81  131643.85     0.0    
   1000     6082.73     3.9719     3.9841     0.0782     0.041     54366.69  131288.59     0.0    
   1050      6399.3     3.9778     3.9879     0.078      0.0405    54229.17  130952.22     0.0    
   1100     6715.87     3.9751     3.9922     0.0711     0.0401    54099.64   130635.5     0.0    
   1150     7031.72     3.9857     3.9979     0.0668     0.0374    53975.19  130331.61     0.0    
   1200     7350.66     3.9855     4.0005     0.0733     0.036     53857.85  130044.82     0.0    
   1250     7666.41     3.9934     4.0049     0.071      0.0361    53744.32   129767.4     0.0    
   1300     7982.45     3.9939     4.0105     0.0699     0.0329    53635.77  129502.24     0.0    
   1350     8298.19     4.001      4.0138     0.067      0.0327    53531.26  129246.81     0.0    
   1400     8614.03     4.0038     4.0168     0.065      0.0308    53432.13  129004.88     0.0    
   1450      8930.0     4.008      4.0216     0.0681     0.0311    53336.62  128771.71     0.0    
   1500     9246.08     4.0128     4.0245     0.0724     0.0289    53245.62  128549.73     0.0    
   1550     9561.56     4.0139     4.029      0.066      0.0307    53158.72  128337.77     0.0    
   1600     9877.12     4.0193     4.0316     0.0639     0.0284    53074.83  128133.34     0.0    
   1650     10192.89    4.0218     4.0352     0.0566     0.0266    52994.46  127937.52     0.0    
   1700     10508.82    4.0249     4.0369     0.0586     0.0263    52916.1    127746.4     0.0    
   1750     10825.73    4.0251      4.04      0.0588     0.0258    52841.97   127565.8     0.0    
   1800     11141.36    4.0311     4.0429     0.0609     0.0242    52769.78  127389.92     0.0    
   1850     11457.09    4.032      4.0469     0.0676     0.0232    52700.61  127221.27     0.0    
   1900     11773.01    4.037      4.0495     0.0686     0.0228    52633.68  127058.33     0.0    
   1950     12089.05    4.0375     4.0525     0.0598     0.0224    52569.15  126901.19     0.0    
   2000     12405.02    4.0417     4.0541     0.0566     0.0227    52507.02  126749.93     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50        55.8      3.8149     3.8237     0.1096     0.1092    60045.03  193680.54     0.0    
   100       433.35     3.8261     3.8364     0.1051     0.1021    59565.78  192123.16     0.0    
   150       811.06     3.8337     3.8448     0.1005     0.0951    59121.68  190681.56     0.0    
   200      1188.64     3.8454     3.8535     0.095      0.0891    58718.6    189371.9     0.0    
   250      1566.52     3.8547     3.8645     0.0961     0.0821    58339.97   188140.7     0.0    
   300      1948.44     3.8636     3.8717     0.1001     0.077     57990.67   187004.3     0.0    
   350      2325.91     3.8688     3.8805     0.0878     0.0727    57668.41  185955.76     0.0    
   400       2703.5     3.8799     3.8885     0.0904     0.0708    57366.45  184972.16     0.0    
   450      3081.12     3.8854     3.8942     0.0997     0.0646    57088.5   184066.69     0.0    
   500      3458.84     3.894      3.9038     0.0823     0.0657    56827.77  183217.57     0.0    
   550      3837.97     3.9033     3.911      0.0814     0.0604    56582.62  182418.38     0.0    
   600      4215.37     3.9061     3.9201     0.0821     0.0569    56352.4   181667.53     0.0    
   650      4592.82     3.9162     3.9224     0.0801     0.0536    56136.67  180964.37     0.0    
   700      4970.18     3.9194     3.9326     0.081      0.0503    55935.73  180309.25     0.0    
   750      5348.66     3.9244     3.9353     0.0804     0.0487    55744.04  179683.85     0.0    
   800      5726.75     3.9318     3.9434     0.083      0.0509    55563.11  179093.45     0.0    
   850      6104.69     3.9394     3.9501     0.0762     0.0445    55389.89  178528.07     0.0    
   900      6477.24     3.9435     3.9549     0.0792     0.042     55227.59  177998.65     0.0    
   950       6840.6     3.9469     3.9577     0.0754     0.0424    55073.22  177494.99     0.0    
   1000     7205.59     3.9526     3.9651     0.0722     0.0388    54925.62  177013.79     0.0    
   1050     7577.49     3.9576     3.9682     0.079      0.038     54785.66  176557.07     0.0    
   1100     7940.72     3.963      3.9725     0.071      0.039     54651.14  176118.37     0.0    
   1150      8304.0     3.9679     3.9775     0.0726     0.0359    54521.7   175696.51     0.0    
   1200      8667.5     3.9698     3.9813     0.0687     0.0358    54397.91  175292.86     0.0    
   1250     9032.91     3.9768     3.9877     0.0742     0.0338    54280.47  174910.11     0.0    
   1300     9402.23     3.9812      3.99      0.0727     0.0331    54167.94  174543.04     0.0    
   1350     9767.24     3.9826     3.9947     0.0698     0.0318    54058.39  174185.78     0.0    
   1400     10130.96    3.986      3.9986     0.0657     0.0308    53953.56  173844.34     0.0    
   1450     10497.08    3.9939     4.0028     0.0706     0.0297    53853.49  173518.42     0.0    
   1500     10861.18    3.9936     4.0062     0.0694     0.0307    53757.18  173204.65     0.0    
   1550     11211.31    3.9974     4.0072     0.064      0.0285    53664.49  172902.63     0.0    
   1600     11562.03    4.0016     4.0122     0.0619     0.0271    53575.95   172614.5     0.0    
   1650     11912.57    4.0018     4.0167     0.0618     0.0262    53490.37  172335.87     0.0    
   1700     12263.5     4.0089     4.0193     0.065      0.0262    53406.8   172063.63     0.0    
   1750     12615.69    4.0123     4.0223     0.0602     0.0243    53326.94  171803.54     0.0    
   1800     12973.94    4.0146     4.0238     0.0613     0.0262    53248.87  171549.45     0.0    
   1850     13332.63    4.0152     4.0278     0.0634     0.0241    53172.78  171301.85     0.0    
   1900     13689.38    4.0197      4.03      0.0601     0.0237    53099.3   171062.77     0.0    
   1950     14046.02    4.0206     4.0345     0.0633     0.023     53029.24  170834.75     0.0    
   2000     14402.79    4.0261     4.0362     0.0543     0.0223    52961.79  170615.36     0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       51.98      3.8158     3.8271     0.0952     0.0897    60126.25  242501.39     0.0    
   100       462.76     3.8244     3.8355     0.1051     0.0885    59714.84  240831.94     0.0    
   150       874.84     3.8303     3.8471     0.0891     0.0824    59328.59  239264.77     0.0    
   200      1289.34     3.8427     3.854      0.1004     0.0782    58967.36   237798.1     0.0    
   250      1701.15     3.8474     3.8635     0.0898     0.0757    58629.34  236426.26     0.0    
   300      2110.21     3.8545     3.8716     0.0804     0.069     58315.19  235150.24     0.0    
   350      2521.73     3.8628     3.8776     0.0938     0.0684    58020.1   233950.65     0.0    
   400      2932.69     3.8721     3.8844     0.0825     0.0634    57738.81   232806.0     0.0    
   450       3343.7     3.8767     3.8926     0.0865     0.0601    57478.38  231746.92     0.0    
   500      3753.81     3.8852     3.8975     0.0769     0.0592    57229.21  230732.67     0.0    
   550      4157.21     3.8893     3.9056     0.0808     0.0555    56997.08  229787.52     0.0    
   600      4537.71     3.8946     3.912      0.0798     0.0512    56778.13  228896.29     0.0    
   650      4917.61     3.9067     3.9196     0.084      0.0495    56570.32  228050.53     0.0    
   700      5298.03     3.9094     3.9235     0.0793     0.0515    56370.05  227234.62     0.0    
   750      5702.75     3.9114      3.93      0.0747     0.047     56182.25  226469.09     0.0    
   800      6143.17     3.9204     3.9368     0.0765     0.0447    56002.57  225737.47     0.0    
   850       6584.0     3.9211     3.9404     0.0721     0.0438    55833.87  225050.57     0.0    
   900      7025.33     3.931      3.9462     0.0758     0.0411    55672.39  224392.74     0.0    
   950      7465.67     3.9361     3.9505     0.0752     0.0426    55516.47  223757.51     0.0    
   1000     7906.48     3.9398     3.9562     0.0691     0.0397    55367.88  223152.01     0.0    
   1050     8346.85     3.9429     3.9611     0.0706     0.0395    55226.49   222575.4     0.0    
   1100     8786.88     3.9476     3.9652     0.0685     0.0365    55090.56  222021.15     0.0    
   1150     9227.44     3.9551     3.9709     0.0661     0.0372    54960.83  221492.61     0.0    
   1200     9668.32     3.9576     3.9751     0.0696     0.0364    54835.85  220982.86     0.0    
   1250     10109.36    3.9584     3.9784     0.0666     0.0339    54716.4   220496.41     0.0    
   1300     10550.33    3.9636     3.9827     0.0649     0.0321    54602.72  220033.75     0.0    
   1350     10991.42    3.9715     3.9856     0.0672     0.0315    54492.83  219586.17     0.0    
   1400     11432.52    3.9748     3.9908     0.0627     0.0314    54385.22  219147.57     0.0    
   1450     11874.21    3.9777     3.9962     0.0697      0.03     54282.08  218727.44     0.0    
   1500     12314.99    3.9824     3.9961     0.0657     0.0331    54182.24  218320.56     0.0    
   1550     12756.09    3.9857     4.0016     0.0595     0.0293    54086.89  217932.35     0.0    
   1600     13196.56    3.9869     4.0038     0.0584     0.029     53994.33  217555.87     0.0    
   1650     13637.99    3.9908     4.0074     0.0631     0.0266    53904.64  217190.57     0.0    
   1700     14079.41    3.9958     4.0119     0.0543     0.0256    53817.82  216837.05     0.0    
   1750     14521.12    3.9922     4.0132     0.0613     0.0256    53733.82  216495.05     0.0    
   1800     14962.67    3.9995     4.0161     0.0639     0.0238    53652.24  216163.02     0.0    
   1850     15404.76    4.0023     4.0205     0.0587     0.0229    53573.82  215843.95     0.0    
   1900     15846.58    4.0065     4.0222     0.0632     0.0236    53497.62  215533.93     0.0    
   1950     16288.43    4.0075     4.025      0.0539     0.024     53423.8   215233.57     0.0    
   2000     16730.01    4.0078     4.0289     0.0581     0.0225    53352.12  214942.13     0.0    
