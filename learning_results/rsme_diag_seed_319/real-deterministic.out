Generating synthetic  real valued data ... 
Generating synthetic  real valued data took:  7.487263917922974
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       34.29     474.3283    470.41     3.1623     1.8524   
   100        69.6     357.2447   355.4899    3.1432     0.6798   
   150       104.94    282.6448   278.2628    3.0765     0.3639   
   200       140.24    213.2285   210.7581    2.7838     0.2337   
   250       175.54    204.7642   204.6023    2.9605     0.1714   
   300       210.92    185.7937   184.5707    2.806      0.1267   
   350       246.23    178.8406   178.8186    2.2036     0.0985   
   400       281.51    179.4429   179.6982    2.232      0.0828   
   450       316.79    169.4221   169.6317    2.2239     0.068    
   500       352.08    167.0128   166.1725    2.1628     0.0558   
   550       387.35    170.6464   170.8177    2.2214     0.0484   
   600       422.64    163.3186   163.0062    2.0909     0.0419   
   650       457.93    160.2487   160.7356    1.5256     0.0371   
   700       493.23    157.2742   157.1227    1.3955     0.0334   
   750       528.52    157.3466   157.7332    1.6321     0.0295   
   800       563.83    155.4143   154.8324    1.8159     0.0272   
   850       599.12    156.1023   154.4723    1.6887     0.0247   
   900       634.44    156.1607   155.3682    1.2999     0.0214   
   950       669.78    154.9813   154.1464    1.3761     0.0201   
   1000      705.11    152.5127   152.3938    1.0715     0.0182   
   1050      740.42    152.3577   152.6711    1.2795     0.0173   
   1100      775.79    151.5076   150.9072    1.2396     0.0159   
   1150      811.11    151.1482   150.5838    1.0059     0.0147   
   1200      846.42    151.626    150.9053    1.0837     0.0136   
   1250      881.74    152.0199   151.7722    1.2076     0.0128   
   1300      917.05    151.1409   149.833     1.4097     0.0122   
   1350      952.38    149.6918   149.1699    0.972      0.0113   
   1400      987.72    151.8978   150.8827    0.8564     0.0107   
   1450     1023.07    149.6211   149.3285    0.8642     0.0102   
   1500     1058.38    152.6325   151.0095    0.9328     0.0096   
   1550      1093.7    150.1267   149.1656    1.2057     0.0091   
   1600     1129.02    149.6778   149.4426    0.8643     0.0086   
   1650     1164.34    149.9662   149.1804    0.9009     0.0084   
   1700     1199.67    148.2113   147.6988    0.8031     0.0077   
   1750      1235.0    149.7268   148.9682    0.9209     0.0076   
   1800     1270.35    149.6439   148.689     0.9466     0.0071   
   1850     1305.68    147.9357   147.6069    0.8812     0.0067   
   1900     1340.99    148.0341   148.0257    0.7062     0.0066   
   1950     1376.33    148.1425    147.61     0.9299     0.0062   
   2000     1411.66    148.4019   147.6397    1.1028     0.0059   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50        34.4     385.0506   382.3831    3.1448     1.2551   
   100       70.47     339.4023   336.0106    3.0835     0.6436   
   150       106.53    269.4244   267.9993    2.8528     0.4135   
   200       142.61    237.958    238.2926    2.6605     0.3071   
   250       178.71    223.8479   223.2724    2.7418     0.2293   
   300       214.84    204.5584   204.4832    2.304      0.183    
   350       250.94    199.5419   198.1557    2.4157     0.1493   
   400       287.02    193.0182   191.4167    2.278      0.1258   
   450       323.1     186.3823   186.1674    1.993      0.1064   
   500       359.17    177.4905    177.08     1.9873     0.0888   
   550       395.25    171.9145   171.3725    1.7279     0.0786   
   600       431.33    170.9707   169.478     1.9261     0.0681   
   650       467.42    165.3253   164.0725    1.7571     0.0594   
   700       503.48    163.3383   163.1504    1.3416     0.0533   
   750       539.56    162.1033   161.6619    1.2014     0.0486   
   800       575.63    158.9795   158.8063    1.2621     0.0437   
   850       611.74    159.1645   159.0109    1.1872     0.0386   
   900       647.83    157.8856   157.9139    1.1491     0.0362   
   950       683.95    157.9366   158.2062    1.1383     0.0328   
   1000      720.05    157.4991   156.8325    1.1742     0.0302   
   1050      756.11    156.715    156.2211    1.1398     0.0275   
   1100      792.18    154.6821   153.8732    1.0789     0.0264   
   1150      828.27    152.5069   151.6949    0.9139     0.024    
   1200      864.33    152.891    152.5805    1.0526     0.023    
   1250      900.41    151.4388   151.8843    1.5178     0.0213   
   1300      936.48    152.1521   151.8569    0.9891     0.0198   
   1350      972.54    152.6442   152.463     0.832      0.019    
   1400     1008.61    152.5417   151.6647    0.7633     0.0178   
   1450     1044.72    150.6987   149.9847    0.7042     0.0168   
   1500     1080.85    151.9784   151.637     0.7064     0.0156   
   1550     1116.95    150.3135   150.5598    1.0689     0.0146   
   1600     1153.07    150.0368   150.0169    0.7954     0.0143   
   1650     1189.12    149.9067   149.5869    0.7729     0.0131   
   1700      1225.2    150.8417   150.7402    0.8981     0.0133   
   1750     1261.32    151.3051   150.3209    0.8303     0.0123   
   1800      1297.4    150.5751   150.0673    0.7478     0.0114   
   1850      1333.5    150.1319   149.7662    0.7888     0.0109   
   1900     1369.57    148.9232   148.3806    0.7719     0.0105   
   1950     1405.67    149.7336   149.5947    0.9589     0.0103   
   2000     1441.73    149.1025   148.9764    0.7118     0.0097   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       34.37      369.99    368.5129    3.0358     0.9866   
   100       71.16     318.8038   318.6317    2.9494     0.567    
   150       107.94    257.4872   256.2385    2.7047     0.4036   
   200       144.76    250.1409   249.148     2.2146     0.3078   
   250       181.55    222.7734   222.2532    2.2251     0.242    
   300       218.34    209.3161   208.2212    2.3088     0.2036   
   350       255.13    193.7283   193.3266    1.9071     0.1724   
   400       291.93    180.7396   180.0422    2.4796     0.1472   
   450       328.73    183.8356   182.5237    1.6817     0.1244   
   500       365.57    180.4056   180.5774    1.8957     0.1046   
   550       402.4     181.0153   180.5836    1.7217     0.0911   
   600       439.18    175.4134   175.8331    1.5865     0.0801   
   650       475.97    169.807    170.3279    1.2147     0.0712   
   700       512.78    165.7726   166.3765    1.4262     0.0651   
   750       549.59    164.1996   164.3594    1.065      0.0575   
   800       586.39    163.4301   163.2181    1.3034     0.0511   
   850       623.17    157.4145   156.5449    1.0042     0.047    
   900       659.96    161.2924   160.1752    1.0622     0.0427   
   950       696.75    160.6244   159.8724    1.2302     0.0393   
   1000      733.54    156.2361   156.1844    1.1648     0.0373   
   1050      770.38    155.4574   155.7196    1.0897     0.0342   
   1100      807.17    158.8913   159.0568    0.8423     0.0316   
   1150      843.99    156.9783   156.5281    0.993      0.0293   
   1200      880.66    153.9227   153.2589    1.1051     0.0275   
   1250      917.07    153.8403   153.5015    1.1215     0.0261   
   1300      953.47    153.6492   153.5215    1.1938     0.0241   
   1350      989.87    153.3472   153.3694    0.7909     0.0225   
   1400     1026.26    153.4219   153.0158    0.7825     0.0216   
   1450     1062.72    152.286    151.9913    0.7707     0.0201   
   1500     1099.21    153.2171   152.4636    1.1088     0.019    
   1550     1135.66    152.249    151.6166    1.3702     0.0183   
   1600     1172.08    153.3959   152.7322    0.7619     0.0174   
   1650     1208.52    150.7889   150.426     0.9096     0.0168   
   1700      1245.0    150.8632   150.2657    0.6592     0.0152   
   1750     1281.52    150.9583   150.4699    0.7417     0.0147   
   1800     1317.95    149.7293   149.2035    0.5673     0.0145   
   1850     1354.38    149.0453   148.3342    0.9242     0.0136   
   1900     1390.85    149.9977   149.6107    0.5694     0.0128   
   1950     1427.34    149.0324   148.6757    0.6443     0.0123   
   2000     1463.87    148.9417   148.3791    0.619      0.0118   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       34.22     378.0591   375.0952    3.0345     0.8338   
   100       71.45     310.9456   311.1355    2.6479     0.4943   
   150       108.65    270.9045   270.5155    2.4027     0.3844   
   200       145.84    253.9408   253.4755    2.5396     0.303    
   250       183.0     235.7558   236.3761    2.1086     0.2465   
   300       220.2     214.3574   214.2445    1.792      0.2068   
   350       257.38    207.0775   207.2654    1.7935     0.1677   
   400       294.59    196.3522   196.2725    1.6193     0.1458   
   450       331.78    191.1961   192.2486    1.594      0.1246   
   500       368.95    183.2578   183.552     1.6783     0.1115   
   550       406.2     176.4558   177.3564    1.268      0.0997   
   600       443.39    174.3301   175.0713    1.1249     0.0869   
   650       480.58    172.6224   172.9797    1.1263     0.0793   
   700       517.79    170.754    170.8995    0.9967     0.0711   
   750       555.04    167.6619   167.9563    1.1848     0.0636   
   800       592.24    163.8983   164.4561    1.5004     0.059    
   850       629.49    159.655    160.0284    1.0864     0.0545   
   900       666.69    160.1683   160.4822    1.006      0.0493   
   950       703.91    161.8804   162.4823    0.9305     0.045    
   1000      741.14    159.5218   160.3084    1.0674     0.0413   
   1050      778.36    160.2629   160.9056    0.8574     0.0389   
   1100      815.57    155.4774   156.2608    1.1421     0.0368   
   1150      852.75    152.4141   152.9953    0.7662     0.0351   
   1200      889.97    153.4153   153.6427    0.7777     0.0323   
   1250      927.18    152.1824   152.5497    0.7396     0.0296   
   1300      964.39    153.1354   153.3563    0.6683     0.0287   
   1350     1001.61    153.9207   153.8133    0.7223     0.0265   
   1400     1038.83    153.0877   152.3736    0.9632     0.0249   
   1450     1076.06    152.8876   152.3908    0.7098     0.024    
   1500     1113.29    153.2662   152.6138    0.6256     0.0227   
   1550     1150.57    152.0478   151.298     0.7947     0.0211   
   1600     1187.78    151.0222   150.6861    0.5529     0.0209   
   1650     1225.03    151.2578   151.0424    0.5397     0.0196   
   1700     1262.25    149.9632   150.1507    0.7196     0.0182   
   1750     1299.45    150.6147   150.514     0.5888     0.0173   
   1800     1336.71    150.7427   150.5823    0.6686     0.0169   
   1850     1373.92    150.4272   150.4017    0.8668     0.0161   
   1900     1411.14    149.7406   149.4939    0.528      0.0156   
   1950     1448.33    149.5606   149.4055    0.5257     0.0145   
   2000     1485.57    148.3073   148.0853    0.5056     0.0139   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       34.25     360.5637   358.2238    2.8607     0.7325   
   100       72.13     307.6533   305.9045    2.6388     0.4609   
   150       110.0     270.9842   269.6388    2.4794     0.3637   
   200       147.87    250.5414   250.4035    1.9792     0.282    
   250       185.78    222.8773   222.7844    2.0894     0.2346   
   300       223.62    212.2541   212.5917    1.9481     0.1997   
   350       261.53    204.1787   203.8129    1.3307     0.1739   
   400       299.37    195.1577   194.5281    1.7239     0.1491   
   450       337.22    185.7627   185.5306    1.2735     0.1324   
   500       375.15    184.7578   184.3867    1.5868     0.1166   
   550       413.01    183.1834   181.9301    1.3165     0.1022   
   600       450.83    170.8995   170.5845    1.4271     0.092    
   650       488.7     167.1203   167.5099    1.5962     0.0822   
   700       526.59    167.4528   167.0707    1.5132     0.0741   
   750       564.51    166.8235   165.9613    1.1309     0.0679   
   800       602.4     164.6231   164.0997    1.2277     0.0637   
   850       640.31    163.7821   163.2758    1.2512     0.0557   
   900       678.2      159.2     158.7535    1.1444     0.0524   
   950       716.05    162.3437   161.9115    1.2937     0.048    
   1000      753.93    159.7878   159.5967    0.713      0.0449   
   1050      791.8     158.3159   157.9754    1.0162     0.0422   
   1100      829.7     158.9296   158.9937    0.6807     0.0387   
   1150      867.62    157.4095   157.7648    0.7574     0.0373   
   1200      905.51    154.2422   154.7361    0.7583     0.0344   
   1250      943.4     157.1621   157.547     0.9084     0.0319   
   1300      981.3     154.832    154.7887    0.7564     0.0296   
   1350     1019.17    153.5691   154.082     0.612      0.0284   
   1400     1057.05    154.2826   154.8848    0.8271     0.0265   
   1450     1094.96    154.1025   154.2792    0.7347     0.0254   
   1500     1132.86    151.9963   152.6928    0.6254     0.0239   
   1550     1170.77    151.0761   151.266     0.6004     0.0227   
   1600     1208.62    152.1916   152.5215    0.9011     0.0215   
   1650     1246.53    150.4359   150.4527    0.6458     0.0207   
   1700     1284.43    150.5698   150.699     0.6246     0.0194   
   1750     1322.34    149.7993   150.0325    0.6841     0.0186   
   1800     1360.19    149.2393   149.2929    0.5549     0.0177   
   1850     1398.05     148.67    148.629     0.7468     0.017    
   1900     1435.96    149.0762   148.711     0.621      0.0162   
   1950     1473.83    148.8269   148.8686    0.6536     0.0153   
   2000     1511.67    148.9143   148.7709    0.4468     0.015    
