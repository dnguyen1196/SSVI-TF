Generating synthetic  count valued data ... 
Generating synthetic  count valued data took:  8.880582571029663
max_count =  16  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       225.64     3.8336     3.8612     0.3162     0.358     58955.68   47614.11     0.0    
   100       585.79     3.8634     3.8896     0.2878     0.3426    57955.32   46800.38     0.0    
   150       946.1      3.8933     3.9213     0.246      0.3139    57254.05   46228.27     0.0    
   200      1306.36     3.9202     3.9424     0.2348     0.3033    56730.17   45800.47     0.0    
   250      1666.62     3.9366     3.9606     0.2006     0.3088    56315.2    45461.36     0.0    
   300      2026.81     3.9477     3.9771     0.1954     0.3009    55975.09   45182.76     0.0    
   350      2387.29     3.9619     3.9881     0.1882     0.3051    55688.57   44947.41     0.0    
   400      2747.81     3.9779     4.0026     0.1683     0.3104    55435.49   44740.81     0.0    
   450      3108.34     3.9883     4.0152     0.1527     0.3165    55222.94   44566.38     0.0    
   500      3469.06     3.9981     4.0237     0.1482     0.3197    55042.65   44418.04     0.0    
   550      3829.86     4.0101     4.0307     0.1424     0.3275    54874.65   44279.51     0.0    
   600      4190.73     4.0185     4.0418     0.1449     0.349     54731.46   44162.15     0.0    
   650      4549.58     4.0266     4.0552     0.1369     0.3518    54587.25   44044.1      0.0    
   700      4907.43     4.0351     4.0645     0.133      0.3697    54462.63   43942.1      0.0    
   750      5265.55     4.0448     4.0749      0.13      0.3858    54349.67   43849.19     0.0    
   800      5623.76     4.056      4.0814     0.1222     0.3994    54249.51   43767.58     0.0    
   850      5981.88     4.0644     4.0891     0.1182     0.4181    54150.93   43686.9      0.0    
   900      6339.99     4.072      4.0964     0.119      0.4375    54058.99   43611.69     0.0    
   950      6697.96     4.0789     4.1064     0.1185     0.4636    53981.42   43547.94     0.0    
   1000     7055.99     4.0892     4.1163     0.1166     0.4884    53907.68   43487.91     0.0    
   1050     7413.97     4.0984     4.125      0.1193     0.5125    53838.95   43430.98     0.0    
   1100      7772.0     4.1092     4.1325     0.1073     0.5375    53777.59   43380.24     0.0    
   1150     8130.02     4.1172     4.1409     0.102      0.566     53716.35   43330.22     0.0    
   1200     8488.24     4.1279     4.1543      0.11      0.6148    53661.12   43284.63     0.0    
   1250     8846.17     4.1412     4.161      0.1052     0.6437    53604.23   43237.56     0.0    
   1300     9204.38     4.1424     4.1701     0.0929     0.6727    53554.79   43196.45     0.0    
   1350     9562.72     4.1567     4.1794     0.0999     0.7236    53509.41   43158.62     0.0    
   1400     9921.18     4.1693     4.1925     0.0906     0.7801    53465.82   43122.05     0.0    
   1450     10279.33    4.176      4.2019     0.0883     0.8603    53425.94   43088.47     0.0    
   1500     10637.64    4.1892     4.2169     0.0906     0.9087    53391.64   43059.25     0.0    
   1550     10995.65    4.2055     4.2236     0.0962     0.9861    53358.57   43030.99     0.0    
   1600     11353.39    4.2146     4.2381     0.0859     1.0744    53330.75   43007.11     0.0    
   1650     11711.62    4.2285     4.2508     0.0899     1.2062    53303.29   42983.54     0.0    
   1700     12069.44    4.2467     4.2648     0.0906     1.2679    53281.9    42964.51     0.0    
   1750     12427.3     4.2563     4.2807     0.0845     1.3918    53259.94   42945.36     0.0    
   1800     12785.05    4.2815     4.298      0.0862     1.5686    53242.96   42930.13     0.0    
   1850     13143.1     4.2939     4.3197     0.0828     1.7025    53229.23   42917.41     0.0    
   1900     13501.0     4.3175     4.3382     0.0822     1.9021    53217.5    42906.38     0.0    
   1950     13858.82    4.3397     4.3529     0.0839     2.1345    53207.81   42896.84     0.0    
   2000     14216.61    4.3603     4.3844     0.0835     2.4184    53204.27   42892.28     0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       225.15     3.8143     3.8288     0.185      0.266     59550.94   96354.86     0.0    
   100       644.95     3.8407     3.8549     0.1796     0.2207    58821.32   95157.65     0.0    
   150      1064.27     3.8582     3.8781     0.1714     0.2139    58227.98   94185.24     0.0    
   200      1483.87     3.8781     3.8959     0.1634     0.2102    57725.58   93363.22     0.0    
   250      1903.62     3.8932     3.9097     0.1571     0.2088    57311.32   92684.11     0.0    
   300      2323.35     3.9068     3.9223     0.1424     0.2135    56971.4    92125.49     0.0    
   350      2743.02     3.9195     3.9362     0.1478     0.2079    56656.57   91608.79     0.0    
   400      3162.76     3.9319     3.9476     0.1327     0.2137    56388.5    91168.4      0.0    
   450      3582.32     3.943      3.9609     0.1323     0.2129    56157.65   90788.2      0.0    
   500      4001.83     3.9526     3.9716     0.131      0.2208    55941.77   90431.98     0.0    
   550      4421.83     3.9667     3.9816     0.1259     0.2156    55762.24   90135.61     0.0    
   600      4841.55     3.9738     3.9905     0.1327     0.2217    55589.31   89850.68     0.0    
   650       5261.3     3.9763     3.9958     0.1203     0.2269    55427.63   89585.05     0.0    
   700      5680.97     3.9896     4.0035     0.1213     0.2339    55285.69   89350.85     0.0    
   750      6100.97     3.9947     4.0142     0.1173     0.2381    55150.88   89128.22     0.0    
   800      6520.78     4.0031     4.0193     0.1227     0.2476    55023.11   88917.18     0.0    
   850      6940.37     4.0132     4.0267     0.1031     0.2603    54905.74   88724.6      0.0    
   900       7359.9     4.0222     4.0343     0.1046     0.2577    54794.08   88539.44     0.0    
   950      7779.34     4.0246     4.0418     0.1006     0.2699    54698.36   88381.45     0.0    
   1000     8199.14     4.0329     4.048      0.0966     0.2744    54605.13   88228.05     0.0    
   1050     8618.93     4.0397     4.0555     0.092       0.29     54517.34   88082.68     0.0    
   1100     9038.52     4.0405     4.0618     0.0986     0.2965    54435.26   87947.17     0.0    
   1150     9458.22     4.054      4.0684     0.0925     0.3144    54357.58   87818.73     0.0    
   1200      9878.0     4.0613     4.0729     0.0979     0.3092    54284.95   87698.86     0.0    
   1250     10297.88    4.0668     4.0816     0.0986     0.3327    54214.5    87582.3      0.0    
   1300     10717.5     4.0741     4.0889     0.0906     0.3437    54143.51   87464.49     0.0    
   1350     11137.45    4.0794     4.097      0.086      0.3535    54082.98   87364.28     0.0    
   1400     11557.17    4.0871     4.1026     0.0815     0.3632    54021.88   87262.73     0.0    
   1450     11977.01    4.0922     4.1079     0.0838     0.3845    53966.62   87170.61     0.0    
   1500     12396.97    4.0991     4.1148     0.0897     0.3992    53913.08   87081.17     0.0    
   1550     12816.81    4.1038     4.123      0.0755     0.4158    53859.32   86992.22     0.0    
   1600     13236.83    4.1153     4.128      0.0774     0.4424    53811.2    86912.34     0.0    
   1650     13656.55    4.1178     4.1345     0.0752     0.4673    53768.52   86841.03     0.0    
   1700     14076.41    4.1297     4.1442     0.0753     0.473     53726.44   86771.03     0.0    
   1750     14496.31    4.135      4.1512     0.0779     0.5028    53687.88   86707.05     0.0    
   1800     14916.49    4.1407     4.1573     0.0774     0.5291    53650.82   86645.34     0.0    
   1850     15336.85    4.151      4.1641     0.0727     0.5597    53614.53   86584.81     0.0    
   1900     15757.06    4.1601     4.1752     0.0756     0.586     53577.8    86523.65     0.0    
   1950     16176.91    4.1643     4.1816     0.0734     0.6352    53547.81   86472.83     0.0    
   2000     16596.79    4.1756     4.1903      0.07      0.651     53514.85   86417.61     0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       224.62     3.808      3.8159     0.153      0.2053    59840.97  144649.18     0.0    
   100       704.17     3.8282     3.8345     0.1369     0.1823    59273.38  143263.38     0.0    
   150      1183.69     3.8444     3.8506     0.1339     0.1752    58758.48  142006.89     0.0    
   200      1663.34     3.8566     3.8681     0.1379     0.1576    58330.45  140960.83     0.0    
   250      2142.74     3.8655     3.8802     0.1333     0.3743    57958.57  140054.89     0.0    
   300      2622.28     3.8806     3.8913     0.1361     0.1521    57625.44  139244.76     0.0    
   350      3103.18     3.8931     3.9031     0.1115     0.1879    57317.92  138493.01     0.0    
   400       3582.7     3.9069     3.9137     0.1139     0.1492    57041.14  137819.06     0.0    
   450      4062.37     3.9136     3.9227     0.1229     0.1534    56788.36  137202.83     0.0    
   500      4542.12     3.9256     3.934      0.1117     0.156     56568.07  136662.92     0.0    
   550      5022.05     3.9339     3.9439     0.1016     0.1543    56353.15  136139.09     0.0    
   600      5501.75     3.9407     3.9529      0.1       0.1604    56179.5   135714.39     0.0    
   650      5981.88     3.9515     3.9579     0.0994     0.1556    56009.38  135298.35     0.0    
   700      6461.96     3.9536     3.9656     0.0957     0.1619    55852.28  134913.39     0.0    
   750       6942.0     3.9634     3.9727     0.0948     0.162     55707.71  134559.53     0.0    
   800      7422.26     3.967      3.9792     0.0954     0.1656    55573.68  134230.65     0.0    
   850      7902.52     3.9762     3.9873     0.0906     0.1747    55455.82  133942.26     0.0    
   900      8382.59     3.986      3.9951     0.0965     0.1731    55336.62  133650.19     0.0    
   950      8862.75     3.9843     3.9997     0.0895     0.1817    55225.95  133379.58     0.0    
   1000     9343.04     3.9943     4.0064     0.0905     0.186     55119.12   133118.4     0.0    
   1050     9823.23     3.9996     4.0121     0.0831     0.1873    55023.02  132882.22     0.0    
   1100     10303.57    4.0094     4.0158     0.0821     0.1954    54932.81  132662.23     0.0    
   1150     10783.66    4.0118     4.0222     0.0785     0.1937    54843.2   132442.38     0.0    
   1200     11263.8     4.0123     4.0272     0.0798      0.2      54760.88  132240.19     0.0    
   1250     11744.06    4.0212     4.0309     0.0816     0.207     54680.33  132042.78     0.0    
   1300     12224.49    4.0257     4.0362     0.0764      0.21     54606.23  131860.73     0.0    
   1350     12705.38    4.0298     4.0426     0.0798     0.2102    54534.83  131685.66     0.0    
   1400     13186.51    4.038      4.0469     0.0816     0.2236    54465.38  131516.51     0.0    
   1450     13667.57    4.0397     4.0495     0.0727     0.2312    54400.67  131358.94     0.0    
   1500     14148.51    4.0453     4.0577     0.0755     0.2375    54340.73  131212.62     0.0    
   1550     14628.81    4.0519     4.062      0.0766     0.2367    54282.66  131069.74     0.0    
   1600     15109.39    4.0569     4.0685     0.0791     0.2566    54227.97  130935.86     0.0    
   1650     15589.88    4.0628     4.0727     0.0675     0.2669    54172.12  130799.14     0.0    
   1700     16070.59    4.0649     4.0774     0.0777     0.2677    54121.0   130674.29     0.0    
   1750     16551.27    4.0696     4.0807     0.0718     0.2854    54067.96  130544.78     0.0    
   1800     17032.05    4.0786     4.0869     0.0677     0.288     54021.37  130430.54     0.0    
   1850     17512.78    4.081      4.0939     0.0649     0.3017    53972.83  130311.53     0.0    
   1900     17993.63    4.0844     4.0964     0.0752     0.3124    53930.69  130208.29     0.0    
   1950     18474.36    4.091      4.1037     0.0685     0.3172    53881.62  130088.48     0.0    
   2000     18955.67    4.0983     4.1089     0.0686     0.3301    53836.39  129977.64     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       225.52     3.7983     3.8065     0.1203     0.2555    59989.53  193495.54     0.0    
   100       767.12     3.819      3.8212     0.1336     0.1729    59481.69  191843.59     0.0    
   150      1308.68     3.8296     3.8388     0.1124     0.1483    59034.44  190387.27     0.0    
   200       1850.4     3.8417     3.8493     0.114      0.1371    58662.5   189177.05     0.0    
   250       2392.2     3.8518     3.8602     0.1113     0.1566    58330.93  188101.24     0.0    
   300      2934.25     3.8655     3.8769     0.1034      0.14     58042.39  187162.28     0.0    
   350       3476.1     3.8757     3.8851     0.1011     0.1176    57774.95  186290.87     0.0    
   400      4018.34     3.8839     3.8926     0.1074     0.1178    57527.71  185484.97     0.0    
   450      4560.56     3.8935     3.9021     0.0991     0.2054    57276.79  184668.47     0.0    
   500      5102.72     3.9018     3.9083     0.0993     0.1611    57051.29  183932.11     0.0    
   550      5645.13     3.9108     3.9198     0.0939     0.119     56860.11  183311.16     0.0    
   600      6187.37     3.9175     3.9277     0.0908     0.1242    56678.19  182718.61     0.0    
   650      6729.59     3.9284     3.9343     0.0851     0.1847    56506.57  182159.73     0.0    
   700      7271.93     3.9301     3.9409     0.0848     0.1274    56347.88   181644.1     0.0    
   750      7813.55     3.9351     3.9448     0.0847     0.1305    56204.56  181175.36     0.0    
   800       8355.3     3.9426     3.9517     0.0804     0.1275    56065.22  180721.31     0.0    
   850      8897.19     3.949      3.9592     0.0804     0.1278    55933.82  180292.71     0.0    
   900       9439.0     3.9529     3.9637     0.0788     0.1311    55812.31  179897.64     0.0    
   950      9980.83     3.9576     3.9697      0.08      0.1304    55696.57  179519.95     0.0    
   1000     10522.34    3.9663     3.975      0.0769     0.1378    55590.8   179174.44     0.0    
   1050     11064.09    3.9662     3.9788     0.0812     0.1372    55490.35  178845.26     0.0    
   1100     11605.81    3.9755     3.986      0.0741     0.1416    55387.78  178510.68     0.0    
   1150     12147.88    3.9834     3.9906     0.0788     0.1427    55285.61  178177.35     0.0    
   1200     12689.76    3.9833     3.996      0.0789     0.1469    55189.82  177865.16     0.0    
   1250     13231.99    3.9922     4.0014     0.0756     0.1463    55109.6   177602.15     0.0    
   1300     13773.75    3.9959     4.003      0.076      0.1496    55032.31  177348.99     0.0    
   1350     14314.93    4.0006     4.0084     0.0721     0.1554    54947.1   177071.75     0.0    
   1400     14856.64    4.0042     4.0162     0.0701     0.161     54872.23  176826.78     0.0    
   1450     15397.93    4.0076     4.0177     0.0729     0.1597    54797.24  176580.62     0.0    
   1500     15938.87    4.0193     4.0229     0.0717     0.1597    54730.04  176361.36     0.0    
   1550     16480.25    4.0172     4.0266     0.0673     0.171     54659.79   176131.6     0.0    
   1600     17021.49    4.0208     4.0332     0.0729     0.1711    54596.79  175925.95     0.0    
   1650     17563.84    4.026      4.0352     0.067      0.1817    54534.32  175721.74     0.0    
   1700     18105.2     4.0277      4.04      0.0675      0.18     54478.15  175538.85     0.0    
   1750     18646.62    4.0336     4.0458     0.064      0.1794    54419.17  175347.83     0.0    
   1800     19187.77    4.0414     4.0494     0.0649     0.1867    54366.41  175175.72     0.0    
   1850     19728.91    4.0422     4.0525     0.0622     0.1959    54314.37  175005.43     0.0    
   1900     20270.12    4.048      4.0574     0.0611     0.1947    54261.98  174834.25     0.0    
   1950     20811.33    4.0517     4.0614     0.0654     0.2002    54210.55  174665.74     0.0    
   2000     21352.59    4.0583     4.0647     0.066      0.2123    54165.83  174519.78     0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       224.65     3.7982     3.8078     0.1038     0.1711    60081.97  242320.17     0.0    
   100       826.19     3.8127     3.8221     0.1099     0.147     59629.85  240487.91     0.0    
   150      1427.06     3.8236     3.8342     0.0986     0.1192    59255.49   238968.4     0.0    
   200      2028.15     3.8398     3.8493     0.0981     0.1443    58920.65  237606.22     0.0    
   250       2629.4     3.8408     3.8582     0.0946     0.1209    58612.78   236351.9     0.0    
   300      3230.44     3.855      3.8689     0.0979     0.126     58318.71  235155.55     0.0    
   350      3831.33     3.8641     3.8774     0.0971     0.1378    58056.42  234090.23     0.0    
   400      4432.51     3.8703     3.8883     0.0899     0.1018    57830.74  233174.76     0.0    
   450      5033.48     3.8828     3.8974     0.0907     0.101     57608.98   232276.3     0.0    
   500      5634.97     3.8845     3.8999     0.0855     0.1617    57403.83  231442.28     0.0    
   550      6236.26     3.8969     3.9082     0.0873     0.1002    57218.37  230687.81     0.0    
   600      6837.55     3.9005     3.9136     0.0846     0.1019    57036.2   229949.76     0.0    
   650      7439.12     3.9071     3.9225     0.0829     0.1024    56878.07  229308.34     0.0    
   700      8040.82     3.919      3.9303     0.0792     0.1023    56709.21  228620.21     0.0    
   750      8642.08     3.919      3.9343     0.0831     0.1048    56560.44  228011.97     0.0    
   800      9243.75     3.9277     3.941      0.079      0.1053    56422.61  227449.94     0.0    
   850      9845.36     3.9306     3.9475     0.0796     0.1082    56292.33  226920.73     0.0    
   900      10446.92    3.938      3.9513     0.0766     0.1067    56176.13   226446.8     0.0    
   950      11048.11    3.9403     3.9588     0.0708     0.1105    56055.0   225953.38     0.0    
   1000     11649.53    3.9472     3.9632     0.0765     0.1094    55947.11  225511.76     0.0    
   1050     12250.79    3.9529     3.9692     0.0727     0.1103    55837.94  225064.98     0.0    
   1100     12852.18    3.9612     3.9726     0.0696     0.1125    55737.26  224653.24     0.0    
   1150     13454.28    3.9682     3.9776     0.0665     0.1143    55638.67  224248.83     0.0    
   1200     14056.46    3.9694     3.9822     0.0702     0.1154    55549.1   223882.66     0.0    
   1250     14658.45    3.975      3.9863     0.0643     0.1171    55458.88  223513.31     0.0    
   1300     15260.28    3.9824     3.9915     0.0687     0.1193    55376.89  223178.64     0.0    
   1350     15861.62    3.9798     3.9959     0.0677     0.1202    55297.6   222856.36     0.0    
   1400     16463.15    3.9886     4.0002     0.0626     0.1258    55217.44   222528.6     0.0    
   1450     17064.79    3.9905     4.0036     0.0622     0.1239    55144.08   222230.0     0.0    
   1500     17667.04    3.9941     4.0082     0.0631     0.1277    55071.9   221936.27     0.0    
   1550     18268.66    3.9976     4.0123     0.0611     0.1309    55006.47  221669.51     0.0    
   1600     18870.26    4.0026     4.0158     0.0612     0.1436    54939.29  221395.84     0.0    
   1650     19472.58    4.0094     4.0208     0.0662     0.1348    54876.47  221139.53     0.0    
   1700     20074.31    4.0083     4.0243     0.0643     0.1377    54816.26  220893.77     0.0    
   1750     20676.29    4.0137     4.0269     0.0614     0.1393    54760.63  220666.08     0.0    
   1800     21277.88    4.0163     4.0302     0.0763     0.1429    54706.92  220448.15     0.0    
   1850     21879.41    4.0191     4.0355     0.0618     0.146     54650.22   220215.1     0.0    
   1900     22481.07    4.0259     4.0383     0.0557     0.1477    54591.19  219973.89     0.0    
   1950     23086.13    4.0271     4.0412     0.0673     0.149     54537.93   219756.4     0.0    
   2000     23688.07    4.0334     4.0465     0.0578     0.1543    54487.91  219552.56     0.0    
