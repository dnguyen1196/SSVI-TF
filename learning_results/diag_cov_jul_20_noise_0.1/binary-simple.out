Generating synthetic binary valued data ... 
Generating synthetic  binary valued data took:  6.801523208618164
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       80.94      0.7491     0.7279     3.1254     0.7039      0.0    
   200       217.61     0.7172     0.6928     2.913      0.2231      0.0    
   300       354.76     0.7096     0.6893     2.8772     0.1516      0.0    
   400       492.14     0.7171     0.7067     3.0002     0.1079      0.0    
   500       627.64     0.7227     0.6991     2.9294     0.0867      0.0    
   600       762.24     0.7104     0.685      2.7163     0.0847      0.0    
   700       894.48     0.7061     0.6859     2.6029     0.0701      0.0    
   800      1025.68     0.7097     0.693      2.5345     0.0696      0.0    
   900      1156.77     0.7165     0.7041     2.6589     0.0655      0.0    
   1000     1287.68     0.7176     0.705      2.6494     0.0981      0.0    
   1100     1418.59     0.7168     0.6924     2.6097     0.0911      0.0    
   1200     1550.47     0.7178     0.7043     2.3393     0.0584      0.0    
   1300     1682.73     0.7188     0.6933     2.5673     0.0781      0.0    
   1400     1814.62     0.7223     0.6956     2.5092     0.0751      0.0    
   1500     1946.43     0.7207     0.6983     2.0933     0.0628      0.0    
   1600     2078.37     0.7196     0.7007     2.2912     0.052       0.0    
   1700     2210.23     0.7174     0.7046     1.9639     0.0576      0.0    
   1800     2342.08     0.7177     0.704      1.9892     0.0531      0.0    
   1900     2473.78     0.7174     0.7065     2.3323     0.0736      0.0    
   2000     2606.15     0.7172     0.7011     1.8764     0.0382      0.0    
   2100     2738.29     0.7161     0.7033     1.8934     0.0537      0.0    
   2200     2870.26     0.7155     0.7017     1.8526     0.0331      0.0    
   2300      3002.0     0.7176     0.7063     2.1434     0.0341      0.0    
   2400     3133.59     0.7163     0.7055     1.8504     0.0477      0.0    
   2500     3265.15     0.7165     0.7011     2.2019     0.0313      0.0    
   2600      3396.9     0.7167     0.6974     1.666      0.0361      0.0    
   2700     3529.09     0.7174     0.7013     1.5314     0.0368      0.0    
   2800     3660.77     0.7173     0.7006     1.7475     0.0453      0.0    
   2900     3792.89     0.718      0.7007     1.6704     0.0226      0.0    
   3000     3924.81     0.7164     0.7047     1.8263     0.0183      0.0    
   3100     4056.33     0.7172     0.7029     1.7102     0.026       0.0    
   3200     4188.25     0.7168     0.701      1.5297     0.0242      0.0    
   3300     4320.13     0.717      0.7034     1.504      0.026       0.0    
   3400     4452.36     0.7169     0.6963     1.4124     0.0219      0.0    
   3500      4584.3     0.7181     0.6999     1.7907     0.0309      0.0    
   3600     4715.89     0.7164     0.6994     1.613      0.0373      0.0    
   3700     4847.44     0.7158     0.6991     1.4664     0.0202      0.0    
   3800     4979.09     0.7167     0.6997     1.4274     0.0288      0.0    
   3900     5110.53     0.7174     0.7009     1.5413     0.0226      0.0    
   4000     5241.77     0.7173      0.7       1.6613     0.0249      0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       80.09      1.4187     1.4151     0.0015     0.2037      0.0    
   200       238.2      1.4118     1.417      0.001      0.1342      0.0    
   300       396.23     1.4161     1.4138     0.0009     0.1076      0.0    
   400       553.82     1.4147     1.4168     0.0011     0.0919      0.0    
   500       711.36     1.4122     1.4157     0.0019     0.0825      0.0    
   600       869.02     1.4063     1.4125     0.0009     0.0764      0.0    
   700      1026.26     1.4121     1.4138     0.0008     0.0711      0.0    
   800      1183.92     1.4104     1.4164     0.0008     0.0665      0.0    
   900      1341.11     1.4149     1.4207     0.0009     0.062       0.0    
   1000     1498.26     1.4212     1.4164     0.0007     0.058       0.0    
   1100     1655.22     1.4083     1.4203     0.0006     0.0538      0.0    
   1200     1812.28     1.4166     1.4188     0.0009     0.0506      0.0    
   1300     1970.51     1.4134     1.4133     0.0009     0.0469      0.0    
   1400     2129.79     1.4106     1.4136     0.0009     0.0442      0.0    
   1500      2289.3     1.4055     1.4132     0.0007     0.0414      0.0    
   1600     2448.72     1.417      1.4196     0.0008     0.0385      0.0    
   1700     2608.28     1.418      1.4095     0.0006     0.0362      0.0    
   1800     2767.31     1.4175     1.4104     0.0009     0.0343      0.0    
   1900     2926.79     1.4137     1.4125     0.0008     0.0318      0.0    
   2000     3086.03     1.4199     1.4185     0.0006      0.03       0.0    
   2100     3245.45     1.413      1.4133     0.0007     0.0283      0.0    
   2200     3405.07     1.416      1.4139     0.0006     0.0268      0.0    
   2300     3564.78     1.4075     1.4146     0.001      0.0253      0.0    
   2400     3724.45     1.4142     1.4158     0.0007     0.024       0.0    
   2500     3884.18     1.4173     1.4163     0.0007     0.0229      0.0    
   2600     4044.08     1.4164     1.4142     0.0006     0.0218      0.0    
   2700     4203.83     1.4153     1.4194     0.0005     0.0206      0.0    
   2800     4363.95     1.4061     1.4235     0.0006     0.0198      0.0    
   2900     4523.59     1.4177     1.4112     0.0006     0.0189      0.0    
   3000     4683.55     1.4129     1.415      0.0012     0.0181      0.0    
   3100     4843.19     1.4192     1.415      0.0007     0.0173      0.0    
   3200     5002.67     1.4168     1.415      0.0006     0.0167      0.0    
   3300     5162.24     1.4149     1.4159     0.0006     0.0161      0.0    
   3400     5321.69     1.4099     1.4137     0.0006     0.0154      0.0    
   3500     5481.09     1.4169     1.4103     0.0011     0.0146      0.0    
   3600     5640.79     1.4197     1.4121     0.0008     0.0141      0.0    
   3700     5800.24     1.4164     1.4147     0.0006     0.0136      0.0    
   3800     5960.24     1.4109     1.4174     0.0007     0.0133      0.0    
   3900     6119.83     1.408      1.4139     0.001      0.0125      0.0    
   4000     6279.59     1.4112     1.415      0.0007     0.0122      0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       81.18      1.4125     1.4186     0.0023     0.1879      0.0    
   200       266.15     1.4157     1.416      0.0016     0.1509      0.0    
   300       451.01     1.4115     1.4112     0.0017     0.1311      0.0    
   400       634.95     1.4155     1.4112     0.0015     0.1146      0.0    
   500       818.16     1.4108     1.4117     0.0017     0.1021      0.0    
   600      1001.65     1.4146     1.4162     0.001      0.0927      0.0    
   700      1184.62     1.421      1.4136     0.0013     0.0845      0.0    
   800      1367.62     1.4146     1.4105     0.001      0.0766      0.0    
   900      1551.38     1.4173     1.4165     0.0012     0.0698      0.0    
   1000     1735.23     1.4164     1.4143     0.0013     0.0625      0.0    
   1100     1918.64     1.411      1.4113     0.0008     0.0568      0.0    
   1200     2101.71     1.4089     1.4112     0.0008     0.0514      0.0    
   1300      2285.4     1.4077     1.4131     0.0009     0.0472      0.0    
   1400      2468.7     1.4119     1.4134     0.0007     0.043       0.0    
   1500     2648.89     1.4063     1.4133     0.0008     0.0393      0.0    
   1600     2828.33     1.4092     1.4128     0.0009     0.0363      0.0    
   1700     3007.82     1.4124     1.4125     0.001      0.0337      0.0    
   1800     3187.24     1.4114      1.41      0.0008     0.0315      0.0    
   1900      3366.7      1.41      1.4144     0.0008     0.0293      0.0    
   2000      3546.1     1.4179     1.4122     0.001      0.0272      0.0    
   2100     3725.53     1.4041     1.4118     0.0011     0.0256      0.0    
   2200      3905.0     1.4058     1.4135     0.0011     0.0242      0.0    
   2300     4084.34     1.417      1.4153     0.0015     0.0226      0.0    
   2400     4263.68     1.4089     1.4154     0.0009     0.0211      0.0    
   2500     4443.56     1.416      1.4129     0.0008     0.0201      0.0    
   2600     4623.76     1.4123     1.4097     0.0007     0.0189      0.0    
   2700     4803.79     1.4141     1.4142     0.001      0.0181      0.0    
   2800     4983.76     1.4125     1.4105     0.0006     0.017       0.0    
   2900     5163.79     1.4174     1.4091     0.001      0.016       0.0    
   3000     5343.52     1.418      1.4105     0.0008     0.0154      0.0    
   3100     5523.31     1.4279     1.4126     0.0008     0.0147      0.0    
   3200     5703.42     1.4077     1.4204     0.0006     0.0141      0.0    
   3300     5883.55     1.421      1.415      0.0008     0.0133      0.0    
   3400      6063.6     1.4186     1.4105     0.001      0.0127      0.0    
   3500     6243.82     1.4162     1.4148     0.001      0.0122      0.0    
   3600     6424.13     1.4156     1.4126     0.0008     0.0117      0.0    
   3700     6604.89     1.4125     1.4128     0.0008     0.0111      0.0    
   3800     6786.54     1.4136     1.4101     0.0009     0.0106      0.0    
   3900     6967.04     1.4142     1.4104     0.0007     0.0102      0.0    
   4000     7150.26     1.4105     1.4133     0.0009     0.0098      0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       79.39      1.4129     1.4148     0.0024     0.2068      0.0    
   200       282.4      1.4079     1.4127     0.0022     0.1694      0.0    
   300       485.16     1.4128     1.416      0.003      0.1478      0.0    
   400       687.55     1.4195     1.4142     0.0018     0.1294      0.0    
   500       889.83     1.4156     1.4153     0.0014     0.1147      0.0    
   600      1092.03      1.41      1.4091     0.0017     0.1013      0.0    
   700      1296.51     1.4071     1.4147     0.001      0.0894      0.0    
   800      1502.35     1.4153     1.4109     0.0012     0.0791      0.0    
   900      1707.86     1.4126     1.4138     0.001      0.0702      0.0    
   1000     1914.73     1.4201     1.4148     0.0014     0.0623      0.0    
   1100     2122.69     1.4156     1.4169     0.0011     0.0552      0.0    
   1200     2328.04     1.4135     1.4112     0.001      0.0497      0.0    
   1300     2532.49     1.4058     1.4101     0.0012     0.0448      0.0    
   1400     2738.34     1.4187     1.4214     0.0013     0.0408      0.0    
   1500     2943.33     1.4117     1.4157     0.0009     0.0372      0.0    
   1600     3147.43     1.4172     1.4132     0.0012     0.0343      0.0    
   1700     3352.21     1.4148     1.4173     0.0011     0.0314      0.0    
   1800      3556.5     1.4132     1.4147     0.0008     0.029       0.0    
   1900     3761.04     1.4188     1.4151     0.0009     0.0268      0.0    
   2000      3965.4     1.4149     1.4183     0.0009     0.0251      0.0    
   2100      4169.2     1.4142     1.4158     0.0014     0.0231      0.0    
   2200     4374.08     1.4162     1.4134     0.001      0.0214      0.0    
   2300     4578.28     1.4079     1.4194     0.001      0.0202      0.0    
   2400     4782.84     1.4153     1.4185     0.0009     0.0188      0.0    
   2500     4986.91     1.4194     1.4164     0.0011     0.0175      0.0    
   2600     5191.38     1.4214     1.415      0.0009     0.0165      0.0    
   2700      5395.7     1.4151     1.4148     0.0008     0.0158      0.0    
   2800     5600.37     1.4091     1.4173     0.0011     0.0148      0.0    
   2900     5804.73     1.4168     1.4141     0.0008     0.0141      0.0    
   3000     6009.54     1.4214      1.42      0.001      0.0133      0.0    
   3100     6215.53     1.413      1.4122     0.001      0.0126      0.0    
   3200     6421.22     1.4125     1.4159     0.0009     0.0119      0.0    
   3300     6628.16     1.4164     1.4148     0.0011     0.0114      0.0    
   3400     6835.54     1.4156     1.4161     0.0008     0.011       0.0    
   3500     7042.35     1.4193     1.4146     0.0008     0.0106      0.0    
   3600     7250.16      1.42      1.4104     0.0009      0.01       0.0    
   3700     7458.85     1.4123     1.4198     0.0011     0.0098      0.0    
   3800     7668.73     1.4148     1.4138     0.001      0.0092      0.0    
   3900     7878.02     1.4108     1.4138     0.001      0.0089      0.0    
   4000     8084.54     1.4208     1.4122     0.0012     0.0085      0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       81.35      1.4134     1.4156     0.0022     0.2215      0.0    
   200       313.51     1.4135     1.4145     0.0035     0.1848      0.0    
   300       547.8      1.4179      1.41      0.0031     0.1597      0.0    
   400       784.38     1.4156     1.4161     0.0027     0.1384      0.0    
   500      1028.62     1.4147     1.4107     0.0017     0.1207      0.0    
   600      1263.32     1.4103     1.4117     0.0015     0.1052      0.0    
   700      1496.43     1.4124     1.4151     0.0024     0.0909      0.0    
   800      1729.58     1.4124     1.4125     0.0013     0.0792      0.0    
   900      1963.15     1.419      1.4146     0.0023     0.0688      0.0    
   1000     2194.52     1.4098     1.4183     0.0012     0.0606      0.0    
   1100     2429.24     1.4127     1.4105     0.0013     0.0536      0.0    
   1200     2656.01     1.4182     1.4129     0.0011     0.048       0.0    
   1300     2878.96     1.4175     1.4166     0.0014     0.043       0.0    
   1400     3100.17     1.4138     1.4119     0.0012     0.0385      0.0    
   1500     3321.13     1.4067     1.4172     0.0012     0.0352      0.0    
   1600     3542.29     1.4126     1.4166     0.0011     0.0318      0.0    
   1700     3761.53     1.4143     1.4174     0.0019     0.0292      0.0    
   1800     3980.42     1.4165     1.4165     0.0009     0.0269      0.0    
   1900     4199.42     1.4184     1.4152     0.0009     0.0247      0.0    
   2000     4420.16     1.4119     1.4146     0.001      0.0225      0.0    
   2100      4643.4     1.4164     1.4141     0.001      0.0212      0.0    
   2200     4867.44     1.4178     1.4092     0.0008     0.0196      0.0    
   2300     5091.02     1.4117     1.414      0.0011     0.0182      0.0    
   2400     5315.77     1.4079     1.4137     0.0008     0.0171      0.0    
   2500     5544.67     1.424      1.4138     0.0009     0.0161      0.0    
   2600     5773.89     1.4214     1.4153     0.0009     0.015       0.0    
   2700     6002.88     1.4146     1.4136     0.0014     0.0139      0.0    
   2800     6231.86     1.4187     1.416      0.0011     0.0133      0.0    
   2900     6460.78     1.4124     1.4147     0.0012     0.0127      0.0    
   3000     6689.65     1.424      1.4152     0.0011     0.012       0.0    
   3100      6918.5      1.41      1.4123     0.0011     0.0113      0.0    
   3200     7147.41     1.4192     1.4133     0.0009     0.0109      0.0    
   3300     7376.35     1.4213     1.4148     0.0009     0.0104      0.0    
   3400     7605.31     1.4168     1.4131     0.0012     0.0098      0.0    
   3500      7835.1     1.4164     1.4125     0.0009     0.0095      0.0    
   3600     8064.56     1.4108     1.4139     0.0015     0.009       0.0    
   3700     8293.71     1.4131     1.4161     0.001      0.0087      0.0    
   3800     8522.83     1.4074     1.4181     0.0011     0.0084      0.0    
   3900     8751.97     1.4196     1.4129     0.0011     0.008       0.0    
   4000     8981.09     1.4135     1.4107     0.0012     0.0078      0.0    
