Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  7.02823281288147
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       58.91     265.4223   265.328     3.1621     0.6922   
   200       118.54    239.3355   239.3432    2.8728     0.2336   
   300       178.17    234.1321   233.2202    1.7908     0.1228   
   400       237.8     234.0234   232.7778    2.2758     0.0799   
   500       297.43    233.4481   232.3188    1.6394     0.0548   
   600       357.06    231.5663   230.9527    1.6007     0.0416   
   700       416.66    230.4142   230.9115    1.6949     0.0319   
   800       476.29    231.7971   230.8772    1.4642     0.0265   
   900       535.91    231.9621   232.0095    1.4973     0.0216   
   1000      595.53    230.2556   230.3587    1.3901     0.0181   
   1100      655.14    229.5838   230.0622    1.4327     0.0159   
   1200      714.76    230.9072   230.6963    1.447      0.0135   
   1300      774.38    230.5164   229.7747    1.1573     0.012    
   1400      834.0     230.5577   230.4702    1.0594     0.0105   
   1500      893.62    229.7529   229.5189    1.2809     0.0095   
   1600      953.24    228.9606   229.7922    1.3261     0.0087   
   1700     1012.87    229.4463   229.5324    0.9964     0.0077   
   1800     1072.51    229.1804   229.3704    1.1223     0.0071   
   1900     1132.12    229.3972   229.5319     1.14      0.0066   
   2000     1191.75    228.3842   228.9016    1.1188     0.006    
   2100     1251.38    229.5861   229.4639    1.0402     0.0056   
   2200     1311.01    228.8531   228.8655    0.8326     0.0051   
   2300     1370.61    228.5916   229.5175    1.187      0.0048   
   2400     1430.24    229.3117   229.2422    1.1433     0.0046   
   2500     1489.86    228.3748   228.6909    1.2669     0.0042   
   2600     1549.49    228.6532   228.7278    1.0473     0.004    
   2700     1609.12    228.9422   228.8504    0.8349     0.0038   
   2800     1668.75    228.773    228.7285    0.9362     0.0037   
   2900     1728.38    228.8242   228.9269    0.9148     0.0034   
   3000     1787.99    229.2873   229.1972    0.9166     0.0032   
   3100     1847.61    229.3819   229.0669    1.0338     0.0031   
   3200     1907.25    228.3895   228.4017    0.8091     0.0029   
   3300     1966.85    228.163    228.7698    1.0814     0.0028   
   3400     2026.49    227.9987   228.2272    0.6952     0.0027   
   3500     2086.11    228.6155   228.4924    1.175      0.0025   
   3600     2145.73    228.3446   228.1979    0.9683     0.0024   
   3700     2205.35    228.8496   229.1582    1.1066     0.0023   
   3800     2264.98    228.7896   228.6643    0.9406     0.0022   
   3900      2324.6    228.3994   228.5485    0.7941     0.0021   
   4000     2384.22    228.3956   228.3339    1.0989     0.002    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100        59.2     249.1352   248.4949    2.7015     0.5988   
   200       119.71    237.0731   236.2788    1.9075     0.3176   
   300       180.22    231.0192   231.4951    1.4153     0.2047   
   400       240.76    230.3811   230.9125    1.6302     0.1412   
   500       301.31    231.0974   231.3608    1.4135     0.1052   
   600       361.82    230.0826   230.7085    1.855      0.0794   
   700       422.36    230.5787   231.2559    1.445      0.0637   
   800       482.9     230.9445   231.1108    1.6914     0.0531   
   900       543.44    229.5799   230.0766    1.4692     0.0434   
   1000      603.98    230.0835   230.7941    1.2562     0.0365   
   1100      664.51    229.3916   230.2164    1.3481     0.0319   
   1200      725.02    229.3531   230.0221    1.3385     0.0273   
   1300      785.54    230.1988   230.0789    1.2928     0.0241   
   1400      846.1     229.3891   229.3479    1.3188     0.0212   
   1500      906.65    229.6144   229.3394    0.8603     0.0194   
   1600      967.19    229.0916   229.1964    0.911      0.0173   
   1700     1027.74    228.6514   229.5371    1.3872     0.0153   
   1800     1088.28    229.0989   229.4381    0.9863     0.0139   
   1900     1148.81    229.2881   229.672     1.1021     0.0128   
   2000     1209.33    230.0074   229.867     1.4271     0.0119   
   2100     1269.85    228.8665   229.2382    0.7853     0.0107   
   2200      1330.4    229.1602   229.2901    0.9887     0.0099   
   2300     1390.94    229.0058   229.3339    0.826      0.0092   
   2400     1451.47    229.6209   229.3658    1.1773     0.0085   
   2500     1512.01    228.574    229.3128    1.0947     0.0078   
   2600     1572.56    229.0534   229.1244    0.7916     0.0074   
   2700      1633.1    228.9075   229.3536    0.8683     0.0069   
   2800     1693.62    229.5527   229.4616    0.9572     0.0065   
   2900     1754.18    228.8833   229.2464    1.0906     0.0061   
   3000      1814.9    228.3863   228.6322    0.7673     0.0058   
   3100     1875.63    228.5883   229.2668    0.804      0.0055   
   3200     1936.35    228.7013   228.5622    0.9071     0.005    
   3300     1997.08    229.1884   229.648     1.0563     0.0049   
   3400     2057.79    228.7455   229.7907    1.0882     0.0047   
   3500     2118.51    228.4417   229.1331    0.7577     0.0046   
   3600     2179.22    228.2204   228.5288    0.7537     0.0041   
   3700     2239.94    228.3217   228.6302    1.0262     0.004    
   3800     2300.68    228.7006   229.3225    0.7224     0.0037   
   3900     2361.38    228.8333   229.0617    0.7667     0.0037   
   4000     2422.07    228.0586   228.4385    0.849      0.0034   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       59.22     249.878    249.0502    2.5549     0.4754   
   200       120.31    231.9678   232.1709    1.6416     0.3047   
   300       181.3     229.6768   229.9423    1.3064     0.2096   
   400       242.38    230.1511   230.6117    1.3405     0.1523   
   500       303.47    228.8271   229.3963    1.1141     0.1176   
   600       364.49    229.5303   229.5126    0.9245     0.0904   
   700       425.54    229.4673   229.4436    1.1434     0.075    
   800       485.89    229.396    229.4396    1.353      0.0643   
   900       546.13    229.4698   230.433     1.055      0.0512   
   1000      606.37    228.6289   229.1026    1.4875     0.0441   
   1100      666.62    228.8713   229.4458    0.8414     0.0387   
   1200      726.86    228.4893   228.8134    0.872      0.0334   
   1300      787.09    228.7193   229.2017    1.1275     0.0297   
   1400      847.34    228.0292   228.7232    0.9042     0.0264   
   1500      907.58    228.8054   229.1462    1.1662     0.0239   
   1600      967.79    228.1005   229.0791    0.8575     0.0209   
   1700     1028.02    228.5758   228.8886    0.7351     0.019    
   1800     1088.27    228.7776   229.6246    1.0773     0.0173   
   1900      1148.5    228.0687   228.6458    0.7478     0.0159   
   2000     1208.73    228.3645   228.5628    1.0542     0.0152   
   2100     1268.97    228.393    228.9685    1.1281     0.0134   
   2200      1329.2    228.2504   228.6797    0.8492     0.0124   
   2300     1389.44    229.1397   229.1359    0.8244     0.0117   
   2400     1449.68    228.6125   228.3072    1.225      0.0106   
   2500     1509.91    227.4361   228.0956    0.859      0.0102   
   2600     1570.22    228.4364   229.0333    1.1012     0.0092   
   2700     1630.55    228.187    228.9754    0.8923     0.0088   
   2800     1690.95    227.3864   228.0269    0.7962     0.0084   
   2900     1751.47    228.0748   228.7232    0.8856     0.0081   
   3000     1811.96    228.2891   229.0573    0.9853     0.0074   
   3100     1872.49    228.0126   228.4345    0.8203     0.007    
   3200     1932.95    228.336    228.4604    0.737      0.0067   
   3300     1993.47    228.0585   228.2389    0.8777     0.0062   
   3400     2053.92    228.4986   228.479     0.8788     0.0058   
   3500     2114.45    228.647    228.792     0.729      0.0056   
   3600     2174.92    227.4432   228.2892    0.7339     0.0054   
   3700     2235.47    227.2511   228.5225    0.883      0.0051   
   3800     2295.96    228.1679   228.3688    0.709      0.0048   
   3900     2356.43    227.7392   227.7828    0.9116     0.0046   
   4000     2416.85    227.5515   227.9969    0.6733     0.0045   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       58.76     254.6841   254.1626    2.4048     0.4205   
   200       119.86    232.9852   233.7843    0.9377     0.2847   
   300       180.92    229.6773   230.6394    1.3716     0.2003   
   400       242.03    228.7673   229.9227    1.0584     0.1555   
   500       303.09    228.5232   229.2517    0.9192     0.1183   
   600       364.24    227.9808   228.7105    0.8778     0.0973   
   700       425.39    228.7541   229.7742    0.9449     0.0792   
   800       486.45    228.5421   229.2326    0.6099     0.0679   
   900       547.55    228.5211   228.956     1.0234     0.058    
   1000      608.63    228.0872   229.012     0.9818     0.0497   
   1100      669.78    227.8658   228.9609    1.157      0.0425   
   1200      731.0     227.9758   229.1813    0.7411     0.0375   
   1300      792.16    227.438    228.6196    1.0828     0.0343   
   1400      853.3     227.6826   228.4905    0.9439     0.0292   
   1500      914.52    227.9894   229.1832    0.8689     0.027    
   1600      975.65    228.7544   229.4391    1.1205     0.024    
   1700     1036.79    228.4431   229.1401    0.8097     0.022    
   1800     1097.91    228.3547   229.2327    0.7736     0.0202   
   1900     1159.09     229.06    229.319     0.8649     0.0184   
   2000     1220.31    227.9908   228.8118    1.0867     0.0167   
   2100     1281.57    227.5198   228.6643    0.8984     0.0156   
   2200     1342.61    227.3648   228.7509    0.9707     0.0144   
   2300      1403.7    228.2933   229.2766    0.6982     0.0133   
   2400     1464.92    227.6139   228.4922    0.8024     0.0125   
   2500     1526.13    227.3244   228.4138    0.6725     0.012    
   2600     1587.28    227.6503   228.6459    0.8547     0.0108   
   2700     1648.37    227.2735   228.3343    0.5934     0.0101   
   2800     1709.53    227.4163   228.3614    0.7343     0.0095   
   2900     1770.66    228.5543   228.8968    0.9099     0.009    
   3000     1831.72    227.4201   228.2598    0.6717     0.0084   
   3100     1892.92    227.7438   228.8214    0.909      0.0081   
   3200     1954.08    228.0732   228.8804    0.9474     0.0075   
   3300     2015.36    227.5183   228.4787    0.594      0.0072   
   3400     2076.43     228.3     228.8207    0.7605     0.007    
   3500     2137.53    227.4443    228.41     0.7022     0.0065   
   3600     2198.73    227.3311   228.6064    0.6944     0.0062   
   3700     2259.85    227.2694   228.197     0.7382     0.006    
   3800     2320.91    227.494    228.3475    0.7252     0.0056   
   3900     2382.01    227.9264   228.7425    0.5983     0.0054   
   4000     2443.12    227.3318   228.562     0.7077     0.0051   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       58.84     259.6195   259.3365    2.0398     0.3741   
   200       120.71    234.4796   234.732     0.7741     0.2612   
   300       182.57    230.5171   230.5883    1.1229     0.1959   
   400       244.4     228.9235   229.0941    0.7354     0.153    
   500       306.24    228.2983   228.8591    0.8335     0.1211   
   600       368.07    228.3308   228.9656    1.4435     0.1008   
   700       429.87    228.0342   228.6028    0.8861     0.082    
   800       491.79    227.8329   228.2465    0.886      0.0694   
   900       553.69    227.2314   228.2227    1.2305     0.0615   
   1000      615.74    227.6844   228.6783    0.8102     0.053    
   1100      677.58    227.7445   228.2779    0.6596     0.0478   
   1200      739.44    227.8187    228.39     0.8616     0.0404   
   1300      801.29    227.6312   228.4575    0.7374     0.0368   
   1400      863.18    227.7061   228.4887    0.7515     0.0318   
   1500      925.05    228.1914   228.855     0.7379     0.0293   
   1600      986.98    227.9327   228.7495    0.8162     0.0258   
   1700     1048.81    227.2962   228.1732    0.6946     0.024    
   1800     1110.63    227.5354   228.1866    0.4858     0.0223   
   1900     1172.43    228.1405   228.7146    0.8332     0.0201   
   2000     1234.29    227.834    228.173     0.8212     0.0187   
   2100     1296.04    227.6018   228.3795    0.7236     0.0175   
   2200     1357.82    227.5446   228.2309    0.7727     0.0162   
   2300      1419.7    227.0656   228.2411    0.8427     0.0148   
   2400     1481.19    227.3407   228.3649    1.0196     0.0136   
   2500     1542.64    227.539    228.1185    0.6928     0.0128   
   2600     1604.16    227.7201   228.1334    0.6007     0.0122   
   2700     1665.64    227.5326   228.3761    0.7787     0.0115   
   2800     1727.12    227.5733   228.3285    0.9819     0.0109   
   2900     1788.61    227.8308   228.2964    0.7933     0.0103   
   3000     1850.13    227.9165   228.6408    0.6976     0.0098   
   3100     1911.65    227.9817   228.5477    0.6826     0.0091   
   3200     1973.13    227.4308   228.0613    0.8272     0.0085   
   3300     2034.63    227.596    228.3244    0.6778     0.008    
   3400     2096.09    227.0065   227.8568    0.6294     0.0078   
   3500     2157.53    227.2962   227.9793    0.7916     0.0073   
   3600     2219.02    227.5222   228.2693    0.9207     0.0069   
   3700      2280.5    227.4045   227.9696    0.537      0.0067   
   3800     2341.96    227.3776   227.9804    0.9487     0.0064   
   3900     2403.48    227.7475   228.1087    0.6457     0.0061   
   4000      2465.0    227.2824   227.9796    0.7082     0.0059   
