Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  8.22786569595337
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       230.73    539.5644   541.1073    3.1621     0.3098   
   200       468.08    524.578    525.5614    2.9157     0.1312   
   300       705.03    523.6482   522.459      2.51      0.0499   
   400       941.59    522.0091   521.1829    2.5187     0.042    
   500      1178.08    523.5118   521.9098    2.2483     0.0183   
   600      1414.57    521.0866   520.1487    2.0776     0.0158   
   700      1650.94    518.9394   520.5468    1.9435     0.0076   
   800      1888.47    521.1817   520.198     1.9267     0.0089   
   900      2125.33    519.9232   520.3593    2.5058     0.0048   
   1000     2361.22    518.5184   518.9539    1.7535     0.0047   
   1100     2597.29    518.5656   519.1908    1.6727     0.0026   
   1200      2833.3    518.812    518.848     1.5657     0.003    
   1300     3069.91    519.2427   518.4267    1.6979     0.0021   
   1400     3305.59    519.3306   519.618     1.264      0.0024   
   1500     3543.42    517.3386   518.1204    1.515      0.0025   
   1600     3778.93    516.7019   518.4039    1.6909     0.0019   
   1700     4014.98    517.8463   518.1613    1.1516     0.0018   
   1800     4251.39    516.9347   517.8623    1.2383     0.0016   
   1900     4487.82    516.7945   517.9029    1.5132     0.0019   
   2000     4724.94    516.5503   517.4871    1.4461     0.0011   
   2100     4959.21    517.9187   518.4639    1.5555     0.0013   
   2200     5196.79    516.8147   517.3466    1.2004     0.001    
   2300     5432.81    515.7795   517.7709    1.5198     0.0008   
   2400     5667.73    517.3754   517.6576    1.3535     0.0009   
   2500     5904.67    516.0906   516.9929    1.4294     0.0008   
   2600     6142.04    516.5684   517.2077    1.231      0.0008   
   2700     6378.32    516.9902   517.3215    1.1255     0.0007   
   2800     6615.32    516.2431   516.9904    0.9301     0.0006   
   2900      6851.8    516.414    517.6895    1.4479     0.0007   
   3000     7088.26    516.9772   517.3889    1.2249     0.0005   
   3100     7324.43    517.5994   517.5979    1.4007     0.0007   
   3200     7561.09    516.1646   516.6898    1.0219     0.0005   
   3300     7797.99    515.8048   517.0047    1.0946     0.0005   
   3400     8035.22    516.2514   516.9734    1.262      0.0005   
   3500     8270.26    516.7703   517.1476    1.2156     0.0005   
   3600     8505.84    516.2971   516.5581    1.1145     0.0005   
   3700     8742.02    516.4308   517.3673    1.3916     0.0004   
   3800     8977.36    516.4065   517.0276    1.0549     0.0004   
   3900     9213.14    516.7003   516.9081    1.033      0.0004   
   4000     9448.78    516.3581   516.7945    1.1574     0.0003   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       230.03    526.7049   527.0831    2.4938     0.3484   
   200       468.43    519.3927   521.315     1.9796     0.0864   
   300       706.52    519.0208   520.7781    2.0875     0.0343   
   400       944.11    517.1673   519.257     1.6534     0.0184   
   500      1183.14    517.9389   519.7746    1.6969     0.0116   
   600      1420.04    516.8013   519.0324    1.5231     0.0078   
   700       1657.0    517.5984   520.4847    1.7013     0.0066   
   800      1893.82    518.1008   519.7456    1.4574     0.0052   
   900      2131.47    517.2319   519.1373    1.8478     0.0041   
   1000     2368.47    517.0385   519.5125    1.4245     0.0032   
   1100     2604.69    516.223    518.6985    1.3273     0.0023   
   1200     2841.04    516.4195   518.5072    1.7828     0.0024   
   1300     3078.05    517.833     518.94     1.4926     0.002    
   1400     3313.94    516.982    518.4259    1.7073     0.0015   
   1500     3551.61     517.85    518.225     1.1685     0.0014   
   1600     3788.08    517.2249   518.5329    1.132      0.0012   
   1700      4024.8    515.9546   518.3804    1.2811     0.0012   
   1800     4260.63    517.0166   518.6696    1.2794     0.0011   
   1900     4495.61    517.2609   518.5604    1.476      0.001    
   2000     4732.27    517.3686   518.8306    1.4387     0.0009   
   2100     4969.42    516.6566   518.5105    1.1091     0.0008   
   2200     5206.87    517.0245   518.3489    1.429      0.0007   
   2300     5443.79    516.5696   518.5594    1.1664     0.0007   
   2400      5680.0    517.315    518.4288    1.0852     0.0006   
   2500     5915.87    515.5992   518.2435    1.4182     0.0006   
   2600      6152.4    516.5815   518.2809    1.1717     0.0005   
   2700     6387.79    516.0095   518.6079    1.2219     0.0005   
   2800     6624.24    516.7811   518.2353    1.2287     0.0004   
   2900     6859.98    516.0137   517.6928    1.3727     0.0004   
   3000     7095.21    515.7124   517.9914    0.9119     0.0004   
   3100     7331.77    515.8249   518.3056    0.9782     0.0004   
   3200     7567.74    516.4586   517.4965    0.9273     0.0003   
   3300     7804.52    516.562    518.5263    1.0744     0.0003   
   3400     8040.21    515.5468   518.4445    1.3418     0.0003   
   3500     8277.09    515.5895   517.9056    0.8674     0.0003   
   3600     8514.05    515.3838   517.4655    0.9859     0.0003   
   3700     8750.32    515.5092   517.3766    1.2768     0.0003   
   3800     8987.74    515.9066   518.3649    1.006      0.0003   
   3900     9225.61    516.8903   517.8823    1.0423     0.0002   
   4000     9462.09    515.1783   517.3973    0.961      0.0003   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       229.38    530.0924   531.0515    2.2532     0.3992   
   200       466.8     517.5755   519.4034    1.4085     0.0885   
   300       703.67    516.3121   518.0626    1.2415     0.0381   
   400       941.23    516.8805   518.7353    1.5521     0.0231   
   500      1179.51    515.8394   518.0434    1.1193     0.0157   
   600       1417.8    516.8285   518.5452    1.1532     0.0094   
   700      1655.55    516.2639   518.0823    1.0999     0.0077   
   800      1892.05    516.5826   518.1163    1.1317     0.0059   
   900      2129.39    515.2295   518.7696    1.3719     0.0049   
   1000      2364.5    515.1079   517.5873    1.6034     0.0039   
   1100     2599.98    515.9161   518.8333    1.2216     0.0031   
   1200     2837.97    515.7507   517.5516    1.1597     0.0026   
   1300     3075.64    516.2479   518.3796    1.066      0.002    
   1400     3313.53    514.9554   517.3486    1.2696     0.0019   
   1500     3550.29    516.1161   517.9083    1.3921     0.0017   
   1600     3788.75    514.7386   517.6416    1.0981     0.0016   
   1700     4027.09    516.3165   518.3163    0.971      0.0014   
   1800     4264.16    515.7848   518.3791    1.2376     0.0013   
   1900      4501.8    514.9216   517.3393    1.0558     0.001    
   2000     4740.05    515.5998   517.233     1.1284     0.001    
   2100     4977.56    515.7875   518.0133    1.1076     0.001    
   2200     5215.58    515.322    517.6313    1.1674     0.0009   
   2300     5454.22    516.4624   517.8999    1.0489     0.0008   
   2400     5691.98    515.8739   517.1696    1.2381     0.0007   
   2500     5930.42    514.4029   516.8614    1.1176     0.0007   
   2600     6167.57    516.1308   518.2581    1.2882     0.0006   
   2700      6404.7    514.9098   517.7116    1.0139     0.0005   
   2800     6642.31    514.0218   516.887     1.0344     0.0005   
   2900     6879.27    514.5884   517.5314    1.0467     0.0005   
   3000      7115.7    514.7935   517.6759    1.1448     0.0004   
   3100     7352.79    514.6067   517.0216    1.034      0.0004   
   3200     7589.64    515.6151   517.1469    0.8815     0.0004   
   3300     7828.67    515.2362   516.827     0.9374     0.0004   
   3400     8066.82    516.1053   517.2355    1.0699     0.0003   
   3500     8303.63    515.6591   517.5948    0.7663     0.0004   
   3600     8541.22    514.0365   516.8462    0.8375     0.0003   
   3700     8778.35    513.5055   517.3676    0.9381     0.0003   
   3800     9016.82    514.9033   516.9934    0.9135     0.0003   
   3900     9253.74    514.9278   516.5702    0.9471     0.0003   
   4000     9491.24    514.0221   516.6812    0.8655     0.0003   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       230.61    531.9261   534.092     2.2722     0.4795   
   200       469.42    518.8113   521.3761    1.0489     0.0759   
   300       707.19    515.7347   518.8601    1.5337     0.0321   
   400       945.17    514.8563   517.8209    1.017      0.0166   
   500       1182.6    515.005    517.7957    1.0248     0.012    
   600      1420.49    515.1313   517.3754    1.1227     0.0082   
   700      1657.22    515.254    518.252     0.9752     0.0063   
   800      1892.19    515.437    517.8425    0.9044     0.005    
   900      2126.62    515.7348   517.8326    1.1151     0.0042   
   1000     2362.83    515.2528   517.4488    1.0342     0.0033   
   1100     2597.68    514.5904   517.6041    1.3097     0.0029   
   1200     2833.33    515.2572   518.1209    0.9646     0.0025   
   1300     3067.07    514.3692   517.4252    1.1016     0.0022   
   1400     3300.64    514.9645   517.1652    0.9112     0.0018   
   1500     3534.95    515.5544   518.1139    0.9262     0.0017   
   1600     3768.44    515.2076   517.7052    1.5393     0.0014   
   1700     4002.61    514.7754   517.442     1.1209     0.0013   
   1800     4238.18    514.9969   517.8516    1.0262     0.0011   
   1900      4473.2    516.3701    517.97     0.9863     0.001    
   2000     4707.18    515.2314   517.6447    1.2849     0.0009   
   2100     4941.41    514.8314   517.4882    1.0148     0.001    
   2200     5175.62    513.8941   517.3837     1.16      0.0008   
   2300     5409.94    515.086    518.2018    0.8057     0.0007   
   2400      5645.1    514.6475   517.3606    1.1249     0.0007   
   2500     5880.68    514.0487   517.2179    0.7175     0.0006   
   2600     6116.15    514.587    517.3184    0.9586     0.0006   
   2700     6350.55    514.3532   517.2487    0.9494     0.0005   
   2800     6584.39    514.3576   517.0877    1.0429     0.0005   
   2900     6818.62    515.6788   517.392     0.8864     0.0005   
   3000     7054.27    514.6813   516.934     0.6998     0.0005   
   3100     7288.22    514.7748   517.5941    0.9307     0.0005   
   3200     7523.73    515.0896   517.6277    1.0342     0.0004   
   3300     7758.86    514.3609   517.0748    0.8292     0.0004   
   3400     7993.39    515.5476   517.4118    0.9358     0.0004   
   3500     8228.53    514.1244   516.8435    0.8833     0.0003   
   3600     8462.61    513.8882   517.1765    0.923      0.0003   
   3700     8697.44    514.1051   516.8218     0.77      0.0003   
   3800     8932.25    514.1338   516.8155    0.8979     0.0003   
   3900      9166.6    514.9001   517.6466    0.9171     0.0003   
   4000     9401.04    513.893    517.1499    0.8175     0.0003   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       225.33    535.6576   536.9658    1.4263     0.4063   
   200       462.49    519.1937   521.2748    1.0086     0.0803   
   300       698.2     516.2656   518.3795    1.0783     0.0335   
   400       935.24    515.9747   517.6812    0.8244     0.0201   
   500      1171.15    515.3141   517.3566    0.9812     0.0121   
   600      1407.79    515.3842   517.4629    1.5735     0.0091   
   700      1644.65    514.9056   517.1504    0.8037     0.0065   
   800      1882.12    514.8168   516.8718    1.0193     0.0054   
   900      2118.18    514.2284   516.8045    0.9978     0.0041   
   1000     2353.67    514.697    517.4529    0.9886     0.0036   
   1100     2590.12    514.5312   516.9464    0.7013     0.0028   
   1200     2825.71    514.6196   517.1149    0.7815     0.0025   
   1300     3061.59    514.7011   517.3247    0.8383     0.0022   
   1400     3297.55    514.9675   517.4396    0.9116     0.002    
   1500     3534.53    515.2938   517.6199    0.9099     0.0018   
   1600     3770.05    514.3193   517.0347    0.8479     0.0015   
   1700     4007.99    513.9458   516.8719    0.863      0.0014   
   1800     4244.49    514.4258   516.7875    0.6038     0.0012   
   1900      4480.3    514.8679   517.2808    0.9557     0.0012   
   2000      4716.0    515.2782   517.0017    0.7394     0.001    
   2100     4952.91    514.5717   516.8356    0.8956     0.0009   
   2200     5189.04    514.6741   516.844     0.8277     0.0009   
   2300     5424.65    513.9595   517.1134    0.9725     0.0008   
   2400     5660.64    513.7679   516.8823    0.992      0.0008   
   2500     5897.58    514.7062   517.0267    0.9052     0.0007   
   2600     6134.03    514.5154   516.7354    0.7466     0.0007   
   2700     6370.52    514.1529   517.0094    0.9005     0.0006   
   2800     6606.54    514.6712   516.9678    0.9217     0.0005   
   2900     6842.12    514.8714   516.8818    0.8522     0.0005   
   3000     7077.89    514.9818   517.1492    0.9775     0.0005   
   3100     7314.78    515.2021   517.1963    0.8521     0.0004   
   3200     7550.94    514.5362   516.6615    0.7572     0.0004   
   3300     7787.65    515.0473   517.1786    0.7514     0.0004   
   3400     8023.41    514.055    516.2539    0.7481     0.0004   
   3500     8259.47    514.3525   516.5739    0.8051     0.0004   
   3600     8495.26    514.2419   516.8257    0.847      0.0003   
   3700     8731.18    514.3919   516.6356    0.7659     0.0003   
   3800      8967.2    514.2855   516.6293    1.1874     0.0003   
   3900     9203.36    514.8107   516.7157    0.7608     0.0003   
   4000     9438.77    513.9882    516.5      0.7468     0.0003   
