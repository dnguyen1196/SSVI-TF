Generating synthetic binary valued data ... 
Generating synthetic  binary valued data took:  3.498816728591919
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       140.51     0.7658     0.7442      3.14      0.2685      0.0    
   200       386.14     0.716      0.6644     2.6738     0.1108      0.0    
   300       630.46     0.6729     0.5978     2.4163     0.0832      0.0    
   400       874.95     0.6365     0.5452     1.9565     0.0696      0.0    
   500      1121.81     0.6284     0.5261      2.07      0.055       0.0    
   600      1367.78     0.6094     0.4958     1.7725     0.0542      0.0    
   700      1613.32     0.6144     0.4972     1.8046     0.0465      0.0    
   800      1858.34     0.6013     0.465      2.0147     0.0483      0.0    
   900      2103.35     0.6011     0.4574     2.3722     0.0457      0.0    
   1000     2346.15     0.609      0.4841     2.3176     0.0405      0.0    
   1100     2590.57     0.6119      0.48      2.2494     0.0408      0.0    
   1200     2833.57     0.6149     0.481      2.4319     0.0459      0.0    
   1300     3075.48     0.6266     0.5036     2.6276     0.046       0.0    
   1400     3317.56     0.6295     0.5173     2.7277     0.0493      0.0    
   1500     3559.87     0.6114     0.4954     2.4856     0.0455      0.0    
   1600     3800.34     0.6239     0.5171     2.4584     0.0434      0.0    
   1700      4040.3     0.6167     0.5054     2.4992     0.043       0.0    
   1800     4278.65     0.5942     0.4743     2.5781     0.0446      0.0    
   1900     4517.88     0.5839     0.4596     2.4801     0.0404      0.0    
   2000     4756.02     0.6028     0.499      2.8789     0.0529      0.0    
   2100     4992.73     0.5824     0.465      2.7112     0.0489      0.0    
   2200     5229.24     0.5836     0.4648     2.7746     0.049       0.0    
   2300     5464.29     0.5819     0.4663     2.4489     0.0695      0.0    
   2400     5698.73     0.5776     0.4506     2.217      0.0497      0.0    
   2500     5932.51     0.5692     0.4477     2.4288     0.0605      0.0    
   2600     6165.94     0.5738     0.4567     1.9813     0.0542      0.0    
   2700      6400.4     0.5755     0.4459     2.0229     0.0634      0.0    
   2800     6632.88     0.5716     0.4343     2.0249     0.0669      0.0    
   2900     6865.45     0.5672     0.4322     1.8901     0.0561      0.0    
   3000     7097.38     0.5594     0.4162     2.2378     0.0643      0.0    
   3100     7331.02     0.5573     0.4297     2.2225     0.0649      0.0    
   3200     7562.71     0.5627     0.4377     2.0741     0.0558      0.0    
   3300     7793.96     0.5597     0.4317     2.1394     0.0643      0.0    
   3400     8025.94     0.565      0.4352     2.0913     0.062       0.0    
   3500      8257.3     0.5701     0.4308     1.9495     0.069       0.0    
   3600     8489.18     0.5611     0.4207     1.657      0.0643      0.0    
   3700     8720.58     0.5573     0.4164      1.82      0.0648      0.0    
   3800     8952.08     0.5564     0.4224     2.0303     0.0533      0.0    
   3900     9182.68     0.5593     0.4273     1.7205     0.066       0.0    
   4000     9414.23     0.5619     0.4207     2.1656     0.0504      0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       141.04     1.4114     1.4225     0.0126     0.566       0.0    
   200       429.43     1.4119     1.4179     0.0097     0.3449      0.0    
   300       717.37     1.4153     1.4151     0.0101     0.2092      0.0    
   400      1005.01     1.4042     1.4118     0.0082     0.1342      0.0    
   500      1292.82     1.4109     1.4119     0.0079     0.0917      0.0    
   600      1581.51     1.4186     1.4156     0.0084     0.0666      0.0    
   700      1869.15     1.4129     1.4124     0.0084     0.0507      0.0    
   800      2155.73     1.4159     1.4188     0.0083     0.0398      0.0    
   900      2443.11     1.4112     1.4162     0.0095     0.033       0.0    
   1000     2731.02     1.4202     1.4095     0.0089     0.0272      0.0    
   1100     3019.49     1.4121     1.4161     0.0097     0.0232      0.0    
   1200     3303.94     1.4136     1.4096     0.0093     0.0197      0.0    
   1300     3588.12     1.4173     1.4146     0.0093     0.0173      0.0    
   1400      3874.0     1.4259     1.4085     0.0097     0.0151      0.0    
   1500     4159.15     1.4136     1.4222     0.0094     0.0135      0.0    
   1600     4443.61     1.4141     1.4107     0.0098     0.0122      0.0    
   1700     4726.29     1.4068     1.4105     0.0102     0.0109      0.0    
   1800     5011.24     1.4169     1.4112     0.0107      0.01       0.0    
   1900     5296.25     1.4116     1.4087     0.0102     0.0091      0.0    
   2000     5581.76     1.4119     1.4158     0.0101     0.0084      0.0    
   2100      5867.5     1.4116     1.4131     0.0105     0.0077      0.0    
   2200     6150.99      1.41      1.4138     0.0101     0.0071      0.0    
   2300     6435.16     1.4077     1.4179     0.0106     0.0066      0.0    
   2400     6719.78     1.4079     1.4078     0.0104     0.0062      0.0    
   2500     7004.97     1.4081     1.4098     0.0104     0.0058      0.0    
   2600     7289.01     1.4209     1.4111     0.0106     0.0055      0.0    
   2700     7572.72     1.4109     1.4028     0.0105     0.0051      0.0    
   2800     7858.03     1.4071     1.4144     0.0103     0.0049      0.0    
   2900     8144.12     1.4151     1.414      0.0111     0.0047      0.0    
   3000     8428.74     1.4112     1.4171     0.0112     0.0044      0.0    
   3100      8714.8     1.4112     1.4107     0.0105     0.0042      0.0    
   3200     9000.77     1.414      1.4096     0.0112     0.0041      0.0    
   3300     9285.87     1.4149     1.402      0.012      0.0038      0.0    
   3400     9570.42     1.4026     1.409      0.0113     0.0037      0.0    
   3500     9856.21     1.408      1.4022     0.0117     0.0036      0.0    
   3600     10143.43    1.4048     1.4013     0.0125     0.0034      0.0    
   3700     10428.82    1.3995     1.3904     0.0125     0.0033      0.0    
   3800     10716.08    1.3943     1.3895     0.0135     0.0032      0.0    
   3900     11004.45    1.3932     1.3905     0.0135     0.0032      0.0    
   4000     11293.11    1.3909     1.3821     0.0142     0.003       0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       140.87     1.4131     1.4135     0.0198     0.4746      0.0    
   200       472.74     1.4133     1.4165     0.0135     0.331       0.0    
   300       803.69     1.3997     1.4091     0.0114     0.2249      0.0    
   400       1134.9     1.4131     1.4126     0.0104     0.1517      0.0    
   500      1466.79     1.4142     1.4212     0.0097     0.1066      0.0    
   600      1796.91     1.4134     1.4165     0.0108     0.0783      0.0    
   700      2128.25     1.4208     1.4141     0.0097     0.0595      0.0    
   800      2460.33     1.4173     1.4135     0.0095     0.0472      0.0    
   900      2791.59     1.4093     1.4156     0.0105     0.0382      0.0    
   1000     3122.53     1.417      1.4142     0.0099     0.0318      0.0    
   1100     3454.31     1.4173     1.4105     0.0093     0.0268      0.0    
   1200     3785.13     1.4203     1.4154     0.0093     0.0229      0.0    
   1300     4115.08     1.4172     1.4142     0.0096     0.0198      0.0    
   1400     4447.12     1.4141     1.4177     0.0097     0.0173      0.0    
   1500     4780.69     1.4163     1.4118     0.0096     0.0155      0.0    
   1600     5113.69     1.415      1.4153     0.0103     0.0138      0.0    
   1700      5446.6     1.4154     1.4144      0.01      0.0125      0.0    
   1800     5781.27     1.4065     1.4176     0.0104     0.0115      0.0    
   1900     6116.74     1.4174     1.4118     0.0105     0.0105      0.0    
   2000     6450.47     1.411      1.4145     0.0105     0.0095      0.0    
   2100     6784.37     1.4118     1.4166     0.0101     0.0089      0.0    
   2200     7118.48     1.4041     1.4077     0.0099     0.0084      0.0    
   2300     7452.55     1.4139     1.4195     0.0102     0.0077      0.0    
   2400     7786.47     1.4097     1.414      0.0099     0.0072      0.0    
   2500     8120.25     1.4177     1.4106     0.0105     0.0067      0.0    
   2600     8453.25     1.4178     1.4124     0.0108     0.0063      0.0    
   2700     8786.13     1.4077     1.4155     0.0108     0.006       0.0    
   2800     9118.05     1.4128     1.4141     0.0109     0.0057      0.0    
   2900      9447.5     1.4138     1.4131     0.0109     0.0053      0.0    
   3000     9777.77     1.4105     1.4101     0.0118     0.0051      0.0    
   3100     10108.17    1.4127     1.4119     0.011      0.0049      0.0    
   3200     10438.85    1.4097     1.4067     0.0109     0.0046      0.0    
   3300     10769.65    1.3982     1.4057     0.0122     0.0044      0.0    
   3400     11099.41    1.4047     1.4004     0.0114     0.0042      0.0    
   3500     11429.35    1.3965     1.403      0.0144     0.0041      0.0    
   3600     11758.93    1.3896     1.392      0.0146     0.004       0.0    
   3700     12089.06    1.3991     1.3928     0.0146     0.0038      0.0    
   3800     12419.55    1.3864     1.3843     0.015      0.0036      0.0    
   3900     12750.18    1.3782     1.3855     0.0153     0.0036      0.0    
   4000     13081.46    1.3747     1.3753     0.0174     0.0034      0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       135.5      1.4075     1.4136     0.0248     0.4361      0.0    
   200       491.83     1.4129     1.4167     0.0198     0.3181      0.0    
   300       850.62     1.4075     1.4107     0.0175     0.2267      0.0    
   400      1204.42     1.4086     1.4088     0.0145     0.1593      0.0    
   500      1559.84     1.4113     1.4102     0.0137     0.1147      0.0    
   600      1919.14     1.4186     1.4136     0.0109     0.0836      0.0    
   700      2284.81     1.4096     1.4144     0.0111     0.0639      0.0    
   800       2662.2     1.4153     1.4155     0.0117     0.0505      0.0    
   900      3039.88     1.4159     1.4149     0.0114     0.041       0.0    
   1000     3417.64     1.4111     1.4136     0.0113     0.0335      0.0    
   1100     3794.79     1.4076     1.4145     0.0112     0.0284      0.0    
   1200     4171.02     1.4089     1.415      0.0103     0.0243      0.0    
   1300     4547.71     1.4146     1.4168     0.0103     0.0211      0.0    
   1400     4924.24     1.4087     1.4156     0.0103     0.0186      0.0    
   1500     5302.28     1.4157     1.4142     0.0114     0.0164      0.0    
   1600     5682.56     1.4217     1.4158     0.0106     0.0148      0.0    
   1700     6059.96     1.4163     1.4135     0.0105     0.0133      0.0    
   1800     6437.86     1.4159     1.4134     0.0106     0.0121      0.0    
   1900     6816.37     1.4152     1.414      0.0104     0.011       0.0    
   2000     7194.42     1.4114     1.4186     0.0106     0.0101      0.0    
   2100     7572.61     1.4152     1.4126     0.0106     0.0093      0.0    
   2200     7949.69     1.4206     1.4124     0.0107     0.0087      0.0    
   2300     8327.24     1.4123     1.4147     0.0105     0.008       0.0    
   2400     8703.38     1.4059     1.4111     0.0117     0.0075      0.0    
   2500     9080.35     1.4091     1.4142     0.0104     0.0071      0.0    
   2600      9459.0     1.4101     1.4081     0.0104     0.0066      0.0    
   2700     9835.72     1.4125     1.4113     0.0106     0.0062      0.0    
   2800     10212.57    1.4089      1.41      0.0112     0.0059      0.0    
   2900     10589.99    1.4068     1.4085     0.0112     0.0056      0.0    
   3000     10965.76    1.4146     1.4104     0.0118     0.0054      0.0    
   3100     11342.81    1.4136     1.4089     0.012      0.0051      0.0    
   3200     11719.91    1.3993     1.4013     0.013      0.0049      0.0    
   3300     12096.7     1.3969     1.4032     0.0139     0.0046      0.0    
   3400     12475.07    1.4017     1.4082     0.0126     0.0044      0.0    
   3500     12853.67    1.3991     1.3977     0.0134     0.0043      0.0    
   3600     13231.44    1.3928     1.3934     0.0157     0.0041      0.0    
   3700     13609.68    1.3784      1.39      0.0152     0.004       0.0    
   3800     13989.29    1.3792     1.3816     0.0155     0.0038      0.0    
   3900     14366.46    1.3727     1.3699     0.0162     0.0037      0.0    
   4000     14744.37    1.366      1.3621     0.0161     0.0036      0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       142.15     1.4124     1.4138     0.0342     0.4189      0.0    
   200       561.27     1.4187     1.416      0.0252     0.3112      0.0    
   300       979.32     1.4203     1.416      0.0213     0.2267      0.0    
   400      1398.72     1.4157     1.414      0.0195     0.1625      0.0    
   500       1816.1     1.4113     1.4164     0.0152     0.118       0.0    
   600      2234.52     1.4155     1.414      0.0147     0.0871      0.0    
   700      2652.09     1.4174     1.4151     0.0137     0.0666      0.0    
   800      3069.93     1.4108     1.4134     0.0129     0.0523      0.0    
   900      3487.58     1.4069     1.4135     0.0115     0.0423      0.0    
   1000     3904.91     1.4093     1.4133     0.0117     0.0349      0.0    
   1100     4322.66     1.4113     1.4169     0.0128     0.0295      0.0    
   1200     4740.37     1.4183     1.4127     0.0116     0.0252      0.0    
   1300      5158.4     1.426      1.4146     0.0122     0.0218      0.0    
   1400     5576.12     1.4055     1.4165     0.013      0.019       0.0    
   1500     5993.27     1.4175     1.4109     0.0113     0.017       0.0    
   1600     6409.05     1.4079     1.4149     0.0113     0.0151      0.0    
   1700     6824.92     1.4183     1.4139     0.0107     0.0136      0.0    
   1800     7242.19     1.4192     1.4122     0.0116     0.0124      0.0    
   1900     7659.45     1.4164     1.4106     0.0114     0.0113      0.0    
   2000     8076.73     1.4106     1.416      0.0112     0.0103      0.0    
   2100      8493.2     1.409      1.4111     0.0117     0.0095      0.0    
   2200     8909.34     1.4173     1.4125     0.0115     0.0089      0.0    
   2300     9325.68     1.4153     1.4136     0.0106     0.0083      0.0    
   2400     9742.26     1.4129     1.4104     0.013      0.0077      0.0    
   2500     10159.99    1.413      1.4146     0.0115     0.0072      0.0    
   2600     10576.21    1.4129     1.4125     0.0115     0.0069      0.0    
   2700     10991.13    1.4186     1.4107     0.0108     0.0065      0.0    
   2800     11407.74    1.4057     1.4099     0.0115     0.0061      0.0    
   2900     11824.57    1.3981     1.4119     0.0128     0.0057      0.0    
   3000     12241.51    1.4083     1.4104     0.013      0.0055      0.0    
   3100     12657.58    1.4146     1.4046     0.0123     0.0052      0.0    
   3200     13072.96    1.4031     1.4047     0.0131     0.005       0.0    
   3300     13488.0     1.4045     1.4053     0.0145     0.0048      0.0    
   3400     13903.48    1.4018     1.3976     0.0151     0.0045      0.0    
   3500     14320.38    1.3927     1.394      0.0163     0.0044      0.0    
   3600     14736.82    1.3879     1.3931     0.0177     0.0042      0.0    
   3700     15153.22    1.3827     1.3794     0.0165     0.0041      0.0    
   3800     15577.36    1.3841     1.3736     0.0184     0.0039      0.0    
   3900     15999.26    1.3586     1.3607     0.0187     0.0038      0.0    
   4000     16423.04    1.3605     1.3513     0.0207     0.0037      0.0    
