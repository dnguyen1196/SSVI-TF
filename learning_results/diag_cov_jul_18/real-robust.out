Generating synthetic  real valued data ... 
Generating synthetic  real valued data took:  6.073478698730469
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       93.69     361.7854   361.8257    3.1623     1.8524      0.0    
   100       187.9     191.6896   192.3627    3.162      0.7617      0.0    
   150       282.55    169.1302   168.7699    2.8839     0.3676      0.0    
   200       377.26    160.1656   159.8007     2.54      0.2458      0.0    
   250       472.03    156.3146   155.4488    2.6867     0.1433      0.0    
   300       566.81    151.6116   151.4862    2.0067     0.097       0.0    
   350       661.61    150.5734   150.3238    1.5584     0.0791      0.0    
   400       756.44    149.0919   148.5169    1.6409     0.0681      0.0    
   450       851.28    147.6368   147.8431     1.99      0.0915      0.0    
   500       946.1     147.8405   147.2968    1.7172     0.0827      0.0    
   550      1040.95    146.9794   146.8545    1.4305     0.0589      0.0    
   600       1135.8    147.5312   146.8468    1.254      0.0476      0.0    
   650      1230.65    146.381    146.579     0.999       0.04       0.0    
   700       1325.5    146.5421   145.885     1.0348     0.0463      0.0    
   750      1420.38    146.6516   146.5661    0.962      0.0444      0.0    
   800      1515.26    147.3717   146.5616    0.9915     0.0407      0.0    
   850      1610.12    146.6564   146.5722    0.954      0.0343      0.0    
   900      1704.98    146.5949   146.2218    1.1635     0.0416      0.0    
   950      1799.84    146.4646   146.2955    1.1169     0.0362      0.0    
   1000      1894.7    146.5619   145.8605    0.9732     0.0356      0.0    
   1050     1989.57    145.5903   145.7006    0.9492     0.0291      0.0    
   1100     2084.44    147.4664   146.6268    0.9931     0.0277      0.0    
   1150     2179.28    146.3645   146.2676    1.2163     0.0321      0.0    
   1200     2274.14    146.5694   146.0631    1.0777     0.0304      0.0    
   1250     2369.02    146.0086   145.5801    1.1132     0.0268      0.0    
   1300      2463.9    146.0766   145.866     1.0131     0.0284      0.0    
   1350     2558.77    146.8502   146.1466    1.0844     0.0257      0.0    
   1400     2653.64    145.808    145.5992    0.877      0.0271      0.0    
   1450     2748.53    145.8045   145.3909    0.6955     0.0243      0.0    
   1500     2843.42    146.2804   145.9083    0.8548     0.0213      0.0    
   1550      2938.3    146.5324   145.8538    0.906      0.0212      0.0    
   1600     3033.19    146.0449   145.7992    1.0088     0.0212      0.0    
   1650     3128.08    145.7745   145.7584    1.1641     0.0221      0.0    
   1700     3222.94    145.8683   145.5879    1.0288     0.0193      0.0    
   1750      3317.8    146.5531   145.9623    0.8414     0.0208      0.0    
   1800     3412.69    145.4659   145.4016    0.6821     0.0181      0.0    
   1850     3507.59    145.9371   145.4018    0.6611     0.0171      0.0    
   1900     3602.47    146.1909   145.7472    0.788      0.0172      0.0    
   1950     3697.35    145.905    145.8172    0.9026     0.0174      0.0    
   2000     3792.23    146.0313   145.5564     0.74      0.0162      0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       94.73     304.5752   304.0802    3.0301     1.8419      0.0    
   100       189.88    177.542    177.2763    3.089      0.7918      0.0    
   150       285.34    161.1321   160.1427    2.199      0.2792      0.0    
   200       380.83    154.483    154.3861    2.3232     0.2879      0.0    
   250       476.38    152.4013   152.0305    2.1013     0.1522      0.0    
   300       571.95    150.4617   150.0207    2.0626     0.1286      0.0    
   350       667.52    150.2192   149.6422    1.7531     0.1131      0.0    
   400       763.13    148.0784   148.0429    1.4926     0.1136      0.0    
   450       858.72    147.0258   146.7587    1.3839     0.0843      0.0    
   500       954.32    148.1744   147.6066    1.2737     0.0826      0.0    
   550      1049.92    147.5191   146.9693    1.1921     0.0672      0.0    
   600      1145.53    147.4471   147.3639    1.1845     0.0792      0.0    
   650      1241.16    147.1138   146.7707    1.3646     0.0601      0.0    
   700      1336.78    146.9257   146.6141    1.6851     0.0579      0.0    
   750      1432.41    146.9043   146.822     1.5745     0.0586      0.0    
   800      1528.02    146.3703   146.0344    1.0266      0.05       0.0    
   850      1623.69    147.2852   146.8323    1.1669     0.0487      0.0    
   900       1719.3    146.5942   146.5415    1.1946     0.0495      0.0    
   950       1814.9    146.5945   146.2849    1.149      0.0454      0.0    
   1000     1910.13    146.624    146.1942    1.3691     0.0402      0.0    
   1050      2005.1    146.5813   146.297     1.5583     0.0393      0.0    
   1100     2100.01    147.0239   146.6061    0.9704     0.0421      0.0    
   1150     2194.93    146.2433   145.6575    0.8975     0.0345      0.0    
   1200     2289.82    145.9764   145.7623    1.0034     0.0378      0.0    
   1250     2384.68    145.6974   145.607     0.979      0.0396      0.0    
   1300     2479.57    145.8243   145.4343    0.9328      0.03       0.0    
   1350     2574.45    146.2304   145.6966    0.7532     0.0361      0.0    
   1400     2669.34    145.8812   145.4736    0.8212     0.029       0.0    
   1450      2764.2    146.703    146.1301    1.0039     0.0259      0.0    
   1500     2859.06    146.3419   146.3366    1.2946     0.0249      0.0    
   1550     2953.94    146.4064   146.0778    1.1008     0.0291      0.0    
   1600      3048.8    145.8968   145.6504    1.0389     0.0241      0.0    
   1650      3143.7    146.3871   146.0416    1.1918     0.025       0.0    
   1700     3238.58    146.7284   146.2142    0.9141     0.0251      0.0    
   1750     3333.44    145.2345   144.9479    0.9979     0.0259      0.0    
   1800     3428.36    145.4392   145.3149     0.95      0.0223      0.0    
   1850     3523.28    145.8415   145.6733    0.6846     0.0223      0.0    
   1900     3618.19    145.9998   145.8959    1.0583     0.0215      0.0    
   1950     3713.12    145.9934   145.7492    0.9369     0.0188      0.0    
   2000     3808.05    145.7929   145.7484    1.0038     0.0233      0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       94.14     291.3667   290.0878    2.8807     1.8077      0.0    
   100       189.26    175.6104   174.5432    2.6954     0.974       0.0    
   150       284.67    158.3027   157.4181    1.6819     0.2865      0.0    
   200       380.16    151.4555   150.8096    1.4972     0.1602      0.0    
   250       475.72    147.6564   147.4209    1.4155     0.1526      0.0    
   300       571.3     147.4786   146.742     1.1194     0.1224      0.0    
   350       666.86    146.7063   146.1952    1.1109     0.1379      0.0    
   400       762.45    147.1491   146.5838    1.5983     0.1126      0.0    
   450       858.02    147.1035   146.5589    1.4875     0.0912      0.0    
   500       953.57    146.8319   146.3488    1.2484     0.0865      0.0    
   550      1049.15    146.6862   146.3961    1.3462     0.0779      0.0    
   600      1144.76    146.6284   146.3967    1.4747     0.079       0.0    
   650      1240.36    146.4212   146.2516    1.5193     0.0751      0.0    
   700      1335.95    146.579    146.1585    1.0846     0.067       0.0    
   750      1431.61    146.1563   145.5445    1.2091     0.0727      0.0    
   800      1527.24    145.6169   145.4335    1.1111     0.0665      0.0    
   850      1622.88    146.3014   145.7789    0.8949     0.0486      0.0    
   900      1718.56    145.9893   145.3909    1.0044     0.0438      0.0    
   950      1814.22    145.5396   145.4621    0.7916     0.0563      0.0    
   1000     1909.86    145.9565   145.501     0.8567     0.0437      0.0    
   1050     2005.56    145.6398   145.3902    0.9019     0.0395      0.0    
   1100     2101.23    145.9846   145.5119    0.9257      0.04       0.0    
   1150      2196.9    146.3988   146.1391    0.8067     0.0422      0.0    
   1200     2292.62    145.619    145.217     0.9798     0.0368      0.0    
   1250     2388.32    145.8818   145.4781    0.7855     0.0453      0.0    
   1300     2484.02    145.595    145.3972    0.9508     0.0334      0.0    
   1350     2579.67    145.7112   145.1805    0.9672     0.0299      0.0    
   1400     2675.37    145.5229   145.3407    0.8799     0.0299      0.0    
   1450     2771.05    146.2743   145.6869    1.0599     0.0297      0.0    
   1500     2866.71    145.5265   145.3027    0.6602     0.0278      0.0    
   1550      2962.4    145.8512   145.2426    0.8877     0.0267      0.0    
   1600     3058.07    146.3904   145.8664    0.8685     0.0271      0.0    
   1650     3153.77    145.2701   145.2308    0.7859     0.0265      0.0    
   1700     3249.46    145.904    145.6181    0.816      0.0261      0.0    
   1750     3345.15    145.9115   145.4923    0.8561     0.0263      0.0    
   1800     3440.84    145.5197   145.0925    0.9016     0.0275      0.0    
   1850     3536.55    145.5761   145.3809    0.8982     0.0194      0.0    
   1900     3632.28    145.3438   144.9105    0.6497     0.0211      0.0    
   1950     3728.01    145.2376   144.8279    0.6231     0.0212      0.0    
   2000     3823.73    145.1372   145.0501    0.9729     0.0203      0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       94.17     285.689    284.6068    2.7513     1.763       0.0    
   100       189.93    179.4435   178.3812    2.625      0.7759      0.0    
   150       286.01    159.2547   158.7484    2.0271     0.3269      0.0    
   200       382.14    152.211    152.2089    1.2974     0.1736      0.0    
   250       478.3     148.7822   148.5351    1.1054     0.1464      0.0    
   300       574.46    146.6522   146.8506    0.963      0.1234      0.0    
   350       670.59    147.0479   147.1072    0.9211     0.1099      0.0    
   400       766.78    146.0026   146.2061    0.8249     0.104       0.0    
   450       862.98    145.6897   145.7286    1.0941     0.1055      0.0    
   500       959.17    146.3953   146.4128    0.9221     0.1002      0.0    
   550      1055.35    146.3488   146.5577    1.1935     0.0751      0.0    
   600      1151.57    146.2647   146.0236    0.9905     0.0783      0.0    
   650      1247.74    146.0186   145.9183    0.8186     0.0637      0.0    
   700      1343.92    145.5884   145.6859    1.2234     0.0722      0.0    
   750       1440.1    146.021    146.0007    1.2932     0.0622      0.0    
   800      1536.32    145.3479   145.4535    0.8082     0.0556      0.0    
   850      1632.52    146.5345   146.1154    0.9673     0.0582      0.0    
   900      1728.75    145.9063   145.9531    1.0328     0.0535      0.0    
   950       1825.0    145.7241   145.643     0.9836     0.0518      0.0    
   1000     1921.21    145.7935   145.691     1.2022     0.0456      0.0    
   1050     2017.43    145.3981   145.4918    0.9063     0.0486      0.0    
   1100     2113.81    145.8088   146.0881    0.9688     0.0371      0.0    
   1150     2210.07    145.2703   145.6305    0.8633     0.0379      0.0    
   1200     2306.29    144.9158   145.2072    0.7907     0.0368      0.0    
   1250     2402.52    145.2571   145.1784    0.6123     0.0331      0.0    
   1300     2498.75    146.058    146.117     0.7598     0.036       0.0    
   1350     2594.99    145.7687   145.981     1.2647     0.0356      0.0    
   1400     2691.21    146.0208   146.0746    1.0745     0.0296      0.0    
   1450     2787.45    145.2619   145.364     0.7775     0.0289      0.0    
   1500      2883.7    145.5979   145.646     0.7946     0.0278      0.0    
   1550     2979.95    145.7139   145.9497    0.8489     0.0254      0.0    
   1600     3076.14    145.6167   145.5064    0.7139     0.0308      0.0    
   1650     3172.36    145.1087   145.2752    0.5991     0.0253      0.0    
   1700     3268.59    145.9769   145.6507    0.9122     0.0285      0.0    
   1750     3364.88    145.0344   145.3032    0.7542     0.0235      0.0    
   1800     3461.15    145.626    145.534     0.7115     0.0258      0.0    
   1850     3557.42    144.9993   145.2907    0.8751     0.0222      0.0    
   1900     3653.67     145.46    145.5165    0.9522     0.0239      0.0    
   1950     3749.93    145.3429   145.6253    0.8901     0.0197      0.0    
   2000     3846.28    144.9531   145.2643    0.9562     0.0192      0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       94.11     286.232    285.1615    2.6386     1.7552      0.0    
   100       190.48    186.3089   184.8052    2.4155     0.7919      0.0    
   150       287.15    162.472    161.859     1.7003     0.2718      0.0    
   200       383.9     153.0484   152.4727    1.2569     0.217       0.0    
   250       480.68    149.7423   149.2798    1.0027     0.2128      0.0    
   300       577.52    147.3158   147.3427    1.2616     0.1375      0.0    
   350       674.33    146.4011   146.3364    1.0663     0.1307      0.0    
   400       771.13    146.6027   146.6578    1.1482     0.1148      0.0    
   450       867.93    145.4983   145.5503    1.1885     0.1104      0.0    
   500       964.77    145.5093   145.6055    0.7364     0.1005      0.0    
   550      1061.57    145.787    145.5316    0.8622     0.087       0.0    
   600      1158.38    144.9747   145.1603    0.9644     0.0777      0.0    
   650      1255.18    145.6211   145.5234    0.8843     0.0758      0.0    
   700       1352.0    145.3154   145.4163    0.7096     0.0564      0.0    
   750      1448.81    145.6123   145.6858    0.852      0.0558      0.0    
   800      1545.63    145.446    145.3757    1.078      0.0611      0.0    
   850      1642.45    145.7399   145.6249    1.0444     0.052       0.0    
   900      1739.26    145.4674   145.5792    1.0064     0.0516      0.0    
   950      1836.21    145.3487   145.3648    0.7974     0.0474      0.0    
   1000     1933.05    145.8482   145.584     0.8604     0.0453      0.0    
   1050     2029.87    145.1389   145.4141    0.8901     0.0442      0.0    
   1100      2126.7    145.0486   144.9608    0.7956     0.0383      0.0    
   1150     2223.53    145.9232   146.0145    0.9822     0.049       0.0    
   1200     2320.36    144.8287   144.9708    0.8936     0.0375      0.0    
   1250     2417.21    145.0621   145.0521    0.5811     0.0374      0.0    
   1300     2514.25    145.5984   145.5178    0.5011     0.0324      0.0    
   1350     2611.22    145.1214   145.0061    0.7396     0.033       0.0    
   1400     2708.12    144.8493   145.067     0.6516     0.0369      0.0    
   1450     2805.12    145.1756   145.1775    0.7572     0.0368      0.0    
   1500      2902.1    145.317    145.1882    0.8497     0.0367      0.0    
   1550     2999.04    145.4325   145.2312    0.9434     0.0267      0.0    
   1600      3096.0    145.1604   145.2929    0.8967     0.0274      0.0    
   1650     3192.92    145.5665   145.5129    0.8145     0.0292      0.0    
   1700     3289.86    145.3425   145.3665    0.7973     0.0265      0.0    
   1750     3386.83    145.148    145.3119    0.769      0.0236      0.0    
   1800     3483.71    145.2387   145.0641    0.6877     0.0257      0.0    
   1850     3580.43    144.8435   144.885     0.6294     0.0251      0.0    
   1900     3677.18    145.109    145.0692    0.6659     0.0205      0.0    
   1950     3773.87    144.781    144.7915    0.6633      0.02       0.0    
   2000     3870.55    144.7636    144.91     0.6696     0.0197      0.0    
Generating synthetic  real valued data ... 
Generating synthetic  real valued data took:  6.627734184265137
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       172.53    361.0716   362.617     3.1623     4.4721      0.0    
   100       353.68    191.3754   192.1535    3.1623     0.2069      0.0    
   150       536.1     167.6278   167.582     2.8845      0.0        0.0    
   200       718.7     160.2231   159.484     2.6523      0.0        0.0    
   250       901.46    155.0211   154.3849    2.3185      0.0        0.0    
   300      1083.29    151.3789   151.1281    2.0788      0.0        0.0    
   350      1265.16    149.6503   149.328     1.6998      0.0        0.0    
   400      1447.43    147.8986   147.3924    1.3092      0.0        0.0    
   450      1629.52    146.9017   146.8251    1.1975      0.0        0.0    
   500      1812.01    147.0375   146.7422    1.1806      0.0        0.0    
   550      1994.45    147.352    146.9827    1.2067      0.0        0.0    
   600      2176.63    147.3521   146.9611    1.2732      0.0        0.0    
   650      2358.67    146.6537   146.6474    1.4006      0.0        0.0    
   700      2541.32    146.3807   145.9902    1.332       0.0        0.0    
   750      2723.81    146.4721   146.201     0.8164      0.0        0.0    
   800      2906.01    147.1585   146.6462    1.0483      0.0        0.0    
   850      3088.34    146.7284   146.5673    1.2278      0.0        0.0    
   900      3270.72    146.7389   146.4529    1.1919      0.0        0.0    
   950      3452.96    146.6276   146.4002    1.0322      0.0        0.0    
   1000      3635.5    146.256    145.7002    1.0394      0.0        0.0    
   1050     3817.96    145.7151   145.7061    0.9614      0.0        0.0    
   1100     4000.06    147.2506   146.5417    0.8785      0.0        0.0    
   1150      4182.3    146.543    146.3915    1.1631      0.0        0.0    
   1200     4364.42    146.5019   146.0626    1.0281      0.0        0.0    
   1250     4546.09    145.8385   145.4521    1.1164      0.0        0.0    
   1300     4727.57    146.1593   145.9264    1.0173      0.0        0.0    
   1350     4907.36    146.8611   146.1568    1.088       0.0        0.0    
   1400     5087.23    145.8995   145.6987    0.8789      0.0        0.0    
   1450     5267.25    145.8365   145.4777    0.7686      0.0        0.0    
   1500     5447.28    146.4155   146.0817    0.8638      0.0        0.0    
   1550     5627.37    146.4746   145.8128    0.9295      0.0        0.0    
   1600     5807.35    145.8275   145.614     0.9597      0.0        0.0    
   1650      5987.4    145.7297   145.6901    1.0713      0.0        0.0    
   1700     6167.41    145.8696   145.5965    0.946       0.0        0.0    
   1750     6347.29    146.3561   145.8105    0.7509      0.0        0.0    
   1800     6527.14    145.5031   145.404     0.7367      0.0        0.0    
   1850     6707.08    145.8201   145.3319    0.674       0.0        0.0    
   1900     6887.12    146.2479   145.8208    0.8181      0.0        0.0    
   1950     7067.24    145.9223   145.883     0.833       0.0        0.0    
   2000     7247.34    146.0731   145.5418    0.833       0.0        0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       171.62    303.2906   302.8966    3.0279     4.4721      0.0    
   100       352.6     177.3034   177.0036    3.0906      0.0        0.0    
   150       534.05    161.9109   160.9195    2.1479      0.0        0.0    
   200       715.41    154.5262   154.3104    2.3044      0.0        0.0    
   250       896.92    152.2929   152.1152    2.1927      0.0        0.0    
   300      1078.31    151.5245   150.9239    2.0987      0.0        0.0    
   350      1259.81    150.3386   149.7194    1.7717      0.0        0.0    
   400      1441.43    147.8934   148.0226    1.5884      0.0        0.0    
   450       1622.9    146.8571   146.4136    1.2796      0.0        0.0    
   500      1804.43    147.3553   147.0004    1.2586      0.0        0.0    
   550      1985.94    147.2235   146.5252    1.0021      0.0        0.0    
   600      2167.56    147.2419   147.3557    1.3264      0.0        0.0    
   650      2348.96    147.1704   146.6675    1.6075      0.0        0.0    
   700      2530.52    146.4232   146.2442    1.6644      0.0        0.0    
   750      2712.02    146.8706   146.6139    1.4021      0.0        0.0    
   800      2893.46    146.3302   146.1239    0.9218      0.0        0.0    
   850      3074.95    147.149    146.6961    1.1996      0.0        0.0    
   900      3256.41    146.4909   146.4571    1.2237      0.0        0.0    
   950      3437.93    146.3968   146.1384    1.1887      0.0        0.0    
   1000      3619.4    146.2503   145.7725    1.0681      0.0        0.0    
   1050     3800.84    145.9493   145.7588    1.0213      0.0        0.0    
   1100     3982.33    146.7705   146.3047    0.8534      0.0        0.0    
   1150     4163.73    146.1808   145.6618    0.8519      0.0        0.0    
   1200      4345.3    145.8752   145.6215    0.9987      0.0        0.0    
   1250      4526.8    145.5376   145.4954    1.0011      0.0        0.0    
   1300     4708.15    145.9328   145.522     0.9672      0.0        0.0    
   1350     4889.57    146.1403   145.6187    0.7901      0.0        0.0    
   1400     5071.05    145.9013   145.5122    0.816       0.0        0.0    
   1450     5252.56    146.6447   146.0992    1.0589      0.0        0.0    
   1500     5433.77    146.3167   146.2476    1.2927      0.0        0.0    
   1550     5615.14    146.106    145.8293    0.9465      0.0        0.0    
   1600     5796.62    145.854    145.6082    1.0376      0.0        0.0    
   1650     5978.54    146.3422   146.0305    1.1872      0.0        0.0    
   1700     6160.83    146.4101   145.9072    0.9374      0.0        0.0    
   1750     6342.54    145.2698   144.9889    0.9978      0.0        0.0    
   1800     6523.63    145.3154   145.2388    0.9149      0.0        0.0    
   1850     6704.88    145.8139   145.6333    0.7366      0.0        0.0    
   1900     6886.15     145.85    145.783     1.019       0.0        0.0    
   1950     7067.41    145.9727   145.7185    0.8904      0.0        0.0    
   2000     7248.55    145.6774   145.6553    0.9769      0.0        0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       171.13    290.2659   288.9922    2.8786     4.4721      0.0    
   100       352.33    175.4512   174.3703    2.6916      0.0        0.0    
   150       533.89    158.6565   157.7927    1.6801      0.0        0.0    
   200       715.55    151.124    150.5018    1.5706      0.0        0.0    
   250       897.23    147.4749   147.2273    1.4964      0.0        0.0    
   300      1078.94    147.248    146.5481    1.1566      0.0        0.0    
   350       1260.6    146.6337   146.126     1.1165      0.0        0.0    
   400       1442.3    146.7932   146.2724    1.5835      0.0        0.0    
   450      1623.92    146.8662   146.3349    1.5065      0.0        0.0    
   500      1805.62    146.5413   146.0673     1.23       0.0        0.0    
   550       1987.3    146.401    146.1112    1.2964      0.0        0.0    
   600      2169.08    146.4639   146.2714    1.509       0.0        0.0    
   650      2350.87    146.3985   146.2098    1.5739      0.0        0.0    
   700      2532.53    146.5319   146.173     1.1311      0.0        0.0    
   750      2714.28    146.2044   145.5392    1.1997      0.0        0.0    
   800      2895.84    145.7345   145.6251    1.1205      0.0        0.0    
   850      3077.65    146.2571   145.721     0.9901      0.0        0.0    
   900      3259.36    145.955    145.4033    1.0126      0.0        0.0    
   950      3441.16    145.5426   145.4105    0.813       0.0        0.0    
   1000     3622.92    145.8629   145.473     0.9192      0.0        0.0    
   1050     3804.73    145.6279   145.3521    0.9228      0.0        0.0    
   1100     3986.62    145.9666   145.5592    1.0705      0.0        0.0    
   1150     4168.46    146.3277   146.0436    0.9075      0.0        0.0    
   1200     4350.23    145.5025   145.127     0.9519      0.0        0.0    
   1250     4532.01    145.8309   145.4139    0.7754      0.0        0.0    
   1300      4713.9    145.6484   145.4613    0.9466      0.0        0.0    
   1350     4895.68    145.6079   145.0547    0.9857      0.0        0.0    
   1400     5077.57    145.3898   145.2045    0.8877      0.0        0.0    
   1450     5259.43    146.1419   145.5983    1.0415      0.0        0.0    
   1500     5441.29    145.4684   145.2426    0.6994      0.0        0.0    
   1550     5623.05    145.858    145.2686    0.8715      0.0        0.0    
   1600      5804.9    146.2231   145.7079    0.8347      0.0        0.0    
   1650     5986.59    145.2771   145.2419    0.8139      0.0        0.0    
   1700     6168.43    145.8709   145.6087    0.7549      0.0        0.0    
   1750     6350.17    145.9965   145.5632    0.8688      0.0        0.0    
   1800     6531.81    145.396    144.9753    0.9094      0.0        0.0    
   1850     6713.67    145.5293   145.3984    0.8547      0.0        0.0    
   1900     6895.51    145.3851   144.9494    0.7355      0.0        0.0    
   1950     7077.36    145.0943   144.7074    0.6127      0.0        0.0    
   2000     7259.07    144.9845   144.9573    0.9066      0.0        0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       170.93    284.5703   283.4564    2.755      4.4721      0.0    
   100       352.13    179.1812   178.1401    2.6435      0.0        0.0    
   150       533.94    159.5609   159.0838     2.01       0.0        0.0    
   200       715.79    151.9939   152.0084    1.2501      0.0        0.0    
   250       897.6     148.7638   148.5162    1.0587      0.0        0.0    
   300      1079.54    146.6003   146.8226    0.9376      0.0        0.0    
   350       1261.5    146.7918   146.8648    0.9691      0.0        0.0    
   400      1443.44    145.9391   146.1405    0.8561      0.0        0.0    
   450      1625.48    145.8257   145.8412    1.1627      0.0        0.0    
   500      1807.52    146.2003   146.2723    1.0019      0.0        0.0    
   550      1989.41    146.2828   146.4958    1.2235      0.0        0.0    
   600      2171.56    146.1731   145.9854    1.0086      0.0        0.0    
   650       2353.6    145.9558   145.8674    0.8433      0.0        0.0    
   700      2535.75    145.7844   145.9183    1.2084      0.0        0.0    
   750      2717.73    145.9604   145.9404    1.2882      0.0        0.0    
   800      2899.74    145.2578   145.3743    0.7958      0.0        0.0    
   850      3081.81    146.3645   145.9295    0.9927      0.0        0.0    
   900      3263.82    145.8795   145.973     0.9956      0.0        0.0    
   950      3445.82    145.6981   145.6041    0.9936      0.0        0.0    
   1000     3627.86    145.6836   145.6343    1.2034      0.0        0.0    
   1050     3809.89    145.4112   145.5265    0.9362      0.0        0.0    
   1100     3991.97    145.7514   146.0486    0.9355      0.0        0.0    
   1150     4173.93    145.2682   145.6171    0.8808      0.0        0.0    
   1200     4356.01    144.9753   145.2622    0.9087      0.0        0.0    
   1250     4538.01    145.0325   144.991     0.7167      0.0        0.0    
   1300      4720.0    145.9947   146.068     0.8307      0.0        0.0    
   1350     4902.02    145.8489   146.1053    1.3649      0.0        0.0    
   1400     5084.06    145.7787   145.8319    1.1301      0.0        0.0    
   1450     5266.05    145.2528   145.3856    0.8547      0.0        0.0    
   1500     5448.06    145.6501   145.6706    0.8486      0.0        0.0    
   1550     5630.11    145.3236   145.618     0.8532      0.0        0.0    
   1600     5812.04    145.5887   145.4963    0.7098      0.0        0.0    
   1650     5994.07    145.1545   145.3537    0.5613      0.0        0.0    
   1700      6176.1    145.8908   145.5774    0.9026      0.0        0.0    
   1750     6358.05    144.9084    145.2      0.7337      0.0        0.0    
   1800     6540.17    145.5865   145.4972    0.7025      0.0        0.0    
   1850     6722.23    144.9129   145.1973    0.8388      0.0        0.0    
   1900     6904.23    145.3915   145.4726    0.9596      0.0        0.0    
   1950     7086.27    145.2528   145.5517    0.9099      0.0        0.0    
   2000     7268.24    144.8833   145.1974    0.9262      0.0        0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       170.72    285.1432   284.0419    2.6398     4.4721      0.0    
   100       352.74    186.1255   184.6143    2.4241      0.0        0.0    
   150       534.9     162.6336   161.9969    1.6933      0.0        0.0    
   200       717.27    152.9247   152.3795    1.1979      0.0        0.0    
   250       899.67    149.8185   149.3393    1.0048      0.0        0.0    
   300      1082.05     147.31    147.3515    1.2759      0.0        0.0    
   350       1264.4    146.4349   146.3623    1.0958      0.0        0.0    
   400      1446.65    146.3334   146.4244    1.1121      0.0        0.0    
   450      1628.91    145.3935   145.4729    1.1372      0.0        0.0    
   500      1811.11    145.3741   145.4624    0.708       0.0        0.0    
   550      1993.31    145.7505   145.527     0.895       0.0        0.0    
   600      2175.66    144.7529   144.9609    0.9443      0.0        0.0    
   650      2358.11    145.5704   145.5074    0.7902      0.0        0.0    
   700      2540.51    145.265    145.3435    0.8149      0.0        0.0    
   750       2722.9    145.3693   145.4785    0.7911      0.0        0.0    
   800      2905.22    145.4389   145.3744    1.0327      0.0        0.0    
   850      3087.68    145.6437   145.5473    0.9785      0.0        0.0    
   900      3270.03    145.3752   145.5078    0.9531      0.0        0.0    
   950      3452.39    145.4613   145.4712    0.7113      0.0        0.0    
   1000     3634.82    145.6575   145.4153    0.869       0.0        0.0    
   1050     3817.19    145.0246   145.3199    0.8632      0.0        0.0    
   1100     3999.54    145.0978   145.0271    0.7923      0.0        0.0    
   1150     4181.89    145.7285   145.8282    0.9542      0.0        0.0    
   1200     4364.34    144.7472   144.8683    0.8673      0.0        0.0    
   1250     4546.72    144.9623   144.9965    0.6311      0.0        0.0    
   1300     4729.17    145.4675   145.3924    0.5073      0.0        0.0    
   1350     4911.22    145.0578   144.9848    0.709       0.0        0.0    
   1400     5093.19    144.7753   145.0074    0.6298      0.0        0.0    
   1450     5275.33    145.0847   145.1118    0.7661      0.0        0.0    
   1500     5457.47    145.1572   145.0234    0.8401      0.0        0.0    
   1550      5639.5    145.4034   145.2306    0.914       0.0        0.0    
   1600     5821.55    145.0551   145.2187    0.8581      0.0        0.0    
   1650      6003.6    145.3943   145.3664    0.7774      0.0        0.0    
   1700     6185.73    145.3463   145.3636    0.782       0.0        0.0    
   1750     6367.95    144.9846   145.1331    0.7898      0.0        0.0    
   1800      6550.1    145.0866   144.9331    0.7096      0.0        0.0    
   1850     6732.32    144.8522   144.902     0.6235      0.0        0.0    
   1900     6914.52    145.2096   145.1814    0.6548      0.0        0.0    
   1950     7096.62    144.7687   144.7621     0.64       0.0        0.0    
   2000     7278.77    144.7317   144.873     0.6706      0.0        0.0    
