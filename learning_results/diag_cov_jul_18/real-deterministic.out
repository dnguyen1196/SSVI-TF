Generating synthetic  real valued data ... 
Generating synthetic  real valued data took:  6.464718341827393
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50        30.5     372.8156   372.8099    3.1623     1.8524   
   100       61.71     198.3373   197.9371    3.162      0.6916   
   150       92.91     169.219    168.5956    2.8345     0.3624   
   200       124.06    158.1669   157.7982    2.6659     0.2323   
   250       155.18    152.5239   152.1445    2.2051     0.1675   
   300       186.31    150.8465   150.244     1.7761     0.123    
   350       217.58    150.4763   150.8658    1.8256     0.0971   
   400       248.83    151.139    149.7683    1.8167     0.0798   
   450       280.01    148.332    148.3497    1.4876     0.0663   
   500       311.24    149.559    148.574     1.2792     0.055    
   550       342.43    148.3026   148.4427    1.4153     0.0476   
   600       373.56    147.5993   146.9404    1.0991     0.0411   
   650       404.76    147.945    147.7858    1.1677     0.0371   
   700       436.07    148.0979   147.6855    1.3557     0.032    
   750       467.29    146.7642   146.9955    1.1848     0.029    
   800       498.48    147.5066   146.7941    1.2282     0.0264   
   850       529.64    147.6456   147.2242    1.3843     0.0237   
   900       560.78    148.8169   148.4226    1.5737     0.0215   
   950       591.93    147.5136   147.2574    1.4897     0.0195   
   1000      623.08    147.4081   147.0517    1.1018     0.0181   
   1050      654.26    146.6547   146.824     1.0539     0.0168   
   1100      685.44    146.2011   146.3126    1.0494     0.0159   
   1150      716.67    147.2714   146.5652    1.0306     0.0146   
   1200      747.93    147.0021   146.6254    1.0846     0.0136   
   1250      779.17    146.3772   146.2279    0.8928     0.0127   
   1300      810.46    146.6871   146.091     1.0533     0.012    
   1350      841.62    147.2687   146.5984    1.141      0.0112   
   1400      873.17    147.2145   146.6576    1.0973     0.0105   
   1450      904.41    146.5494   146.2734    0.9556      0.01    
   1500      935.84    146.5931   145.9399    1.0073     0.0095   
   1550      967.09    146.184    145.6653     0.9       0.0091   
   1600      998.64    146.0118   146.1823    0.9659     0.0087   
   1650     1030.15    146.6071   145.972     1.0336     0.0082   
   1700     1061.45    146.1864   145.9765    0.8186     0.0077   
   1750     1092.74    146.7721   146.3312    0.9868     0.0074   
   1800     1124.02    146.2909   146.0355    0.9886     0.007    
   1850     1155.31    146.3047   145.9478    0.8088     0.0067   
   1900     1186.49    146.4312   146.1889    0.8581     0.0066   
   1950     1217.71    146.7921   145.9632    0.8417     0.0062   
   2000     1248.92    145.6985   145.5333    0.8127     0.0059   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       30.47     298.7995   298.9345    3.0521     1.2712   
   100       62.48     178.9264   178.2563    2.8894     0.6788   
   150       94.47     161.1336   160.7411    2.3934     0.4467   
   200       126.41    155.1261   154.9811    2.1688     0.3161   
   250       158.43    153.459    153.1344    1.8736     0.2378   
   300       190.43    150.2602   150.0521    1.717      0.1923   
   350       222.44    150.2184   149.7297    1.6822     0.152    
   400       254.4     149.1094   148.4889    1.7646     0.1262   
   450       286.4     148.1617   148.0664    1.2218     0.1063   
   500       318.41    148.3292   148.4773    1.383      0.0898   
   550       350.44    148.6706   148.0455    1.7421     0.0779   
   600       382.46    147.7443   147.7491    1.2285     0.0684   
   650       414.46    147.4139   147.2259    1.131      0.0605   
   700       446.51    147.229    146.7269    1.2827     0.0538   
   750       478.51    146.5178   146.4732    1.2287     0.0482   
   800       510.53    146.647    146.4805    0.727      0.0435   
   850       542.5     146.7336   146.8126    0.7711     0.0382   
   900       574.41    147.6993   147.1413    1.1711     0.0359   
   950       606.33    146.7697   146.8907    1.132      0.0328   
   1000      638.24    146.9526   146.692     1.0992     0.0298   
   1050      670.15    146.9943   146.876     1.0043     0.028    
   1100      702.08    146.5981   146.1461    1.1583     0.0259   
   1150      734.0     146.3419   146.1581    0.9114     0.0238   
   1200      765.93    146.1408   145.9349    0.9832     0.0229   
   1250      797.85    147.3284   146.5975    0.7875     0.0214   
   1300      829.77    146.8061   146.5076    1.0964     0.0195   
   1350      861.72    147.2426   146.8031    1.1816     0.0187   
   1400      893.69    146.6346   146.0939    1.101      0.0173   
   1450      925.69    146.2293   145.799     0.9097     0.0161   
   1500      957.64    146.1501   146.0761    1.1664     0.0151   
   1550      989.57    145.738    145.6926    0.9604     0.0145   
   1600     1021.49    146.3349   145.8247    0.9455     0.0138   
   1650     1053.46    145.628    145.5171    0.9277     0.0127   
   1700     1085.44    146.2671   146.0023    0.6152     0.0132   
   1750     1117.38    146.6917   146.1433    0.9946     0.0119   
   1800     1149.35    146.5212   146.2905    0.7742     0.0112   
   1850      1181.3    146.9384   146.2729    0.9605     0.0107   
   1900     1213.31    146.7294   146.1173    0.9325     0.0102   
   1950     1245.29    145.5395   145.6746    0.8156     0.0099   
   2000     1277.23    146.1598   145.9226    0.8392     0.0095   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       30.39     291.3396   290.4955    2.8838     1.0103   
   100       62.81     177.807    176.6625    2.804      0.5761   
   150        95.3     159.3317   159.0354    1.6648     0.4202   
   200       127.74    153.8053   152.9867    2.0316     0.3148   
   250       160.45    150.4316   150.212     1.6297     0.2539   
   300       192.93    150.3095   149.5429    1.7099     0.2078   
   350       225.51    150.1117   149.8155    1.541      0.1745   
   400       257.99    147.8958   147.6192    1.6915     0.143    
   450       290.41    147.6584   147.1286    1.3898     0.1212   
   500       322.94    147.5547   147.4024    1.3017     0.105    
   550       355.54    147.0371   146.8805    1.3508     0.0925   
   600       388.1     146.9612   146.6113    1.3994     0.0808   
   650       420.61    147.2569   147.0609    1.4172     0.0716   
   700       453.16    146.5682   146.3124    1.2115     0.0653   
   750       485.67    146.8747   146.5447    1.2193     0.058    
   800       518.13    146.6749   146.506     1.0794     0.0523   
   850       550.72    146.1874   145.9883    0.8992     0.0471   
   900       583.24    147.5061    146.82     0.9793     0.0433   
   950       615.72    146.2037   145.878     1.2643     0.0391   
   1000      648.25    146.6908   146.4066    1.1156     0.0373   
   1050      680.81    146.3091    145.94     1.1864     0.0342   
   1100      713.34    146.4588   145.9235    0.9059     0.0318   
   1150      745.86    147.4514   147.013     1.5167     0.0297   
   1200      778.48    146.3659   145.9475    1.2793     0.0275   
   1250      811.01    146.3399   145.9823    0.8963     0.0261   
   1300      843.44    145.6941   145.7467    0.8959     0.024    
   1350      875.92    145.8674   145.6047    0.9994     0.0226   
   1400      908.38    146.4125   145.9259    0.8807     0.0214   
   1450      940.81    146.1218   145.807     0.8211     0.0203   
   1500      973.22    146.1708   145.7184    0.8727     0.0189   
   1550     1005.64    146.5742   145.8734    0.962      0.0183   
   1600     1038.07    145.6868   145.4722    0.8199     0.0172   
   1650     1070.54    145.9925   145.2327    0.7949     0.0167   
   1700     1103.01    145.9106   145.261     1.0173     0.0154   
   1750     1135.43    145.2056   144.8014    0.5916     0.0145   
   1800     1167.95    146.1595   145.5041    0.6677     0.0143   
   1850     1200.37    145.7534   145.3367    0.7417     0.0133   
   1900     1232.84    146.0248   145.5206    0.6479     0.0126   
   1950     1265.29    145.3534   145.3344    0.7519     0.0123   
   2000     1297.67    146.4483   145.7891    0.8365     0.0115   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       30.21     285.5976   285.2236    2.749      0.8601   
   100       62.89     180.836    179.6227    2.5211     0.5091   
   150        95.6     161.0935   160.4557    1.6192      0.4     
   200       128.34    154.5502   153.8582    1.5291     0.3163   
   250       161.03    150.0439   150.3397    1.4194     0.2504   
   300       193.68    148.7148   148.5101    1.3125     0.2098   
   350       226.48    147.5919   147.6446    1.4261     0.1729   
   400       259.2     146.8796   147.3978    1.1646     0.1472   
   450       291.99    147.8897   147.9896    1.2593     0.1282   
   500       324.75    147.3271   147.4605    1.363      0.1129   
   550       357.43    145.9929   146.1667    1.0204     0.1004   
   600       390.12    146.1564   146.0806    0.9516     0.0865   
   650       422.79    145.827    145.8116    0.6782     0.0781   
   700       455.51    145.5759   146.0344    1.1291     0.0707   
   750       488.19    146.2089   146.2826    0.859      0.0647   
   800       520.89    145.5796   145.9749    0.7135     0.0589   
   850       553.53    146.0775   146.2804    0.7814     0.0539   
   900       586.98    145.3203   145.6845    0.7699     0.0498   
   950       620.68    146.0959   146.0262    0.8084     0.0452   
   1000      654.39    145.3429   145.7803    0.8189     0.0414   
   1050      688.1     145.3868   145.751     0.8261     0.0385   
   1100      721.78    145.8503   145.9781    0.741      0.0363   
   1150      755.47    145.6438   145.8065    1.0482     0.0347   
   1200      788.16    146.057    146.1196    1.0538     0.0318   
   1250      820.86    145.1144   145.5987    0.9294     0.0294   
   1300      853.6     145.3046   145.6404    0.7542     0.0282   
   1350      886.27    145.462    145.4424    0.7723     0.0263   
   1400      919.02    145.9011   146.1598    1.0031     0.0246   
   1450      951.71    145.7024   145.744     0.9801     0.0236   
   1500      984.42    145.7034   145.9105    0.7407     0.0224   
   1550     1017.15     146.17    146.032     0.9379     0.0208   
   1600     1049.82    146.3595   146.6356    0.9443     0.0205   
   1650     1082.54    145.3346   145.5861    0.7715     0.0191   
   1700      1115.2    146.1641   146.4531    1.0445     0.0177   
   1750     1147.88    145.8725   146.0174    0.8431     0.0171   
   1800     1180.54    145.7002   145.6142    0.7126     0.0165   
   1850     1213.29    145.218    145.5162    0.7305     0.0158   
   1900     1246.37    145.2999   145.2737    0.7031     0.0153   
   1950     1279.18    145.3148   145.2644    0.6239     0.0143   
   2000     1311.89    145.7372   145.5762    0.5734     0.0137   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       30.29     287.2883   286.1768    2.6772     0.772    
   100       63.75     189.1142   187.4808    2.4601     0.4618   
   150       97.28     163.1813   162.6836    1.7211     0.3738   
   200       130.75    154.2387   153.765     1.0586     0.2987   
   250       164.17    150.3316   150.0922    0.9713     0.246    
   300       197.62    148.3897    147.95     1.025      0.2087   
   350       231.13    147.8365   147.4836    0.8811     0.1786   
   400       264.52    146.7202   146.592     0.883      0.155    
   450       298.08    146.6815   146.6449    0.8878     0.1349   
   500       331.57    145.9999   145.8639    0.7886     0.1174   
   550       365.18    145.7444   145.6858    0.7699     0.1041   
   600       398.61    145.7064   145.7336    0.9887     0.092    
   650       432.06    145.8863   145.5949    0.8773     0.0835   
   700       465.47    145.2174   145.324     0.7395     0.0753   
   750       498.96    146.6873   146.157     0.8258     0.0684   
   800       532.49    145.8223   146.0756    0.7035     0.0642   
   850       566.65    145.5001   145.3937    0.8974     0.0568   
   900       600.83    145.6757   145.5285    0.9437     0.0534   
   950       634.27    146.256    145.9738    0.8182     0.0481   
   1000      667.7     145.7403   145.7024     0.82      0.0452   
   1050      701.12    145.7373   145.5812    1.0807     0.0425   
   1100      734.58    145.3154   145.2711    0.8145     0.0392   
   1150      768.05    146.133    145.9993    0.7771     0.0377   
   1200      801.49    145.7728   145.7922    0.9816     0.0344   
   1250      834.97    145.2521   145.2415    0.7328     0.0321   
   1300      868.39    145.3411   145.4675    0.6215      0.03    
   1350      901.8     145.357    145.6149    0.762      0.0287   
   1400      935.15    145.7741   145.6412    0.6273     0.0266   
   1450      968.52    145.0954   145.2869    0.725      0.0255   
   1500     1002.42    145.4598   145.5651    0.7972     0.0241   
   1550     1036.81    145.4788   145.5196    0.7819     0.0228   
   1600     1071.21    144.7955   144.9973    0.604      0.0214   
   1650     1105.62    145.1339   145.1909    0.7786     0.0205   
   1700     1139.79    145.4625   145.4779    1.1446     0.0196   
   1750     1173.22    145.9636   145.9107    1.0645     0.0187   
   1800     1206.63    145.5073   145.4417    0.9235     0.0181   
   1850     1239.88    145.8707   145.719     0.8604     0.0171   
   1900     1273.13    146.0886   145.8244    0.9689     0.0159   
   1950     1306.35    145.2818   145.5213    0.8333     0.0156   
   2000     1339.59    145.2107   145.2307    0.8651     0.015    
Generating synthetic  real valued data ... 
Generating synthetic  real valued data took:  6.386800765991211
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       125.35    373.5064   373.3549    3.1623     4.4719   
   100       256.21    199.5149   199.6186    3.1622     0.2708   
   150       386.61    167.8248   167.6452    2.7498     0.1084   
   200       516.73    158.3946   158.0223    2.5942     0.1283   
   250       646.82    151.8615   151.5665    2.1371     0.0605   
   300       778.42    151.1766   150.5291    2.1959     0.051    
   350       908.95    150.1188   150.3603    2.1976     0.0245   
   400      1040.03    150.2048    148.86     1.8733     0.0427   
   450      1171.21    147.8019   147.6965    1.5427     0.0217   
   500      1302.17    148.5157   147.6753    1.7946     0.0204   
   550      1432.94    146.9539   146.9519    1.3895     0.0189   
   600      1564.18    146.9539   146.509     1.0484     0.0169   
   650      1694.84    147.738    147.4475    1.0764     0.0133   
   700      1825.67    147.9263   147.6512    1.3617     0.0091   
   750      1956.71    147.0425   147.1068    1.5843     0.0086   
   800      2087.77    147.6143   147.0574    1.1868     0.0099   
   850      2219.86    147.8044   147.3854    1.3762     0.0094   
   900      2351.46    148.5569   148.1819    1.2964     0.0053   
   950      2482.42    147.3967   147.1674    1.2407     0.0065   
   1000      2613.4    147.3769   146.938     1.0271     0.0056   
   1050     2744.28    146.6258   146.7706    1.1347     0.0045   
   1100     2875.09    146.0553   146.2499    0.9971     0.0037   
   1150     3005.68    147.4011   146.6587    1.2184     0.0039   
   1200      3136.5    146.8771   146.5284    1.1264     0.0042   
   1250     3267.74    146.3656   146.2022    0.9579     0.0034   
   1300     3398.48    146.6573   146.1644    0.9477     0.0027   
   1350     3529.71    147.5157   146.7896    1.2471     0.0034   
   1400     3660.22    147.1353   146.666     1.1721     0.0028   
   1450      3791.1    146.7549   146.3996    1.1356     0.0032   
   1500     3921.96    146.5983   146.0829    1.0155     0.0028   
   1550      4052.5    146.2753   145.7502    0.9318     0.0024   
   1600     4183.57    145.985    146.1629    0.9596     0.0022   
   1650      4313.9    146.548    145.9776    1.046      0.002    
   1700     4444.64    146.1604    145.91     0.8283     0.0022   
   1750     4575.45    146.7783   146.3806    0.9915     0.0024   
   1800     4706.65    146.1242   145.8964    1.0065     0.0019   
   1850      4837.5    146.2732   145.873     0.8027     0.0017   
   1900     4968.27    146.5091   146.2684    0.9541     0.0019   
   1950     5099.37    146.8481   146.055     0.9296     0.0016   
   2000     5230.01    145.7796   145.663     0.884      0.0013   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       125.11    297.5675   297.7026    3.0504     4.4679   
   100       257.25    175.4476   175.0753    2.8894     0.5663   
   150       389.84    161.2851   160.7733    2.2919     0.153    
   200       521.9     153.5491   153.285     2.2487     0.0821   
   250       653.38    152.0995   151.7791    1.8042     0.0397   
   300       785.4     149.7646   149.7208    1.8842     0.0308   
   350       917.87    150.1245   149.5433    1.7595     0.0201   
   400      1050.17    149.3658   148.9278    1.777      0.0186   
   450      1182.66    148.4844   148.1747    1.5466     0.0135   
   500      1314.57    148.1183   148.3371    1.4279     0.0125   
   550      1446.28    148.6447   147.9882    1.6187     0.009    
   600      1577.36    147.3644   147.4191    1.2919     0.008    
   650      1709.66    147.0408   146.8878    0.9886     0.0071   
   700      1840.73    147.6762   147.1605    1.1564     0.0062   
   750       1972.6    146.9027   146.8846    1.2683     0.005    
   800      2103.61    146.5746   146.4344    1.207      0.005    
   850      2234.47    146.7356   146.8146    0.771      0.0046   
   900       2365.7    147.3856   146.7834    1.076      0.0042   
   950      2497.64    146.5946   146.6598    1.113      0.0036   
   1000     2628.95    146.8126   146.7146    1.0964     0.0034   
   1050     2760.69    146.8227   146.6673    1.0467     0.0029   
   1100     2892.21    146.669    146.275     1.1159     0.0021   
   1150     3023.33    146.2239   146.1221    0.8516     0.0023   
   1200     3154.27    146.1411   145.8339    0.9975     0.0021   
   1250     3286.17    147.4575   146.6361    0.8363     0.0019   
   1300      3417.7    146.719    146.482     1.0821     0.002    
   1350     3549.05    147.3062   146.8093    1.0198     0.0018   
   1400      3681.1    146.572    146.1411    0.9818     0.0017   
   1450     3812.77    146.5181   146.0835    0.9023     0.0019   
   1500     3943.91    146.0591   146.0173    1.1156     0.0014   
   1550     4075.25    145.7711   145.6656    0.9338     0.0013   
   1600     4207.32    146.4972   145.9774    0.9971     0.0012   
   1650     4338.55    145.4633   145.4298    0.9149     0.0012   
   1700     4469.76    146.0314   145.6947    0.6249     0.0011   
   1750     4601.51    146.5396   146.0836    0.8863     0.0012   
   1800     4732.94    146.5703   146.2601    0.9232     0.001    
   1850     4864.23    146.8489   146.1476    0.9145     0.0009   
   1900     4996.37    146.6366   146.0589    0.8178     0.0009   
   1950     5128.16    145.6205   145.7196    0.8711     0.0007   
   2000      5259.5    146.1264   145.8869    0.8284     0.0008   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       125.32    289.9423   289.0708    2.8862     4.4665   
   100       257.36    175.8394   174.4561    2.8125     0.3347   
   150       389.91    157.9827   157.5502    1.6801     0.1291   
   200       523.21    151.9361   151.2544    1.3229     0.0654   
   250       655.19    149.3553   148.9351    1.2795     0.0481   
   300       787.82    147.9564   147.335     1.3071     0.034    
   350       921.1     148.5971   148.2818    1.4382     0.0236   
   400      1053.39    146.9097   146.6347    1.3969     0.0163   
   450      1185.49    146.7751   146.309     1.071      0.0155   
   500      1317.62    147.2482   147.0687    1.1901     0.0123   
   550      1450.16    146.7648   146.6804    1.4154     0.0099   
   600      1582.07    146.763    146.3434    1.1435     0.0094   
   650      1714.68    147.4541   147.3547    1.3455     0.0082   
   700      1847.14    147.2582   146.8591    1.2639     0.0074   
   750      1978.96    147.1695   146.9056    1.1291     0.0054   
   800      2111.84    146.4666   146.3174    0.9523     0.0049   
   850      2243.98    146.0531   145.8826    0.9794     0.0044   
   900       2376.4    146.9235   146.3174    1.0387     0.0043   
   950      2508.91    146.2699   145.8544    1.0626     0.0039   
   1000     2640.96    147.1603   146.8421    1.3486     0.0034   
   1050     2773.28    146.6163   146.1428    1.2628     0.0027   
   1100     2905.16    146.4979   145.9459    0.869      0.0024   
   1150     3037.35    147.222    146.7575    1.4965     0.0023   
   1200     3169.67    146.236    145.9625    1.2126     0.0024   
   1250     3302.06    146.3917   145.9856    0.8685     0.0022   
   1300     3433.83    145.8166   145.8932    1.0784     0.0019   
   1350     3565.61    146.0482   145.7286    0.9868     0.0019   
   1400     3697.97    146.3791   145.9825    0.847      0.0016   
   1450     3830.53    146.2391   145.9001    0.8086     0.0015   
   1500      3962.5    146.0483   145.6595    0.9224     0.0015   
   1550     4094.83    146.5312   145.816     0.9793     0.0014   
   1600     4226.88    145.554    145.3652    0.8778     0.0012   
   1650     4359.58    146.0952   145.3138    0.7261     0.0012   
   1700     4491.63    145.7796   145.1211    1.0178     0.0012   
   1750     4623.94    145.2001   144.8385    0.6242     0.0011   
   1800     4756.32    146.2602   145.5772    0.7889     0.0011   
   1850     4888.37    145.6384   145.2798    0.7186     0.001    
   1900     5021.05    146.0614   145.5286    0.8206     0.001    
   1950     5152.93    145.3927   145.3606    0.6651     0.0009   
   2000     5285.09    146.4614   145.8475    0.8863     0.0009   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       125.29    284.8412   284.3961    2.7542     4.4658   
   100       257.05    179.6317   178.2816    2.5107     0.2628   
   150       390.51    159.2861   158.7047    1.5816     0.1045   
   200       522.43    152.2047   151.8474    1.5371     0.0562   
   250       655.39    149.375    149.5646    1.3653      0.04    
   300       787.51    147.8707   147.8425    1.1444     0.0309   
   350       920.15    147.1163   147.1539    1.1254     0.0235   
   400      1052.59    146.5952   147.164     1.1628     0.0155   
   450      1184.45    147.4049   147.2216    1.3221     0.0147   
   500      1316.54    146.8163   147.1535    1.1612     0.011    
   550      1449.13    146.3533   146.231     1.2034     0.0098   
   600      1581.95    145.647    145.7965    1.0618     0.0081   
   650      1714.65    145.7415   145.7627    0.6274     0.0066   
   700      1846.84    145.7564   146.2905    1.0073     0.0059   
   750      1978.85    146.3634   146.4095    1.0515     0.0053   
   800      2110.82    145.5264   145.9107    1.0052     0.0046   
   850      2242.96    145.8655   146.0098    0.7618     0.0039   
   900      2375.55    145.3205   145.6539    0.786      0.0037   
   950      2507.79    146.2923   146.1346    0.9652     0.003    
   1000     2639.63    145.4605   145.8865     0.94      0.0031   
   1050     2771.98    145.4007   145.6775    0.7379     0.0026   
   1100     2904.64    145.8797   145.9842    0.8469     0.0026   
   1150      3037.0    145.7804   145.9401    0.9432     0.0021   
   1200     3169.37    145.9315   146.0824    1.0207     0.0019   
   1250     3302.27    145.1426   145.6245    0.9424     0.002    
   1300     3434.57    145.4405   145.7577    0.9608     0.0019   
   1350     3567.38    145.3766   145.4364    0.7954     0.0016   
   1400     3699.94    145.9029   146.263     1.0106     0.0014   
   1450     3832.22    145.7595   145.8339    1.0581     0.0016   
   1500     3965.17    145.5641   145.8487    0.8134     0.0014   
   1550     4097.62    146.1744   146.0587    0.831      0.0013   
   1600     4230.26    146.2711   146.5855    0.9633     0.0013   
   1650     4363.18     145.26    145.5223    0.7751     0.0011   
   1700     4495.63    146.1327   146.4021    1.0561     0.0011   
   1750     4627.71    145.9202   146.1147    0.9217     0.0011   
   1800     4760.35    145.7901   145.7252    0.7411     0.001    
   1850     4893.08    145.1926   145.5197    0.8478     0.0009   
   1900     5025.65    145.2433   145.2751    0.709      0.0009   
   1950     5157.98    145.2427   145.2098    0.6496     0.0009   
   2000      5290.2    145.7292   145.5773    0.5592     0.0008   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       124.09    286.4337   285.2802    2.6801     4.4653   
   100       257.05    186.312    184.7332    2.5058     0.4126   
   150       390.15    162.0426   161.5467    1.2132     0.1424   
   200       523.75    153.0361   152.3355    0.8285     0.0788   
   250       656.94    149.359    149.0708    0.6745     0.0414   
   300       790.37    147.6801   147.2026    0.965      0.0307   
   350       923.59    146.9272   146.6443    1.0241     0.0244   
   400      1056.71    146.3521   146.172     0.8621     0.0178   
   450      1190.64    146.2441   146.1762    0.8562     0.0122   
   500      1323.86    145.3587   145.255     0.7563     0.0135   
   550      1457.26    145.3029   145.3896    0.8505     0.0089   
   600       1590.8    145.243    145.148     0.8245     0.0082   
   650      1724.14    145.707    145.4028    0.7651     0.0069   
   700      1857.26    145.3541   145.5461    0.8851     0.0067   
   750      1991.37    146.0959   145.7618    0.8367     0.0055   
   800      2124.84    145.5203   145.7614    0.8158     0.0046   
   850      2258.09    145.1222   145.0178    0.7629     0.0043   
   900      2391.58    145.3108   145.1687    0.5325     0.0034   
   950      2525.11    145.7741   145.5191    0.697      0.0035   
   1000      2658.5    145.6048   145.5258    0.7133     0.003    
   1050     2791.32    145.7053   145.554     0.9927     0.0029   
   1100     2924.93    145.3406   145.3056    0.8743     0.0024   
   1150     3058.42    146.2814   146.0627    0.8509     0.0023   
   1200     3192.15    145.716    145.737     1.0231     0.0021   
   1250     3325.85    144.981    144.9721    0.7543     0.002    
   1300     3459.39    145.3722   145.4907    0.6579     0.002    
   1350     3593.55    145.2797   145.5097    0.7296     0.0017   
   1400     3727.31    145.9361   145.7451    0.7873     0.0017   
   1450     3860.69    145.1349   145.3855    0.9729     0.0014   
   1500     3994.33    145.6598   145.684     1.0601     0.0014   
   1550     4127.35    145.449    145.5491    0.7869     0.0013   
   1600     4260.63    144.9122   145.0694    0.5926     0.0012   
   1650     4393.74    145.017    145.0845    0.5862     0.0012   
   1700     4527.27    145.2047   145.2093    0.9659     0.0011   
   1750     4660.18    146.037    145.9212    1.0931     0.0011   
   1800     4793.88    145.6262   145.5714     1.02      0.0011   
   1850     4926.41    145.9984    145.88     1.0757     0.001    
   1900     5059.74    146.1075   145.9375    1.0727     0.001    
   1950      5192.8    145.3725   145.5801    0.9809     0.0008   
   2000     5325.74    145.159    145.268     0.8821     0.0008   
