Generating synthetic  real valued data ... 
Generating synthetic  real valued data took:  6.183661937713623
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       29.78     375.0307   374.2975    3.1623     1.8524     0.0001  
   100       60.27     209.0969   209.9185    3.1612     0.6949      0.0    
   150       90.73     170.1773   168.9152    3.1427     0.3681      0.0    
   200       121.15    162.5854   161.5003    2.3458     0.2342      0.0    
   250       151.56    156.5315   155.9675    2.7062     0.1691      0.0    
   300       181.98    154.2845   154.0021    2.0522     0.1271      0.0    
   350       212.47    150.1732   150.5155    1.5748     0.0969      0.0    
   400       243.06    149.9828   149.4786    1.8267     0.0792      0.0    
   450       273.53    149.5399   148.8756    1.8506     0.0658      0.0    
   500       304.03    148.6865   148.5143    1.7111     0.056       0.0    
   550       334.48    148.1332   147.7354    1.3854     0.0472      0.0    
   600       364.85    147.8281   147.4015    1.0741     0.0414      0.0    
   650       395.31    147.7588   148.0708    1.1643     0.0375      0.0    
   700       425.78    149.3829   148.4766    1.4712     0.0324      0.0    
   750       456.32    146.8985   147.0311    1.6125     0.0292      0.0    
   800       486.81    147.6957   146.8955    1.7006     0.0258      0.0    
   850       517.24    146.9393   146.7495    1.4477     0.0236      0.0    
   900       547.63    149.165    148.3243    1.1811     0.0213      0.0    
   950       578.0     147.8062   147.2133    1.3545     0.0195      0.0    
   1000      608.41    147.7529   147.3574    1.1667     0.0182      0.0    
   1050      638.79    147.5055   147.3177    1.3239     0.0166      0.0    
   1100      669.21    147.3672   146.575     1.3325     0.0157      0.0    
   1150      699.65    146.5574   146.4463    1.1009     0.0146      0.0    
   1200      730.2     146.9596   146.3872    1.2118     0.0137      0.0    
   1250      760.64    147.8013   147.2439    1.1717     0.0127      0.0    
   1300      791.2     146.4748   146.1796    1.0426     0.0119      0.0    
   1350      821.6     146.3943   146.2395    1.2124     0.0112      0.0    
   1400      852.16    146.7161   146.4336    1.0353     0.0107      0.0    
   1450      882.88    147.1735   147.1316    1.2783     0.0101      0.0    
   1500      913.31    146.8782   146.4824    1.0703     0.0094      0.0    
   1550      943.96    146.7243   146.236     0.9251     0.009       0.0    
   1600      974.44    146.5909   146.2039    0.7181     0.0085      0.0    
   1650     1005.47    146.666    146.0063    0.932      0.0082      0.0    
   1700     1035.93    146.5762   146.1743    1.2886     0.0077      0.0    
   1750      1066.5    146.3263   146.0501    0.8731     0.0073      0.0    
   1800     1097.01    146.2755   145.7242    1.0883     0.0072      0.0    
   1850     1127.57    146.6804   146.0897    0.9784     0.0069      0.0    
   1900     1158.04    147.4122   146.9328    0.8947     0.0064      0.0    
   1950     1188.45    146.3015   145.9316    0.7769     0.0061      0.0    
   2000     1218.91    145.7913   145.4685    0.5999     0.0061      0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50        29.8     300.3026   300.4223    3.0625     1.2649      0.0    
   100       60.88     178.2969   178.103     2.8082     0.7001      0.0    
   150        92.0     160.4411   160.1631    2.2594     0.4506      0.0    
   200       123.1     154.8941   154.2185    2.2032     0.319       0.0    
   250       154.17    152.5164   152.2173    1.9578     0.2391      0.0    
   300       185.31    151.5923   151.3329    2.0685     0.1898      0.0    
   350       216.44    152.0976   150.9944    1.976      0.1493      0.0    
   400       247.56    150.2502   150.3012    1.5878     0.1258      0.0    
   450       278.68    151.4288   150.9277    2.0365     0.1077      0.0    
   500       309.82    149.0767   148.8897    1.8638      0.09       0.0    
   550       340.97    147.7322   147.832     1.4136     0.0769      0.0    
   600       372.11    148.464    147.9601    1.4133     0.0686      0.0    
   650       403.29    147.8367   147.2777    1.2919     0.0603      0.0    
   700       434.41    146.8419   146.396     0.987      0.0547      0.0    
   750       465.56    148.2036   147.4793    1.0433     0.0486      0.0    
   800       496.71    147.5469   147.4287    0.9976     0.0437      0.0    
   850       527.87    146.0392   146.2332    0.8882     0.0395      0.0    
   900       559.01    147.5866   147.1588    1.2216     0.0359      0.0    
   950       590.06    147.7384   147.3239    1.2324     0.0333      0.0    
   1000      621.12    147.3591   147.0857    1.5874     0.0305      0.0    
   1050      652.16    147.4236   146.8178    1.1506     0.0282      0.0    
   1100      683.23    146.3109   145.7884    0.8402     0.0263      0.0    
   1150      714.3     146.2194   145.8766    1.1401     0.0241      0.0    
   1200      745.35    146.3319   146.3896    0.9617     0.0218      0.0    
   1250      776.4     147.9003   147.6707    1.0319     0.021       0.0    
   1300      807.44    147.6949   147.4387    1.1689     0.0194      0.0    
   1350      838.5     147.3831   147.125     1.0218     0.0182      0.0    
   1400      869.54    146.5706   146.3354    1.1582     0.0166      0.0    
   1450      900.63    147.3041   146.7383    0.9954     0.016       0.0    
   1500      931.73    146.7915   146.5353    1.0119     0.0149      0.0    
   1550      962.83    146.5871   146.2653    1.0147     0.0148      0.0    
   1600      993.91    147.5808   147.224     0.9657     0.0136      0.0    
   1650     1024.98    146.8165   146.6681    1.4941     0.0131      0.0    
   1700     1056.05    146.8263   146.5911    0.9763     0.0126      0.0    
   1750     1087.16    146.7563   146.2435    1.0146     0.0116      0.0    
   1800     1118.24    146.2351   145.9869    0.8671     0.0114      0.0    
   1850     1149.34    146.3879   146.0995    0.793      0.011       0.0    
   1900     1180.44    145.9016   145.6334    1.0804     0.0102      0.0    
   1950     1211.56    145.7083   145.7773    1.0079     0.0097      0.0    
   2000     1242.68    146.2273   146.0644    1.0936     0.0095      0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       29.83     289.1291   287.497     2.9099     1.0132      0.0    
   100       61.51     179.305    177.7077    2.6496     0.578       0.0    
   150       93.13     159.273    158.1709    1.7664     0.4142      0.0    
   200       124.85    152.5194   151.5837    1.4701     0.3155      0.0    
   250       156.6     149.7402   149.2895    1.0136     0.2564      0.0    
   300       188.28    147.8152   147.4398    1.0431     0.2023      0.0    
   350       220.24    147.9904   147.6143    1.5725     0.1726      0.0    
   400       251.98    147.0648   146.9035    1.1631     0.1466      0.0    
   450       283.8     147.596    146.8082    1.0298     0.1245      0.0    
   500       315.57    147.6448   147.4193    1.0858     0.1046      0.0    
   550       347.27    147.4758   147.1167    1.2837     0.0943      0.0    
   600       379.05    147.8806   147.1622    1.4607     0.0812      0.0    
   650       410.87    145.8403   145.5298    1.0022     0.0727      0.0    
   700       442.68    146.7715   146.0416    0.7554     0.0647      0.0    
   750       474.45    146.5381   146.2251    0.8172     0.0587      0.0    
   800       506.27    146.5752   146.029     1.0391     0.0534      0.0    
   850       538.12    147.9899   147.2719    1.1507     0.0473      0.0    
   900       569.9     146.3315   146.3147    1.0873     0.045       0.0    
   950       601.74    146.7613   146.3057    1.1477     0.0406      0.0    
   1000      633.57    146.2802   145.9862    1.0774     0.0379      0.0    
   1050      665.37    146.9029   146.627     1.1517     0.0348      0.0    
   1100      697.23    146.4591   145.976     1.5069     0.0319      0.0    
   1150      729.03    147.5216   146.9414    0.9492     0.0296      0.0    
   1200      760.87    147.0118   146.3197    1.4957     0.0272      0.0    
   1250      792.71    146.3614   146.0565    1.0362     0.0255      0.0    
   1300      824.55    145.4751   145.0746    0.9804     0.0241      0.0    
   1350      856.37    145.4819   145.0293    1.0116     0.0228      0.0    
   1400      888.12    146.3389   145.8994    0.8649     0.0213      0.0    
   1450      919.85     145.75    145.6733    0.9276     0.0204      0.0    
   1500      951.6     146.6748   145.9031    1.2683     0.0191      0.0    
   1550      983.33    146.1801   145.8974    0.8141     0.0178      0.0    
   1600     1015.03    145.9657   145.7061    0.8877     0.0168      0.0    
   1650     1046.71    145.6396   145.1287    0.8082     0.0167      0.0    
   1700      1078.4    145.4803   145.2888    0.7438     0.0156      0.0    
   1750      1110.1    145.4538   144.8804    0.6974     0.0148      0.0    
   1800     1141.83    146.2186   145.6097    0.9762     0.014       0.0    
   1850     1173.54    146.0797   145.5861    1.0904     0.0136      0.0    
   1900     1205.25    146.063    145.7392    0.6432     0.0131      0.0    
   1950     1236.97    146.0578   145.4225    0.759      0.0124      0.0    
   2000     1268.63    146.0574   145.5639    0.8199     0.0116      0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       29.85     281.7612   280.8559    2.7771     0.8674      0.0    
   100       62.17     182.4986   181.5146    2.3946     0.508       0.0    
   150       94.44     160.9906   160.6236    1.6561     0.3872      0.0    
   200       126.85    154.7313   154.8437    1.2398     0.3064      0.0    
   250       159.16    150.9266   150.9411    1.4326     0.2496      0.0    
   300       191.49    148.6355   148.2361    1.6372     0.2055      0.0    
   350       223.87    148.3698   148.9234    1.3111     0.1747      0.0    
   400       256.2     147.3615   147.4031    1.1941     0.1499      0.0    
   450       288.5     147.0042   146.9369    1.2872     0.1293      0.0    
   500       320.9     146.6682   146.874     1.2244     0.1114      0.0    
   550       353.26    146.5536   146.8017    0.9253     0.1019      0.0    
   600       385.7     145.9208   146.1392    1.0464     0.0916      0.0    
   650       418.11    146.1927   146.5767    1.2403     0.0792      0.0    
   700       450.42    146.2329   146.3612    1.1528     0.0717      0.0    
   750       482.79    145.7723   145.8088    0.9326     0.0634      0.0    
   800       515.11    146.2717   146.2874    0.9792     0.0584      0.0    
   850       547.48    146.4962   146.7517    1.0057     0.0537      0.0    
   900       579.78    146.3561   146.2068    0.8759     0.0485      0.0    
   950       612.11    145.8484   146.2492    1.1238     0.0463      0.0    
   1000      644.38    145.7624   145.8158    0.7518     0.0418      0.0    
   1050      677.5     145.1453   145.4891    0.803      0.039       0.0    
   1100      710.9     145.9143   146.2002    1.0656     0.0354      0.0    
   1150      744.3     146.9886   146.8405    1.1092     0.0335      0.0    
   1200      777.7     145.2904   145.6528    0.9326     0.0309      0.0    
   1250      811.1     146.037    146.2421    0.7988     0.0298      0.0    
   1300      844.48    145.8446   145.6704    0.7291     0.0276      0.0    
   1350      876.94    145.7516   145.7862    0.9677     0.0258      0.0    
   1400      909.3     145.8151   145.7601    0.7965     0.0247      0.0    
   1450      941.7     145.3753   145.7177    0.8118     0.0239      0.0    
   1500      973.73    146.2017   145.855     0.821      0.0219      0.0    
   1550     1005.81    145.9119   146.0146    0.7858     0.0208      0.0    
   1600     1037.83    145.5502   145.6631    0.8553     0.0208      0.0    
   1650     1069.84    145.4144   145.4529    0.9129     0.0187      0.0    
   1700     1101.89    146.3673   146.0584    0.7539     0.0186      0.0    
   1750     1133.91    145.2859   145.5605    1.042      0.017       0.0    
   1800     1165.96    145.7351   145.5969    0.8366     0.0164      0.0    
   1850     1197.99    145.4311   145.4392    0.6111     0.0158      0.0    
   1900     1229.99    145.862    146.1403    0.7366     0.0147      0.0    
   1950     1261.99    145.4777   145.5722    0.9836     0.0146      0.0    
   2000     1294.05    145.5399   145.6824    0.786      0.0136      0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       29.72     289.1078   287.5459    2.6468     0.7712      0.0    
   100       62.73     190.7171   189.5362    2.6203     0.4562      0.0    
   150       95.35     164.4573   163.6858    1.2348     0.3601      0.0    
   200       127.99    154.3222   154.195     1.3359     0.3027      0.0    
   250       160.67    150.915    150.5529    1.1071     0.2416      0.0    
   300       193.44    149.2154   148.9957    1.1161     0.2059      0.0    
   350       226.15    147.5234   147.2427    1.2023     0.1782      0.0    
   400       258.82    147.4025   147.4152    1.0637     0.1523      0.0    
   450       291.53    147.8744   147.5896    1.3484     0.1327      0.0    
   500       324.27    146.5361   146.4287    1.5653     0.1162      0.0    
   550       356.96    146.4148   146.1224    1.1131     0.104       0.0    
   600       389.76    146.5448   146.5065    1.1702     0.0939      0.0    
   650       422.41    145.7805   145.7272    0.822      0.085       0.0    
   700       455.2     145.787    145.8199    0.7611     0.0758      0.0    
   750       487.91    145.3172   145.4608    0.7343     0.0685      0.0    
   800       520.56     145.18    145.1597    0.7099     0.0623      0.0    
   850       553.19    145.4029   145.3365    1.0095     0.0578      0.0    
   900       585.89    145.0332   145.2228    0.6063     0.0536      0.0    
   950       618.65    145.6721   145.5408    0.5207     0.0484      0.0    
   1000      651.39    145.5827   145.6981    0.6208     0.0449      0.0    
   1050      685.0     145.1485   145.3801    0.6036     0.0416      0.0    
   1100      718.15    145.8273   145.8063    0.8163     0.039       0.0    
   1150      750.78    144.7528   144.8672    0.9152     0.0363      0.0    
   1200      783.43    145.5563   145.5082    0.6247     0.0345      0.0    
   1250      816.17    145.5864   145.5571    0.5787     0.0334      0.0    
   1300      848.85    145.6434   145.5679    0.5745     0.0309      0.0    
   1350      881.58    145.2454   145.2824    0.7125     0.0281      0.0    
   1400      914.21    144.9606   145.1736    0.5696     0.0269      0.0    
   1450      946.89    145.3134   145.3068    0.6851     0.0262      0.0    
   1500      979.5     145.2894    145.32     0.8871     0.0242      0.0    
   1550     1012.14    145.3096   145.2028    0.9013     0.0227      0.0    
   1600     1044.77    145.5268   145.7362    0.9716     0.0218      0.0    
   1650     1077.37    145.499    145.3731    0.8452     0.0204      0.0    
   1700      1110.5    145.9604   146.0604    0.9857     0.0198      0.0    
   1750     1144.13    145.9262   145.757     1.2499     0.0186      0.0    
   1800     1177.75    144.9782   145.041     0.7931     0.0178      0.0    
   1850     1211.39    145.5183   145.5055    0.6476     0.0173      0.0    
   1900     1244.94    145.4008   145.4469    0.891      0.0163      0.0    
   1950     1277.62    145.4306   145.4703    0.8415     0.0158      0.0    
   2000     1310.32    145.501    145.4059    1.131      0.015       0.0    
Generating synthetic  real valued data ... 
Generating synthetic  real valued data took:  6.484760999679565
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       125.37    374.8893   374.1494    3.1623     4.4719     0.0001  
   100       256.77    207.3954   208.3424    3.1618     0.3001      0.0    
   150       388.76    173.9327   172.8013    3.0743     0.1877      0.0    
   200       519.89    161.7229   160.6904    2.8246     0.1478      0.0    
   250       651.2     155.8758   156.0619    2.1492     0.1103      0.0    
   300       781.78    153.8565   153.0644    1.9318     0.0461      0.0    
   350       912.6     149.241    149.8133    1.7477     0.0263      0.0    
   400      1043.69    151.1031   150.4564    1.656      0.018       0.0    
   450      1173.97    150.2249   149.6781    2.293      0.0224      0.0    
   500      1304.48    149.5322   149.2472    1.7269     0.0195      0.0    
   550      1435.77    147.9841   147.8655    1.4985     0.0121      0.0    
   600      1566.44     147.78    147.1694    1.1261     0.0104      0.0    
   650      1696.22    148.0817   148.2596    1.2415     0.0076      0.0    
   700      1827.32    149.3228   148.5251    1.3988     0.0092      0.0    
   750      1958.04    147.3288   147.3348    1.3695     0.0094      0.0    
   800      2088.65    148.0903   147.4655    1.3606     0.0068      0.0    
   850      2219.95    147.1436   147.0048    1.2275     0.0056      0.0    
   900      2350.41    149.1828   148.4084    1.3345     0.0057      0.0    
   950      2481.87    147.4824   146.8715    1.1779     0.0064      0.0    
   1000     2612.85    147.2449   146.8202    1.0825     0.0043      0.0    
   1050     2744.08    147.1926   147.1396    1.1899     0.0045      0.0    
   1100     2874.82    147.4191   146.5299    1.3155     0.004       0.0    
   1150     3005.11    146.1324   146.1363    0.8217     0.0046      0.0    
   1200     3136.37    146.6395   146.0416    1.0936     0.0035      0.0    
   1250     3266.88    147.5832   147.0839    1.114      0.0039      0.0    
   1300     3397.78    146.5909   146.2438    0.9835     0.0027      0.0    
   1350      3528.0    146.4321   146.3231    0.9199     0.0025      0.0    
   1400     3659.13    146.9901   146.6881    1.1317     0.0025      0.0    
   1450     3789.33    146.9641   146.9672    1.2379     0.0023      0.0    
   1500     3919.89    146.8008   146.4119    0.9998     0.002       0.0    
   1550     4050.56     146.67    146.1897    0.9735     0.0027      0.0    
   1600     4180.89    146.416    146.1307    0.8531     0.0018      0.0    
   1650     4311.74    146.5737   145.9535    0.8686     0.0019      0.0    
   1700     4441.93    146.3205   145.9935    1.1224     0.0018      0.0    
   1750     4572.02    146.247    145.9559    0.9275     0.0014      0.0    
   1800     4702.51    146.1963   145.6857    1.1295     0.0016      0.0    
   1850      4833.6    146.6665   146.1055    0.9904     0.0014      0.0    
   1900     4964.43    147.3599   146.8946    0.8628     0.0015      0.0    
   1950     5095.79    146.3285   145.9486    0.8875     0.0015      0.0    
   2000     5227.17    145.7367   145.4198    0.6176     0.0013      0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       126.32    298.4206   298.5488    3.0672     4.4679      0.0    
   100       259.06    177.8279   177.8959    2.8261     0.3764      0.0    
   150       391.54    159.9513   159.6051    2.343      0.1416      0.0    
   200       524.02    154.0894   153.7318    1.9909     0.0628      0.0    
   250       656.42    152.9162   152.2553    2.1468     0.0379      0.0    
   300       788.74    150.521    150.4598    2.0312     0.0275      0.0    
   350       921.1     150.8026   149.6713    1.7594     0.0194      0.0    
   400      1053.55    148.6086   148.7655    1.4139     0.0164      0.0    
   450      1186.38    150.1533   149.414     1.7929     0.0126      0.0    
   500      1319.04     148.55    148.4456    1.532      0.0098      0.0    
   550       1451.4    147.2063   147.543     1.2534     0.0082      0.0    
   600      1583.62    148.6445   148.1234    1.5609     0.0078      0.0    
   650      1715.85    147.6846   147.3104    1.3918     0.0061      0.0    
   700      1848.13    146.7213   146.3046    0.995      0.0057      0.0    
   750      1980.75    147.7239   147.1316    0.9523     0.0039      0.0    
   800      2113.33    147.3874   147.1258    1.0009     0.0041      0.0    
   850      2246.31    145.7618   146.0154    1.0996     0.0039      0.0    
   900      2378.78    147.3133   146.8802    1.1544     0.0034      0.0    
   950      2511.13    147.7767   147.2829    1.2838     0.0028      0.0    
   1000     2643.03    147.7247   147.4594    1.8435     0.0029      0.0    
   1050     2774.49    147.2908   146.7068    1.3046     0.0025      0.0    
   1100     2905.49    146.5669   145.9195    0.9409     0.0021      0.0    
   1150      3037.5    146.0426   145.7485    0.8452     0.0021      0.0    
   1200     3168.57    146.5006   146.4965    0.9399     0.0021      0.0    
   1250     3300.01    147.4629   147.2792    1.0365     0.0018      0.0    
   1300     3431.63    147.5422   147.2179    1.1794     0.0016      0.0    
   1350     3562.97    147.0622   146.8237     0.98      0.0014      0.0    
   1400     3694.78    146.6296   146.3506    1.0801     0.0015      0.0    
   1450     3826.01    147.1356   146.6118    0.9848     0.0012      0.0    
   1500     3957.43    146.7969   146.5141    0.9931     0.0013      0.0    
   1550     4088.86    146.628    146.2772    1.0684     0.0013      0.0    
   1600     4220.85    147.4131   147.0378    0.9005     0.0012      0.0    
   1650     4352.49    146.7998   146.5808    1.4783     0.0011      0.0    
   1700      4483.9    146.7675    146.54     0.9586     0.0009      0.0    
   1750     4615.12    146.8766   146.3067    0.978      0.0012      0.0    
   1800     4746.07    146.288    146.1112    0.8443     0.0009      0.0    
   1850      4877.4    146.3399   146.0992    0.9445     0.0009      0.0    
   1900     5009.36    146.0587   145.7972    1.1953     0.0008      0.0    
   1950     5140.31    145.8185   145.9061    0.8303     0.0007      0.0    
   2000     5272.15    146.3985   146.2079    1.0765     0.0007      0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       124.7     288.338    286.6741    2.9108     4.4666      0.0    
   100       256.28    176.8216   175.5901    2.6711     0.3809      0.0    
   150       388.04    158.0338   156.8848    2.1449     0.1216      0.0    
   200       519.76    150.987    150.3535    1.5685     0.0721      0.0    
   250       651.6     149.2306   148.6323    1.3361     0.0485      0.0    
   300       783.36    147.2499   146.9469    1.064      0.0307      0.0    
   350       915.14    147.7314   147.1325    1.2146     0.0218      0.0    
   400      1047.09    146.6009   146.419     1.095      0.0163      0.0    
   450      1178.81    147.0409   146.3291    1.1801     0.0141      0.0    
   500      1310.84    147.2113   146.9726    1.3101     0.0118      0.0    
   550      1442.51    146.6637   146.3199    1.1539     0.0098      0.0    
   600      1574.06    147.7509   147.0967    1.4011     0.0087      0.0    
   650      1705.92    145.7031   145.4651    0.9928     0.0065      0.0    
   700      1837.98    146.0938   145.4733    0.6928     0.0065      0.0    
   750      1970.11    146.2701   145.8817    0.945      0.0051      0.0    
   800      2101.93    146.6633   146.2034    0.8664     0.0047      0.0    
   850      2234.14    147.6916   147.0973    1.4334     0.0036      0.0    
   900      2365.51    146.2924   146.2489    1.2151     0.0043      0.0    
   950      2497.17    146.504    146.0256    1.2388     0.0035      0.0    
   1000     2628.57    146.0486   145.8563    1.1535     0.003       0.0    
   1050     2760.48    146.5954   146.2752    1.1231     0.0029      0.0    
   1100      2892.2    146.5779   146.1254    1.3813     0.0026      0.0    
   1150     3023.97    147.2666   146.671     1.144      0.0023      0.0    
   1200     3155.65    146.459    145.8947    1.3878     0.0022      0.0    
   1250     3287.73    146.0723   145.7786    0.9417     0.0021      0.0    
   1300     3419.81    145.5581   145.1012    0.8134     0.0018      0.0    
   1350      3551.8    145.5841   145.1191    0.9616     0.0016      0.0    
   1400      3683.4    146.2138   145.9136    0.7114     0.0017      0.0    
   1450     3814.88    145.7687   145.6758    0.954      0.0016      0.0    
   1500      3946.3    146.7529   146.0731    1.3666     0.0014      0.0    
   1550     4077.67    146.3987   146.0733    0.983      0.0014      0.0    
   1600     4209.69    145.9007   145.6788    0.9251     0.0012      0.0    
   1650     4341.31    145.6182   145.1035    0.8752     0.0012      0.0    
   1700     4472.83    145.4819   145.301     0.7549     0.0012      0.0    
   1750      4605.0    145.5457   144.9721    0.7375     0.001       0.0    
   1800     4736.59    146.2191   145.6017    0.9537     0.0011      0.0    
   1850     4868.64    145.8835   145.4552    1.0092     0.0009      0.0    
   1900     5000.52    145.969    145.643     0.6657     0.001       0.0    
   1950     5131.97    146.117    145.4842    0.7377     0.0009      0.0    
   2000     5263.79    146.0001   145.4839    0.7788     0.0008      0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       124.83    280.9537   280.0363    2.7719     4.4658      0.0    
   100       257.73    181.4164   180.3929    2.3456     0.3817      0.0    
   150       391.36    159.8523   159.5265    1.7233     0.1392      0.0    
   200       524.3     152.8141   152.848     1.0771     0.0762      0.0    
   250       656.95    150.2034   150.0225    1.1601     0.0508      0.0    
   300       789.83    147.2633   147.1936    1.4187     0.0367      0.0    
   350       922.3     147.0022   147.3777    1.3141     0.0277      0.0    
   400      1054.37    146.8467   147.0476    1.508      0.0198      0.0    
   450      1186.74    146.8847   146.9258    1.502      0.0149      0.0    
   500      1318.92    146.7766   146.9086    1.3639     0.0135      0.0    
   550       1451.5    146.3212   146.6179    1.3185     0.0101      0.0    
   600      1584.12    145.3766   145.574      1.18      0.009       0.0    
   650      1716.79    145.8368   146.1798    0.8509     0.008       0.0    
   700      1849.04    145.8651   145.9981    1.0663     0.0056      0.0    
   750      1981.39    145.4191   145.4579    0.9291     0.0059      0.0    
   800      2113.62    145.6398   145.6956    1.025      0.005       0.0    
   850      2245.93    145.9773   146.3557    0.8581     0.0049      0.0    
   900      2378.14    146.286    146.1658    0.8135     0.0037      0.0    
   950      2510.76    145.7547   146.1086    1.2633     0.0035      0.0    
   1000     2642.82    145.7264   145.7528    0.8714     0.0035      0.0    
   1050     2775.72    144.974    145.3149    0.8635     0.0031      0.0    
   1100     2908.35    145.8763   146.1579    1.0337     0.003       0.0    
   1150     3041.46    146.8339   146.709     1.0332     0.0026      0.0    
   1200     3174.03    145.4586   145.7998    0.9782     0.0024      0.0    
   1250     3306.96    145.9071   146.0791    0.7928     0.002       0.0    
   1300     3439.72    145.7418   145.6787    0.7334     0.0019      0.0    
   1350     3573.11    145.6758   145.6896    0.7866     0.0017      0.0    
   1400     3706.05    145.8183   145.7744    0.7368     0.0018      0.0    
   1450     3838.66    145.2873   145.648     0.8348     0.0017      0.0    
   1500     3971.18    146.2824   145.9304    0.8249     0.0016      0.0    
   1550     4103.38    145.8927   146.006     0.7404     0.0014      0.0    
   1600     4235.95    145.5276   145.6897    0.7946     0.0013      0.0    
   1650     4368.43    145.4836   145.5037    0.8821     0.0013      0.0    
   1700     4500.61    146.3305   146.0083    0.7463     0.0012      0.0    
   1750     4632.64    145.4049   145.6708    0.8904     0.0011      0.0    
   1800     4765.85    145.7393   145.6548    0.8955     0.0011      0.0    
   1850     4898.06    145.5962   145.5481    0.6437     0.0011      0.0    
   1900     5030.95    145.7655   146.0261    0.815      0.001       0.0    
   1950     5163.37    145.4425   145.4996    0.9896     0.0009      0.0    
   2000     5296.31    145.7637   145.8953    0.8651     0.0009      0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
    50       124.4     288.3813   286.8034    2.6519     4.4652      0.0    
   100       257.95    188.5562   187.2671    2.6289     0.3458      0.0    
   150       392.02    163.4834   162.5261    1.3253     0.1484      0.0    
   200       525.26    153.101    152.8583    1.2045     0.0679      0.0    
   250       658.6     149.8225   149.4932    0.8838     0.0518      0.0    
   300       791.49    148.0262   147.8548    0.9741     0.0286      0.0    
   350       925.54    147.2054   146.856     0.9745     0.0203      0.0    
   400      1058.68    146.2515   146.3699    0.9531     0.017       0.0    
   450      1192.34    146.7454   146.5088    1.3647     0.0135      0.0    
   500      1325.71    145.8124   145.782     1.4046     0.0101      0.0    
   550      1459.39    146.0934   145.8644    0.9686     0.0088      0.0    
   600       1593.2    146.5837   146.4731    1.1484     0.0083      0.0    
   650      1726.67    145.7399   145.6548    1.2038     0.0063      0.0    
   700      1860.27    145.5266   145.5108    0.9148     0.0062      0.0    
   750      1993.44    145.2779   145.3591    0.9615     0.0054      0.0    
   800      2126.77    145.1847   145.0754    0.7702     0.0048      0.0    
   850      2259.79    145.363    145.2731    1.0512     0.0041      0.0    
   900      2392.64    145.0031    145.22     0.7374     0.0037      0.0    
   950      2525.52    145.5366   145.3793    0.7211     0.0035      0.0    
   1000     2658.88    145.4518   145.6125    0.6759     0.0029      0.0    
   1050     2791.75    145.1456   145.3909    0.6841     0.0031      0.0    
   1100     2924.48    145.5911   145.5544    0.713      0.0023      0.0    
   1150     3058.03    144.7547   144.9084    0.7849     0.0022      0.0    
   1200     3191.54    145.2149   145.2569    0.6465     0.0022      0.0    
   1250     3325.22    145.3345   145.3866    0.6041     0.002       0.0    
   1300     3458.41    145.7478   145.6593    0.5677     0.0019      0.0    
   1350     3592.81    145.2277   145.2567    0.697      0.0018      0.0    
   1400     3726.24    144.9946   145.1811    0.5466     0.0018      0.0    
   1450     3858.82    145.2511   145.2403    0.6599     0.0016      0.0    
   1500     3991.84    145.2107   145.2505    0.9212     0.0014      0.0    
   1550     4124.14    145.3643   145.2142    0.8702     0.0015      0.0    
   1600     4257.91    145.5283   145.7134    0.9541     0.0012      0.0    
   1650     4391.72    145.4822   145.3846    0.8181     0.0012      0.0    
   1700      4524.5    145.9972   146.0712    0.9943     0.0011      0.0    
   1750     4658.04    145.911     145.71     1.2958     0.0012      0.0    
   1800     4791.69    144.9157   144.9376    0.7536     0.0011      0.0    
   1850     4924.57    145.577    145.5777    0.6314     0.0009      0.0    
   1900     5057.69    145.2868   145.2984    0.8379     0.0009      0.0    
   1950      5191.3    145.4368   145.4449    0.8519     0.0009      0.0    
   2000     5324.39    145.4703   145.414     1.0701     0.0008      0.0    
