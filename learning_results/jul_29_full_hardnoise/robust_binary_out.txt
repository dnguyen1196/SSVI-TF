Generating synthetic binary valued data ... 
Generating synthetic  binary valued data took:  7.053071022033691
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |
0.4051666324 0.421615939    0.04104      0.04444   
Using  0.01  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  0.01
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500       334.53     0.7594     0.1442     0.4427     0.049      1.523      0.0016    8755.15     216.56      0.0    
   1000      842.31     0.786      0.1544     0.1549     0.006      1.0278     0.0008    8927.43     114.93      0.0    
   1500     1341.98     0.7849     0.154      0.0632     0.001      0.8393     0.0005    9235.71     80.89       0.0    
   2000     1867.28     0.7941     0.1576     0.0632     0.001      0.6778     0.0003    9285.09     72.65       0.0    
   2500     2418.16     0.7882     0.1553      0.0        0.0       0.7457     0.0003    9251.14     66.75       0.0    
   3000     2972.47     0.7848     0.154       0.0        0.0       0.6849     0.0002    9234.19      64.5       0.0    
   3500     3475.08     0.7925     0.157       0.0        0.0       0.6547     0.0002    9219.63      62.7       0.0    
   4000     3986.49     0.792      0.1568      0.0        0.0       0.5959     0.0002    9260.16     64.92       0.0    
   4500      4489.7     0.7863     0.1546      0.0        0.0       0.5649     0.0001    9099.66     62.85       0.0    
   5000     4990.26     0.7802     0.1522      0.0        0.0       0.6566     0.0001    9082.04     62.92       0.0    
   5500     5487.14     0.7844     0.1538      0.0        0.0       0.5861     0.0001    9114.32      63.3       0.0    
   6000     5975.88     0.7885     0.1554      0.0        0.0       0.696      0.0001    9148.97     62.63       0.0    
Using  0.02  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  0.01
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500       485.01     0.7662     0.1468     0.5831     0.085      1.3416     0.0031    8345.95     542.75      0.0    
   1000      1185.1     0.7397     0.1368     0.4817     0.058      1.0383     0.0018    7977.48     424.18      0.0    
   1500     1872.78     0.7527     0.1416     0.2898     0.021      0.8538     0.0013    8134.23     296.56      0.0    
   2000     2562.34     0.7606     0.1446     0.0775     0.0015     0.9762     0.0008    8626.28     162.04      0.0    
   2500     3220.47     0.7818     0.1528      0.0        0.0       0.8902     0.0005    9749.23     89.99       0.0    
   3000     3862.23     0.7798     0.152       0.0        0.0       0.7296     0.0004    10487.6     62.85       0.0    
   3500     4502.58     0.7793     0.1518      0.0        0.0       0.621      0.0003    11080.26    50.15       0.0    
   4000     5123.03     0.7823     0.153       0.0        0.0       0.8272     0.0002    11155.09    43.97       0.0    
   4500     5738.73     0.7817     0.1528      0.0        0.0       0.5905     0.0003    11561.71    42.16       0.0    
   5000     6329.16     0.785      0.154       0.0        0.0       0.5108     0.0002    11523.06    38.95       0.0    
   5500     6925.44     0.7787     0.1516      0.0        0.0       0.5296     0.0002    11560.54    38.74       0.0    
   6000     7516.56     0.7824     0.153       0.0        0.0       0.509      0.0002    11403.88    37.65       0.0    
Using  0.05  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  0.01
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500       912.84     0.7611     0.1448     0.7537     0.142      1.4746     0.0069     8238.7    1599.56      0.0    
   1000     2018.63     0.7614     0.1449     0.7589     0.144      0.9295     0.0037    8109.56    1577.14      0.0    
   1500     3089.68     0.7555     0.1427     0.7478     0.1398     0.7088     0.0026    8091.47    1583.82      0.0    
   2000     4171.91     0.7609     0.1448     0.7668     0.147      0.7025     0.002     8082.88    1583.99      0.0    
   2500     5256.06     0.7549     0.1425     0.7499     0.1406     0.6156     0.0016    8126.67    1586.98      0.0    
   3000     6334.32     0.7529     0.1417     0.7579     0.1436     0.5499     0.0013    8133.39    1595.93      0.0    
   3500     7397.83     0.7524     0.1415      0.76      0.1444     0.5251     0.0012    8104.67    1593.27      0.0    
   4000     8453.38     0.7495     0.1404     0.744      0.1384     0.5101     0.001     8091.07    1582.53      0.0    
   4500     9496.65     0.7566     0.1431     0.7647     0.1462     0.5025     0.0009    8145.78    1594.39      0.0    
   5000     10551.06    0.7563     0.143      0.7473     0.1396     0.4416     0.0008    8162.49    1594.59      0.0    
   5500     11588.92    0.7576     0.1435     0.7632     0.1456     0.4347     0.0008    8132.73    1582.61      0.0    
   6000     12621.18    0.7597     0.1443     0.7584     0.1438     0.4341     0.0006    8143.31    1590.64      0.0    
Using  0.1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  0.01
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500      1098.19     0.7612     0.1448     0.7582     0.1437     1.2878     0.0147    8223.61    3237.48      0.0    
   1000     2393.28     0.7487     0.1401     0.7414     0.1374     1.0237     0.0075    8107.27    3196.13      0.0    
   1500     3692.62     0.7597     0.1443     0.743      0.138      1.041      0.0054    8128.49    3199.08      0.0    
   2000     5020.83     0.7528     0.1417     0.7531     0.1418     0.8493     0.0041    8134.66    3194.77      0.0    
   2500      6338.6     0.751      0.141      0.7395     0.1367     1.0705     0.0032     8073.3    3175.67      0.0    
   3000     7624.98     0.7539     0.1421     0.7481     0.1399     0.6656     0.0028    8117.96    3177.61      0.0    
   3500     8920.58     0.7569     0.1432     0.7523     0.1415     0.5725     0.0027    8106.23    3159.91      0.0    
   4000     10207.7     0.756      0.1429     0.7419     0.1376     0.6375     0.0023    8089.32    3174.96      0.0    
   4500     11475.4     0.7617     0.145      0.7422     0.1377     0.6356     0.0019    8109.41    3196.04      0.0    
   5000     12722.62    0.7521     0.1414     0.7483      0.14      0.5475     0.002     8099.79    3172.74      0.0    
   5500     13977.88    0.7483      0.14      0.7459     0.1391     0.5574     0.0017    8063.43    3162.91      0.0    
   6000     15243.06    0.7509     0.141      0.7373     0.1359     0.4802     0.0016    8157.14     3217.5      0.0    
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  0.01
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500       1058.5     0.7499     0.1406     0.7391     0.1366     1.2158     0.0432     8314.6    6572.31      0.0    
   1000     2355.06     0.7532     0.1418     0.7343     0.1348     0.956      0.0257    8283.06    6517.22      0.0    
   1500     3649.04     0.7544     0.1423     0.7404     0.137      0.8592     0.0227    8373.65    6578.31      0.0    
   2000     4928.43     0.7568     0.1432     0.7348     0.135      0.8691     0.0187  