Generating synthetic binary valued data ... 
Generating synthetic  binary valued data took:  6.009849309921265
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |
0.4051666324 0.421615939    0.04104      0.04444   
Using  0.01  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500       291.36     0.7668     0.147      0.7014     0.123      2.6882     1.4347    59046.07   1969.76      0.0    
   1000      703.61     0.7669     0.147      0.7043     0.124      2.111      1.6118    65569.98   2222.24      0.0    
   1500      1138.7     0.7665     0.1469     0.7071     0.125      1.7898     2.867     67389.3    2284.96      0.0    
   2000     1526.59     0.7665     0.1469     0.7071     0.125      1.6274     3.5505    67627.31   2303.29      0.0    
   2500     1990.74     0.7679     0.1474     0.7127     0.127      1.4143     6.7627    67774.88   2309.52      0.0    
   3000     2451.29     0.7679     0.1474     0.7127     0.127      1.3176     5.4471    67880.21   2339.43      0.0    
   3500     2947.69     0.7679     0.1474     0.7127     0.127      1.2566     8.2597    67880.21   2339.43      0.0    
   4000     3391.65     0.7679     0.1474     0.7127     0.127      1.0628     5.5451    67880.21   2339.43      0.0    
   4500     3838.14     0.7679     0.1474     0.7127     0.127      0.9708     9.8217    67880.21   2339.43      0.0    
   5000     4260.12     0.7679     0.1474     0.7127     0.127      0.9677     8.4074    67880.21   2339.43      0.0    
   5500     4675.84     0.7679     0.1474     0.7127     0.127      0.9348     4.4522    67880.21   2339.43      0.0    
   6000     5117.38     0.7679     0.1474     0.7127     0.127      0.8578     9.5948    67880.21   2339.43      0.0    
Using  0.02  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500       389.29     0.7414     0.1374     0.7183     0.129      2.5731     0.6188    51870.84   3909.33      0.0    
   1000      993.19     0.7445     0.1386     0.7169     0.1285     2.1268     0.7235    53762.78   3996.29      0.0    
   1500     1595.11     0.7429     0.138      0.7155     0.128      1.8345     1.2255    56291.35   4285.32      0.0    
   2000      2185.0     0.7416     0.1375     0.7113     0.1265     1.6837     1.5461    56543.87   4283.22      0.0    
   2500      2780.8     0.7391     0.1366     0.7169     0.1285     1.4583     1.5437    56492.76   4300.91      0.0    
   3000     3362.26     0.7438     0.1383     0.7155     0.128      1.4245     2.606     56651.07   4292.62      0.0    
   3500      3918.2     0.7465     0.1393     0.7127     0.127      1.2745     3.0788    56698.75    4291.8      0.0    
   4000     4438.76     0.7442     0.1384     0.7099     0.126      1.1545     3.5851    56727.01   4279.03      0.0    
   4500     4929.73      0.75      0.1406     0.7141     0.1275     1.0516     2.9402    56822.81   4283.58      0.0    
   5000     5454.88     0.7461     0.1392     0.7239     0.131      1.2077     3.936     56897.23   4282.39      0.0    
   5500     5973.77     0.7524     0.1415     0.7183     0.129      1.2584     6.404     57183.59    4296.0      0.0    
   6000     6483.31     0.7519     0.1413     0.7253     0.1315     1.3698     3.3656    57097.66   4311.08      0.0    
Using  0.05  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500       714.85     0.7368     0.1357     0.6717     0.1128     2.7662     0.1718    44220.73   6529.98      0.0    
   1000     1645.59     0.7283     0.1326     0.6356     0.101      2.1841     0.185     51399.18   7813.55      0.0    
   1500     2467.17     0.7282     0.1326     0.6293     0.099      1.8407     0.2108    53406.25   7834.71      0.0    
   2000     3249.89     0.7278     0.1324     0.6337     0.1004     1.6001     0.3453    54920.95   7890.49      0.0    
   2500     4046.27     0.7278     0.1324     0.6203     0.0962     1.4867     0.6126    55645.44   8228.27      0.0    
   3000      4852.1     0.7309     0.1336     0.6248     0.0976     1.3062     0.7331    56466.51   8295.55      0.0    
   3500      5628.3     0.7334     0.1345     0.6306     0.0994     1.2758     0.8541    57312.37   8437.52      0.0    
   4000     6398.85     0.7359     0.1354     0.6312     0.0996     1.1996     0.4828    57729.96   8577.53      0.0    
   4500     7172.66     0.7388     0.1364     0.6344     0.1006     1.0967     1.6203    58123.8    8591.81      0.0    
   5000     7942.71     0.7409     0.1372     0.6337     0.1004     1.0507     0.2922    58531.26   8649.43      0.0    
   5500     8715.29     0.7401     0.1369     0.635      0.1008     1.0031     0.5866    58438.68   8614.02      0.0    
   6000     9474.21     0.7403     0.137      0.6369     0.1014     0.9108     0.8173    58338.35   8498.82      0.0    
Using  0.1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500       812.05     0.7272     0.1322     0.5933     0.088      2.6951     0.0794    24307.35    4286.6      0.0    
   1000      1839.0     0.7084     0.1254     0.5817     0.0846     2.5554     0.0659    45887.83   11523.42     0.0    
   1500     2840.49     0.6985     0.122      0.5621     0.079      2.247      0.0659    47902.8    11750.73     0.0    
   2000     3810.07     0.7001     0.1225     0.5571     0.0776     2.0699     0.0924    50364.03   12388.45     0.0    
   2500     4781.14     0.6934     0.1202     0.5474     0.0749     2.4101     0.0939    49967.28   12122.67     0.0    
   3000     5726.08     0.6948     0.1207     0.551      0.0759     1.7477     0.1099    50921.87   12708.09     0.0    
   3500     6663.02     0.6913     0.1195     0.5503     0.0757     1.5981     0.1058    50918.89   12542.79     0.0    
   4000     7613.27     0.6893     0.1188     0.5359     0.0718     1.8993     0.1536    50961.0    12091.12     0.0    
   4500      8564.6     0.6936     0.1203     0.5452     0.0743     1.5235     0.0948    52462.69   12585.34     0.0    
   5000     9521.03     0.6959     0.1211     0.5426     0.0736     1.3683     0.0977    52337.29   12533.33     0.0    
   5500     10477.84    0.7018     0.1231     0.5488     0.0753     1.3136     0.1234    53326.67   12715.32     0.0    
   6000     11431.44    0.6952     0.1208     0.543      0.0737     1.2438     0.0883    52741.95   12578.34     0.0    
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  |   dw   |
   500       784.56     0.6789     0.1152     0.5767     0.0832     2.0507     0.0625    7138.56    3999.02      0.0    
   1000      1857.4     0.6688     0.1118     0.5233     0.0684     1.9647     0.0427    8160.28    3317.97      0.0    
   1500     2911.11     0.6921     0.1198     0.5863     0.086      2.8356     0.0502    24708.67   10293.76     0.0    
   2000     3962.36     0.6754     0.114      0.5758     0.0829     2.5431     0.051   