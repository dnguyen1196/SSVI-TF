Generating synthetic binary valued data ... 
Generating synthetic  binary valued data took:  6.475630760192871
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |
0.4051666324 0.421615939    0.04104      0.04444   
Using  0.01  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  
   500       286.09     0.768      0.1474     0.7043     0.124      2.5334     1.4409    57103.61   1919.75   
   1000      571.33     0.7671     0.1471     0.7043     0.124      2.0853     2.0156    66357.9    2224.79   
   1500      885.7      0.7664     0.1468     0.7071     0.125      1.8692     1.9576    67597.8    2285.88   
   2000     1232.35     0.7679     0.1474     0.7127     0.127      1.6765     5.2158    67640.8    2305.39   
   2500     1512.51     0.7679     0.1474     0.7127     0.127      1.5172     6.6488    67851.69    2310.9   
   3000     1878.84     0.7679     0.1474     0.7127     0.127      1.312      5.1834    67880.21   2339.43   
   3500     2233.04     0.7679     0.1474     0.7127     0.127      1.2107    11.0922    67880.21   2339.43   
   4000      2566.3     0.7679     0.1474     0.7127     0.127      1.1588     4.9004    67880.21   2339.43   
   4500     2951.36     0.7679     0.1474     0.7127     0.127      1.0399     8.0182    67880.21   2339.43   
   5000     3312.08     0.7679     0.1474     0.7127     0.127      0.9653    12.4566    67880.21   2339.43   
   5500     3661.66     0.7679     0.1474     0.7127     0.127      0.8982     12.219    67880.21   2339.43   
   6000     3995.25     0.7679     0.1474     0.7127     0.127      0.8577     7.1933    67880.21   2339.43   
Using  0.02  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  
   500       424.63     0.746      0.1391     0.7225     0.1305     2.6284     0.5843    51597.27   3875.71   
   1000      957.77     0.7357     0.1353     0.6957     0.121      2.1072     0.6545    52780.62   3899.18   
   1500     1481.94     0.743      0.138      0.7071     0.125      1.8336     1.1297    53172.06   3906.54   
   2000     1988.64     0.7428     0.1379     0.7127     0.127      1.6141     1.5999    55916.47   4274.13   
   2500     2478.52     0.7378     0.1361     0.7099     0.126      1.4519     1.2387    55685.35   4248.97   
   3000     2975.55     0.7398     0.1368     0.7211      0.13      1.3923     2.8208    56436.28   4320.89   
   3500      3476.9     0.7407     0.1372     0.7197     0.1295     1.2368     2.4069    56450.22   4333.86   
   4000      3964.2     0.7496     0.1405     0.7183     0.129      1.3102     3.2165    56908.47   4385.36   
   4500     4417.79     0.742      0.1376     0.7211      0.13      1.3772     4.6769    56710.33   4353.24   
   5000     4886.88     0.7422     0.1377     0.7239     0.131      1.197      2.3849    56689.26   4367.53   
   5500     5346.96     0.7435     0.1382     0.7253     0.1315     1.3844     4.0651    57444.72    4408.6   
   6000     5775.03     0.7439     0.1384     0.7239     0.131      1.0263     4.3792    58188.48   4520.32   
Using  0.05  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  
   500       744.64     0.7304     0.1334     0.6548     0.1072     2.7333     0.1807    46412.37   6589.07   
   1000      1566.7     0.7248     0.1313     0.6248     0.0976     2.2096     0.1612    52686.94   7598.27   
   1500     2395.17     0.7315     0.1338     0.6093     0.0928     1.9491     0.216     55337.54    7509.6   
   2000     3175.71     0.7368     0.1357     0.6112     0.0934     1.6261     0.2927    56498.29   7590.88   
   2500     3930.37     0.7355     0.1352     0.6119     0.0936     1.493      0.3492    57598.85    7864.8   
   3000     4650.59     0.7363     0.1355     0.6158     0.0948     1.3661     0.4739    58019.4    8041.19   
   3500     5360.26     0.7394     0.1367     0.6171     0.0952     1.2548     0.8837    58663.34   8019.58   
   4000     6075.21     0.7409     0.1372     0.6223     0.0968     1.1588     0.5033    59223.32   8176.38   
   4500     6806.95     0.7418     0.1376     0.6242     0.0974     1.1094     0.3696    59384.86   8174.27   
   5000      7500.7     0.7408     0.1372     0.6235     0.0972     1.0244     0.592     59343.06   8256.12   
   5500     8188.14     0.7403     0.137      0.6242     0.0974     1.0466     0.6282    59254.8    8251.05   
   6000      8889.5     0.7417     0.1375     0.619      0.0958     0.949      0.6617    59381.07   8258.93   
Using  0.1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  
   500       843.59     0.704      0.1239     0.5772     0.0833     1.7827     0.0698    7291.08    1965.17   
   1000     1841.67     0.7317     0.1338     0.6271     0.0983     2.8451     0.0661    37511.26   9441.25   
   1500     2814.33     0.7146     0.1277     0.6037     0.0911     2.4053     0.0837    47583.65   12777.81  
   2000     3753.03     0.6927      0.12      0.5875     0.0863     2.2514     0.0743    47620.69   12808.18  
   2500     4679.05     0.684      0.117      0.5506     0.0758     1.8756     0.1143    47368.11   11758.62  
   3000     5597.95     0.6893     0.1188     0.551      0.0759     1.7806     0.1095    48595.14   12188.46  
   3500     6508.08     0.6904     0.1192     0.5532     0.0765     1.6551     0.1012    50017.72   12727.3   
   4000     7421.41     0.6821     0.1163     0.5596     0.0783     1.5586     0.1067    49002.98   12730.01  
   4500      8318.6     0.6861     0.1177     0.5404     0.073      1.3119     0.1083    49561.65   12189.89  
   5000     9212.51     0.6967     0.1214     0.5499     0.0756     1.3477     0.0994    51811.96   12605.58  
   5500     10106.72    0.6983     0.1219     0.5492     0.0754     1.6823     0.107     52358.07   12816.87  
   6000     10980.54    0.692      0.1197     0.5448     0.0742     1.2104     0.1036    51391.52   12733.55  
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|  d_mean  |   d_cov  | test_nll | train_nll  
   500       802.14     0.6878     0.1183     0.5838     0.0852     2.6043     0.0745    6636.93    4410.32   
   1000     1768.99     0.6518     0.1062     0.5284     0.0698     1.6163     0.0299    6215.61    3601.26   
   1500     2741.14     0.6536     0.1068     0.4942     0.061      1.4878     0.025     6197.31    3168.25   
   2000     3677.09     0.6584     0.1084     0.504      0.0635     1.4028     0.0259    6997.49    3075.89   
   2500     4594.43     0.7207     0.1298     0.6174     0.0953     2.8002     0.0326    21608.16   9375.61   
   3000     5521.23     0.6795     0.1154     0.5819     0.0846     2.6495     0.0466    38407.31   20394.42  
   3500     6440.72     0.6609     0.1092     0.569      0.0809     2.5666     0.0394    41777.96   23068.98  
   4000      7359.1     0.646      0.1043     0.5374     0.0722     1.9492     0.0612    40649.66   21549.05  
   4500     8270.84     0.6454     0.1041     0.5299     0.0702     1.6675     0.0586  