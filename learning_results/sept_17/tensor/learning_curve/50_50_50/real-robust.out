Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  8.300543546676636
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
    0.0          0.0          0.0          0.0       287494.79    1149836.49 
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.38    9982.4061    0.998    10010.7398   0.9981     3.1623     4.4274   17362.6238 1.947876664914943e+17 287823.14   11512.93   -11519.0  -11512.925   6.529       0.0    
    10       61.86    9972.9812    0.9971   10000.3392   0.997      3.1623     4.4274   252772.8389 2.8435369505798385e+18 287823.14   11512.93   -11520.0  -11512.925   6.792       0.0    
    25       125.37   9953.5207    0.9951   9981.6901    0.9952     3.1623     4.4274   667551.8639 7.766921735483948e+18 287823.14   11512.93   -11520.0  -11512.925   7.263       0.0    
   500       395.2    4345.9727    0.4238   4372.6146    0.4255     1.8859      0.0     17987936.6396 4.680283908336858e+20 287823.14   11512.93   -11594.0  -11512.925   80.677      0.0    
   1000      688.98    476.9913    0.0376    436.4226    0.0336     0.3247      0.0     1222764.1505 2.900435894047161e+17 264276.35   10314.64   -11008.0  -10922.311   85.447      0.0    
   1500      967.34    290.4028    0.0233    246.4835    0.0197     0.0873      0.0     283720.1178 2.3557856181081828e+16 249272.83   9707.13    -10631.0  -10544.605   86.048      0.0    
   2000     1249.58    263.4023    0.0211    220.9643    0.0178     0.0326      0.0     116491.5541 1.3528286965525846e+16 245254.96   9462.16    -10444.0  -10358.027   86.214      0.0    
   2500     1536.01    259.1256    0.0208    215.8689    0.0175     0.0144      0.0     65574.4523 1.1762503502637058e+16 244556.36   9497.64    -10609.0  -10522.917   86.264      0.0    
   3000     1819.54    258.3197    0.0207    213.7557    0.0173     0.0101      0.0     51254.2492 1.1220196651841672e+16 244834.58    9536.0    -10586.0  -10499.762   86.28       0.0    
   3500     2104.75    258.0481    0.0207    212.1641    0.0172      0.01       0.0     47883.2018 1.0817593931476068e+16  244666.0   9477.42    -10557.0  -10470.967   86.285      0.0    
   4000     2390.49    257.8549    0.0207    210.6903    0.0171     0.0099      0.0     46621.9616 1.0506314838201162e+16 244211.82    9530.3    -10554.0  -10467.703   86.286      0.0    
   4500     2672.29    257.714     0.0207    209.2534    0.017      0.0097      0.0     46064.4617 1.0278436660965692e+16 244256.83   9463.13    -10565.0  -10478.409   86.287      0.0    
   5000     2956.77    257.542     0.0207    207.8369    0.0169     0.0096      0.0     45670.621  9932333012274694.0 244119.78   9452.73    -10466.0  -10380.062   86.288      0.0    
   5500     3242.22    257.4433    0.0207    206.4374    0.0167     0.0095      0.0     45230.3544 9689009590004722.0 244359.81   9476.68    -10516.0  -10430.068   86.289      0.0    
   6000     3524.09    257.3032    0.0207    205.0522    0.0166     0.0094      0.0     45019.4288 9458137518856800.0 243749.86   9531.49    -10479.0  -10392.865   86.289      0.0    
   6500     3808.32    257.1232    0.0206    203.6801    0.0165     0.0093      0.0     44656.9249 9220358852321584.0 244265.48   9379.04    -10493.0  -10406.314   86.288      0.0    
   7000     4091.05    256.9921    0.0206    202.3199    0.0164     0.0094      0.0     44277.8483 8973766323804532.0 244056.83   9353.47    -10470.0  -10384.015   86.289      0.0    
   7500     4374.29    256.8419    0.0206    200.9708    0.0163     0.0092      0.0     43883.7251 8745744911062920.0 244238.11   9445.57    -10454.0  -10367.609   86.289      0.0    
   8000     4658.37    256.7589    0.0206    199.6306    0.0162     0.0093      0.0     43798.0872 8522756819383502.0 244056.64   9461.81    -10501.0  -10415.169   86.29       0.0    
   8500     4936.16    256.6389    0.0206     198.3      0.0161     0.0092      0.0     43416.6775 8350734620736083.0 243811.48   9376.82    -10519.0  -10432.299   86.291      0.0    
   9000     5218.83    256.5968    0.0206    196.9765    0.016      0.0091      0.0     43041.7692 8096056722012576.0 243856.02   9419.22    -10415.0  -10329.037   86.292      0.0    
   9500     5497.34    256.4804    0.0206    195.6609    0.0159     0.0093      0.0     43098.8897 7948725024250108.0 243749.13   9422.42    -10387.0  -10300.961   86.293      0.0    
  10000     5778.58    256.4001    0.0206    194.3515    0.0158     0.0091      0.0     42469.7316 7701202735684503.0 243651.28   9328.72    -10500.0  -10413.275   86.294      0.0    
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.89    9979.8358    0.9978   9981.2521    0.9978     3.1623     4.4274   78754.1869 4.0776972608181075e+17 287823.14   23025.85   -23034.0  -23025.851   7.831       0.0    
    10       68.42    9969.5947    0.9968   9971.1631    0.9968     3.1623     4.4274   511687.9497 5.342548762684378e+18 287823.14   23025.85   -23034.0  -23025.851   8.073       0.0    
    25       141.46   9948.7204    0.9946   9950.3011    0.9946     3.1623     4.4274   1402687.4227 1.6030105200435995e+19 287823.14   23025.85   -23034.0  -23025.851   8.417       0.0    
   500       602.68   4292.3402    0.4177    4295.498    0.4179     1.9066      0.0     35552207.6805 8.905855955346665e+20 287823.14   23025.85   -23107.0  -23025.851   81.083      0.0    
   1000     1087.22    466.5113    0.0365    449.4032    0.035      0.3886      0.0     2455221.5855 6.568058961183553e+17 263091.26   20906.45   -22074.0  -21988.42    85.573      0.0    
   1500     1575.25    271.0728    0.0218    252.8414    0.0205     0.1114      0.0     540774.2884 4.676812256316666e+16 247318.94   19707.12   -21266.0  -21180.163   86.134      0.0    
   2000     2063.28    250.819     0.0202    232.2343    0.0189     0.0385      0.0     185247.8204 3.047077297196243e+16 243201.23   19344.56   -21176.0  -21090.159   86.301      0.0    
   2500     2551.73    248.8946     0.02     229.3262    0.0186     0.0143      0.0     98537.4932 2.8721039102148884e+16 242947.62   19204.14   -21131.0  -21044.235   86.36       0.0    
   3000     3039.57    248.6259     0.02     228.2093    0.0185     0.0065      0.0     79970.4346 2.8252643242596948e+16 243325.01   19290.03   -21050.0  -20964.014   86.381      0.0    
   3500     3528.13    248.4285     0.02     227.3085    0.0184     0.0057      0.0     76140.4724 2.7823664111902956e+16 242765.31   19198.77   -20957.0  -20871.002   86.39       0.0    
   4000      4017.6    248.2289     0.02     226.4448    0.0184     0.0057      0.0     74781.0104 2.7337296353566544e+16 242985.81   19311.29   -21019.0  -20932.241   86.393      0.0    
   4500     4504.27    248.0379    0.0199    225.5943    0.0183     0.0057      0.0     74112.1526 2.7109481873092964e+16 242697.49   19136.73   -21093.0  -21006.791   86.394      0.0    
   5000     4993.89    247.816     0.0199    224.7551    0.0182     0.0056      0.0     73427.803  2.660824076576546e+16 242611.45   19189.48   -21046.0  -20959.986   86.395      0.0    
   5500     5485.18    247.6503    0.0199    223.925     0.0181     0.0056      0.0     72970.8008 2.6325298794489172e+16 242565.59   19083.79   -20950.0  -20863.19    86.396      0.0    
   6000     5976.85    247.4622    0.0199    223.1035    0.0181     0.0055      0.0     72379.2448 2.58456494749893e+16  242678.5   19060.55   -20989.0  -20902.477   86.396      0.0    
   6500     6466.25    247.2807    0.0199    222.2907    0.018      0.0055      0.0     72077.5498 2.5624609388902092e+16 242867.61   19094.51   -21022.0  -20935.312   86.397      0.0    
   7000     6955.83    247.0935    0.0199    221.485     0.0179     0.0056      0.0     71506.1036 2.5181625127303684e+16 242756.32   19041.83   -21109.0  -21022.629   86.397      0.0    
   7500     7446.39    246.9201    0.0198    220.6861    0.0179     0.0055      0.0     71166.1063 2.4876214176124836e+16 242673.81   19048.47   -21051.0  -20964.121   86.398      0.0    
   8000     7936.18    246.7332    0.0198    219.8945    0.0178     0.0054      0.0     70913.5959 2.457559449323296e+16 242207.63   19120.12   -20920.0  -20833.857   86.399      0.0    
   8500     8424.88    246.5904    0.0198    219.1087    0.0177     0.0054      0.0     70470.9299 2.4194953773766576e+16 242286.84   19122.3    -21024.0  -20937.907   86.399      0.0    
   9000     8912.63    246.4152    0.0198    218.3288    0.0177     0.0054      0.0     70259.2532 2.3889870660659064e+16 242326.54   19138.2    -20946.0  -20859.103   86.399      0.0    
   9500     9402.34    246.2596    0.0198    217.5542    0.0176     0.0054      0.0     69636.7411 2.358113287634579e+16 242683.47   18992.91   -21064.0  -20977.284    86.4       0.0    
  10000     9890.99    246.1061    0.0198    216.7848    0.0176     0.0053      0.0     69343.7156 2.3271950102804336e+16 242495.86   19034.51   -21028.0  -20941.22     86.4       0.0    
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.08    9980.5841    0.9978   9978.1699    0.9979     3.1623     4.4274   162108.574 9.894907783601594e+17 287823.14   57564.63   -57572.0  -57564.627   7.518       0.0    
    10       92.21    9970.4698    0.9968   9968.0592    0.9969     3.1623     4.4274   1236751.8576 1.2841494888450652e+19 287823.14   57564.63   -57572.0  -57564.627   7.764       0.0    
    25       194.46   9949.9034    0.9948   9947.3675    0.9948     3.1623     4.4274   3431807.2054 3.831710801738048e+19 287823.14   57564.63   -57573.0  -57564.627   8.096       0.0    
   500      1261.38   4303.8269    0.4187   4306.0676    0.4193     1.8795      0.0     88922311.4153 2.2309446368609755e+21 287823.14   57564.63   -57645.0  -57564.627   80.305      0.0    
   1000     2387.61    438.7436    0.0345    432.4062    0.0341     0.3187      0.0     6190508.0962 1.2699786980998444e+18 261639.32   52380.63   -54828.0  -54742.469   85.229      0.0    
   1500      3518.9    257.7883    0.0207    253.4479    0.0205     0.0809      0.0     1201719.0716 1.1372996916087782e+17 244409.87   48925.46   -52860.0  -52774.257   85.993      0.0    
   2000     4652.06    243.6258    0.0195    238.9839    0.0192     0.026       0.0     360200.4836 8.596125019690562e+16 241674.95   48213.73   -52643.0  -52556.997   86.226      0.0    
   2500     5786.17    242.4276    0.0194    237.3226    0.0191     0.0081      0.0     184920.6008 8.297644612688363e+16 241631.78   48042.58   -52600.0  -52513.251   86.302      0.0    
   3000     6921.76    242.1345    0.0194    236.6802    0.0191     0.0051      0.0     155437.5792 8.204182198593774e+16 241937.67   48101.58   -52468.0  -52381.654   86.327      0.0    
   3500     8056.31    241.908     0.0194    236.1368    0.019      0.005       0.0     150102.6207 8.142388506525899e+16 241410.05   48381.6    -52444.0  -52358.027   86.335      0.0    
   4000     9190.74    241.6738    0.0194    235.609     0.019      0.005       0.0     148438.4192 8.062035430900846e+16 242057.08   48085.96   -52476.0  -52389.666   86.337      0.0    
   4500     10326.25   241.4506    0.0194    235.0886    0.0189     0.005       0.0     147583.543 7.987417273042888e+16 241612.19   47939.54   -52491.0  -52404.269   86.339      0.0    
   5000     11459.29   241.2301    0.0194    234.5748    0.0189     0.0049      0.0     146237.655 7.928496588014462e+16 241589.86   47853.6    -52726.0  -52639.965   86.339      0.0    
   5500     12593.97   241.0183    0.0193    234.0673    0.0188     0.0049      0.0     145615.9439 7.859655157610854e+16 241253.05   48036.26   -52451.0  -52364.608   86.339      0.0    
   6000     13727.65   240.8122    0.0193    233.5655    0.0188     0.0048      0.0     144161.7237 7.779456584684293e+16 241721.76   47782.33   -52674.0  -52587.542   86.34       0.0    
   6500     14861.27   240.5995    0.0193    233.0691    0.0188     0.0049      0.0     143456.6996 7.72592601542467e+16 241206.19   47939.18   -52663.0  -52576.921   86.339      0.0    
   7000     15995.91   240.3915    0.0193    232.5779    0.0187     0.0048      0.0     142855.7591 7.66827546198547e+16 241409.39   47903.51   -52602.0  -52516.083   86.339      0.0    
   7500     17129.86   240.1856    0.0193    232.0917    0.0187     0.0048      0.0     141850.2424 7.588702240578245e+16 241917.52   47899.94   -52341.0  -52255.128   86.339      0.0    
   8000     18265.19   239.9956    0.0193    231.6103    0.0187     0.0048      0.0     141153.5689 7.540325941080555e+16 241303.39   47868.74   -52350.0  -52263.974   86.339      0.0    
   8500     19400.28   239.7925    0.0192    231.1333    0.0186     0.0047      0.0     140146.8493 7.471993094952456e+16 241331.87   47851.08   -52450.0  -52364.056   86.34       0.0    
   9000     20536.81   239.5964    0.0192    230.6608    0.0186     0.0047      0.0     139553.6461 7.407950417981715e+16  241408.1   47853.42   -52291.0  -52204.168   86.339      0.0    
   9500     21675.44    239.41     0.0192    230.1923    0.0185     0.0047      0.0     138883.2003 7.35124619421963e+16 241303.61   47892.15   -52227.0  -52141.064   86.339      0.0    
  10000     22810.92   239.2214    0.0192    229.7277    0.0185     0.0046      0.0     138283.9237 7.288976201235275e+16  241557.9   47822.7    -52392.0  -52305.363   86.339      0.0    
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.62    9981.2843    0.9979   9986.6489    0.9979     3.1623     4.4274   329319.9547 2.0425258423190382e+18 287823.14  115129.25  -115138.0  -115129.255   8.656       0.0    
    10       115.78   9971.3853    0.9969   9976.8814    0.9969     3.1623     4.4274   2393369.9785 2.415406887970092e+19 287823.14  115129.25  -115138.0  -115129.255   8.771       0.0    
    25       243.68   9951.2361    0.9949   9956.5779    0.9949     3.1623     4.4274   6690547.6809 7.332886681491715e+19 287823.14  115129.25  -115138.0  -115129.255   8.984       0.0    
   500      1603.07   4320.7479    0.4213   4329.8151    0.422      1.8734      0.0     178316859.7392 4.509765398386357e+21 287823.14  115129.25  -115210.0  -115129.255   81.215      0.0    
   1000     3040.72    428.1502    0.0336    429.815     0.0336     0.354       0.0     12186371.5157 2.7552234300703135e+18 261168.23  104461.04  -109531.0  -109444.87   85.672      0.0    
   1500     4484.09    254.9135    0.0205    253.9406    0.0205     0.0938      0.0     2415833.9801 2.327182257370333e+17 244018.57   97890.03  -105750.0  -105663.878   86.116      0.0    
   2000     5930.24    242.4027    0.0195    240.3672    0.0194     0.0258      0.0     908060.0311 1.6760832253611235e+17 242059.47   97021.76  -105673.0  -105586.333   86.213      0.0    
   2500     7374.12    241.4717    0.0194    238.9931    0.0193     0.0227      0.0     744942.646 1.702819592963448e+17 241976.49   96997.66  -105629.0  -105543.235   86.246      0.0    
   3000     8824.41    241.1886    0.0194    238.5504    0.0193     0.0194      0.0     702959.5674 1.627575465480502e+17 241998.91   96642.05  -105500.0  -105413.588   86.246      0.0    
   3500     10270.03   240.9941    0.0194    238.1963    0.0193     0.0204      0.0     719437.1405 1.653917996016347e+17 241738.65   96671.47  -105436.0  -105350.038   86.264      0.0    
   4000     11716.14   240.774     0.0194    237.8401    0.0193     0.0229      0.0     680915.4954 1.6661412271207552e+17 241902.22   96731.47  -105620.0  -105533.749   86.252      0.0    
   4500     13160.61   240.705     0.0194    237.4856    0.0192     0.0202      0.0     646692.8268 1.638950539263779e+17 242085.49   96677.39  -105494.0  -105407.824   86.246      0.0    
   5000     14607.96   240.3616    0.0194    237.1357    0.0192     0.0206      0.0     630269.1911 1.5943773968622864e+17 241621.77   96682.64  -105145.0  -105059.124   86.256      0.0    
   5500     16053.48   240.038     0.0193    236.7855    0.0192     0.0167      0.0     639581.33  1.5886040459754288e+17 242030.81   96397.89  -105153.0  -105066.375   86.263      0.0    
   6000     17500.58   239.852     0.0193    236.4559    0.0191     0.0223      0.0     698872.2935 1.573271392326076e+17 241234.52   96734.98  -105533.0  -105446.511   86.261      0.0    
   6500     18947.13   239.7442    0.0193    236.1224    0.0191     0.0248      0.0     652783.46  1.600649733265645e+17 241692.67   96672.23  -105073.0  -104986.286   86.254      0.0    
   7000     20395.28   239.6113    0.0193    235.7937    0.0191     0.0177      0.0     670744.5473 1.545493028084367e+17 241517.85   96660.81  -105169.0  -105082.34   86.259      0.0    
   7500     21839.62   239.2438    0.0193    235.4507    0.0191     0.0155      0.0     659442.6853 1.5488994339587587e+17 241448.44   96669.55  -105104.0  -105018.126   86.251      0.0    
   8000     23285.81   239.0882    0.0193    235.1428    0.019      0.0174      0.0     668961.5277 1.5718142619796643e+17 241679.44   96342.31  -104981.0  -104894.711   86.254      0.0    
   8500     24731.37   238.9996    0.0193    234.8253    0.019      0.0206      0.0     663352.6105 1.5351320927800474e+17 241678.15   96649.76  -105189.0  -105102.445   86.246      0.0    
   9000     26180.2    238.5523    0.0192    234.5059    0.019      0.0194      0.0     668238.2624 1.5586584121947363e+17 241736.61   96449.75  -105526.0  -105439.594   86.242      0.0    
   9500     27625.9    238.534     0.0192    234.201     0.019      0.0197      0.0     685568.8878 1.5349517948548186e+17 241438.86   96584.33  -105166.0  -105080.174   86.233      0.0    
  10000     29069.56   238.2518    0.0192    233.8771    0.0189     0.0185      0.0     698145.0414 1.5264982505003462e+17 241202.45   96259.68  -105256.0  -105169.826   86.233      0.0    
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.63    9980.4003    0.9978   9978.2717    0.9979     3.1623     4.4274   1056292.0324 4.112856266593876e+18 287823.14  230258.51  -230264.0  -230258.509    5.4        0.0    
    10       150.15   9970.3498    0.9968   9968.0585    0.9968     3.1623     4.4274   5394750.5261 5.334943050168881e+19 287823.14  230258.51  -230264.0  -230258.509   5.719       0.0    
    25       313.22   9949.8646    0.9948   9947.5352    0.9948     3.1623     4.4274   14059706.4338 1.537830817026103e+20 287823.14  230258.51  -230265.0  -230258.509   6.264       0.0    
   500      1712.42   4315.9653    0.4207   4315.1111    0.4207     1.8837      0.0     355889176.1499 8.950280019408437e+21 287823.14  230258.51  -230339.0  -230258.509   80.921      0.0    
   1000      3183.8    431.6359    0.0338    431.3101    0.0339     0.3219      0.0     24595056.5298 4.995991702248545e+18  260602.7  209421.59  -219040.0  -218954.78   85.519      0.0    
   1500     4667.23    256.039     0.0205    253.3265    0.0203     0.0831      0.0     5337638.8204 4.6135346881170656e+17 243510.73  194422.07  -211296.0  -211209.5    86.066      0.0    
   2000     6152.34    244.0711    0.0196    240.9792    0.0194     0.0319      0.0     1954139.5421 3.613384491827655e+17 242233.73  192817.31  -210384.0  -210298.169   86.184      0.0    
   2500     7642.33    243.0299    0.0195    239.8116    0.0193     0.0241      0.0     1695429.807 3.392096686960003e+17 242396.02  193015.16  -209860.0  -209774.227   86.233      0.0    
   3000     9136.04    242.6798    0.0195    239.4262    0.0193     0.0257      0.0     1733356.1284 3.396459853866403e+17 242023.15   192693.9  -210220.0  -210134.075   86.247      0.0    
   3500     10622.53   242.4756    0.0195    239.1221    0.0193     0.0257      0.0     1732097.5719 3.401968915296156e+17  242110.8  192426.31  -210310.0  -210223.707   86.24       0.0    
   4000     12111.16   242.2202    0.0195    238.8001    0.0192     0.028       0.0     1719949.3573 3.258701681457603e+17 242122.07  192339.47  -210014.0  -209927.974   86.236      0.0    
   4500     13596.68   241.9622    0.0195    238.5259    0.0192     0.033       0.0     1707278.0817 3.326173755400463e+17 242269.16  192529.79  -209964.0  -209877.593   86.23       0.0    
   5000     15082.67   241.7157    0.0194    238.2407    0.0192     0.0255      0.0     1688280.5159 3.353998270748828e+17 241948.94   192454.8  -210370.0  -210283.38   86.24       0.0    
   5500     16568.7    241.4799    0.0194    237.9273    0.0192     0.027       0.0     1794124.6578 3.363893852942199e+17 241781.75  192692.63  -210261.0  -210175.157   86.22       0.0    
   6000     18054.23   241.167     0.0194    237.6511    0.0191     0.0294      0.0     1827871.9678 3.2469764468032915e+17 241781.63   192192.4  -210222.0  -210135.33   86.229      0.0    
   6500     19540.79   241.0866    0.0194    237.378     0.0191     0.0282      0.0     1818433.2081 3.409936292215997e+17 241849.09  192129.91  -210290.0  -210203.488   86.236      0.0    
   7000     21025.69   240.8174    0.0194    237.1142    0.0191     0.0267      0.0     1744568.1495 3.285850854634735e+17 241598.12  192459.16  -209733.0  -209646.853   86.236      0.0    
   7500     22509.76   240.7856    0.0194    236.8277    0.0191     0.0302      0.0     1693169.0004 3.258833497517507e+17  241910.9  192447.32  -210075.0  -209988.666   86.234      0.0    
   8000     23998.56   240.5288    0.0193    236.5368    0.019      0.0269      0.0     1876599.5316 3.177450257124806e+17 241502.06   192710.3  -209954.0  -209867.836   86.245      0.0    
   8500     25483.62   240.1054    0.0193    236.2827    0.019      0.0294      0.0     1752919.519 3.2006824027502624e+17 241748.18   192092.0  -210390.0  -210303.582   86.233      0.0    
   9000     26970.34   239.9329    0.0193    236.0111    0.019      0.0281      0.0     1759020.2908 3.2381089357935475e+17  241417.3  192235.35  -209776.0  -209689.717   86.219      0.0    
   9500     28458.73   239.7307    0.0193    235.7455    0.019      0.0325      0.0     1862144.38 3.319356323672433e+17 241702.32  191916.54  -209788.0  -209701.332   86.227      0.0    
  10000     29950.84   239.4599    0.0193    235.4797    0.019      0.0343      0.0     1924576.4744 3.235184911820829e+17 241960.73  191924.22  -209929.0  -209842.678   86.235      0.0    
Using  0.5  of training data 
Using  0.5 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.63    9982.1597    0.998    9981.8865    0.998      3.1623     4.4274   2786668.1029 9.450256467125975e+18 287823.14  575646.27  -575655.0  -575646.273   8.308       0.0    
    10       252.82   9972.5709    0.9971   9972.1244    0.997      3.1623     4.4274   13184535.6601 1.2479025978593722e+20 287823.14  575646.27  -575655.0  -575646.273   8.447       0.0    
    25       520.41    9952.937    0.9951   9952.4544    0.995      3.1623     4.4274   33678414.821 3.59553563627076e+20 287823.14  575646.27  -575655.0  -575646.273   8.704       0.0    
   500       2033.4   4358.2515    0.4246   4354.0283    0.4242     1.8987      0.0     893293701.8736 2.3009349553028973e+22 287823.14  575646.27  -575727.0  -575646.273   80.634      0.0    
   1000     3623.97    449.2589    0.0346    447.6266    0.0346     0.3665      0.0     59755376.927 1.5520707722284775e+19 261193.82  522614.85  -547518.0  -547432.408   85.492      0.0    
   1500     5222.68    258.1123    0.0206    257.4931    0.0206     0.1081      0.0     12402423.2973 1.2918545694321257e+18 244244.11  489019.48  -528690.0  -528604.291   86.117      0.0    
   2000     6823.42    241.6727    0.0194    241.3631    0.0194     0.0352      0.0     5990122.9934 9.057656562644214e+17 242332.05   483390.9  -527241.0  -527155.196   86.294      0.0    
   2500     8425.49    240.363     0.0193    240.075     0.0193     0.0347      0.0     5551487.5462 8.705724760131754e+17 242057.91  483489.11  -525766.0  -525679.488   86.334      0.0    
   3000     10026.19   239.8445    0.0193    239.6305    0.0193     0.0296      0.0     5282564.1177 8.621997625631648e+17 242036.63  482724.95  -526646.0  -526559.422   86.352      0.0    
   3500     11626.88   239.5909    0.0193    239.3522    0.0193     0.0277      0.0     5186339.3562 8.554455376300022e+17 242371.51  483684.78  -525743.0  -525656.574   86.354      0.0    
   4000     13225.99   239.4329    0.0193    239.1262    0.0193     0.0269      0.0     4662415.4222 8.570177681018241e+17 241492.06  482508.04  -526295.0  -526208.712   86.349      0.0    
   4500     14828.56   239.2813    0.0193    238.8486    0.0192     0.0353      0.0     4853233.3024 8.550273754657546e+17 241947.33  482394.77  -526596.0  -526510.113   86.353      0.0    
   5000     16436.95   238.899     0.0192    238.5966    0.0192     0.0401      0.0     5356159.0281 8.858092037056142e+17 241814.57  482014.04  -526025.0  -525938.949   86.357      0.0    
   5500     18038.8    238.7456    0.0192    238.3183    0.0192     0.0228      0.0     4703374.8024 8.13975143677251e+17 242060.41  482896.61  -526738.0  -526651.735   86.355      0.0    
   6000     19644.96   238.4295    0.0192    238.0939    0.0192     0.0328      0.0     5337713.0732 8.650385940558792e+17  241486.9  482972.16  -526352.0  -526265.489   86.362      0.0    
   6500     21245.98   238.3092    0.0192    237.8175    0.0192     0.0282      0.0     4907756.925 8.493445107502839e+17 241628.71  482220.71  -525601.0  -525514.793   86.36       0.0    
   7000     22855.12   238.2647    0.0192    237.6408    0.0191     0.0357      0.0     5186667.912 8.582117529278812e+17 241732.65  482091.73  -524998.0  -524911.809   86.363      0.0    
   7500     24459.43   237.9868    0.0192    237.3818    0.0191     0.0311      0.0     4797576.2724 8.408435234045066e+17 241740.59   481937.2  -525623.0  -525536.915   86.355      0.0    
   8000     26067.97   237.693     0.0191    237.0859    0.0191     0.0298      0.0     4500143.4569 8.294601716037734e+17 241799.37  481635.17  -525998.0  -525911.495   86.357      0.0    
   8500     27675.93   237.4147    0.0191    236.9024    0.0191     0.0311      0.0     4678318.001 8.220224438720404e+17 241550.03  482397.17  -525705.0  -525618.988   86.349      0.0    
   9000     29285.41   237.3056    0.0191    236.6415    0.0191     0.0311      0.0     4907962.2841 8.076143022862312e+17 241940.97  481927.24  -525297.0  -525210.784   86.343      0.0    
   9500     30893.61   237.1172    0.0191    236.4196    0.019      0.0353      0.0     4512966.6056 8.118140385589652e+17 241699.04  481806.28  -524830.0  -524743.453   86.348      0.0    
  10000     32501.36   236.7707    0.019     236.1725    0.019      0.0263      0.0     4899283.1949 8.146602783750396e+17 241679.86  481664.37  -525694.0  -525607.543   86.361      0.0    
Using  1  of training data 
Using  1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.75     9979.451    0.9977   9976.6638    0.9977     3.1623     4.4274   6698789.1998 2.0747906685346e+19 287823.14  1151292.55 -1151301.0 -1151292.546   8.091       0.0    
    10       424.96   9969.0447    0.9967   9966.0631    0.9967     3.1623     4.4274   28283832.7027 2.667839938883439e+20 287823.14  1151292.55 -1151301.0 -1151292.546   8.284       0.0    
    25       867.09   9947.9418    0.9946   9944.8542    0.9945     3.1623     4.4274   71521078.0887 7.828637430635048e+20 287823.14  1151292.55 -1151301.0 -1151292.546   8.555       0.0    
   500      2560.46   4291.9521    0.4179   4286.0605    0.4175     1.8887      0.0     1775186982.3375 4.411473836041873e+22 287823.14  1151292.55 -1151373.0 -1151292.546   80.619      0.0    
   1000     4341.84    450.627     0.0351    450.6469    0.0351     0.382       0.0     120309110.3436 3.4033057334583325e+19 261968.92  1047381.23 -1095918.0 -1095832.254   85.436      0.0    
   1500     6130.36    257.976     0.0206    258.2594    0.0207     0.1064      0.0     26165542.0938 2.588683546643466e+18 244098.55  976037.23  -1057492.0 -1057405.995   86.095      0.0    
   2000     7923.85    242.0026    0.0194    242.0318    0.0194     0.0433      0.0     12302961.0483 1.8113261198075343e+18 241487.82  965562.06  -1052206.0 -1052120.063   86.268      0.0    
   2500     9718.57    240.6599    0.0193    240.6445    0.0193     0.0299      0.0     10052309.2339 1.8980970112156733e+18  241636.8  964853.86  -1051145.0 -1051058.781   86.31       0.0    
   3000     11509.97   240.395     0.0193    240.3439    0.0193     0.0316      0.0     11025004.4394 1.818483384976373e+18 241898.65  963676.12  -1050964.0 -1050877.873   86.32       0.0    
   3500     13303.29   240.2217    0.0193    240.0712    0.0193     0.0269      0.0     10091352.9526 1.7721699657091766e+18 241672.46  964793.75  -1051079.0 -1050992.673   86.335      0.0    
   4000     15098.16   239.9543    0.0193    239.8229    0.0193     0.0349      0.0     9761259.2911 1.7851095348627116e+18 241620.37  964461.89  -1051514.0 -1051428.145   86.337      0.0    
   4500     16890.9    239.7456    0.0192    239.5567    0.0192     0.0304      0.0     10372663.6442 1.712096810287101e+18  241428.7  964032.86  -1052014.0 -1051927.751   86.35       0.0    
   5000     18683.18   239.6041    0.0192    239.3146    0.0192     0.0363      0.0     9885029.1409 1.7827438219348457e+18 241261.86  964768.59  -1051064.0 -1050977.234   86.338      0.0    
   5500     20474.44   239.2413    0.0192    239.038     0.0192     0.0318      0.0     10207121.0458 1.772352838542363e+18 241272.36  963805.61  -1051287.0 -1051200.714   86.344      0.0    
   6000     22268.65   239.1179    0.0192    238.8042    0.0192     0.0373      0.0     10109360.3208 1.735307931177468e+18  241385.1  963221.11  -1051315.0 -1051228.642   86.339      0.0    
   6500     24065.6    238.7966    0.0192    238.5694    0.0192     0.0309      0.0     9805640.1564 1.7196773370862428e+18  241104.6  963797.62  -1050387.0 -1050301.167   86.325      0.0    
   7000     25856.92   238.6575    0.0192    238.3351    0.0191     0.0284      0.0     9874861.9624 1.6448484366937172e+18 241346.03  963564.77  -1051153.0 -1051066.765   86.323      0.0    
   7500     27651.3    238.331     0.0191    238.0548    0.0191     0.0299      0.0     8356905.0905 1.706392978993055e+18 241225.67  963529.37  -1051964.0 -1051877.369   86.324      0.0    
   8000     29448.43   238.2177    0.0191    237.8587    0.0191     0.034       0.0     9968065.1218 1.6523678759358205e+18 241622.43  962993.31  -1051083.0 -1050997.01   86.324      0.0    
   8500     31239.13   237.9044    0.0191    237.6132    0.0191     0.0331      0.0     10075197.3687 1.7174801754823503e+18 241169.94  963005.81  -1050544.0 -1050458.063   86.311      0.0    
   9000     33036.01   237.7605    0.0191    237.3912    0.0191     0.0345      0.0     9868121.1423 1.659952929607246e+18 241223.23  963708.72  -1049287.0 -1049200.208   86.309      0.0    
   9500     34834.33   237.4311    0.0191    237.1417    0.019      0.0352      0.0     10307669.5868 1.6996555980464177e+18  240799.6  962307.04  -1050762.0 -1050675.793   86.319      0.0    
  10000     36635.36   237.3152    0.0191    236.9479    0.019      0.0265      0.0     9938840.4797 1.7107806137239508e+18 240997.87  963113.25  -1050806.0 -1050719.273   86.321      0.0    
