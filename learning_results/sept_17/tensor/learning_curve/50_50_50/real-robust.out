Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  8.300543546676636
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
    0.0          0.0          0.0          0.0       287494.79    1149836.49 
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.38    9982.4061    0.998    10010.7398   0.9981     3.1623     4.4274   17362.6238 1.947876664914943e+17 287823.14   11512.93   -11519.0  -11512.925   6.529       0.0    
    10       61.86    9972.9812    0.9971   10000.3392   0.997      3.1623     4.4274   252772.8389 2.8435369505798385e+18 287823.14   11512.93   -11520.0  -11512.925   6.792       0.0    
    25       125.37   9953.5207    0.9951   9981.6901    0.9952     3.1623     4.4274   667551.8639 7.766921735483948e+18 287823.14   11512.93   -11520.0  -11512.925   7.263       0.0    
   500       395.2    4345.9727    0.4238   4372.6146    0.4255     1.8859      0.0     17987936.6396 4.680283908336858e+20 287823.14   11512.93   -11594.0  -11512.925   80.677      0.0    
   1000      688.98    476.9913    0.0376    436.4226    0.0336     0.3247      0.0     1222764.1505 2.900435894047161e+17 264276.35   10314.64   -11008.0  -10922.311   85.447      0.0    
   1500      967.34    290.4028    0.0233    246.4835    0.0197     0.0873      0.0     283720.1178 2.3557856181081828e+16 249272.83   9707.13    -10631.0  -10544.605   86.048      0.0    
   2000     1249.58    263.4023    0.0211    220.9643    0.0178     0.0326      0.0     116491.5541 1.3528286965525846e+16 245254.96   9462.16    -10444.0  -10358.027   86.214      0.0    
   2500     1536.01    259.1256    0.0208    215.8689    0.0175     0.0144      0.0     65574.4523 1.1762503502637058e+16 244556.36   9497.64    -10609.0  -10522.917   86.264      0.0    
   3000     1819.54    258.3197    0.0207    213.7557    0.0173     0.0101      0.0     51254.2492 1.1220196651841672e+16 244834.58    9536.0    -10586.0  -10499.762   86.28       0.0    
   3500     2104.75    258.0481    0.0207    212.1641    0.0172      0.01       0.0     47883.2018 1.0817593931476068e+16  244666.0   9477.42    -10557.0  -10470.967   86.285      0.0    
   4000     2390.49    257.8549    0.0207    210.6903    0.0171     0.0099      0.0     46621.9616 1.0506314838201162e+16 244211.82    9530.3    -10554.0  -10467.703   86.286      0.0    
   4500     2672.29    257.714     0.0207    209.2534    0.017      0.0097      0.0     46064.4617 1.0278436660965692e+16 244256.83   9463.13    -10565.0  -10478.409   86.287      0.0    
   5000     2956.77    257.542     0.0207    207.8369    0.0169     0.0096      0.0     45670.621  9932333012274694.0 244119.78   9452.73    -10466.0  -10380.062   86.288      0.0    
   5500     3242.22    257.4433    0.0207    206.4374    0.0167     0.0095      0.0     45230.3544 9689009590004722.0 244359.81   9476.68    -10516.0  -10430.068   86.289      0.0    
   6000     3524.09    257.3032    0.0207    205.0522    0.0166     0.0094      0.0     45019.4288 9458137518856800.0 243749.86   9531.49    -10479.0  -10392.865   86.289      0.0    
   6500     3808.32    257.1232    0.0206    203.6801    0.0165     0.0093      0.0     44656.9249 9220358852321584.0 244265.48   9379.04    -10493.0  -10406.314   86.288      0.0    
   7000     4091.05    256.9921    0.0206    202.3199    0.0164     0.0094      0.0     44277.8483 8973766323804532.0 244056.83   9353.47    -10470.0  -10384.015   86.289      0.0    
   7500     4374.29    256.8419    0.0206    200.9708    0.0163     0.0092      0.0     43883.7251 8745744911062920.0 244238.11   9445.57    -10454.0  -10367.609   86.289      0.0    
   8000     4658.37    256.7589    0.0206    199.6306    0.0162     0.0093      0.0     43798.0872 8522756819383502.0 244056.64   9461.81    -10501.0  -10415.169   86.29       0.0    
   8500     4936.16    256.6389    0.0206     198.3      0.0161     0.0092      0.0     43416.6775 8350734620736083.0 243811.48   9376.82    -10519.0  -10432.299   86.291      0.0    
   9000     5218.83    256.5968    0.0206    196.9765    0.016      0.0091      0.0     43041.7692 8096056722012576.0 243856.02   9419.22    -10415.0  -10329.037   86.292      0.0    
   9500     5497.34    256.4804    0.0206    195.6609    0.0159     0.0093      0.0     43098.8897 7948725024250108.0 243749.13   9422.42    -10387.0  -10300.961   86.293      0.0    
  10000     5778.58    256.4001    0.0206    194.3515    0.0158     0.0091      0.0     42469.7316 7701202735684503.0 243651.28   9328.72    -10500.0  -10413.275   86.294      0.0    
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.89    9979.8358    0.9978   9981.2521    0.9978     3.1623     4.4274   78754.1869 4.0776972608181075e+17 287823.14   23025.85   -23034.0  -23025.851   7.831       0.0    
    10       68.42    9969.5947    0.9968   9971.1631    0.9968     3.1623     4.4274   511687.9497 5.342548762684378e+18 287823.14   23025.85   -23034.0  -23025.851   8.073       0.0    
    25       141.46   9948.7204    0.9946   9950.3011    0.9946     3.1623     4.4274   1402687.4227 1.6030105200435995e+19 287823.14   23025.85   -23034.0  -23025.851   8.417       0.0    
   500       602.68   4292.3402    0.4177    4295.498    0.4179     1.9066      0.0     35552207.6805 8.905855955346665e+20 287823.14   23025.85   -23107.0  -23025.851   81.083      0.0    
   1000     1087.22    466.5113    0.0365    449.4032    0.035      0.3886      0.0     2455221.5855 6.568058961183553e+17 263091.26   20906.45   -22074.0  -21988.42    85.573      0.0    
   1500     1575.25    271.0728    0.0218    252.8414    0.0205     0.1114      0.0     540774.2884 4.676812256316666e+16 247318.94   19707.12   -21266.0  -21180.163   86.134      0.0    
   2000     2063.28    250.819     0.0202    232.2343    0.0189     0.0385      0.0     185247.8204 3.047077297196243e+16 243201.23   19344.56   -21176.0  -21090.159   86.301      0.0    
   2500     2551.73    248.8946     0.02     229.3262    0.0186     0.0143      0.0     98537.4932 2.8721039102148884e+16 242947.62   19204.14   -21131.0  -21044.235   86.36       0.0    
   3000     3039.57    248.6259     0.02     228.2093    0.0185     0.0065      0.0     79970.4346 2.8252643242596948e+16 243325.01   19290.03   -21050.0  -20964.014   86.381      0.0    
   3500     3528.13    248.4285     0.02     227.3085    0.0184     0.0057      0.0     76140.4724 2.7823664111902956e+16 242765.31   19198.77   -20957.0  -20871.002   86.39       0.0    
   4000      4017.6    248.2289     0.02     226.4448    0.0184     0.0057      0.0     74781.0104 2.7337296353566544e+16 242985.81   19311.29   -21019.0  -20932.241   86.393      0.0    
   4500     4504.27    248.0379    0.0199    225.5943    0.0183     0.0057      0.0     74112.1526 2.7109481873092964e+16 242697.49   19136.73   -21093.0  -21006.791   86.394      0.0    
   5000     4993.89    247.816     0.0199    224.7551    0.0182     0.0056      0.0     73427.803  2.660824076576546e+16 242611.45   19189.48   -21046.0  -20959.986   86.395      0.0    
   5500     5485.18    247.6503    0.0199    223.925     0.0181     0.0056      0.0     72970.8008 2.6325298794489172e+16 242565.59   19083.79   -20950.0  -20863.19    86.396      0.0    
   6000     5976.85    247.4622    0.0199    223.1035    0.0181     0.0055      0.0     72379.2448 2.58456494749893e+16  242678.5   19060.55   -20989.0  -20902.477   86.396      0.0    
   6500     6466.25    247.2807    0.0199    222.2907    0.018      0.0055      0.0     72077.5498 2.5624609388902092e+16 242867.61   19094.51   -21022.0  -20935.312   86.397      0.0    
   7000     6955.83    247.0935    0.0199    221.485     0.0179     0.0056      0.0     71506.1036 2.5181625127303684e+16 242756.32   19041.83   -21109.0  -21022.629   86.397      0.0    
   7500     7446.39    246.9201    0.0198    220.6861    0.0179     0.0055      0.0     71166.1063 2.4876214176124836e+16 242673.81   19048.47   -21051.0  -20964.121   86.398      0.0    
   8000     7936.18    246.7332    0.0198    219.8945    0.0178     0.0054      0.0     70913.5959 2.457559449323296e+16 242207.63   19120.12   -20920.0  -20833.857   86.399      0.0    
   8500     8424.88    246.5904    0.0198    219.1087    0.0177     0.0054      0.0     70470.9299 2.4194953773766576e+16 242286.84   19122.3    -21024.0  -20937.907   86.399      0.0    
   9000     8912.63    246.4152    0.0198    218.3288    0.0177     0.0054      0.0     70259.2532 2.3889870660659064e+16 242326.54   19138.2    -20946.0  -20859.103   86.399      0.0    
   9500     9402.34    246.2596    0.0198    217.5542    0.0176     0.0054      0.0     69636.7411 2.358113287634579e+16 242683.47   18992.91   -21064.0  -20977.284    86.4       0.0    
  10000     9890.99    246.1061    0.0198    216.7848    0.0176     0.0053      0.0     69343.7156 2.3271950102804336e+16 242495.86   19034.51   -21028.0  -20941.22     86.4       0.0    
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.08    9980.5841    0.9978   9978.1699    0.9979     3.1623     4.4274   162108.574 9.894907783601594e+17 287823.14   57564.63   -57572.0  -57564.627   7.518       0.0    
    10       92.21    9970.4698    0.9968   9968.0592    0.9969     3.1623     4.4274   1236751.8576 1.2841494888450652e+19 287823.14   57564.63   -57572.0  -57564.627   7.764       0.0    
    25       194.46   9949.9034    0.9948   9947.3675    0.9948     3.1623     4.4274   3431807.2054 3.831710801738048e+19 287823.14   57564.63   -57573.0  -57564.627   8.096       0.0    
   500      1261.38   4303.8269    0.4187   4306.0676    0.4193     1.8795      0.0     88922311.4153 2.2309446368609755e+21 287823.14   57564.63   -57645.0  -57564.627   80.305      0.0    
   1000     2387.61    438.7436    0.0345    432.4062    0.0341     0.3187      0.0     6190508.0962 1.2699786980998444e+18 261639.32   52380.63   -54828.0  -54742.469   85.229      0.0    
   1500      3518.9    257.7883    0.0207    253.4479    0.0205     0.0809      0.0     1201719.0716 1.1372996916087782e+17 244409.87   48925.46   -52860.0  -52774.257   85.993      0.0    
   2000     4652.06    243.6258    0.0195    238.9839    0.0192     0.026       0.0     360200.4836 8.596125019690562e+16 241674.95   48213.73   -52643.0  -52556.997   86.226      0.0    
   2500     5786.17    242.4276    0.0194    237.3226    0.0191     0.0081      0.0     184920.6008 8.297644612688363e+16 241631.78   48042.58   -52600.0  -52513.251   86.302      0.0    
   3000     6921.76    242.1345    0.0194    236.6802    0.0191     0.0051      0.0     155437.5792 8.204182198593774e+16 241937.67   48101.58   -52468.0  -52381.654   86.327      0.0    
   3500     8056.31    241.908     0.0194    236.1368    0.019      0.005       0.0     150102.6207 8.142388506525899e+16 241410.05   48381.6    -52444.0  -52358.027   86.335      0.0    
   4000     9190.74    241.6738    0.0194    235.609     0.019      0.005       0.0     148438.4192 8.062035430900846e+16 242057.08   48085.96   -52476.0  -52389.666   86.337      0.0    
   4500     10326.25   241.4506    0.0194    235.0886    0.0189     0.005       0.0     147583.543 7.987417273042888e+16 241612.19   47939.54   -52491.0  -52404.269   86.339      0.0    
   5000     11459.29   241.2301    0.0194    234.5748    0.0189     0.0049      0.0     146237.655 7.928496588014462e+16 241589.86   47853.6    -52726.0  -52639.965   86.339      0.0    
   5500     12593.97   241.0183    0.0193    234.0673    0.0188     0.0049      0.0     145615.9439 7.859655157610854e+16 241253.05   48036.26   -52451.0  -52364.608   86.339      0.0    
   6000     13727.65   240.8122    0.0193    233.5655    0.0188     0.0048      0.0     144161.7237 7.779456584684293e+16 241721.76   47782.33   -52674.0  -52587.542   86.34       0.0    
   6500     14861.27   240.5995    0.0193    233.0691    0.0188     0.0049      0.0     143456.6996 7.72592601542467e+16 241206.19   47939.18   -52663.0  -52576.921   86.339      0.0    
   7000     15995.91   240.3915    0.0193    232.5779    0.0187     0.0048      0.0     142855.7591 7.66827546198547e+16 241409.39   47903.51   -52602.0  -52516.083   86.339      0.0    
   7500     17129.86   240.1856    0.0193    232.0917    0.0187     0.0048      0.0     141850.2424 7.588702240578245e+16 241917.52   47899.94   -52341.0  -52255.128   86.339      0.0    
   8000     18265.19   239.9956    0.0193    231.6103    0.0187     0.0048      0.0     141153.5689 7.540325941080555e+16 241303.39   47868.74   -52350.0  -52263.974   86.339      0.0    
   8500     19400.28   239.7925    0.0192    231.1333    0.0186     0.0047      0.0     140146.8493 7.471993094952456e+16 241331.87   47851.08   -52450.0  -52364.056   86.34       0.0    
   9000     20536.81   239.5964    0.0192    230.6608    0.0186     0.0047      0.0     139553.6461 7.407950417981715e+16  241408.1   47853.42   -52291.0  -52204.168   86.339      0.0    
   9500     21675.44    239.41     0.0192    230.1923    0.0185     0.0047      0.0     138883.2003 7.35124619421963e+16 241303.61   47892.15   -52227.0  -52141.064   86.339      0.0    
  10000     22810.92   239.2214    0.0192    229.7277    0.0185     0.0046      0.0     138283.9237 7.288976201235275e+16  241557.9   47822.7    -52392.0  -52305.363   86.339      0.0    
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.62    9981.2843    0.9979   9986.6489    0.9979     3.1623     4.4274   329319.9547 2.0425258423190382e+18 287823.14  115129.25  -115138.0  -115129.255   8.656       0.0    
    10       115.78   9971.3853    0.9969   9976.8814    0.9969     3.1623     4.4274   2393369.9785 2.415406887970092e+19 287823.14  115129.25  -115138.0  -115129.255   8.771       0.0    
    25       243.68   9951.2361    0.9949   9956.5779    0.9949     3.1623     4.4274   6690547.6809 7.332886681491715e+19 287823.14  115129.25  -115138.0  -115129.255   8.984       0.0    
   500      1603.07   4320.7479    0.4213   4329.8151    0.422      1.8734      0.0     178316859.7392 4.509765398386357e+21 287823.14  115129.25  -115210.0  -115129.255   81.215      0.0    
   1000     3040.72    428.1502    0.0336    429.815     0.0336     0.354       0.0     12186371.5157 2.7552234300703135e+18 261168.23  104461.04  -109531.0  -109444.87   85.672      0.0    
