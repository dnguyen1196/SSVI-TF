Generating synthetic count valued data ... 
Generating synthetic  count valued data took:  16.93817138671875
max_count =  52  min count =  0
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
2.6464995749 2.6289161265   1.51876      1.50536     163417.29    651123.47  
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         0.6       9.2466     6.8898     9.4156     6.992      3.1623     2.8161     2.5736     0.2286    70252.59   2849.48    -40871.0  -40857.889   13.579   
    10       72.45      9.4363     6.9244     9.1582      6.63      3.1623     3.6851    29.5943     2.5827    74788.24   2873.63    -33750.0  -33735.618   14.146   
    25       164.8      9.6723     6.9678     8.8918     6.194      3.1623     3.8438     61.92      6.169     81800.15   2957.68    -23180.0  -23164.858   15.003   
   500       623.56     9.6013     6.808      1.6658     1.095      0.9312     0.0742     4.1834    45.4062    99293.79   1589.72    -2178.0   -2149.812    27.942   
   1000     1129.94     9.2642     6.4648     1.3176     0.864      0.8564     0.0459     3.2447    44.7586    91830.07   1546.61    -2026.0   -1996.991    28.933   
   1500     1625.74     8.2262     5.3768     1.3172     0.815      0.8762     0.0469     3.3908    41.9971    74543.74   1522.42    -1909.0   -1881.949    27.265   
   2000     2126.44     6.8411     4.2267     1.3828     0.856      0.6887     0.0348     3.5285    42.9579    60567.17   1507.76    -1847.0   -1823.259    23.967   
   2500     2623.78     5.6757     3.4807     1.3979      0.85      0.5088     0.0252     3.2204    44.3907    53715.2    1499.77    -1773.0   -1751.206    21.588   
   3000     3121.41     4.9705     3.071      1.4896     0.943      0.614      0.019      3.1627     44.904    50671.76   1497.65    -1763.0   -1743.829    19.262   
   3500     3621.23     4.5721     2.8478     1.5238     0.898      0.4226     0.0143     2.9297    45.1713    49336.86    1496.6    -1751.0   -1734.283    17.019   
   4000     4136.54     4.3624     2.7321     1.5723      0.93      0.7817     0.0117     2.7808    44.1887    48630.8    1500.18    -1757.0   -1741.384    15.919   
   4500     4655.03     4.2574     2.6784     1.5495     0.919      0.4516     0.0099     2.329     43.8064    48244.22   1493.28    -1739.0   -1723.485    15.853   
   5000     5169.88     4.209      2.6527     1.5405     0.921      0.4638     0.0087     2.1549     44.163    48085.44   1492.36    -1735.0   -1719.669    15.45    
   5500     5690.64     4.1657     2.6378     1.5405     0.915      0.531      0.0078     2.0864    43.9268    47899.14   1489.61    -1737.0   -1721.923    14.966   
   6000     6208.99     4.1391     2.611      1.5398     0.911      0.6114     0.007      2.1041    43.1749    47812.14   1492.43    -1730.0    -1715.22    14.283   
   6500      6727.1     4.1253     2.6071     1.5418     0.919      0.3348     0.0062     1.801     43.7045    47694.85   1491.61    -1727.0   -1712.671    14.473   
   7000     7245.08     4.1187     2.5937     1.5643     0.931      0.5158     0.0057     1.8226    43.6947    47710.94   1490.45    -1732.0   -1717.167    14.387   
   7500     7757.06     4.0984     2.5904     1.577      0.915      0.4435     0.0053     1.9845    43.7735    47618.24   1493.74    -1755.0   -1740.918    14.051   
   8000     8272.34     4.1087     2.6023     1.5601     0.918      0.2897     0.0049     1.7044    44.0221    47693.03   1489.62    -1734.0   -1719.677    13.83    
   8500     8789.63     4.1087     2.6009     1.6056     0.962      0.3543     0.0047     1.7623    43.9314    47739.91   1496.51    -1745.0   -1731.355    13.873   
   9000     9307.64     4.0937     2.5857     1.554      0.921      0.2561     0.0041     1.5474     43.889    47658.8    1492.55    -1727.0   -1712.919    13.717   
   9500     9825.82     4.101      2.5827     1.5694     0.919      0.2098     0.0039     1.5493    43.9687    47607.87   1490.25    -1743.0   -1729.065    13.518   
  10000     10343.21    4.0849     2.5815     1.5489     0.933      0.6888     0.0036     1.6145    44.2789    47655.75   1490.73    -1723.0   -1709.484    13.447   
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         0.91      9.2428     6.8896     9.2285     6.8745     3.1623     3.4443     5.0077    43.4575    70668.43   5664.85    -82066.0  -82052.723   13.375   
    10       79.62      9.4901      6.88      9.2074     6.6855     3.1623     4.108     53.2211     37.613    78071.43   5959.09    -64858.0  -64843.631   14.212   
    25       181.59     9.771      6.8494     9.2021     6.4115     3.1623     4.108     105.953    32.4124    92695.02   6622.76    -45286.0  -45269.904   16.114   
   500       818.26     8.4607     5.2862     1.7713     1.0595     1.0901     0.0625     9.2842    69.0343    92191.9    3009.33    -3534.0   -3511.999    22.446   
   1000     1514.35     6.7435     3.9086     1.5479     0.885      0.485      0.0255     7.2602    69.0121    64942.57   2877.12    -3206.0   -3186.768    19.582   
   1500     2214.31     5.5161     3.2038     1.6083     0.9025     0.538      0.0199     5.5059    76.2089    55281.98    2863.3    -3157.0   -3138.421    18.475   
   2000     2919.04     4.8434     2.8627     1.6883     0.9385     0.5014     0.0179     4.7837    82.7938    51548.83   2870.31    -3150.0   -3131.767    17.775   
   2500     3628.05     4.5102     2.697      1.7426     0.9635     0.4355     0.0145     4.5465     86.84     49925.51   2868.65    -3155.0   -3138.468    16.952   
   3000      4343.6     4.3479     2.6142     1.737      0.959      0.3054     0.0117     3.6842    86.8646    49114.03   2874.02    -3160.0   -3143.537    16.177   
   3500     5062.98     4.2583     2.573      1.7142     0.9505     0.236      0.0094     3.2729    87.2824    48639.81   2869.39    -3167.0   -3151.768    15.656   
   4000     5783.42     4.1971     2.5344     1.6938     0.936      0.3661     0.0079     3.1071    85.9388    48309.7    2870.22    -3149.0   -3133.667    15.193   
   4500     6503.28     4.1386     2.5046     1.7157     0.9485     0.3275     0.0069     3.2225    84.6094    47888.13   2870.77    -3171.0   -3155.911    14.804   
   5000     7217.32     4.1056     2.4892     1.6821     0.9325     0.4263     0.006      3.7485    83.6947    47673.44   2876.19    -3153.0   -3138.358    14.441   
   5500      7933.3     4.068      2.4682     1.6583     0.923      0.6367     0.0054     3.5067    83.0418    47540.8    2871.65    -3153.0   -3138.847    14.185   
   6000     8651.28     4.0474     2.4633     1.6745     0.922      0.2753     0.005      2.7898    81.9438    47322.98   2866.44    -3168.0   -3153.798    13.934   
   6500     9360.72     4.0444     2.4584     1.6811      0.95      0.3239     0.0044     2.3583    81.7977    47336.8    2866.01    -3154.0   -3139.933    13.802   
   7000     10082.51    4.0127     2.4421     1.6562     0.917      0.3079     0.004      2.4713    81.2086    47133.42   2866.18    -3134.0   -3120.594    13.763   
   7500     10805.2     4.0143     2.4438     1.6441     0.913      0.4279     0.0038     3.0006    81.0278    47170.96   2868.84    -3166.0   -3152.113    13.628   
   8000     11526.9     4.0069     2.4379     1.6413      0.9       0.2577     0.0034     2.8325     81.064    47014.2    2867.35    -3161.0   -3147.147    13.583   
   8500     12256.54    3.9916     2.4304     1.6027     0.8985     0.3528     0.0032     3.1103     80.99     46978.86   2869.45    -3160.0   -3147.014    13.476   
   9000     12987.73    3.9916     2.4316     1.6104     0.8875     0.376      0.0031     2.9275    81.1753    46985.21   2864.94    -3158.0   -3144.132    13.428   
   9500     13706.71    3.994      2.4318     1.6182     0.9035     0.2649     0.0028     2.4109    81.9135    46901.9     2863.4    -3163.0   -3149.255    13.404   
  10000     14421.81    3.9901     2.4327     1.6179     0.9095     0.4652     0.0026     3.0388    82.1732    46904.64   2869.19    -3153.0   -3139.602    13.38    
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.82      9.2518     6.8956     9.2247     6.8614     3.1623     4.0429     12.766    80.1902    70685.47   14084.73  -203437.0  -203423.705   13.056   
    10       98.23      9.589      6.8675     9.4359     6.731      3.1623     4.3157    105.1067   72.6517    83849.27   16275.71  -162175.0  -162161.21   14.204   
    25       225.27     9.9629     6.8095     9.6622     6.5588     3.1623     4.3402    206.2634   65.0155   110338.91   20801.6   -116572.0  -116554.943   16.966   
   500      1401.04     7.3512     4.1715     2.7894     1.6362     1.2871     0.0225    21.4002    139.2042   80935.26   8035.57    -8818.0   -8781.382    36.971   
   1000     2701.88     6.2873     3.5532     2.2556     1.2956     0.3891     0.017      11.717    159.6274   66280.22   7470.07    -8035.0   -8003.449    31.901   
   1500     4025.25     5.6587     3.2387     2.1244     1.2134     0.3751     0.0144     8.2818    172.1228   60690.45   7293.44    -7826.0   -7796.378    29.557   
   2000     5355.62     5.2513     3.0419     2.0652     1.1654     0.2213     0.0118     6.5753    177.0385   57757.12   7209.01    -7729.0   -7700.396    28.114   
   2500     6678.49     4.9921     2.923      2.0237     1.1414     0.2242     0.0098     5.4848    181.0208   55928.1    7167.06    -7651.0   -7623.798    27.137   
   3000     7983.18     4.7999     2.8337     1.9945     1.115      0.172      0.0083     4.4697    182.1935   54654.51   7128.14    -7622.0   -7595.779    26.373   
   3500      9289.8      4.66      2.7692     1.9823     1.0986     0.2465     0.0071     4.3631    183.7571   53695.26   7108.42    -7591.0   -7564.975    25.731   
   4000     10595.15    4.5408     2.7127     1.9679     1.088      0.2452     0.0062      4.48     184.7347   52903.93   7094.72    -7583.0   -7558.092    25.225   
   4500     11914.15    4.464      2.674      1.9561     1.0798     0.184      0.0055     4.1743    186.3546   52344.97   7074.43    -7573.0   -7548.085    24.727   
   5000     13221.78    4.388      2.6391     1.9544     1.0752     0.2141     0.005      4.0984    187.7049   51845.44   7076.31    -7564.0    -7539.7     24.378   
   5500     14527.22    4.3371     2.6078     1.9391     1.0632     0.1352     0.0044     3.4511    188.8864   51454.55    7064.7    -7558.0   -7534.312    24.021   
   6000     15837.22    4.2901     2.5886     1.9339     1.0586     0.1901     0.004      4.2218    190.3517   51172.73   7058.87    -7558.0   -7534.521    23.601   
   6500     17149.8     4.2533     2.5681     1.9132     1.0494     0.161      0.0036     3.8402    192.9713   50845.42   7054.05    -7534.0   -7511.085    23.05    
   7000     18458.81    4.2273     2.554      1.9239     1.0496     0.166      0.0034     4.1633    195.3314   50625.06   7056.62    -7524.0    -7501.33    22.855   
   7500     19769.57    4.1947     2.5358     1.9068     1.0392     0.1776     0.0031     3.8039    196.5753   50432.01   7040.69    -7543.0   -7519.944    22.625   
   8000     21081.48    4.1753     2.5223     1.8977     1.0338     0.1506     0.0028     3.8614    197.6814   50203.64   7037.27    -7529.0   -7506.846    22.367   
   8500     22391.59    4.145      2.5075     1.8803     1.025      0.1487     0.0026     3.8402    197.8045   50038.3    7029.29    -7529.0   -7506.868    22.322   
   9000     23704.17    4.1309     2.4951     1.887      1.0316     0.1339     0.0024     3.5272    199.2861   49779.75   7023.06    -7517.0   -7494.491    22.287   
   9500     25020.51    4.1175     2.492      1.8802     1.0234     0.1489     0.0022     3.3588    199.9812   49687.52   7016.57    -7507.0   -7484.641    22.266   
  10000     26331.47    4.1097     2.4853     1.8578     1.0136     0.1158     0.0021     3.3451    200.7734   49569.48   7015.68    -7503.0    -7480.41    22.179   
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         2.24      9.2661     6.8866     9.2836     6.8922     3.1623     4.2414    22.3217    196.0191   70842.33   28496.29  -402672.0  -402660.816   10.702   
    10       120.23     9.661      6.886      9.5728     6.8149     3.1623     4.3781    200.5536   172.679    88939.59   34876.8   -323123.0  -323111.419   11.481   
    25       275.19    10.0525     6.8247     9.9333     6.7164     3.1623     4.4095    401.586    144.3209  120851.27   46969.22  -236874.0  -236860.161   14.143   
   500      1709.82     4.2332     2.5477     3.3521     2.0446     1.6275     0.0472    49.7066    240.7126   52086.56   18036.2    -19360.0  -19322.503   37.556   
   1000     3295.05     3.9397     2.3659     3.0227     1.8028     1.0329     0.0186    30.0536    238.9219   49062.1    16626.59   -17844.0  -17810.251   33.778   
   1500     4878.31     3.8552     2.318      2.9105     1.7239     0.8223     0.0121      25.0     240.7319   48052.91   16149.99   -17289.0  -17256.008   32.777   
   2000     6465.68     3.7964     2.2784     2.8221     1.6493     0.5079     0.0091     21.033    245.9218   47398.29   15816.17   -16900.0  -16867.784   32.352   
   2500     8058.91     3.7655     2.2627     2.7584     1.6022      0.55      0.007     20.9383    247.0012   47078.28   15629.45   -16736.0  -16703.629   32.363   
   3000     9647.68     3.7341     2.2391     2.7177     1.5643     0.4179     0.006     20.9664    247.525    46726.62   15483.79   -16561.0  -16529.382   32.103   
   3500     11240.17    3.7165     2.2362     2.6719     1.5373     0.459      0.0054    19.3087    252.2585   46620.33   15367.18   -16414.0  -16382.001   32.43    
   4000     12833.3     3.6923     2.2166     2.6525     1.5143     0.4662     0.0047    19.8212    250.7195   46466.24   15289.92   -16324.0  -16292.771   31.693   
   4500     14424.15    3.6713     2.2036     2.6165     1.4892     0.4609     0.0039     18.262    254.9521   46240.43   15194.23   -16202.0  -16170.716   31.635   
   5000     16021.29    3.6723     2.1996     2.5963     1.4733     0.3285     0.0038    18.1943    250.8687   46171.16   15125.93   -16160.0  -16128.211   31.678   
   5500     17619.16    3.6641     2.1962     2.5777     1.4643     0.4827     0.0039     18.427    254.8859   46167.23   15088.1    -16104.0  -16072.75    31.221   
   6000     19241.3     3.6595     2.1942     2.5671     1.4573     0.2543     0.004     18.0258    255.551    46021.16   15039.81   -16039.0  -16007.016   31.532   
   6500     20885.43    3.6497     2.1862     2.554      1.4402     0.4555     0.0033    18.5001    254.8908   45978.61   15002.38   -16022.0  -15991.395   31.044   
   7000     22540.38    3.6454     2.1918     2.5305      1.43      0.3949     0.0027     19.993    259.8537   45954.62   14989.16   -15986.0  -15954.363   31.474   
   7500     24187.08    3.6414     2.1848     2.5252     1.4219     0.3545     0.0029     16.754    260.2086   45875.53   14956.73   -15958.0  -15927.061   30.833   
   8000     25840.5     3.6355     2.1775     2.5036     1.4023     0.2764     0.0025     17.282    262.2339   45855.96   14899.55   -15920.0  -15889.781   30.651   
   8500     27492.37    3.6519     2.1913     2.4921     1.3983     0.2661     0.0022    17.1477    268.3393   45916.65   14900.28   -15864.0  -15832.996   30.633   
   9000     29139.24    3.6372     2.1825     2.4967     1.3995     0.3637     0.0023    19.2365    262.5288   45914.57   14891.31   -15882.0   -15851.2    30.778   
   9500     30795.06    3.6341     2.1864     2.4827     1.3972     0.3514     0.0024    18.2271    269.5083   45753.39   14866.03   -15831.0  -15800.565   30.624   
  10000     32449.55    3.6239     2.1716     2.4677     1.3791     0.3306     0.0021    17.1863    268.0332   45823.67   14837.2    -15826.0  -15795.144   30.759   
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         2.31      9.2671     6.9074     9.2585     6.8748     3.1623     4.3535    50.6232    262.7324   71130.34   57021.49  -810435.0  -810423.363   11.625   
    10       160.01     9.6033     6.8323     9.5687     6.7788     3.1623     4.4232    415.5357   241.9346   89175.24   70713.05  -656112.0  -656099.789   12.617   
    25       359.66    10.0349     6.7554     9.9942     6.687      3.1623     4.4268    823.8472   225.8653  123273.12   97410.71  -485432.0  -485416.346   15.669   
   500      1880.98     3.9232     2.4214     3.6054     2.2342     1.3459     0.0522    111.7492   415.0961   50434.73   37937.26   -39748.0  -39696.666   51.787   
   1000     3529.93     3.7008     2.2474     3.3445     2.0286     0.8655     0.0265    68.4128    458.0877   47761.8    35479.53   -37255.0  -37206.578   48.394   
   1500     5175.25     3.6258     2.1836     3.2245     1.9316     0.6765     0.0147    62.7289    455.821    46547.48   34225.89   -35995.0  -35948.862   45.673   
   2000     6829.28     3.5733     2.1432     3.1487     1.867      0.5725     0.0123    54.7058    458.4651   45585.43   33404.55   -35112.0  -35068.035   44.417   
   2500     8527.15     3.5316     2.1128     3.0864     1.8245     0.5753     0.0094    58.1065    462.766    44968.49   32917.31   -34601.0  -34556.613   44.354   
   3000     10177.17    3.5024     2.0934     3.0208     1.7749     0.5164     0.0075    52.1183    457.8364   44612.57   32437.97   -34135.0  -34090.635   44.504   
   3500     11820.41    3.4675     2.0638     2.9825     1.7383     0.464      0.0078    50.2874    454.8729   44234.37   32134.03   -33838.0  -33795.092   43.131   
   4000     13466.63    3.443      2.0476     2.9517     1.7144     0.6363     0.0062     48.832    455.9065   43906.28   31855.8    -33523.0  -33480.938   41.911   
   4500     15123.28    3.4317     2.0418     2.9239     1.7026     0.4732     0.0057     55.494    461.2264   43835.74   31761.11   -33429.0  -33387.114   42.046   
   5000     16780.15    3.413      2.0307     2.8921     1.6838     0.4901     0.0059    50.4052    470.8222   43589.99   31588.78   -33183.0  -33140.818   41.891   
   5500     18431.06    3.389      2.0078     2.8748     1.6678     0.5428     0.0053    51.1767    457.1164   43455.9    31416.13   -33026.0  -32983.263   42.326   
   6000     20094.67    3.3723     2.0031     2.8581     1.6597     0.5511     0.0045    56.0602    469.5429   43321.31   31361.38   -32993.0  -32951.522   41.942   
   6500     21747.5     3.3637     1.9951     2.8441     1.6443     0.4136     0.004     51.0085    462.6287   43270.15   31238.66   -32852.0  -32810.376   41.609   
   7000     23398.07    3.3525     1.9892     2.8273     1.6344     0.4389     0.0042    48.0222    466.0545   43167.2    31162.19   -32765.0  -32723.683   41.699   
   7500     25050.82    3.3432     1.9787     2.811      1.621      0.2954     0.004     45.5345     461.51    43061.76   31078.41   -32681.0  -32640.508   40.763   
   8000     26697.36    3.337      1.9732     2.7983     1.6114     0.3826     0.0031     48.342    465.2381   43038.72   30994.26   -32602.0  -32561.087   41.282   
   8500     28336.67    3.3448     1.9812      2.79      1.611      0.359      0.0033    48.0462    469.1283   43012.14   30952.4    -32541.0  -32499.753   40.785   
   9000     29980.47    3.3453     1.9876     2.7911     1.6143     0.3313     0.0035    50.2319    474.521    43087.92   30949.87   -32539.0  -32497.265   41.508   
   9500     31635.82    3.3274     1.9732      2.78      1.5966     0.3136     0.0028    48.6781    469.0715   42919.81   30837.23   -32393.0  -32351.929   41.339   
  10000     33277.02    3.3168     1.9718     2.7843     1.6016     0.3862     0.0026    49.5854    471.7001   42866.56   30818.07   -32377.0  -32336.118   41.101   
Using  0.5  of training data 
Using  0.5 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         2.24      9.2542     6.9355     9.2752     6.9253     3.1623     4.4248    124.7022   463.9982   70554.18   141545.7  -2063728.0 -2063712.224   15.752   
    10       259.31     9.6108     6.8747     9.5785     6.8229     3.1623     4.4274   1029.0686   445.7409   88497.89  175866.74  -1680816.0 -1680798.446   17.446   
    25       562.11    10.0602     6.802     10.0084     6.7404     3.1623     4.4274   2122.9692   457.1044  125947.47  248635.09  -1265283.0 -1265260.584   22.327   
   500      2091.51     3.9745     2.4274     3.8872     2.3669     1.161      0.0292    273.5398  1130.6968   51065.65   99753.56  -104041.0  -103995.921   45.108   
   1000     3960.65     3.6518     2.2381     3.5482     2.1716     1.0921     0.0207    230.2423  1247.6603   47897.78   93313.02   -96749.0  -96708.177   41.125   
   1500     5806.96     3.545      2.1432     3.4152     2.0599     0.6282     0.0155    182.4719  1265.5416   46216.9    89572.93   -92878.0  -92839.322   39.159   
   2000     7625.54     3.4665     2.0813      3.34      1.9965     0.7606     0.0123    194.807   1214.2681   45119.0    87477.36   -90875.0  -90836.277   38.809   
   2500     9433.48     3.4178     2.0576     3.2727     1.9577     0.8395     0.0108    182.7268  1275.5614   44413.66   85941.25   -89005.0  -88966.77    38.358   
   3000     11234.58    3.3596     2.0116     3.2114     1.9078     0.8872     0.012     181.2571  1247.3323   43824.81   84536.93   -87587.0  -87548.746   38.069   
   3500     13065.62    3.3279     1.9728     3.1695     1.8658     0.4445     0.0077    162.6695  1248.1374   43267.02   83285.83   -86446.0  -86407.521   38.191   
   4000     14836.19    3.2914     1.9479     3.123      1.8364     0.3858     0.0071    158.0632  1220.5307   42799.9    82457.99   -85514.0  -85474.491   39.066   
   4500     16608.71    3.2757     1.9358     3.0988     1.8151     0.516      0.0071    155.852   1241.7178   42661.78   81978.61   -84998.0  -84959.177   38.587   
   5000     18385.05    3.2546     1.9188     3.0733     1.7976     0.3536     0.0053    152.3858  1219.2957   42397.66   81447.27   -84536.0  -84497.082   39.179   
   5500     20151.72    3.2226     1.895      3.054      1.7793     0.6059     0.0048    161.9973  1224.4121   42164.04   81029.22   -84175.0  -84135.921   39.313   
   6000     21917.87    3.2157     1.8978     3.0391     1.772      0.4291     0.0047    160.3977  1259.7366   42127.63   80817.98   -83756.0  -83715.51    40.324   
   6500     23686.68    3.2017     1.8845     3.0178     1.7582     0.4544     0.006     138.9958   1251.443   41857.14   80384.11   -83285.0  -83244.733   40.203   
   7000     25452.15    3.1915     1.8768     3.0223     1.7594     0.6561     0.0041    154.5901  1282.7128   41809.0    80416.26   -83412.0  -83371.917   40.264   
   7500     27235.42    3.175       1.86      3.0036     1.739      0.4339     0.0035    148.6538  1272.7129   41561.38   79941.14   -83018.0  -82977.832   40.608   
   8000     28994.22    3.1729     1.8652     2.9856     1.7357     0.4329     0.0046    151.2849  1290.9544   41554.09   79818.22   -82737.0  -82696.971   40.181   
   8500     30738.91    3.1666     1.8604     2.9797     1.7301     0.5886     0.0035    144.5658  1274.7524   41482.45   79664.74   -82511.0  -82470.808   40.19    
   9000     32466.51    3.1561     1.8532     2.9648     1.7189     0.5967     0.0035    152.6179  1282.6758   41401.76   79465.48   -82347.0  -82306.236   40.714   
   9500     34189.34    3.1484     1.8496     2.9568     1.713      0.4003     0.004      140.41   1279.0475   41313.62   79265.63   -82118.0  -82077.162   40.362   
  10000     35915.66    3.1487     1.846      2.9463     1.7077     0.3915     0.0036    151.038   1245.9092   41355.39   79237.38   -82150.0  -82109.199   40.536   
Using  1  of training data 
Using  1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         2.19      9.2988     6.9368     9.2666     6.9031     3.1623     4.4274    325.6938  1216.8184   71243.16  284180.15  -4019217.0 -4019203.107   14.008   
    10       430.69     9.6846     6.8884     9.6199     6.8288     3.1623     4.4274   2053.5715  1121.3437   91646.89  363128.29  -3285211.0 -3285195.574   15.468   
    25       893.18    10.0848     6.7942    10.0308     6.7407     3.1623     4.4274    4218.454  1069.0515  127368.22  503839.33  -2467484.0 -2467464.837   19.66    
   500      2565.03     3.8902     2.3778     3.829      2.3448     1.7367     0.0308    624.9233  2237.2327   50875.1   200778.63  -208393.0  -208341.292   52.153   
   1000     4676.35     3.5887     2.193      3.5238     2.1462     0.852      0.0218    394.8497   2234.055   47176.86  185630.69  -191568.0  -191518.102   49.732   
   1500     6778.27     3.5098     2.1272     3.439      2.0827     0.8762     0.017     402.5248  2327.3068   45912.5   180815.09  -186160.0  -186110.157   50.216   
   2000     8841.53     3.4436     2.0625     3.3574     2.008      0.8748     0.0129    329.7849  2299.9404   44734.19  175848.88  -181120.0  -181071.009   48.937   
   2500     10900.4     3.3781     2.0245     3.2882     1.9643     0.8023     0.0122    373.1484  2333.2989   44041.04  172794.74  -177879.0  -177829.558   49.637   
   3000     12941.24    3.3284     1.979      3.2301     1.9129     0.7045     0.0087    327.3458   2208.75    43314.32  169810.34  -174827.0  -174778.285   48.738   
   3500     14941.47    3.2866     1.9461     3.1911     1.8788     0.6341     0.0095    319.4756  2207.1627   42785.73  167798.12  -172830.0  -172781.647   48.846   
   4000     16935.05    3.2517     1.9213     3.1642     1.8632     0.5507     0.0086    330.8075  2266.8199   42483.34  166738.06  -171762.0  -171713.266   48.902   
   4500     18903.87    3.2381     1.909      3.1405     1.8409     0.5488     0.0076    330.7233  2259.0088   42253.22  165644.81  -170647.0  -170597.603   49.478   
   5000     20843.59    3.224      1.8928     3.1212     1.829      0.6018     0.0055    332.7816  2248.3751   42031.95  164915.79  -170017.0  -169966.518   50.908   
   5500     22791.42    3.2248     1.9015     3.1054     1.8206     0.6616     0.0133    338.6088  2303.5564   42034.33  164339.99  -169338.0  -169287.443   50.408   
   6000     24738.56    3.2063     1.8878     3.0926     1.8089     0.4272     0.0058    304.5533  2257.5128   41788.57  163378.63  -168349.0  -168298.019   51.404   
   6500     26697.33    3.1888     1.8761     3.0816     1.8041     0.6862     0.0055    329.5499  2288.3769   41714.15  163238.13  -168236.0  -168185.179   50.42    
   7000     28648.63    3.1782     1.8646     3.0652     1.7809     0.5379     0.0056    314.2314   2231.542   41470.48  162297.07  -167318.0  -167266.98   51.103   
   7500     30579.14    3.1632     1.8551     3.0479     1.7762      0.41      0.0043    310.7138  2295.5703   41404.44  161913.87  -166962.0  -166909.725   52.423   
   8000     32511.93    3.1461     1.8423     3.042      1.7724     0.5469     0.0046    319.4468  2312.8524   41287.73  161585.57  -166681.0  -166629.418   51.43    
