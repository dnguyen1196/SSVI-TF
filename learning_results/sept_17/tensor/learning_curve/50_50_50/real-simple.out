Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  8.519246339797974
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
    0.0          0.0          0.0          0.0       287494.79    1149836.49 
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.18    9982.4061    0.998    10010.7398   0.9981     3.1623     4.4242   17507.1603  18.3643   287823.14   11512.93   -11519.0  -11512.925    6.53      0.0183  
    10       60.47    9972.9116    0.9971   10000.331    0.997      3.1623     4.4274   253194.835  261.713   287823.14   11512.93   -11520.0  -11512.925   6.792       0.0    
    25       123.58   9953.4224    0.9951   9981.6588    0.9952     3.1623     4.4274   667948.9099  724.7973  287823.14   11512.93   -11520.0  -11512.925   7.264      0.0001  
   500       307.99    4344.523    0.4237   4371.6028    0.4254     1.8857     0.0324   17986543.775 675162.7284 287823.14   11512.93   -11592.0  -11512.925   78.759      0.0    
   1000      485.36    477.2319    0.0377    436.5504    0.0336     0.3245     0.0058   1221402.1575 1562775.7158 264748.08   10358.84   -11533.0  -11449.014   84.423      0.0    
   1500      670.58    290.6039    0.0233    246.5607    0.0197     0.086      0.0024   282373.95  1595271.5496 250393.92   9782.67    -11503.0  -11417.524   85.16       0.0    
   2000      860.88    263.6299    0.0212    221.0584    0.0178     0.0323     0.0015   115610.815 1597181.3897 246363.77   9641.65    -11494.0  -11408.305   85.382      0.0    
   2500     1033.92    259.3209    0.0208    215.9201    0.0175     0.0161     0.0012   67103.8954 1597565.1457 245855.87   9667.84    -11483.0  -11397.748   85.471      0.0    
   3000     1217.45    258.4518    0.0208    213.7904    0.0173     0.0107     0.001    54935.3746 1597742.8037 245859.38   9588.77    -11478.0  -11392.659   85.512      0.0    
   3500     1412.72    258.1982    0.0207    212.204     0.0172     0.0097     0.0009   51148.1122 1597798.6177 245549.35   9589.45    -11483.0  -11397.821   85.537      0.0    
   4000     1594.73    257.9815    0.0207    210.7289    0.0171     0.0108     0.0008   49616.0448 1597832.1656 245804.71   9567.41    -11480.0  -11394.412   85.555      0.0    
   4500     1769.03    257.7409    0.0207    209.2951    0.017      0.0096     0.0007   48371.1884 1597925.5315 245310.48   9546.65    -11474.0  -11387.987   85.571      0.0    
   5000     1943.46    257.6448    0.0207    207.8796    0.0169     0.0104     0.0007   48058.0347 1597927.4782 245454.31   9520.85    -11494.0  -11408.139   85.584      0.0    
   5500     2121.78    257.4094    0.0207    206.483     0.0167     0.0095     0.0006   48365.0674 1597870.7877 245607.66   9470.28    -11479.0  -11393.109   85.596      0.0    
   6000     2292.99    257.3416    0.0207    205.0999    0.0166     0.0097     0.0006   47623.6547 1597882.1171 245327.45   9494.11    -11475.0  -11389.728   85.609      0.0    
   6500     2477.85    257.3126    0.0207    203.7289    0.0165     0.0093     0.0006    47824.3   1597752.6174 245208.54    9475.2    -11481.0   -11395.1    85.619      0.0    
   7000      2659.7    257.1228    0.0206    202.3712    0.0164     0.0093     0.0005   46920.8434 1597814.5099  245315.5   9432.05    -11479.0  -11392.876   85.63       0.0    
   7500     2851.51    256.9961    0.0206    201.0238    0.0163     0.0096     0.0005   47113.2676 1597922.8732 245836.97   9497.51    -11479.0  -11392.934   85.641      0.0    
   8000     3024.06    256.9112    0.0206    199.686     0.0162     0.0097     0.0005   45976.6177 1597789.8911 245129.02   9514.61    -11470.0  -11384.422   85.651      0.0    
   8500     3202.61    256.7803    0.0206    198.3563    0.0161     0.0092     0.0004   47203.7272 1597908.4291 245302.06   9447.32    -11488.0  -11402.809   85.657      0.0    
   9000     3388.39    256.6657    0.0206    197.0358    0.016      0.009      0.0004   45987.4506 1597884.0402 245486.91   9477.26    -11479.0  -11393.418   85.665      0.0    
   9500     3570.84    256.6222    0.0206    195.7208    0.0159     0.0091     0.0004   45670.1932 1597955.9979 244949.12   9360.72    -11476.0  -11390.147   85.674      0.0    
  10000     3743.46    256.5132    0.0206    194.4135    0.0158     0.009      0.0004   45742.7431 1597889.6437 245120.32   9390.76    -11484.0  -11398.747   85.682      0.0    
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.38    9979.3435    0.9977   9981.1325    0.9978     3.1623     4.4274   82810.305  1568963.3615 287823.14   23025.85   -23033.0  -23025.851   6.921      0.0194  
    10       64.97    9968.9509    0.9967   9971.0911    0.9967     3.1623     4.4274   516741.3383 1237385.8126 287823.14   23025.85   -23033.0  -23025.851   7.198      0.0001  
    25       132.97   9947.8701    0.9946   9950.1683    0.9946     3.1623     4.4274   1415794.9535 772792.4691 287823.14   23025.85   -23033.0  -23025.851   7.537      0.0001  
   500       393.97   4278.3701    0.4159   4291.7841    0.4176     1.8895     0.0045   35554285.1167 1369866.2557 287823.14   23025.85   -23107.0  -23025.851   81.361      0.0    
   1000      668.54    467.4819    0.0367    449.1858    0.0351     0.3566     0.0007   2408577.429 3112547.3498 263562.49   21151.22   -22988.0  -22902.967   85.507      0.0    
   1500      942.68    271.9138    0.0218    255.2198    0.0206     0.0972     0.0002   546241.7991 3176755.7713 247438.76   19662.05   -22908.0  -22821.657   85.882      0.0    
   2000     1217.09    251.9894    0.0202    235.3663    0.0191     0.0316     0.0002   183782.7907 3180509.4352 244397.62   19421.66   -22904.0  -22818.427   85.989      0.0    
   2500     1489.72    250.1071    0.0201    232.5616    0.0189     0.0126     0.0001   101320.2207 3181311.1239 244147.97   19426.58   -22905.0  -22818.55    86.027      0.0    
   3000     1765.08    249.8611     0.02     231.4501    0.0188     0.008      0.0001   83014.1434 3181460.8677  244379.7   19424.38   -22899.0  -22812.655   86.042      0.0    
   3500     2039.85    249.715      0.02     230.5456    0.0187     0.0078     0.0001   79736.6407 3181583.0682 244306.68   19421.42   -22900.0  -22814.053   86.044      0.0    
   4000     2313.53    249.5352     0.02     229.6769    0.0186     0.0077     0.0001   79074.5857 3181638.2309 244142.58   19232.96   -22904.0  -22817.812   86.048      0.0    
   4500     2586.58    249.3645     0.02     228.822     0.0186     0.0075     0.0001   78282.4522 3181520.1986 244160.47   19358.62   -22883.0  -22797.231   86.049      0.0    
   5000     2861.19    249.148      0.02     227.9781    0.0185     0.0077     0.0001   77963.8399 3181490.0211 243758.04   19321.35   -22893.0  -22806.685   86.048      0.0    
   5500     3132.84    248.9456     0.02     227.1443    0.0184     0.0077     0.0001   76993.0723 3181554.8623  244410.5   19240.23   -22898.0  -22811.674   86.05       0.0    
   6000     3407.58    248.7399     0.02     226.321     0.0184     0.0072     0.0001   76212.3145 3181475.798 244203.89   19277.57   -22884.0  -22797.545   86.051      0.0    
   6500      3680.0    248.5693    0.0199    225.5057    0.0183     0.0073      0.0     75950.6024 3181639.5828 243841.42   19283.93   -22908.0  -22821.578   86.049      0.0    
   7000     3952.09    248.3322    0.0199    224.699     0.0182     0.0074      0.0     75567.1879 3181559.2852  244041.7   19308.18   -22906.0  -22819.803   86.048      0.0    
   7500      4225.9    248.1793    0.0199    223.9001    0.0182     0.0074      0.0     74047.4977 3181478.4887 244012.78   19327.88   -22888.0  -22802.02    86.048      0.0    
   8000     4499.18    248.0435    0.0199    223.1087    0.0181     0.0071     0.0001   74334.2811 3181511.2809 243816.41   19201.52   -22880.0  -22794.365   86.049      0.0    
   8500     4772.93    247.8717    0.0199    222.323     0.018      0.007       0.0     73992.4409 3181466.8489 243957.89   19227.53   -22894.0  -22807.841   86.05       0.0    
   9000     5047.92    247.7226    0.0199    221.5438    0.018      0.0069      0.0     73473.3507 3181565.7547 243468.76   19391.67   -22890.0  -22803.911   86.049      0.0    
   9500     5321.57    247.5321    0.0198    220.7703    0.0179     0.007       0.0     72546.1693 3181551.9506 243825.37   19118.87   -22895.0  -22808.839   86.048      0.0    
  10000     5593.87    247.3866    0.0198    220.0026    0.0178     0.0076      0.0     73022.1983 3181474.2401 243747.79   19151.63   -22898.0  -22811.608   86.048      0.0    
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.98    9982.2337    0.998    9979.7761    0.998      3.1623     4.4274   160694.0734 3119986.3591 287823.14   57564.63   -57572.0  -57564.627   7.677      0.0177  
    10       82.18    9972.6774    0.9971   9970.1854    0.9971     3.1623     4.4274   1181872.1408 2508747.0111 287823.14   57564.63   -57572.0  -57564.627   7.854      0.0001  
    25       169.4    9953.0798    0.9951    9950.357    0.9951     3.1623     4.4274   3280882.6522 1548047.9627 287823.14   57564.63   -57573.0  -57564.627   8.162       0.0    
   500       722.14   4353.3605    0.4236   4352.5799    0.4236     1.9156      0.0     89129469.106 3368342.1193 287823.14   57564.63   -57646.0  -57564.627   81.227      0.0    
   1000     1303.98    456.4744    0.0354    453.229     0.0352     0.3436      0.0     6459175.9229 7765059.0456 262274.23   52498.7    -57348.0  -57262.073   85.685      0.0    
   1500     1890.02    261.0433    0.0209    257.1973    0.0207     0.0905      0.0     1248591.7135 7930780.7428 246089.44   49202.48   -57146.0  -57060.238   86.144      0.0    
   2000     2474.04    245.1623    0.0197    240.9381    0.0194     0.0296      0.0     370454.4504 7940056.1768 243570.11   48555.14   -57119.0  -57032.809   86.247      0.0    
   2500     3058.78    243.7465    0.0196    239.1231    0.0193     0.0101      0.0     196253.3431 7941884.2722 243506.08   48428.36   -57118.0  -57031.906   86.274      0.0    
   3000     3643.26    243.4148    0.0195    238.4486    0.0193     0.0055      0.0     162278.0234 7942366.4724 243378.62   48446.26   -57136.0  -57049.454   86.279      0.0    
   3500     4227.82    243.1469    0.0195    237.8862    0.0192     0.0051      0.0     156981.2547 7942432.4953 243627.69   48572.99   -57145.0  -57058.237   86.279      0.0    
   4000     4810.49    242.8791    0.0195    237.3425    0.0192     0.0051      0.0     156276.6019 7942434.6017 243410.51   48613.41   -57124.0  -57037.417   86.28       0.0    
   4500     5393.61    242.6332    0.0195    236.8075    0.0191     0.0051      0.0     154837.2769 7942331.6861 243657.26   48599.77   -57117.0  -57031.022   86.279      0.0    
   5000     5978.01    242.3824    0.0195    236.2799    0.0191     0.005       0.0     152270.3988 7942325.5347 243390.46   48482.11   -57107.0  -57020.961   86.277      0.0    
   5500      6559.1    242.1427    0.0194    235.7592    0.0191     0.005       0.0     152171.9181 7942333.8589 243390.41   48542.08   -57136.0  -57049.891   86.275      0.0    
   6000     7141.03    241.8934    0.0194    235.2446    0.019      0.0049      0.0     150768.5444 7942384.389 242846.71   48388.3    -57113.0  -57027.025   86.274      0.0    
   6500     7723.05    241.665     0.0194    234.7365    0.019      0.0049      0.0     151340.6678 7942353.1229 243258.95   48411.31   -57089.0   -57002.3    86.273      0.0    
   7000     8306.02    241.4312    0.0194    234.2343    0.0189     0.005       0.0     148919.4759 7942340.4889 243553.12   48299.21   -57139.0  -57052.324   86.272      0.0    
   7500      8888.7    241.2085    0.0194    233.7377    0.0189     0.0049      0.0     149086.4334 7942260.0604 243101.92   48169.63   -57103.0  -57017.026   86.272      0.0    
   8000     9472.18    240.983     0.0194    233.2462    0.0189     0.0049      0.0     147090.9947 7942338.6499 243305.24   48340.64   -57118.0  -57032.171   86.27       0.0    
   8500     10054.8    240.7927    0.0193    232.7605    0.0188     0.0048      0.0     147721.3349 7942471.2376 243265.47   48261.4    -57100.0  -57014.131   86.267      0.0    
   9000     10637.58   240.571     0.0193    232.2785    0.0188     0.0048      0.0     145934.9186 7942333.6076 243022.15   48267.2    -57087.0  -57000.832   86.268      0.0    
   9500     11219.84   240.3457    0.0193    231.8015    0.0187     0.0048      0.0     145348.0897 7942259.6747 242828.53   48420.43   -57104.0  -57017.88    86.266      0.0    
  10000     11801.98   240.1442    0.0193    231.3291    0.0187     0.0047      0.0     144232.1021 7942260.6444 242886.42   48236.36   -57114.0  -57027.501   86.265      0.0    
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.24    9981.8158    0.998    9987.3347    0.998      3.1623     4.4274   317567.2359 7782316.2293 287823.14  115129.25  -115136.0  -115129.255   6.471      0.0104  
    10       102.15   9972.1621    0.997    9977.8547    0.997      3.1623     4.4274   2338337.6807 6209742.8883 287823.14  115129.25  -115136.0  -115129.255   6.747      0.0002  
    25       211.06   9952.3365    0.995    9957.9543    0.995      3.1623     4.4274   6569403.7351 3808598.8482 287823.14  115129.25  -115136.0  -115129.255   7.161      0.0005  
   500       913.25   4344.3524    0.4229   4354.0191    0.4238     1.8981      0.0     178386075.4524 6731900.4481 287823.14  115129.25  -115211.0  -115129.255   81.575      0.0    
   1000     1649.96    437.3987    0.0345    437.1049    0.0344     0.3507      0.0     12601128.8126 15542936.345 263472.41  105219.18  -114607.0  -114521.237   85.838      0.0    
   1500     2387.97    255.7371    0.0206    254.2927    0.0206     0.0891      0.0     2424525.3863 15860655.8077 246517.06   98754.1   -114234.0  -114147.423   86.198      0.0    
   2000     3126.58    242.5481    0.0196    240.884     0.0195     0.026       0.0     1016941.3492 15881667.3449 244374.86   97377.5   -114154.0  -114068.05   86.255      0.0    
   2500     3865.36    241.3709    0.0195    239.6154    0.0194     0.019       0.0     741472.5199 15900916.7228 244519.31   97770.77  -114138.0  -114051.409   86.277      0.0    
   3000     4604.06    241.0665    0.0195    239.1583    0.0193     0.0201      0.0     694236.1543 15905725.4754 244486.15   97675.6   -114147.0  -114060.652   86.281      0.0    
   3500     5342.09    240.8603    0.0194    238.7877    0.0193     0.0191      0.0     707422.624 15906598.1012 244768.78   97422.2   -114158.0  -114072.134   86.282      0.0    
   4000     6080.52    240.7621    0.0194    238.433     0.0193     0.0235      0.0     733252.6704 15895215.5499 244220.73   97334.89  -114114.0  -114028.018   86.28       0.0    
   4500     6819.22    240.4353    0.0194    238.0512    0.0193     0.0219      0.0     695266.9012 15891572.8759 244404.95   97497.02  -114183.0  -114096.661   86.277      0.0    
   5000     7557.91    240.2179    0.0194    237.6832    0.0192     0.0219      0.0     656432.3133 15895805.547 244182.62   97491.27  -114145.0  -114059.164   86.28       0.0    
   5500     8297.34    240.0615    0.0194    237.3341    0.0192     0.0214      0.0     703306.6539 15890337.8114 244581.22   97847.56  -114162.0  -114075.773   86.278      0.0    
   6000      9035.5    239.8638    0.0194    236.9817    0.0192     0.0199      0.0     683254.7284 15889448.4396 244453.78   97523.41  -114117.0  -114030.793   86.284      0.0    
   6500     9774.95    239.8027    0.0194    236.6475    0.0191     0.0195      0.0     701428.6989 15910240.3075 243900.14   97276.3   -114122.0  -114035.468   86.275      0.0    
   7000     10513.34   239.4477    0.0193    236.2767    0.0191     0.0204      0.0     667858.1949 15905960.1803 244013.83   97372.21  -114123.0  -114037.027   86.272      0.0    
   7500     11252.62   239.051     0.0193    235.9449    0.0191     0.0206      0.0     677588.8547 15901369.4052 243981.86   97417.12  -114159.0  -114072.428   86.279      0.0    
   8000     11991.13   238.9017    0.0193    235.6032    0.0191     0.0195      0.0     711756.3378 15902629.1515 243820.82   97471.86  -114136.0  -114049.39   86.284      0.0    
   8500     12729.15   238.8805    0.0193     235.29     0.019      0.0247      0.0     684632.6853 15895387.1338 244362.37   97110.55  -114148.0  -114061.394   86.272      0.0    
   9000     13467.46   238.6813    0.0193    234.9521    0.019      0.0201      0.0     715750.5506 15884675.4017 243830.83   97257.59  -114121.0  -114035.025   86.272      0.0    
   9500     14207.2    238.5278    0.0193    234.622     0.019      0.0192      0.0     642282.582 15899406.5556 244101.85   97157.68  -114166.0  -114079.981   86.268      0.0    
  10000     14946.37   238.2776    0.0192    234.2763    0.019      0.0259      0.0     695859.2903 15927714.8617 244033.77   97011.28  -114149.0  -114063.103   86.265      0.0    
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.24    9980.1312    0.9978   9977.8431    0.9978     3.1623     4.4274   1052178.7399 15595116.7454 287823.14  230258.51  -230265.0  -230258.509   6.729      0.004   
    10       136.92   9969.9616    0.9968   9967.4066    0.9968     3.1623     4.4274   5412163.2813 12482409.8455 287823.14  230258.51  -230266.0  -230258.509   7.001      0.0001  
    25       281.42   9949.2219    0.9947   9946.6432    0.9947     3.1623     4.4274   14045281.834 7676098.7747 287823.14  230258.51  -230266.0  -230258.509   7.406      0.0002  
   500      1022.73   4311.7289    0.4201   4306.7672    0.4197     1.8817      0.0     355227835.9981 13625055.2472 287823.14  230258.51  -230340.0  -230258.509   81.297      0.0    
   1000     1808.01    451.7114    0.0352    449.3173    0.035      0.3789      0.0     25005555.9181 31067186.6134 263724.43  211210.75  -229153.0  -229067.71   85.753      0.0    
   1500     2589.18    258.0839    0.0207    256.0553    0.0206     0.1071      0.0     5492089.8096 31715915.9783 247590.49  197592.83  -228343.0  -228256.459   86.219      0.0    
   2000     3371.72    243.0136    0.0195    240.6682    0.0194     0.0396      0.0     2262566.6977 31762559.8306 244809.56  195666.63  -228286.0  -228200.09   86.296      0.0    
   2500     4155.03    241.7666    0.0194    239.3074    0.0193     0.0253      0.0     1811581.2655 31707171.5731 244766.28  195576.65  -228212.0  -228125.867   86.315      0.0    
   3000     4939.57    241.5832    0.0194    238.8907    0.0192     0.024       0.0     1878596.0908 31760291.7245 244311.25  195308.69  -228159.0  -228072.25   86.312      0.0    
   3500      5722.8    241.4494    0.0194    238.5456    0.0192     0.0358      0.0     1903768.3438 31798979.2241 244636.79  195049.58  -228240.0  -228154.181   86.305      0.0    
   4000      6505.4    241.0518    0.0193    238.2319    0.0192     0.0246      0.0     1727489.8813 31741362.6618  244711.7  194908.65  -228171.0  -228084.866    86.3       0.0    
   4500     7284.46    240.8812    0.0193    237.9325    0.0191     0.0221      0.0     1715470.1443 31742671.7289  244768.4  194969.52  -228193.0  -228107.035   86.296      0.0    
   5000     8064.37    240.7329    0.0193    237.6396    0.0191     0.0279      0.0     1794152.3581 31753726.9266 244532.15  195293.38  -228163.0  -228077.158   86.323      0.0    
   5500     8844.44    240.4156    0.0193    237.3683    0.0191     0.0371      0.0     1730187.6947 31741246.5637 244231.15   195136.0  -228164.0  -228077.852   86.32       0.0    
   6000     9626.84    240.0558    0.0193    237.0426    0.0191     0.0326      0.0     1752064.2971 31726681.5583 244613.86   195167.1  -228196.0  -228109.733   86.318      0.0    
   6500     10414.7    239.9544    0.0193    236.7073    0.019      0.0233      0.0     1794494.7463 31740836.7849 244670.82  195299.44  -228136.0  -228050.177   86.311      0.0    
   7000     11193.34   239.6726    0.0192    236.4811    0.019      0.0232      0.0     1792801.6403 31774237.5794 244333.69  195309.24  -228166.0  -228080.06   86.308      0.0    
   7500     11970.99   239.5473    0.0192    236.1842    0.019      0.031       0.0     1897416.108 31776785.1766 244708.32  194905.54  -228151.0  -228064.572   86.298      0.0    
   8000     12749.73   239.1208    0.0192    235.8788    0.019      0.0305      0.0     1776867.8815 31717814.7493 244317.19   195157.8  -228179.0  -228092.567   86.295      0.0    
   8500     13529.37   239.0076    0.0192    235.5957    0.0189     0.0416      0.0     1635161.4539 31749406.1274 244498.97  194849.97  -228147.0  -228060.564   86.304      0.0    
   9000     14310.94   238.7387    0.0192    235.3563    0.0189     0.0225      0.0     1728553.0059 31782241.1581 244235.45  195065.75  -228124.0  -228037.466   86.293      0.0    
   9500     15091.52   238.4371    0.0191    235.0466    0.0189     0.0246      0.0     1685831.0204 31733786.6959 244389.76  194605.19  -228150.0  -228063.496   86.304      0.0    
  10000     15870.04   238.3569    0.0191    234.8036    0.0189     0.0305      0.0     1827078.6387 31781195.205  244407.3  194597.19  -228138.0  -228051.488   86.293      0.0    
Using  0.5  of training data 
Using  0.5 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.25    9980.8973    0.9979   9980.8161    0.9979     3.1623     4.4274   2734101.6087 31142177.9575 287823.14  575646.27  -575653.0  -575646.273    7.05      0.0224  
    10       242.29   9970.9938    0.9969   9970.6627    0.9969     3.1623     4.4274   13274596.6465 24785108.5095 287823.14  575646.27  -575654.0  -575646.273   7.297      0.0005  
    25       494.09    9950.702    0.9949   9950.3828    0.9948     3.1623     4.4274   34318097.1779 15236340.7614 287823.14  575646.27  -575654.0  -575646.273   7.659      0.0002  
   500      1353.46   4325.2151    0.4217   4324.6203    0.4216     1.8663      0.0     889699201.7338 33857423.2973 287823.14  575646.27  -575727.0  -575646.273   80.446      0.0    
   1000     2250.72    439.2201    0.0341    439.344     0.034      0.3613      0.0     62014800.1734 77693232.1492 264087.24   527304.2  -572698.0  -572612.977   85.304      0.0    
   1500     3147.89    255.6762    0.0205    255.3173    0.0205     0.1065      0.0     12568686.7757 79503335.1423 248764.61  496197.67  -570715.0  -570629.174   85.983      0.0    
   2000      4047.0    241.4181    0.0194    240.8035    0.0194     0.0376      0.0     6284164.9909 79519530.7123 245820.17  491533.24  -570478.0  -570391.66   86.144      0.0    
   2500     4943.83    240.1528    0.0193    239.5162    0.0193     0.0304      0.0     4845228.5273 79479165.0149 245990.07  491518.26  -570398.0  -570311.554   86.195      0.0    
   3000     5841.51    239.8347    0.0193    239.1252    0.0192     0.0289      0.0     4604809.2581 79316155.7301 246147.52  491150.61  -570341.0  -570255.29   86.196      0.0    
   3500     6737.83    239.5715    0.0193    238.8686    0.0192     0.0314      0.0     4839886.0686 79474862.5645 245589.52  490915.49  -570343.0  -570256.361   86.195      0.0    
   4000     7633.89    239.3006    0.0192    238.6075    0.0192     0.0366      0.0     4597131.2798 79397041.3654 246095.11  491122.14  -570355.0  -570268.991   86.192      0.0    
   4500     8535.52    239.1687    0.0192    238.3304    0.0192     0.0377      0.0     5027184.892 79527461.987 246077.65   491270.7  -570476.0  -570389.976   86.192      0.0    
   5000     9437.94    238.9784    0.0192    238.0976    0.0192     0.034       0.0     5324039.5253 79454479.0367 246006.19  490651.47  -570420.0  -570333.58   86.184      0.0    
   5500     10335.56   238.6377    0.0192    237.8167    0.0191     0.0356      0.0     4776522.3493 79546945.5237 245900.06  491066.11  -570400.0  -570313.489   86.198      0.0    
   6000     11233.9    238.4978    0.0192    237.5248    0.0191     0.0264      0.0     4970283.8096 79354739.3813 246232.89   491069.8  -570389.0  -570302.935   86.192      0.0    
   6500     12134.51   238.3204    0.0192    237.2691    0.0191     0.0283      0.0     4581736.9403 79354385.6687 246207.14  490912.66  -570396.0  -570309.482   86.195      0.0    
   7000     13039.66   237.9879    0.0191    237.0511    0.0191     0.0265      0.0     5090722.2278 79345274.0576 245984.62  490534.17  -570340.0  -570254.235   86.178      0.0    
   7500     13942.73   237.718     0.0191    236.7519    0.0191     0.0326      0.0     4808066.2516 79334894.1375  245742.8  490203.19  -570333.0  -570247.306   86.187      0.0    
   8000     14845.47   237.6787    0.0191    236.5365    0.019      0.0355      0.0     4872295.6231 79465348.0832 245533.56  490895.53  -570286.0  -570199.724   86.199      0.0    
   8500     15743.82   237.2894    0.0191    236.2701    0.019      0.0293      0.0     4427741.5153 79419041.4195  245676.5  491228.95  -570334.0  -570248.142   86.193      0.0    
   9000     16641.1    237.1908    0.0191    236.0421    0.019      0.0247      0.0     5101279.0335 79336752.2554 245403.22  490602.27  -570300.0  -570213.746   86.196      0.0    
   9500     17537.06   236.7792    0.019     235.8159    0.019      0.0315      0.0     4762574.4849 79587882.3585 245647.64  490170.99  -570307.0  -570220.942   86.202      0.0    
  10000     18431.99   236.695     0.019     235.5819    0.019      0.0361      0.0     4547035.8131 79266122.0438 245785.86  489986.91  -570284.0  -570198.299   86.185      0.0    
Using  1  of training data 
Using  1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.25    9980.6195    0.9979   9977.9146    0.9979     3.1623     4.4274   6312088.8534 77662201.7291 287823.14  1151292.55 -1151301.0 -1151292.546   8.846      0.0301  
    10       416.19   9970.5954    0.9969   9967.7161    0.9968     3.1623     4.4274   27593316.9909 61725393.7129 287823.14  1151292.55 -1151302.0 -1151292.546   8.997      0.001   
    25       844.33   9950.1866    0.9948   9947.2062    0.9948     3.1623     4.4274   70652794.0443 38043767.8492 287823.14  1151292.55 -1151302.0 -1151292.546   9.298      0.0004  
   500      1879.94   4321.0265    0.4211   4313.4959    0.4206     1.9079      0.0     1780059343.5951 67869558.7721 287823.14  1151292.55 -1151372.0 -1151292.546   79.92       0.0    
   1000     2963.52    455.2306    0.0346    452.424     0.0344     0.4052      0.0     120297655.6194 155320598.5677 263665.38  1052066.16 -1144982.0 -1144896.436   85.142      0.0    
   1500     4052.97    260.601     0.0208    259.5483    0.0207     0.1012      0.0     26378982.4511 158792093.1642 249066.98   994858.3  -1141327.0 -1141240.995   86.024      0.0    
   2000     5139.58    241.5657    0.0194    240.9865    0.0193     0.0414      0.0     11813252.1539 158621847.4696 246474.77  983597.67  -1140724.0 -1140637.492   86.298      0.0    
   2500     6226.83    239.861     0.0193    239.4149    0.0192     0.0258      0.0     9552973.046 158556837.7614 246565.39  982468.99  -1140625.0 -1140538.923   86.375      0.0    
   3000     7314.25    239.2639    0.0192     238.93     0.0192      0.03       0.0     9587544.8236 159189565.9169 246566.02  981542.52  -1140471.0 -1140385.019   86.391      0.0    
