Generating synthetic binary valued data ... 
Generating synthetic  binary valued data took:  17.154709339141846
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
0.7319016327 0.7379701891   0.13392      0.13615      24593.08     97734.26  
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.31      1.4129     0.499      1.4408     0.519      3.1623    27.8104     0.2861     0.1055    18381.15    733.35     -759.0    -750.294     8.34       0.0    
    10       82.83      1.4056     0.4939     1.3191     0.435      3.1623    176.3644    2.6406     1.4934    18230.38    685.05     -744.0    -735.556    8.435      0.0338  
    25       169.57     1.4069     0.4948     1.1916     0.355      3.1623    176.3644    5.3806     3.5025    18103.07    629.95     -737.0    -728.455    8.259      0.0013  
   500       442.26     1.0007     0.2504     0.555      0.077      1.7496     0.1211     2.6969     6.2875    14304.77    222.15     -615.0    -602.182    13.178     0.0002  
   1000      793.69     0.9741     0.2372     0.3406     0.029      0.7593     1.7081     1.0954     5.3951    13416.63    175.12     -601.0    -590.982    9.716       0.0    
   1500     1148.65     0.9879     0.244      0.2449     0.015      0.7473     2.4307     0.8795     4.7974    13628.98    164.75     -597.0    -589.569    7.895       0.0    
   2000     1510.89     0.9976     0.2488      0.2        0.01      0.6573     0.3784     0.8836     4.3644    13732.41    167.98     -596.0    -588.971    6.882       0.0    
   2500     1869.69     1.0103     0.2552     0.2098     0.011      0.5756    11.7502     1.0711     4.0124    13896.89    170.24     -597.0    -590.714    5.835       0.0    
   3000     2226.63     1.0073     0.2537     0.1673     0.007      0.5621     3.3996     1.0231     3.7242    13629.71    167.97     -595.0    -589.027    5.603       0.0    
   3500     2574.12     1.0038     0.2519     0.1414     0.005      0.6293     0.3842     1.0349     3.4352    13325.6     164.14     -593.0    -588.072     5.06       0.0    
   4000     2942.72     0.9937     0.2469     0.228      0.013      0.5409     1.3815     1.089      3.1955    12998.3     169.85     -593.0    -588.293    4.932       0.0    
   4500     3304.29     0.9878     0.244      0.1673     0.007      0.5587     1.7268     1.202      3.022     12841.38    168.81     -593.0    -588.462     4.48       0.0    
   5000     3669.42     0.9899     0.245      0.1897     0.009      0.6468     7.2837     1.287      2.9169    12761.82    168.97     -593.0    -588.903    4.481       0.0    
   5500     4018.52     0.9888     0.2444     0.1549     0.006      0.6866    11.5217     1.4655     2.8411    12767.01    166.52     -592.0    -587.079    4.724       0.0    
   6000     4375.64     0.9753     0.2378     0.1673     0.007      0.8133    54.7383     1.7768     3.2821    12453.31    163.9      -590.0    -584.54     5.292       0.0    
   6500      4722.3     1.0053     0.2527     0.1789     0.008      2.4047   10398.4881   7.9765    17.7367    13062.79    167.16     -595.0    -584.515    9.998       0.0    
   7000     5080.74     0.9965     0.2482     0.0632     0.001      1.504     858.3002    3.9752     6.1684    13066.95    125.77     -581.0    -571.493    9.269       0.0    
   7500     5440.19     1.0065     0.2532      0.0        0.0       1.0621    131.0466    3.3565     7.053     13580.32    81.43      -567.0    -555.659    10.879      0.0    
   8000     5799.39     1.0632     0.2826     0.1265     0.004      2.7362   138920.4148  12.3962    16.6432    15637.88    82.02      -597.0    -556.355    41.023      0.0    
   8500     6149.75     1.0801     0.2916      0.0        0.0       2.5264   17563.2662  15.1694    19.9804    18539.12    76.28      -568.0    -553.181    14.849      0.0    
   9000      6510.6     1.0939     0.2992      0.0        0.0       1.6346   1649.1042    8.3999    12.1289    18437.87    77.49      -565.0    -550.885    13.982      0.0    
   9500     6875.12     1.0547     0.2781      0.0        0.0       1.6223   1032.5435   12.4254     18.953    16975.81    81.66      -573.0    -554.785    18.564      0.0    
  10000     7229.76     1.0638     0.2829      0.0        0.0       2.5249   60060.597   41.0443    37.3819    17035.55    87.47      -577.0    -556.285    20.829      0.0    
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.61      1.4126     0.4988     1.4043     0.493      3.1623    15.1163    41.3094    37.2484    18184.78    1449.1    -1500.0   -1491.885    8.346      0.1289  
    10       88.55      1.4115     0.4981     1.3565      0.46      3.1623    149.0766   35.9963    32.6058    18291.34   1395.72    -1491.0   -1482.286    8.527      0.0812  
    25       181.93     1.4151     0.5006     1.2538     0.393      3.1623    269.7297   23.4417    28.5887    18260.51   1326.24    -1473.0   -1464.556    8.713      0.0565  
   500       629.04     0.9217     0.2124     0.496      0.0615     2.1484     0.071      4.1842     7.8622    12768.21    387.86    -1200.0   -1185.535    14.176     0.0001  
   1000     1168.95     0.9149     0.2092     0.2145     0.0115     0.6785     0.0684     1.7367     6.7864    12172.5     265.61    -1157.0   -1145.847    11.378      0.0    
   1500     1715.22     0.9208     0.212      0.1844     0.0085     0.4905     0.1541     1.158      5.4406    11936.57    259.0     -1154.0   -1144.103    9.621       0.0    
   2000     2264.38     0.9263     0.2145     0.1483     0.0055     0.5759     6.413      1.1908     4.6269    11928.03    275.67    -1159.0   -1150.835    8.557       0.0    
   2500     2811.49     0.9324     0.2173     0.1732     0.0075     0.6593     27.806     1.391      4.0564    11890.93    293.6     -1168.0   -1159.155    8.473       0.0    
   3000     3358.18     0.9342     0.2182      0.2        0.01      0.598      3.9924     1.4362     3.7461    11822.82    302.07    -1168.0   -1160.301    7.769       0.0    
   3500     3904.28     0.9345     0.2183     0.1789     0.008      0.8006     6.7832     1.6823     3.6144    11784.06    313.27    -1175.0    -1167.36    7.631       0.0    
   4000     4448.19     0.9229     0.2129     0.1897     0.009      0.7863    22.4881     1.9171     3.6327    11551.09    321.86    -1176.0    -1168.61    7.419       0.0    
   4500     4993.09     0.9332     0.2177     0.2098     0.011      1.216     58.4499     2.6437     5.1577    11767.86    346.62    -1183.0   -1175.066    8.298       0.0    
   5000     5532.89     0.9423     0.222      0.2098     0.011      1.2704    73.2376     3.8788     6.4367    12010.78    394.98    -1201.0   -1193.492    7.537      0.0002  
   5500     6072.67     0.9226     0.2128     0.3847     0.037      1.7456   1794.3035    6.1777    12.1061    11898.68    550.7     -1252.0   -1243.783    7.818      0.0001  
   6000     6619.03     0.9927     0.2464     0.7629     0.1455     2.1151   12414.1735   12.808    24.0734    14253.29    998.59    -1392.0   -1386.459    5.174      0.0007  
   6500     7160.88     0.9491     0.2252     0.8944      0.2       1.3054   1848.6294   12.6577    25.5895    13457.49    1025.5    -1395.0   -1388.343    6.582      0.001   
   7000     7694.49     0.9468     0.2241      0.9       0.2025     1.0579   3913.0214    8.6336     25.921    13634.88   1060.38    -1407.0   -1396.187    10.642     0.002   
   7500     8214.03     1.0153     0.2577     1.0237     0.262      1.3504   5467.6453   14.2845    35.7325    14868.05   1176.77    -1444.0   -1431.469    12.326     0.0029  
   8000     8717.45     1.0713     0.2869     1.0354     0.268      2.0263   17103.3972  21.3993    43.5207    15232.17   1217.76    -1463.0   -1443.063    20.151     0.0014  
   8500     9218.35     1.0095     0.2548     0.9737     0.237      1.5549   11894.4892  18.9325    44.2682    14381.83   1131.92    -1458.0    -1420.13    37.878     0.0008  
   9000     9727.44     0.9887     0.2444     0.9455     0.2235     2.1156   9149.4855   21.7426    65.6761    14854.99   1177.19    -1470.0   -1432.795    36.857     0.0004  
   9500     10251.64    0.9046     0.2046     0.8843     0.1955     1.2578   1224.1956    13.356    69.4963    12818.1    1001.56    -1418.0   -1375.609    42.241     0.0003  
  10000     10784.74    0.8844     0.1955     0.8579     0.184      0.7923   3361.5804     9.01     60.0854    12064.51    927.22    -1401.0   -1350.075    51.078      0.0    
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.57      1.4186     0.5031     1.4097     0.4968     3.1623     4.4274     9.8427    59.4548    18368.59   3659.93    -3745.0   -3727.093    17.884     0.2731  
    10       111.35     1.4162     0.5014     1.3717     0.4704     3.1623     4.4274    12.9472    51.7653    17956.85   3500.01    -3733.0   -3712.317    20.191     0.0176  
    25       231.7      1.4161     0.5014     1.3303     0.4424     3.1623    21.9351    15.1948    31.9252    17958.71   3427.56    -3715.0   -3689.237    26.005     0.0152  
   500      1201.61     0.8848     0.1957     0.5824     0.0848     1.7883     0.1192     6.3132     9.6942    11084.14   1165.61    -3004.0   -2987.804    16.49       0.0    
   1000     2328.87      0.89      0.198      0.4147     0.043      1.0319    13.9687     3.0797     7.4552    11232.14    864.91    -2926.0   -2912.144    13.819      0.0    
   1500     3462.14     0.8915     0.1987     0.3699     0.0342     0.618      5.4944     2.0903     5.9149    10946.21    911.78    -2942.0   -2929.801    12.246     0.0001  
   2000     4593.73     0.8913     0.1986     0.4167     0.0434     0.752      3.786      2.0855     5.1197    10602.32   1070.56    -2993.0   -2982.991    10.15       0.0    
   2500     5723.78     0.8725     0.1903     0.5337     0.0712     0.771      1.4852     2.1835     4.9955    10221.19   1283.13    -3060.0   -3051.911    8.311      0.0003  
   3000     6853.87     0.862      0.1858     0.653      0.1066     1.1224     1.0515     2.902      4.8311    10223.28   1574.59    -3153.0   -3146.276    6.427      0.0003  
   3500     7982.44     0.8629     0.1862     0.7869     0.1548     1.1443    110.207     3.3033     5.2769    10493.86   1908.48    -3240.0   -3235.091    4.919      0.0004  
   4000     9112.94     0.8724     0.1903     0.8528     0.1818     1.0941   1792.1617    5.1385     9.9381    10939.38   2097.38    -3304.0   -3298.687     5.15      0.0002  
   4500     10235.68    0.8858     0.1962     0.8681     0.1884     1.4373   1223.3134     6.25     15.6182    11329.22   2215.42    -3342.0    -3330.66    11.196     0.0009  
   5000     11354.54    0.9049     0.2047     0.8805     0.1938     1.2391    344.4094    7.5336    22.5944    12597.64   2490.51    -3440.0   -3430.839    9.336      0.0017  
   5500     12460.92    1.0107     0.2554     1.0182     0.2592     1.3208   1301.8998   12.9129    30.4913    15341.14   3056.66    -3627.0   -3612.213    14.766     0.0052  
   6000     13536.88    0.9843     0.2422     0.9794     0.2398     1.3014   3280.3912   17.5049    39.4935    14683.95   2917.99    -3586.0    -3568.15    18.319     0.0033  
   6500     14596.86    1.2887     0.4152     1.2934     0.4182      1.42    25751.153   24.1806    54.2434    16873.43   3378.64    -3723.0   -3698.217    25.227     0.0059  
   7000     15660.64    1.408      0.4956     1.3903     0.4832     1.085    1708.9434    11.971    49.1613    17347.97   3459.72    -3797.0   -3722.358    74.96      0.0006  
   7500     16751.03    1.3042     0.4252     1.2778     0.4082     0.8539   4587.6948   14.5112    54.6222    17036.69   3391.84    -3762.0   -3713.376    48.895     0.0008  
   8000     17857.93    0.8732     0.1906     0.8814     0.1942     1.2654   3341.5488   19.8704    103.5223   11144.76   2197.73    -3363.0   -3309.473    53.759     0.0005  
   8500     18973.95    0.8722     0.1902     0.8786     0.193      0.9295   2771.4158   13.4953    62.1987    10549.66   2044.88    -3294.0   -3248.113    46.228     0.0004  
   9000     20093.2     0.8694     0.189      0.8537     0.1822     0.2011    11.7761     6.3243    11.8009    10396.99   2000.62    -3280.0   -3239.377    40.818     0.0002  
   9500     21210.47    0.866      0.1875     0.849      0.1802     0.1328    12.8463     3.8373    11.8973    10039.81   1883.56    -3234.0   -3197.129    36.688     0.0001  
  10000     22327.53    0.8694     0.189      0.8217     0.1688     0.0904     1.5347     2.8926    11.6964     9999.0     1814.3    -3207.0   -3173.936    33.459     0.0001  
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.0       1.4104     0.4973     1.405      0.4935     3.1623     4.4274     5.2346    13.0664    18458.27   7345.86    -7482.0   -7470.566    11.715     0.0528  
    10       137.05     1.4166     0.5017     1.3865     0.4806     3.1623     4.4274     20.548    25.7634    18404.17   7180.53    -7449.0   -7436.648    12.751     0.0141  
    25       284.94     1.4147     0.5004     1.3656     0.4662     3.1623     4.4274    32.1321     32.634    18024.01   6985.57    -7434.0   -7417.759    16.471     0.0055  
   500      1515.43     0.8805     0.1938     0.7313     0.1337     2.3334     0.2888    10.0247    10.2617    10387.07   3145.17    -6245.0   -6228.189    16.945     0.0004  
   1000     2936.82     0.8604     0.1851     0.6714     0.1127     1.2234    11.1097     8.5548     8.9186    10143.71   2830.65    -6147.0   -6135.279    12.067      0.0    
   1500     4368.31     0.8579     0.184      0.6951     0.1208     1.4944     3.9387     6.7636     8.0863    9839.12    3049.56    -6216.0    -6206.68     9.8       0.0001  
   2000     5797.99     0.849      0.1802     0.7381     0.1362     0.9461    123.8317    6.9697     7.8029    9843.73     3312.8    -6287.0   -6278.626    8.651      0.0003  
   2500     7231.11     0.8491     0.1802     0.7694     0.148      0.8019     4.0244     5.4538     7.2121    9908.04    3538.93    -6368.0   -6361.115    6.589      0.0003  
   3000     8660.12     0.8575     0.1838     0.8304     0.1724     0.9309    547.0064    7.3756    14.7976    10317.46   3946.05    -6494.0   -6488.413    5.258      0.0002  
   3500     10080.14    0.8655     0.1873     0.8504     0.1808     1.2068   1008.0334    7.9467    15.2809    11024.99   4293.46    -6628.0   -6619.842    8.439      0.0005  
   4000     11484.16    0.8745     0.1912     0.8713     0.1898     1.4776    858.4854   13.2551    34.8466    11962.14    4741.6    -6782.0   -6771.367    10.169     0.001   
   4500     12869.69    1.0084     0.2542     1.0068     0.2534     1.6251   4457.5319   23.4648    71.6413    15322.71   6108.65    -7237.0   -7223.057    14.335     0.0018  
   5000     14225.91    1.3601     0.4624     1.3543     0.4585     1.5564   1863.5605   20.5476    62.4313    17150.59   6867.51    -7450.0   -7428.992    21.226     0.0027  
   5500     15563.54    1.186      0.3516     1.1698     0.3421     2.4846   38427.1981  63.3047    188.1367   16418.73   6562.59    -7386.0   -7337.796    48.326      0.0    
   6000     16933.61    0.9072     0.2058     0.8967     0.201      1.3849   11402.0328  30.0641    185.4967   14436.11   5742.45    -7169.0   -7123.124    46.054      0.0    
   6500     18332.69    0.9204     0.2118     0.9066     0.2055     0.9473   1068.4356   41.4116    83.2948    13040.6    5123.95    -6969.0   -6930.822    38.212      0.0    
   7000     19737.51    0.8563     0.1833     0.8579     0.184      0.7167    367.201     15.955    53.9591    10293.37   4013.68    -6506.0   -6467.045    39.126     0.0014  
   7500     21143.01    0.8675     0.1881     0.8523     0.1816     0.6486    223.231    10.8467    26.9288    10099.78   3919.11    -6486.0   -6444.492    41.176      0.0    
   8000     22546.75    0.8538     0.1822     0.8398     0.1763     0.3134     4.6253     8.2629    16.4425    9890.53    3787.56    -6426.0   -6385.597     40.5      0.0001  
   8500     23947.42    0.8598     0.1848     0.8333     0.1736     0.2755     1.0036     5.922     14.2366    9807.56     3702.9    -6391.0   -6357.569    33.831     0.0001  
   9000     25348.15    0.8547     0.1826     0.8161     0.1665     0.3234     0.443      6.0179    15.1039    9763.95    3614.88    -6356.0   -6325.653    30.205     0.0001  
   9500     26749.4     0.8606     0.1852     0.8017     0.1607     0.2869     0.2159     7.0041    15.1155     9792.5    3525.07    -6329.0   -6300.759    28.059     0.0001  
  10000     28153.08    0.8626     0.186      0.7769     0.1509     0.2963     0.4705     6.6378    15.3988    9831.75    3403.31    -6303.0   -6275.405    27.181      0.0    
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.02      1.4114     0.498      1.4193     0.5036     3.1623     4.4274    10.8077    17.9866    18507.84   14837.15   -14988.0  -14978.037   9.838      0.0198  
    10       178.56     1.4168     0.5018     1.4066     0.4946     3.1623     4.4274    46.2123    44.9236    19056.21   15003.85   -14966.0  -14955.164   10.533     0.003   
    25       369.18     1.4176     0.5024     1.3952     0.4866     3.1623     4.4274    85.1345    71.3686    19269.78   15083.61   -14957.0  -14943.466   13.127     0.0013  
   500      1663.82     0.8583     0.1842     0.7939     0.1576     1.7238     0.6762    19.0195    16.7406    9809.29    6953.07    -12537.0  -12520.25    16.812      0.0    
   1000     3199.55     0.8404     0.1766     0.7613     0.1449     1.3348     2.0647     17.637    14.4386    9539.69    6635.43    -12507.0  -12492.59    14.297     0.0001  
   1500     4739.31     0.8369     0.1751     0.7642     0.146      1.1199     0.7654    15.4271    14.0514    9524.97    6826.51    -12575.0  -12563.381   11.217      0.0    
   2000     6277.29     0.8429     0.1776     0.7904     0.1562     0.828      35.065    13.5011    13.5403    9621.29    7149.11    -12705.0  -12694.964   10.305     0.0001  
   2500     7810.53     0.8486      0.18      0.8155     0.1662     0.9256    41.2342     13.087    14.1884    9849.48    7610.07    -12838.0  -12827.468   10.074     0.0001  
   3000     9326.71     0.8593     0.1846     0.8452     0.1786     1.2554    150.9757   16.7679    35.7489    10268.23   8073.92    -13002.0  -12990.076   11.677     0.0001  
   3500     10805.62    0.8634     0.1864     0.8546     0.1826     1.4245    958.2766   27.7477    70.3938    10896.21   8662.08    -13247.0  -13228.444   18.386     0.0004  
   4000     12234.9     0.8635     0.1864     0.8654     0.1872     1.0883    855.3049   25.7214    61.4054    10375.41   8259.47    -13050.0  -13017.253   33.002     0.0001  
   4500     13648.1     0.8616     0.1856     0.8616     0.1856     0.922    1647.5924   54.0826    32.2492    10547.65   8356.39    -13137.0  -13102.898   34.524     0.0001  
   5000     15079.28    0.8576     0.1839     0.8551     0.1828     0.7821   3868.8189   20.8487    43.3226    10052.69   7973.23    -12962.0  -12926.437   35.266     0.0003  
   5500     16528.35    0.8656     0.1873     0.8573     0.1838     1.1283   19358.9972  68.1334    283.896    10235.82    8089.6    -13032.0  -12994.184   37.476     0.0002  
   6000     17962.52    0.8616     0.1856     0.8504     0.1808     0.242      5.4305    10.9702    16.1955    10002.67   7870.45    -12945.0  -12910.21    34.539     0.0001  
   6500     19366.58    0.8587     0.1843     0.8478     0.1797     0.3642    16.3681    13.9254     21.641    9920.97    7788.85    -12898.0  -12865.89    32.304     0.0001  
   7000     20770.17    0.8544     0.1825     0.841      0.1768     0.4283    64.6285    11.9784    19.9041     9877.8    7721.33    -12885.0  -12854.054   31.045     0.0001  
   7500     22196.15    0.8462     0.179      0.8284     0.1716     0.4086     1.7638    12.5275     15.696    9857.95    7684.27    -12873.0  -12843.611   29.324     0.0001  
   8000     23649.6     0.8533     0.182      0.8221     0.169      0.5208     4.5619    11.4782    14.9351    9839.22    7616.27    -12860.0  -12831.836   28.035     0.0001  
   8500     25055.6     0.8498     0.1806     0.8112     0.1645     0.3622     2.4619    13.2358    15.8436    9743.14    7416.25    -12796.0  -12768.962   27.261      0.0    
   9000     26464.38    0.8438     0.178      0.7972     0.1589     0.3983     0.1245    14.1369    16.9307    9653.64    7216.32    -12711.0  -12683.859   26.824     0.0001  
   9500     27872.25    0.8418     0.1772     0.7904     0.1562     0.3484     0.0613    14.8498    17.1823    9655.25    7055.48    -12672.0  -12644.748   27.563      0.0    
  10000     29326.42    0.8448     0.1784     0.7778     0.1512     0.3729     3.5601    16.5991    17.2587    9628.23     6909.1    -12628.0  -12601.279   27.042      0.0    
Using  0.5  of training data 
Using  0.5 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.02      1.4141     0.4999     1.4112     0.4979     3.1623     4.4274    28.4579    24.5397    18591.23   37370.03   -37431.0  -37423.855    7.6       0.0064  
    10       303.15     1.413      0.4991      1.41      0.497      3.1623     4.4274    125.4989   91.4171    19195.15   38346.86   -37420.0  -37412.219   7.792      0.0007  
    25       620.88     1.4099     0.497      1.4005     0.4904     3.1623     4.4274    235.8917   161.2846   19948.94   39413.39   -37444.0  -37434.94    9.141      0.0003  
   500      2049.69     0.857      0.1836     0.844      0.1781     1.1015     2.4328    54.2772     55.077    9780.63    18999.86   -31809.0  -31786.658   22.582      0.0    
   1000     3847.82      0.84      0.1764     0.8206     0.1683     0.9429     1.2626    42.9352    56.8315    9413.35    18291.46   -31530.0  -31511.475   18.508      0.0    
   1500      5647.2     0.834      0.1739     0.8173     0.167      0.8212    16.1138    38.5953    53.3312    9444.72    18336.42   -31615.0  -31596.186   18.907      0.0    
   2000     7449.74     0.8369     0.1751     0.8242     0.1698     0.8274     0.5547     39.676    50.4564    9421.72    18478.53   -31613.0  -31597.429   15.18       0.0    
   2500     9256.37     0.8466     0.1792     0.8346     0.1741     0.6995    11.6126    37.7179    53.7928    9512.35    18760.44   -31703.0  -31685.277   17.363      0.0    
   3000     11054.75    0.8518     0.1814     0.8465     0.1792     0.5012    14.4773    32.9125    55.3596     9552.5    18979.6    -31755.0  -31736.357   18.726      0.0    
   3500     12840.98    0.8545     0.1826     0.8593     0.1846     0.6999    348.6626    40.018    69.3628    9665.49    19291.56   -31890.0  -31870.744   19.662      0.0    
   4000     14563.48    0.8591     0.1845     0.8578     0.184      1.1679   1046.3962   81.1368     186.81    9842.28    19676.36   -31932.0  -31913.697   18.431      0.0    
   4500     16197.25    0.8514     0.1812     0.8498     0.1806     1.1501    574.6353   99.4601    167.5851    9789.0    19461.62   -31740.0  -31706.704   33.548      0.0    
   5000     17787.37     0.85      0.1806     0.8527     0.1818     0.7974    312.7461   53.2431    147.2026   9666.32    19178.54   -31763.0  -31724.664   38.463      0.0    
   5500     19411.86    0.8504     0.1808     0.8519     0.1814     0.6406   1699.1322   40.2491    126.2151   9578.53    19146.24   -31786.0  -31743.875   42.16       0.0    
   6000     21047.81    0.8492     0.1803     0.8486      0.18      0.3259     0.8186    31.7004    41.7334    9553.94    19081.25   -31858.0  -31823.12    35.031      0.0    
   6500     22669.86    0.8435     0.1779     0.8439     0.1781     0.4697     0.191     31.8009    42.6844    9532.79    18950.44   -31779.0  -31748.953    29.7       0.0    
   7000     24298.13    0.8452     0.1786     0.8412     0.1769     0.429      0.0798     30.029    44.2182    9497.86    18794.47   -31756.0  -31727.076   28.768      0.0    
   7500     25926.7     0.8321     0.1731     0.8258     0.1705     0.5528     1.5076    30.9539    46.0948    9381.37    18460.47   -31655.0  -31626.699   28.008      0.0    
   8000     27558.45    0.8292     0.1719     0.8089     0.1636     0.508      0.0437    38.2781    45.8092    9297.07    17973.27   -31526.0  -31497.129   29.363      0.0    
   8500     29188.06    0.8228     0.1692     0.7948     0.1579     0.5187     0.0314    42.2514    44.6911    9181.19    17511.1    -31351.0  -31322.427   28.284      0.0    
   9000     30855.8     0.8239     0.1697      0.79      0.156      0.6204     0.027     41.7714    42.7136    9151.44    17256.39   -31294.0  -31267.059   27.202      0.0    
   9500     32528.89    0.8188     0.1676     0.7806     0.1523     0.5465     0.256     43.0555    43.2106    9149.22    17030.87   -31276.0  -31247.221   28.629      0.0    
  10000     34164.21    0.8203     0.1682     0.7772     0.151      0.6561     0.0225    44.6606     43.929    9129.44    16843.63   -31206.0  -31177.29    29.026      0.0    
Using  1  of training data 
Using  1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.07      1.4189     0.5033     1.4138     0.4997     3.1623     4.4274    67.6297    57.6105    18615.88   74323.75   -74881.0  -74872.393    8.67      0.0031  
    10       527.69     1.4152     0.5007     1.4134     0.4994     3.1623     4.4274    248.6456   183.6521   19132.17   76231.94   -74961.0  -74951.668   9.119      0.0003  
    25      1074.01     1.4104     0.4973     1.412      0.4985     3.1623     4.4274    449.0709   313.525    19819.84   79092.43   -75116.0  -75104.451   11.059     0.0001  
   500      2759.01     0.8564     0.1834     0.8529     0.1819     1.0398    26.6771    104.6684   124.3464   9715.31    38649.49   -63335.0  -63308.961   26.443      0.0    
   1000     5050.07     0.8422     0.1773     0.8409     0.1768     0.9459     5.9348    81.4546    126.0858   9474.25    37870.36   -63416.0  -63394.26    22.004      0.0    
   1500     7355.19     0.8405     0.1766     0.8407     0.1767     1.0159    56.0822    84.0513    126.776    9438.73    37654.33   -63336.0  -63308.243   27.634      0.0    
   2000     9648.63     0.8448     0.1784     0.844      0.1781     0.9881    299.7761   82.7135    145.2865   9533.54    38195.94   -63606.0  -63584.345   21.342      0.0    
   2500     11943.47    0.8532     0.182      0.8516     0.1813     0.5841    164.4925    80.229    165.5189   9534.28    38356.21   -63587.0  -63566.06    21.105      0.0    
   3000     14197.0     0.8556     0.183      0.8575     0.1838     1.2169   11868.549   205.658    466.9638   9730.13    39190.34   -63847.0  -63818.255   29.202      0.0    
   3500     16154.91    0.8469     0.1793     0.852      0.1815     0.8399   1982.3259   107.7948    189.66    9647.01    38735.53   -63398.0  -63370.569   27.735      0.0    
   4000     18054.87    0.8491     0.1802     0.8524     0.1816     0.5232    127.0649   83.2963    155.566    9560.13    38496.21   -63600.0  -63574.869   25.062      0.0    
   4500     19964.87    0.8484      0.18      0.8495     0.1804     0.4102     9.2186    71.8517    132.7033   9494.61    38218.86   -63455.0  -63428.082   26.572      0.0    
   5000     21884.18    0.8457     0.1788     0.8498     0.1805     0.4388     7.7378    72.1704    145.074    9472.74    38116.52   -63416.0  -63391.708   23.875      0.0    
   5500     23856.18    0.8429     0.1776     0.8486      0.18      0.3758     5.8336    65.5239    145.3372   9445.12    37857.47   -63325.0  -63302.826   22.528      0.0    
   6000     25906.29    0.8375     0.1754     0.839      0.176      0.4809     0.5931    71.1215    144.1549   9357.53    37453.88   -63198.0  -63175.38    22.649      0.0    
   6500     27973.79    0.8267     0.1708     0.8233     0.1695     0.4849     0.4541    74.4675    143.1946   9321.04    36936.12   -63102.0  -63081.463   20.105      0.0    
   7000     30044.3     0.8244     0.1699     0.8142     0.1657     0.5853     0.1539    86.3946    136.3348   9195.84    36402.75   -62886.0  -62864.466   21.637      0.0    
   7500     32114.81    0.8156     0.1663     0.8032     0.1613     0.6784     0.2703    81.9859    132.7356   9144.11    35962.8    -62788.0  -62766.884   20.987      0.0    
   8000     34195.73    0.8203     0.1682     0.8043     0.1617     0.7747     0.505     87.1499    128.8742   9105.19    35757.17   -62712.0  -62687.495   24.905      0.0    
   8500     36279.99    0.8171     0.1669     0.806      0.1624     0.7455    29.9413    91.2819    139.4011   9055.91    35508.58   -62397.0  -62377.223   20.144      0.0    
   9000     38353.31    0.8142     0.1657     0.8048     0.1619     0.4995     0.0241    81.5619    131.8451   9014.13    35306.29   -62508.0  -62487.337   20.366      0.0    
   9500     40391.1     0.8122     0.1649     0.7979     0.1592     0.5462     0.0231    86.7253    133.546    9011.33    35218.57   -62637.0  -62616.328   20.44       0.0    
  10000     42420.63    0.8115     0.1646     0.7985     0.1594     0.561      0.0312    93.0054    134.2378   9033.33    35188.62   -62604.0  -62584.157   19.939      0.0    
