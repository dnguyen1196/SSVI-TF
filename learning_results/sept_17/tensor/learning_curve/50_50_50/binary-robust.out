Generating synthetic binary valued data ... 
Generating synthetic  binary valued data took:  17.154709339141846
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
0.7319016327 0.7379701891   0.13392      0.13615      24593.08     97734.26  
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.31      1.4129     0.499      1.4408     0.519      3.1623    27.8104     0.2861     0.1055    18381.15    733.35     -759.0    -750.294     8.34       0.0    
    10       82.83      1.4056     0.4939     1.3191     0.435      3.1623    176.3644    2.6406     1.4934    18230.38    685.05     -744.0    -735.556    8.435      0.0338  
    25       169.57     1.4069     0.4948     1.1916     0.355      3.1623    176.3644    5.3806     3.5025    18103.07    629.95     -737.0    -728.455    8.259      0.0013  
   500       442.26     1.0007     0.2504     0.555      0.077      1.7496     0.1211     2.6969     6.2875    14304.77    222.15     -615.0    -602.182    13.178     0.0002  
   1000      793.69     0.9741     0.2372     0.3406     0.029      0.7593     1.7081     1.0954     5.3951    13416.63    175.12     -601.0    -590.982    9.716       0.0    
   1500     1148.65     0.9879     0.244      0.2449     0.015      0.7473     2.4307     0.8795     4.7974    13628.98    164.75     -597.0    -589.569    7.895       0.0    
   2000     1510.89     0.9976     0.2488      0.2        0.01      0.6573     0.3784     0.8836     4.3644    13732.41    167.98     -596.0    -588.971    6.882       0.0    
   2500     1869.69     1.0103     0.2552     0.2098     0.011      0.5756    11.7502     1.0711     4.0124    13896.89    170.24     -597.0    -590.714    5.835       0.0    
   3000     2226.63     1.0073     0.2537     0.1673     0.007      0.5621     3.3996     1.0231     3.7242    13629.71    167.97     -595.0    -589.027    5.603       0.0    
   3500     2574.12     1.0038     0.2519     0.1414     0.005      0.6293     0.3842     1.0349     3.4352    13325.6     164.14     -593.0    -588.072     5.06       0.0    
   4000     2942.72     0.9937     0.2469     0.228      0.013      0.5409     1.3815     1.089      3.1955    12998.3     169.85     -593.0    -588.293    4.932       0.0    
   4500     3304.29     0.9878     0.244      0.1673     0.007      0.5587     1.7268     1.202      3.022     12841.38    168.81     -593.0    -588.462     4.48       0.0    
   5000     3669.42     0.9899     0.245      0.1897     0.009      0.6468     7.2837     1.287      2.9169    12761.82    168.97     -593.0    -588.903    4.481       0.0    
   5500     4018.52     0.9888     0.2444     0.1549     0.006      0.6866    11.5217     1.4655     2.8411    12767.01    166.52     -592.0    -587.079    4.724       0.0    
   6000     4375.64     0.9753     0.2378     0.1673     0.007      0.8133    54.7383     1.7768     3.2821    12453.31    163.9      -590.0    -584.54     5.292       0.0    
   6500      4722.3     1.0053     0.2527     0.1789     0.008      2.4047   10398.4881   7.9765    17.7367    13062.79    167.16     -595.0    -584.515    9.998       0.0    
   7000     5080.74     0.9965     0.2482     0.0632     0.001      1.504     858.3002    3.9752     6.1684    13066.95    125.77     -581.0    -571.493    9.269       0.0    
   7500     5440.19     1.0065     0.2532      0.0        0.0       1.0621    131.0466    3.3565     7.053     13580.32    81.43      -567.0    -555.659    10.879      0.0    
   8000     5799.39     1.0632     0.2826     0.1265     0.004      2.7362   138920.4148  12.3962    16.6432    15637.88    82.02      -597.0    -556.355    41.023      0.0    
   8500     6149.75     1.0801     0.2916      0.0        0.0       2.5264   17563.2662  15.1694    19.9804    18539.12    76.28      -568.0    -553.181    14.849      0.0    
   9000      6510.6     1.0939     0.2992      0.0        0.0       1.6346   1649.1042    8.3999    12.1289    18437.87    77.49      -565.0    -550.885    13.982      0.0    
   9500     6875.12     1.0547     0.2781      0.0        0.0       1.6223   1032.5435   12.4254     18.953    16975.81    81.66      -573.0    -554.785    18.564      0.0    
  10000     7229.76     1.0638     0.2829      0.0        0.0       2.5249   60060.597   41.0443    37.3819    17035.55    87.47      -577.0    -556.285    20.829      0.0    
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.61      1.4126     0.4988     1.4043     0.493      3.1623    15.1163    41.3094    37.2484    18184.78    1449.1    -1500.0   -1491.885    8.346      0.1289  
    10       88.55      1.4115     0.4981     1.3565      0.46      3.1623    149.0766   35.9963    32.6058    18291.34   1395.72    -1491.0   -1482.286    8.527      0.0812  
    25       181.93     1.4151     0.5006     1.2538     0.393      3.1623    269.7297   23.4417    28.5887    18260.51   1326.24    -1473.0   -1464.556    8.713      0.0565  
   500       629.04     0.9217     0.2124     0.496      0.0615     2.1484     0.071      4.1842     7.8622    12768.21    387.86    -1200.0   -1185.535    14.176     0.0001  
   1000     1168.95     0.9149     0.2092     0.2145     0.0115     0.6785     0.0684     1.7367     6.7864    12172.5     265.61    -1157.0   -1145.847    11.378      0.0    
   1500     1715.22     0.9208     0.212      0.1844     0.0085     0.4905     0.1541     1.158      5.4406    11936.57    259.0     -1154.0   -1144.103    9.621       0.0    
   2000     2264.38     0.9263     0.2145     0.1483     0.0055     0.5759     6.413      1.1908     4.6269    11928.03    275.67    -1159.0   -1150.835    8.557       0.0    
   2500     2811.49     0.9324     0.2173     0.1732     0.0075     0.6593     27.806     1.391      4.0564    11890.93    293.6     -1168.0   -1159.155    8.473       0.0    
   3000     3358.18     0.9342     0.2182      0.2        0.01      0.598      3.9924     1.4362     3.7461    11822.82    302.07    -1168.0   -1160.301    7.769       0.0    
   3500     3904.28     0.9345     0.2183     0.1789     0.008      0.8006     6.7832     1.6823     3.6144    11784.06    313.27    -1175.0    -1167.36    7.631       0.0    
   4000     4448.19     0.9229     0.2129     0.1897     0.009      0.7863    22.4881     1.9171     3.6327    11551.09    321.86    -1176.0    -1168.61    7.419       0.0    
   4500     4993.09     0.9332     0.2177     0.2098     0.011      1.216     58.4499     2.6437     5.1577    11767.86    346.62    -1183.0   -1175.066    8.298       0.0    
   5000     5532.89     0.9423     0.222      0.2098     0.011      1.2704    73.2376     3.8788     6.4367    12010.78    394.98    -1201.0   -1193.492    7.537      0.0002  
   5500     6072.67     0.9226     0.2128     0.3847     0.037      1.7456   1794.3035    6.1777    12.1061    11898.68    550.7     -1252.0   -1243.783    7.818      0.0001  
   6000     6619.03     0.9927     0.2464     0.7629     0.1455     2.1151   12414.1735   12.808    24.0734    14253.29    998.59    -1392.0   -1386.459    5.174      0.0007  
   6500     7160.88     0.9491     0.2252     0.8944      0.2       1.3054   1848.6294   12.6577    25.5895    13457.49    1025.5    -1395.0   -1388.343    6.582      0.001   
   7000     7694.49     0.9468     0.2241      0.9       0.2025     1.0579   3913.0214    8.6336     25.921    13634.88   1060.38    -1407.0   -1396.187    10.642     0.002   
   7500     8214.03     1.0153     0.2577     1.0237     0.262      1.3504   5467.6453   14.2845    35.7325    14868.05   1176.77    -1444.0   -1431.469    12.326     0.0029  
   8000     8717.45     1.0713     0.2869     1.0354     0.268      2.0263   17103.3972  21.3993    43.5207    15232.17   1217.76    -1463.0   -1443.063    20.151     0.0014  
   8500     9218.35     1.0095     0.2548     0.9737     0.237      1.5549   11894.4892  18.9325    44.2682    14381.83   1131.92    -1458.0    -1420.13    37.878     0.0008  
   9000     9727.44     0.9887     0.2444     0.9455     0.2235     2.1156   9149.4855   21.7426    65.6761    14854.99   1177.19    -1470.0   -1432.795    36.857     0.0004  
   9500     10251.64    0.9046     0.2046     0.8843     0.1955     1.2578   1224.1956    13.356    69.4963    12818.1    1001.56    -1418.0   -1375.609    42.241     0.0003  
  10000     10784.74    0.8844     0.1955     0.8579     0.184      0.7923   3361.5804     9.01     60.0854    12064.51    927.22    -1401.0   -1350.075    51.078      0.0    
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.57      1.4186     0.5031     1.4097     0.4968     3.1623     4.4274     9.8427    59.4548    18368.59   3659.93    -3745.0   -3727.093    17.884     0.2731  
    10       111.35     1.4162     0.5014     1.3717     0.4704     3.1623     4.4274    12.9472    51.7653    17956.85   3500.01    -3733.0   -3712.317    20.191     0.0176  
    25       231.7      1.4161     0.5014     1.3303     0.4424     3.1623    21.9351    15.1948    31.9252    17958.71   3427.56    -3715.0   -3689.237    26.005     0.0152  
   500      1201.61     0.8848     0.1957     0.5824     0.0848     1.7883     0.1192     6.3132     9.6942    11084.14   1165.61    -3004.0   -2987.804    16.49       0.0    
   1000     2328.87      0.89      0.198      0.4147     0.043      1.0319    13.9687     3.0797     7.4552    11232.14    864.91    -2926.0   -2912.144    13.819      0.0    
   1500     3462.14     0.8915     0.1987     0.3699     0.0342     0.618      5.4944     2.0903     5.9149    10946.21    911.78    -2942.0   -2929.801    12.246     0.0001  
   2000     4593.73     0.8913     0.1986     0.4167     0.0434     0.752      3.786      2.0855     5.1197    10602.32   1070.56    -2993.0   -2982.991    10.15       0.0    
   2500     5723.78     0.8725     0.1903     0.5337     0.0712     0.771      1.4852     2.1835     4.9955    10221.19   1283.13    -3060.0   -3051.911    8.311      0.0003  
   3000     6853.87     0.862      0.1858     0.653      0.1066     1.1224     1.0515     2.902      4.8311    10223.28   1574.59    -3153.0   -3146.276    6.427      0.0003  
   3500     7982.44     0.8629     0.1862     0.7869     0.1548     1.1443    110.207     3.3033     5.2769    10493.86   1908.48    -3240.0   -3235.091    4.919      0.0004  
   4000     9112.94     0.8724     0.1903     0.8528     0.1818     1.0941   1792.1617    5.1385     9.9381    10939.38   2097.38    -3304.0   -3298.687     5.15      0.0002  
   4500     10235.68    0.8858     0.1962     0.8681     0.1884     1.4373   1223.3134     6.25     15.6182    11329.22   2215.42    -3342.0    -3330.66    11.196     0.0009  
   5000     11354.54    0.9049     0.2047     0.8805     0.1938     1.2391    344.4094    7.5336    22.5944    12597.64   2490.51    -3440.0   -3430.839    9.336      0.0017  
   5500     12460.92    1.0107     0.2554     1.0182     0.2592     1.3208   1301.8998   12.9129    30.4913    15341.14   3056.66    -3627.0   -3612.213    14.766     0.0052  
   6000     13536.88    0.9843     0.2422     0.9794     0.2398     1.3014   3280.3912   17.5049    39.4935    14683.95   2917.99    -3586.0    -3568.15    18.319     0.0033  
   6500     14596.86    1.2887     0.4152     1.2934     0.4182      1.42    25751.153   24.1806    54.2434    16873.43   3378.64    -3723.0   -3698.217    25.227     0.0059  
   7000     15660.64    1.408      0.4956     1.3903     0.4832     1.085    1708.9434    11.971    49.1613    17347.97   3459.72    -3797.0   -3722.358    74.96      0.0006  
   7500     16751.03    1.3042     0.4252     1.2778     0.4082     0.8539   4587.6948   14.5112    54.6222    17036.69   3391.84    -3762.0   -3713.376    48.895     0.0008  
   8000     17857.93    0.8732     0.1906     0.8814     0.1942     1.2654   3341.5488   19.8704    103.5223   11144.76   2197.73    -3363.0   -3309.473    53.759     0.0005  
   8500     18973.95    0.8722     0.1902     0.8786     0.193      0.9295   2771.4158   13.4953    62.1987    10549.66   2044.88    -3294.0   -3248.113    46.228     0.0004  
   9000     20093.2     0.8694     0.189      0.8537     0.1822     0.2011    11.7761     6.3243    11.8009    10396.99   2000.62    -3280.0   -3239.377    40.818     0.0002  
   9500     21210.47    0.866      0.1875     0.849      0.1802     0.1328    12.8463     3.8373    11.8973    10039.81   1883.56    -3234.0   -3197.129    36.688     0.0001  
  10000     22327.53    0.8694     0.189      0.8217     0.1688     0.0904     1.5347     2.8926    11.6964     9999.0     1814.3    -3207.0   -3173.936    33.459     0.0001  
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.0       1.4104     0.4973     1.405      0.4935     3.1623     4.4274     5.2346    13.0664    18458.27   7345.86    -7482.0   -7470.566    11.715     0.0528  
    10       137.05     1.4166     0.5017     1.3865     0.4806     3.1623     4.4274     20.548    25.7634    18404.17   7180.53    -7449.0   -7436.648    12.751     0.0141  
    25       284.94     1.4147     0.5004     1.3656     0.4662     3.1623     4.4274    32.1321     32.634    18024.01   6985.57    -7434.0   -7417.759    16.471     0.0055  
   500      1515.43     0.8805     0.1938     0.7313     0.1337     2.3334     0.2888    10.0247    10.2617    10387.07   3145.17    -6245.0   -6228.189    16.945     0.0004  
   1000     2936.82     0.8604     0.1851     0.6714     0.1127     1.2234    11.1097     8.5548     8.9186    10143.71   2830.65    -6147.0   -6135.279    12.067      0.0    
   1500     4368.31     0.8579     0.184      0.6951     0.1208     1.4944     3.9387     6.7636     8.0863    9839.12    3049.56    -6216.0    -6206.68     9.8       0.0001  
   2000     5797.99     0.849      0.1802     0.7381     0.1362     0.9461    123.8317    6.9697     7.8029    9843.73     3312.8    -6287.0   -6278.626    8.651      0.0003  
   2500     7231.11     0.8491     0.1802     0.7694     0.148      0.8019     4.0244     5.4538     7.2121    9908.04    3538.93    -6368.0   -6361.115    6.589      0.0003  
   3000     8660.12     0.8575     0.1838     0.8304     0.1724     0.9309    547.0064    7.3756    14.7976    10317.46   3946.05    -6494.0   -6488.413    5.258      0.0002  
   3500     10080.14    0.8655     0.1873     0.8504     0.1808     1.2068   1008.0334    7.9467    15.2809    11024.99   4293.46    -6628.0   -6619.842    8.439      0.0005  
   4000     11484.16    0.8745     0.1912     0.8713     0.1898     1.4776    858.4854   13.2551    34.8466    11962.14    4741.6    -6782.0   -6771.367    10.169     0.001   
   4500     12869.69    1.0084     0.2542     1.0068     0.2534     1.6251   4457.5319   23.4648    71.6413    15322.71   6108.65    -7237.0   -7223.057    14.335     0.0018  
   5000     14225.91    1.3601     0.4624     1.3543     0.4585     1.5564   1863.5605   20.5476    62.4313    17150.59   6867.51    -7450.0   -7428.992    21.226     0.0027  
   5500     15563.54    1.186      0.3516     1.1698     0.3421     2.4846   38427.1981  63.3047    188.1367   16418.73   6562.59    -7386.0   -7337.796    48.326      0.0    
   6000     16933.61    0.9072     0.2058     0.8967     0.201      1.3849   11402.0328  30.0641    185.4967   14436.11   5742.45    -7169.0   -7123.124    46.054      0.0    
   6500     18332.69    0.9204     0.2118     0.9066     0.2055     0.9473   1068.4356   41.4116    83.2948    13040.6    5123.95    -6969.0   -6930.822    38.212      0.0    
   7000     19737.51    0.8563     0.1833     0.8579     0.184      0.7167    367.201     15.955    53.9591    10293.37   4013.68    -6506.0   -6467.045    39.126     0.0014  
   7500     21143.01    0.8675     0.1881     0.8523     0.1816     0.6486    223.231    10.8467    26.9288    10099.78   3919.11    -6486.0   -6444.492    41.176      0.0    
   8000     22546.75    0.8538     0.1822     0.8398     0.1763     0.3134     4.6253     8.2629    16.4425    9890.53    3787.56    -6426.0   -6385.597     40.5      0.0001  
   8500     23947.42    0.8598     0.1848     0.8333     0.1736     0.2755     1.0036     5.922     14.2366    9807.56     3702.9    -6391.0   -6357.569    33.831     0.0001  
   9000     25348.15    0.8547     0.1826     0.8161     0.1665     0.3234     0.443      6.0179    15.1039    9763.95    3614.88    -6356.0   -6325.653    30.205     0.0001  
   9500     26749.4     0.8606     0.1852     0.8017     0.1607     0.2869     0.2159     7.0041    15.1155     9792.5    3525.07    -6329.0   -6300.759    28.059     0.0001  
  10000     28153.08    0.8626     0.186      0.7769     0.1509     0.2963     0.4705     6.6378    15.3988    9831.75    3403.31    -6303.0   -6275.405    27.181      0.0    
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         2.02      1.4114     0.498      1.4193     0.5036     3.1623     4.4274    10.8077    17.9866    18507.84   14837.15   -14988.0  -14978.037   9.838      0.0198  
    10       178.56     1.4168     0.5018     1.4066     0.4946     3.1623     4.4274    46.2123    44.9236    19056.21   15003.85   -14966.0  -14955.164   10.533     0.003   
    25       369.18     1.4176     0.5024     1.3952     0.4866     3.1623     4.4274    85.1345    71.3686    19269.78   15083.61   -14957.0  -14943.466   13.127     0.0013  
   500      1663.82     0.8583     0.1842     0.7939     0.1576     1.7238     0.6762    19.0195    16.7406    9809.29    6953.07    -12537.0  -12520.25    16.812      0.0    
   1000     3199.55     0.8404     0.1766     0.7613     0.1449     1.3348     2.0647     17.637    14.4386    9539.69    6635.43    -12507.0  -12492.59    14.297     0.0001  
   1500     4739.31     0.8369     0.1751     0.7642     0.146      1.1199     0.7654    15.4271    14.0514    9524.97    6826.51    -12575.0  -12563.381   11.217      0.0    
   2000     6277.29     0.8429     0.1776     0.7904     0.1562     0.828      35.065    13.5011    13.5403    9621.29    7149.11    -12705.0  -12694.964   10.305     0.0001  
   2500     7810.53     0.8486      0.18      0.8155     0.1662     0.9256    41.2342     13.087    14.1884    9849.48    7610.07    -12838.0  -12827.468   10.074     0.0001  
   3000     9326.71     0.8593     0.1846     0.8452     0.1786     1.2554    150.9757   16.7679    35.7489    10268.23   8073.92    -13002.0  -12990.076   11.677     0.0001  
