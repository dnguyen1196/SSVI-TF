Generating synthetic count valued data ... 
Generating synthetic  count valued data took:  16.783715963363647
max_count =  52  min count =  0
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
2.6464995749 2.6289161265   1.51876      1.50536     163417.29    651123.47  
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.63      9.237      6.8875     9.3213      6.95      3.1623     4.4274     1.6496   1526986501103.9688  70515.62   2876.15    -3211.0   -3199.669    11.748      0.0    
    10       104.29     9.4309     6.7991     8.9075      6.4       3.1623     4.4274    21.6686   5583649777053.274  78171.55   2930.93    -3314.0   -3301.865    12.233      0.0    
    25       212.32     9.8528     6.9901     8.5064     5.882      3.1623    234.8218   46.7188   11334226415924.51  95620.33   3097.11    -3449.0   -3435.098    13.412      0.0    
   500       653.83     9.5361     6.4232     1.6474     0.948      0.6745     0.6302     3.4389   1840.6742  116428.23    1512.7    -1788.0   -1755.683    32.103      0.0    
   1000     1189.97     7.8006     4.9144     1.5202     0.927      1.1887     0.5528     3.4042   935577.8377  74631.11   1524.79    -1796.0   -1771.135    24.563      0.0    
   1500     1725.06     6.0017     3.6719     1.6392     1.019      0.9144    58.4931     3.3754   1910.9386   56226.6    1538.18    -1801.0    -1782.28    19.153      0.0    
   2000     2260.98     5.0807     3.1694     1.7295     1.101      1.0171     8.2937     3.2424   63665.8847  51349.29   1550.16    -1816.0   -1798.919    17.334      0.0    
   2500     2795.11     4.606      2.9401     1.7703      1.12      0.9747     7.328      2.7096   309455.2416  49358.04    1551.4    -1814.0   -1796.813    16.949      0.0    
   3000     3329.85     4.5086     2.8962     1.6965     1.076      0.6631     36.285     1.8173   1342.9576   48492.15   1541.25    -1808.0   -1792.903    14.638      0.0    
   3500     3884.07     4.6247     3.0288     1.8826     1.172      0.6261    60.9886     1.8832   310704.1461  48429.54   1555.96    -1820.0   -1806.301    13.533      0.0    
   4000     4438.76     4.5554     3.0112     1.7969     1.107      0.9789    81.1477     1.8668   123896.8456  48052.96   1546.51    -1808.0   -1795.518    12.117      0.0    
   4500     4992.07     4.3692     2.888      1.739       1.12      0.9298    22.8611     1.8575   77947.9621  48004.0    1552.37    -1807.0    -1796.1     11.313      0.0    
   5000      5543.6     4.5016     2.9958     1.8163     1.137      0.7919    52.3445     1.9807    283.3902   47976.06   1553.45    -1812.0   -1801.115    10.835      0.0    
   5500      6090.6     4.6853     3.0776     1.8738     1.137      0.6699    31.8498     1.7256   2180.0187   47926.68   1552.92    -1807.0   -1797.008    10.379      0.0    
   6000     6640.08     4.5829     3.0114     1.7361     1.074      0.5111    19.5055     1.5565   6898.2409   47772.05   1550.13    -1807.0   -1797.008    10.373      0.0    
   6500     7180.41     4.4317     2.9496     1.687      1.074      0.5616    45.9597     1.6118   22710.8398  47882.09   1548.44    -1806.0   -1793.206    13.155      0.0    
   7000     7718.78     4.6524     3.069      1.8918     1.159      0.5557    60.3129     1.7657   5505.9835   47760.23   1548.38    -1810.0   -1797.091    12.96       0.0    
   7500     8253.06     4.7739     3.1582     1.8053     1.115      0.3502    27.5673     1.5622   349231.3769  47975.09   1540.81    -1808.0   -1794.103    13.596      0.0    
   8000     8798.32     4.4345     2.9624     1.761      1.085      0.3709    15.6161     1.3045   11075.7535  47686.97   1538.29    -1796.0   -1783.729    12.666      0.0    
   8500     9330.58     4.554      3.046      1.759      1.108      0.4586    15.7459     1.4053   1315685.929  47960.13   1541.73    -1797.0   -1784.524    11.999      0.0    
   9000     9864.88     4.7994     3.1897     1.8794     1.148      0.5994    89.8491     1.5599   10880.7522  48159.91   1533.03    -1790.0   -1777.276    12.482      0.0    
   9500     10393.37    4.5342     3.037      1.6956     1.047      0.3705    35.3705     1.3725    507.7541   47856.61   1533.32    -1791.0   -1778.733    12.033      0.0    
  10000     10920.56    5.3254     3.5566     1.9997     1.233      1.0242    179.8486    2.2714   21541.5589  48551.38   1540.97    -1799.0   -1786.748    12.165      0.0    
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.26      9.2631      6.95      9.2715     6.955      3.1623     4.4274     4.8097   1882466128334.7605  70235.41   5664.41    -6368.0   -6359.908    8.103       0.0    
    10       119.5      9.5026     6.8365     9.3386     6.729      3.1623     4.4274    37.1157   9501639660294.688  80051.25   6065.07    -6969.0   -6960.736    8.355       0.0    
    25       247.17     9.7867     6.7254     9.1907     6.3045     3.1623     4.4274    79.0935   14819785422405.555  99361.91    6978.2    -7962.0   -7952.897    9.292       0.0    
   500      1040.11     9.0937     5.7507     1.8569     1.074      1.0782     4.7634     6.1563   105439.6414 115006.53    2968.1    -3507.0    -3472.86    34.019      0.0    
   1000     1964.62     7.7312     4.5032     1.6053     0.916      0.5991     0.5059     4.9222    272.8762   77335.66   2909.41    -3453.0   -3424.861    27.874      0.0    
   1500     2887.09     6.1768     3.5503     1.6577     0.969      0.712      0.1863     5.2434   132477.1699  58683.24   2938.57    -3486.0   -3462.028    23.812      0.0    
   2000     3807.33     5.1299     2.9933     1.7297     0.993      0.4656     0.6001     4.8087   22288.7625  51919.34   2958.09    -3497.0   -3476.213    20.889      0.0    
   2500      4703.2     4.566      2.7135     1.7661     1.036      0.6971     0.1705     4.4322   630115.4119  49191.73   2971.64    -3503.0   -3482.612    20.46       0.0    
   3000     5597.33     4.3269     2.5947     1.8221     1.069      0.8069     0.1468     4.0166   1744.9932   48100.66   2984.61    -3518.0   -3499.266    18.972      0.0    
   3500     6490.18     4.2221     2.5374     1.8129     1.0695     0.9811     0.356      4.0695   24835.888   47546.21    2985.6    -3516.0   -3497.972    17.532      0.0    
   4000     7378.81     4.1211     2.4837     1.7873     1.0345     0.6566     0.1916     3.6287   3274508.2409  47134.83   2986.04    -3520.0   -3502.609    17.861      0.0    
   4500     8276.71     4.0791     2.4697     1.8087     1.0625     0.7024     0.1359     3.5376    215.0467   46894.48   2992.89    -3523.0   -3506.216    17.038      0.0    
   5000     9188.14     4.0466     2.4512     1.8191     1.057      0.5242     0.4374     3.3579   9109.3786   46731.95   2994.64    -3531.0   -3514.689    16.168      0.0    
   5500     10101.77    4.0336     2.4389     1.8442     1.075      1.6094    84.3226     3.1754   1234260.3145  46600.41   2998.57    -3534.0   -3517.899    16.131      0.0    
   6000     11013.24    4.0037     2.4266     1.7898     1.0385     0.5062     0.4178     2.7996   2055676.3917  46435.79   3003.33    -3535.0   -3519.692    15.593      0.0    
   6500     11918.61    3.9721     2.411      1.8416     1.0715     0.6103     0.3858     2.7662    231.8257   46355.63   3005.81    -3535.0   -3519.577    15.004      0.0    
   7000     12816.5     3.9578     2.4111     1.8383     1.0835     0.3618     1.3554     2.3989   17699.2708  46267.91   3009.36    -3542.0   -3526.729    15.569      0.0    
   7500     13725.76    3.9653     2.4101     1.8159     1.0525     0.5358     0.873      2.0718   73508926956.2387  46357.69    3003.1    -3535.0   -3518.663    16.38       0.0    
   8000     14639.39    3.9444     2.3992     1.8169     1.062      0.3285     0.2096     1.7164    168.392    46234.6    3009.94    -3541.0   -3525.084    15.996      0.0    
   8500     15556.08    3.9431     2.4008     1.7987     1.0425     0.3601     0.3586     1.9603   5771103.1367  46265.63   3007.77    -3533.0   -3517.399    15.677      0.0    
   9000     16480.37    3.9465     2.4072     1.8341     1.073      0.3384     0.9891     2.1417    214.6351   46167.96    3015.0    -3548.0   -3532.569    15.512      0.0    
   9500     17399.91    3.9497     2.4092     1.7865     1.0485     0.6727     1.3205     1.9106   1963.4348   46175.3     3015.3    -3544.0   -3528.368     15.2       0.0    
  10000     18320.84    4.2173     2.6092     2.2651     1.2055     1.0884    166.4675    2.0963   12683.236   46365.42   3018.77    -3556.0    -3539.16    17.311      0.0    
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         3.46      9.3091     6.9577     9.2045     6.8096     3.1623     4.4274     8.191    3395714853178.054  70676.1    14042.37   -15881.0  -15870.686   10.268      0.0    
    10       163.73     9.6018     6.8688     9.3623     6.632      3.1623     4.4274    70.8077   17793983671132.824  83498.81   16093.77   -18392.0  -18381.161   10.995      0.0    
    25       347.17     9.944      6.7532     9.5265     6.397      3.1623     4.4274    145.3766  27889758474784.19 105744.96   19725.85   -22688.0  -22674.773   13.228      0.0    
   500      2171.43     6.9189     3.8774     2.6216     1.6004     1.1081     0.133     14.4824   704748.5583  72353.83   7975.23    -9235.0   -9189.758    45.682      0.0    
   1000      4208.1     5.8322     3.2956     2.202      1.3244     0.3674     0.5465     7.3121    66.7378    59382.19   7537.02    -8844.0   -8807.441    36.908      0.0    
   1500     6239.42     5.1198     2.9509     2.1067     1.2526     0.299      0.0924     5.3065   25668.7517  53839.97   7434.49    -8757.0   -8724.336    32.26       0.0    
   2000     8271.43     4.6791     2.7418     2.0847     1.2312     0.2818     0.2144     4.8074    318.9947   50969.42   7395.63    -8728.0   -8698.117    30.121      0.0    
   2500     10309.02    4.4096     2.613      2.1158     1.2422     0.4393     0.0778     4.6572   10160.7439  49359.99   7402.24    -8742.0    -8713.35    28.581      0.0    
   3000     12312.15    4.2109     2.5118     2.1051     1.2308     0.2821     0.2023     4.0072   1317.1521   48233.26   7406.78    -8744.0   -8717.835    26.446      0.0    
