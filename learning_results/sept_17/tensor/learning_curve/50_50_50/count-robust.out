Generating synthetic count valued data ... 
Generating synthetic  count valued data took:  16.783715963363647
max_count =  52  min count =  0
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
2.6464995749 2.6289161265   1.51876      1.50536     163417.29    651123.47  
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.63      9.237      6.8875     9.3213      6.95      3.1623     4.4274     1.6496   1526986501103.9688  70515.62   2876.15    -3211.0   -3199.669    11.748      0.0    
    10       104.29     9.4309     6.7991     8.9075      6.4       3.1623     4.4274    21.6686   5583649777053.274  78171.55   2930.93    -3314.0   -3301.865    12.233      0.0    
    25       212.32     9.8528     6.9901     8.5064     5.882      3.1623    234.8218   46.7188   11334226415924.51  95620.33   3097.11    -3449.0   -3435.098    13.412      0.0    
   500       653.83     9.5361     6.4232     1.6474     0.948      0.6745     0.6302     3.4389   1840.6742  116428.23    1512.7    -1788.0   -1755.683    32.103      0.0    
   1000     1189.97     7.8006     4.9144     1.5202     0.927      1.1887     0.5528     3.4042   935577.8377  74631.11   1524.79    -1796.0   -1771.135    24.563      0.0    
   1500     1725.06     6.0017     3.6719     1.6392     1.019      0.9144    58.4931     3.3754   1910.9386   56226.6    1538.18    -1801.0    -1782.28    19.153      0.0    
   2000     2260.98     5.0807     3.1694     1.7295     1.101      1.0171     8.2937     3.2424   63665.8847  51349.29   1550.16    -1816.0   -1798.919    17.334      0.0    
   2500     2795.11     4.606      2.9401     1.7703      1.12      0.9747     7.328      2.7096   309455.2416  49358.04    1551.4    -1814.0   -1796.813    16.949      0.0    
   3000     3329.85     4.5086     2.8962     1.6965     1.076      0.6631     36.285     1.8173   1342.9576   48492.15   1541.25    -1808.0   -1792.903    14.638      0.0    
   3500     3884.07     4.6247     3.0288     1.8826     1.172      0.6261    60.9886     1.8832   310704.1461  48429.54   1555.96    -1820.0   -1806.301    13.533      0.0    
   4000     4438.76     4.5554     3.0112     1.7969     1.107      0.9789    81.1477     1.8668   123896.8456  48052.96   1546.51    -1808.0   -1795.518    12.117      0.0    
   4500     4992.07     4.3692     2.888      1.739       1.12      0.9298    22.8611     1.8575   77947.9621  48004.0    1552.37    -1807.0    -1796.1     11.313      0.0    
   5000      5543.6     4.5016     2.9958     1.8163     1.137      0.7919    52.3445     1.9807    283.3902   47976.06   1553.45    -1812.0   -1801.115    10.835      0.0    
   5500      6090.6     4.6853     3.0776     1.8738     1.137      0.6699    31.8498     1.7256   2180.0187   47926.68   1552.92    -1807.0   -1797.008    10.379      0.0    
   6000     6640.08     4.5829     3.0114     1.7361     1.074      0.5111    19.5055     1.5565   6898.2409   47772.05   1550.13    -1807.0   -1797.008    10.373      0.0    
   6500     7180.41     4.4317     2.9496     1.687      1.074      0.5616    45.9597     1.6118   22710.8398  47882.09   1548.44    -1806.0   -1793.206    13.155      0.0    
   7000     7718.78     4.6524     3.069      1.8918     1.159      0.5557    60.3129     1.7657   5505.9835   47760.23   1548.38    -1810.0   -1797.091    12.96       0.0    
   7500     8253.06     4.7739     3.1582     1.8053     1.115      0.3502    27.5673     1.5622   349231.3769  47975.09   1540.81    -1808.0   -1794.103    13.596      0.0    
   8000     8798.32     4.4345     2.9624     1.761      1.085      0.3709    15.6161     1.3045   11075.7535  47686.97   1538.29    -1796.0   -1783.729    12.666      0.0    
   8500     9330.58     4.554      3.046      1.759      1.108      0.4586    15.7459     1.4053   1315685.929  47960.13   1541.73    -1797.0   -1784.524    11.999      0.0    
   9000     9864.88     4.7994     3.1897     1.8794     1.148      0.5994    89.8491     1.5599   10880.7522  48159.91   1533.03    -1790.0   -1777.276    12.482      0.0    
   9500     10393.37    4.5342     3.037      1.6956     1.047      0.3705    35.3705     1.3725    507.7541   47856.61   1533.32    -1791.0   -1778.733    12.033      0.0    
  10000     10920.56    5.3254     3.5566     1.9997     1.233      1.0242    179.8486    2.2714   21541.5589  48551.38   1540.97    -1799.0   -1786.748    12.165      0.0    
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.26      9.2631      6.95      9.2715     6.955      3.1623     4.4274     4.8097   1882466128334.7605  70235.41   5664.41    -6368.0   -6359.908    8.103       0.0    
    10       119.5      9.5026     6.8365     9.3386     6.729      3.1623     4.4274    37.1157   9501639660294.688  80051.25   6065.07    -6969.0   -6960.736    8.355       0.0    
    25       247.17     9.7867     6.7254     9.1907     6.3045     3.1623     4.4274    79.0935   14819785422405.555  99361.91    6978.2    -7962.0   -7952.897    9.292       0.0    
   500      1040.11     9.0937     5.7507     1.8569     1.074      1.0782     4.7634     6.1563   105439.6414 115006.53    2968.1    -3507.0    -3472.86    34.019      0.0    
   1000     1964.62     7.7312     4.5032     1.6053     0.916      0.5991     0.5059     4.9222    272.8762   77335.66   2909.41    -3453.0   -3424.861    27.874      0.0    
   1500     2887.09     6.1768     3.5503     1.6577     0.969      0.712      0.1863     5.2434   132477.1699  58683.24   2938.57    -3486.0   -3462.028    23.812      0.0    
   2000     3807.33     5.1299     2.9933     1.7297     0.993      0.4656     0.6001     4.8087   22288.7625  51919.34   2958.09    -3497.0   -3476.213    20.889      0.0    
   2500      4703.2     4.566      2.7135     1.7661     1.036      0.6971     0.1705     4.4322   630115.4119  49191.73   2971.64    -3503.0   -3482.612    20.46       0.0    
   3000     5597.33     4.3269     2.5947     1.8221     1.069      0.8069     0.1468     4.0166   1744.9932   48100.66   2984.61    -3518.0   -3499.266    18.972      0.0    
   3500     6490.18     4.2221     2.5374     1.8129     1.0695     0.9811     0.356      4.0695   24835.888   47546.21    2985.6    -3516.0   -3497.972    17.532      0.0    
   4000     7378.81     4.1211     2.4837     1.7873     1.0345     0.6566     0.1916     3.6287   3274508.2409  47134.83   2986.04    -3520.0   -3502.609    17.861      0.0    
   4500     8276.71     4.0791     2.4697     1.8087     1.0625     0.7024     0.1359     3.5376    215.0467   46894.48   2992.89    -3523.0   -3506.216    17.038      0.0    
   5000     9188.14     4.0466     2.4512     1.8191     1.057      0.5242     0.4374     3.3579   9109.3786   46731.95   2994.64    -3531.0   -3514.689    16.168      0.0    
   5500     10101.77    4.0336     2.4389     1.8442     1.075      1.6094    84.3226     3.1754   1234260.3145  46600.41   2998.57    -3534.0   -3517.899    16.131      0.0    
   6000     11013.24    4.0037     2.4266     1.7898     1.0385     0.5062     0.4178     2.7996   2055676.3917  46435.79   3003.33    -3535.0   -3519.692    15.593      0.0    
   6500     11918.61    3.9721     2.411      1.8416     1.0715     0.6103     0.3858     2.7662    231.8257   46355.63   3005.81    -3535.0   -3519.577    15.004      0.0    
   7000     12816.5     3.9578     2.4111     1.8383     1.0835     0.3618     1.3554     2.3989   17699.2708  46267.91   3009.36    -3542.0   -3526.729    15.569      0.0    
   7500     13725.76    3.9653     2.4101     1.8159     1.0525     0.5358     0.873      2.0718   73508926956.2387  46357.69    3003.1    -3535.0   -3518.663    16.38       0.0    
   8000     14639.39    3.9444     2.3992     1.8169     1.062      0.3285     0.2096     1.7164    168.392    46234.6    3009.94    -3541.0   -3525.084    15.996      0.0    
   8500     15556.08    3.9431     2.4008     1.7987     1.0425     0.3601     0.3586     1.9603   5771103.1367  46265.63   3007.77    -3533.0   -3517.399    15.677      0.0    
   9000     16480.37    3.9465     2.4072     1.8341     1.073      0.3384     0.9891     2.1417    214.6351   46167.96    3015.0    -3548.0   -3532.569    15.512      0.0    
   9500     17399.91    3.9497     2.4092     1.7865     1.0485     0.6727     1.3205     1.9106   1963.4348   46175.3     3015.3    -3544.0   -3528.368     15.2       0.0    
  10000     18320.84    4.2173     2.6092     2.2651     1.2055     1.0884    166.4675    2.0963   12683.236   46365.42   3018.77    -3556.0    -3539.16    17.311      0.0    
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         3.46      9.3091     6.9577     9.2045     6.8096     3.1623     4.4274     8.191    3395714853178.054  70676.1    14042.37   -15881.0  -15870.686   10.268      0.0    
    10       163.73     9.6018     6.8688     9.3623     6.632      3.1623     4.4274    70.8077   17793983671132.824  83498.81   16093.77   -18392.0  -18381.161   10.995      0.0    
    25       347.17     9.944      6.7532     9.5265     6.397      3.1623     4.4274    145.3766  27889758474784.19 105744.96   19725.85   -22688.0  -22674.773   13.228      0.0    
   500      2171.43     6.9189     3.8774     2.6216     1.6004     1.1081     0.133     14.4824   704748.5583  72353.83   7975.23    -9235.0   -9189.758    45.682      0.0    
   1000      4208.1     5.8322     3.2956     2.202      1.3244     0.3674     0.5465     7.3121    66.7378    59382.19   7537.02    -8844.0   -8807.441    36.908      0.0    
   1500     6239.42     5.1198     2.9509     2.1067     1.2526     0.299      0.0924     5.3065   25668.7517  53839.97   7434.49    -8757.0   -8724.336    32.26       0.0    
   2000     8271.43     4.6791     2.7418     2.0847     1.2312     0.2818     0.2144     4.8074    318.9947   50969.42   7395.63    -8728.0   -8698.117    30.121      0.0    
   2500     10309.02    4.4096     2.613      2.1158     1.2422     0.4393     0.0778     4.6572   10160.7439  49359.99   7402.24    -8742.0    -8713.35    28.581      0.0    
   3000     12312.15    4.2109     2.5118     2.1051     1.2308     0.2821     0.2023     4.0072   1317.1521   48233.26   7406.78    -8744.0   -8717.835    26.446      0.0    
   3500     14312.76    4.0915     2.4515     2.1152     1.2296     0.2552     0.1468     4.2495   4401.0236   47494.62   7423.77    -8763.0   -8738.473    24.822      0.0    
   4000     16286.98    4.0114     2.4107     2.1355     1.2374     0.2696     0.6794     3.8456   50086.2104  46994.26   7426.13    -8756.0   -8731.789    23.815      0.0    
   4500     18236.34    3.945      2.3768     2.1447     1.2384     0.3224     0.1236     3.9926   1666.8604   46669.73   7412.33    -8746.0   -8721.139    24.454      0.0    
   5000     20176.06    3.8918     2.3483     2.1265     1.2268     0.346      0.1422     3.9648   253608.962  46252.06   7417.25    -8766.0   -8741.607    24.773      0.0    
   5500     22107.79    3.8652     2.3384     2.1117      1.22      0.5822     3.5835     4.8834   128231.7237  46078.53   7417.88    -8755.0   -8730.415    24.197      0.0    
   6000     24038.55    3.8474     2.3151     2.1027     1.2086     0.3903     0.1787     4.4002    483.6675   45855.59   7414.83    -8748.0   -8724.298    23.77       0.0    
   6500     25961.19    3.8152     2.2969     2.1026     1.2094     0.3827     0.2683     4.5092   17092.9569  45655.49   7418.38    -8757.0   -8732.948    24.478      0.0    
   7000     27883.49    3.8066     2.293      2.0979     1.2058     0.3577     0.2078     4.1726   25593.7423  45524.5    7419.89    -8763.0   -8738.455    24.849      0.0    
   7500     29808.77    3.7851     2.2767     2.1051     1.2062     0.4525     0.2862     4.1921   106268.9237  45409.71   7423.47    -8770.0   -8745.794    24.256      0.0    
   8000     31731.19    3.7771     2.2734     2.088      1.2026     0.4099     0.2258     4.4302   3949.5866   45326.52   7433.58    -8766.0   -8741.633    24.032      0.0    
   8500     33648.26    3.7629     2.2643     2.1117     1.2094     0.3708     0.2254     4.1792   8409.5066   45242.29   7438.51    -8770.0   -8744.882    24.643      0.0    
   9000     35566.64    3.7479     2.2546     2.0964     1.2094     0.4588     0.1987     3.8509   105926.0725  45085.83   7437.86    -8780.0   -8754.756    25.442      0.0    
   9500     37477.04    3.7602     2.2545     2.0928     1.2096     0.4132     1.0886     4.3053     697.86    45094.85   7445.96    -8781.0   -8755.128    25.408      0.0    
  10000     39394.5     3.7452     2.2497     2.0812     1.2012     0.4824     1.0116     3.9378   39336.3939  45001.06   7445.36    -8775.0   -8750.481    24.906      0.0    
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         3.99      9.1988     6.8768     9.1804     6.8389     3.1623     4.4274    17.0538   5499759782350.824  70485.99   28264.46   -31840.0  -31828.95    11.019      0.0    
    10       182.65     9.5202     6.8144     9.3658     6.6762     3.1623     4.4274    141.9288  36380119886938.38  82666.89   32191.08   -36621.0  -36609.261   11.75       0.0    
    25       384.05     9.859      6.7131     9.635      6.5522     3.1623     4.4274    301.021   62332310313155.06 103364.12   39438.41   -45215.0  -45201.133   13.802      0.0    
   500      2663.87     4.3205     2.5903     3.3218     2.0343     1.0926     0.2514    32.3989   2292571.8129  50121.21   17531.2    -19987.0  -19944.82    42.116      0.0    
   1000     5187.01     4.0848     2.4596     3.0408     1.8442     0.7483     1.0373    20.8588   2263.5654   48319.43   16658.01   -19182.0  -19138.228   43.505      0.0    
   1500      7761.5     3.9278     2.3708     2.9017     1.7475     0.5073     0.5699    17.4659   6350.7358   47280.87   16214.96   -18770.0  -18729.606   39.959      0.0    
   2000     10368.15     3.84      2.3172     2.8153     1.6814     0.4958     0.3964    16.8436   727153.6429  46578.52   15940.11   -18517.0  -18478.338   38.618      0.0    
   2500     12984.44    3.7724     2.2695     2.764      1.6414     0.3764     3.8277    16.7059   13909.1861  46101.85   15830.71   -18418.0  -18381.446   36.705      0.0    
   3000     15589.04    3.7337     2.2508      2.74      1.6161     0.5339     0.1561    16.3273   11307.4845  45679.65   15716.08   -18316.0  -18279.867   35.719      0.0    
   3500     18194.73    3.694      2.2281     2.7148     1.5952     0.4029     0.4776    14.6712    709.8471   45311.34   15690.36   -18319.0  -18284.662   34.485      0.0    
   4000     20784.05    3.6563     2.2099     2.6859     1.578      0.3671     4.1715    14.6506   3185.9676   45071.44   15637.85   -18265.0  -18231.299   33.699      0.0    
   4500     23379.14    3.6357     2.1894     2.6639     1.5567     0.2661     2.6992    15.1569   12303.133   44842.62   15613.84   -18215.0  -18182.115   33.078      0.0    
   5000     25970.17    3.5985     2.1651     2.6454     1.5455     0.427      1.3658     15.863    4377.703   44632.66   15577.67   -18189.0  -18155.71    33.235      0.0    
   5500     28561.17    3.588      2.1616     2.6228     1.532      0.4287     0.5279    14.5055   633324.095  44457.25   15556.23   -18174.0  -18140.995   33.411      0.0    
   6000     31184.27    3.5623     2.1425     2.6088     1.5261     0.3802      0.54     14.7146   28353.3867  44332.6    15567.26   -18178.0  -18145.038   32.791      0.0    
   6500     33804.74    3.5563     2.1381     2.5946     1.5069     0.3634     1.0221    13.9255   3153.5815   44231.49   15524.76   -18156.0  -18123.512   32.362      0.0    
   7000     36420.68    3.5522     2.1378     2.5834     1.5052     0.4448     0.4328    15.4134    3016.017   44197.61   15542.08   -18167.0  -18133.982   32.65       0.0    
   7500     38999.39    3.5544     2.1368     2.5618     1.4947     0.562      0.6113    15.4067   1145.8738   44094.43   15506.65   -18153.0  -18119.808   32.761      0.0    
   8000     41551.15    3.5467     2.135      2.5688     1.5011     0.5607     2.3753    16.3818   11468.261   44089.76   15531.56   -18163.0  -18130.679   32.304      0.0    
   8500     44048.03    3.527      2.1209     2.5551     1.4857     0.4155     0.5324    14.3334   1660.8373   43985.51   15530.11   -18161.0  -18128.809   31.754      0.0    
   9000     46520.54    3.5211     2.1115     2.5516     1.4768     0.332      0.4524    13.6473   1086.8461   43924.16   15491.52   -18120.0  -18086.973   33.073      0.0    
   9500     48979.99    3.5182     2.1154     2.5255     1.466      0.5373     0.4526    15.4274    901.1273   43943.97   15472.57   -18095.0  -18062.321   32.87       0.0    
  10000     51428.27    3.5203     2.1166     2.5001     1.4529     0.6907     0.2312    14.9211    828.4285   43872.37   15453.77   -18100.0  -18067.358   32.595      0.0    
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         4.06      9.3135     6.9574     9.2993     6.9151     3.1623     4.4274    35.6049   10445450078554.637  70674.44   56790.17   -63845.0  -63830.089   14.931      0.0    
    10       236.61     9.6098     6.8484     9.5503     6.7504     3.1623     4.4274    285.7682  76464100710152.08  84487.47   66920.58   -76561.0  -76544.771   16.505      0.0    
    25       493.81     9.9517     6.717      9.8819     6.6376     3.1623     4.4274    605.9795  126020659150736.31 106559.97   83683.94   -95973.0  -95952.802   20.314      0.0    
   500      2729.14     4.0616     2.4554     3.7258     2.2686     1.2609     1.4216    89.0622   26688946.4218  48488.82   36888.03   -41802.0  -41742.947   58.909      0.0    
   1000     5224.44     3.7327     2.2704     3.3723     2.053      1.1483     1.901     56.1419   20540977334.6055  46593.57   35026.85   -39925.0  -39876.992   48.397      0.0    
   1500     7727.74     3.6867     2.2445      3.26      1.971      0.743      0.2877    56.3425   259277.6685  46144.23   34303.01   -39229.0  -39185.512    43.4       0.0    
   2000     10296.34    3.6312     2.2037     3.1886     1.9108     0.5944    10.5659    46.9724   1621643.5335  45613.79   33702.88   -38650.0  -38606.386   43.413      0.0    
   2500     12855.71    3.6058     2.1724     3.1271     1.8527     0.5117     0.157      45.916   1814164.4607  45340.84   33229.03   -38177.0  -38137.012   40.46       0.0    
   3000     15492.79    3.574      2.1529     3.0618     1.819      0.6605     0.0555    45.3406   56104.3838  44980.4    32822.99   -37814.0  -37775.591   38.079      0.0    
   3500     18135.0     3.5316     2.1252     3.0117     1.7824     0.4511     0.1684    41.2668   4843.4547   44435.31   32492.97   -37483.0  -37447.103   35.651      0.0    
   4000     20818.55    3.5173     2.1113     2.9851     1.7646     0.5824     1.2744    45.5287   460858.6511  44305.67   32316.81   -37383.0  -37344.916   38.16       0.0    
   4500     23513.88    3.484      2.0793     2.9589     1.7352     0.4866     0.3081    43.1306   71382.7546  43944.76   32072.19   -37103.0  -37063.08     39.9       0.0    
   5000     26197.74    3.4505     2.0714     2.9232     1.7222     0.632      1.048     44.3844   164553.8029  43649.31   31983.95   -37104.0  -37065.566   38.337      0.0    
   5500     28856.01    3.4527     2.0635     2.9048     1.7036     0.3829     0.2297    40.0144   62615.9022  43490.37   31817.86   -36923.0  -36885.364   37.837      0.0    
   6000     31446.6     3.4305     2.0426     2.8947     1.6977     0.3432     0.3983    39.4631   28867.2967  43310.95   31772.99   -36863.0  -36825.215   37.758      0.0    
   6500     34044.36    3.4313     2.0506     2.872      1.6705     0.3921     0.5543    38.7184   2868.1947   43270.67   31650.31   -36772.0  -36734.458   37.045      0.0    
   7000     36700.47    3.3986     2.0232     2.8501     1.6576     0.4367     0.2975    38.5614   12155.6736  43045.12   31549.93   -36655.0  -36619.389   35.995      0.0    
   7500     39481.16    3.3886     2.021      2.847      1.662      0.6161     0.8317    43.4484   6579.3384   42945.48   31587.58   -36732.0  -36695.708   36.127      0.0    
   8000     42234.47    3.3739      2.01      2.8395     1.6526     0.4888     0.3642    39.3002   2860.1333   42855.57   31547.1    -36699.0  -36663.987   35.401      0.0    
   8500     45007.41    3.3798     2.0066     2.8256     1.6366     0.6175     0.1765    42.1431   1171.8062   42836.87   31464.27   -36590.0  -36553.061   36.575      0.0    
   9000     47727.81    3.3681     1.9994     2.8166     1.6362     0.6754     0.5584    43.1618   53499.5612  42815.86   31480.94   -36596.0  -36559.263   36.467      0.0    
   9500     50392.17    3.3492     1.9882     2.7982     1.622      0.548      0.4112    41.0711   23428.2172  42673.69   31392.71   -36487.0  -36451.292   35.599      0.0    
  10000     53051.27    3.3506     1.9869     2.8032     1.6251     0.5336     0.4427    40.1627   164144.6744  42736.21   31264.79   -36389.0  -36349.815   39.545      0.0    
Using  0.5  of training data 
Using  0.5 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         4.33      9.2948     6.9449     9.2759     6.929      3.1623     4.4274    92.9534   27557348645946.99  70494.34  141408.72  -159197.0  -159183.364   13.479      0.0    
    10       416.31     9.5528     6.8293     9.5339     6.8116     3.1623     4.4274     720.68   179914881794263.5  82414.75  163481.43  -187547.0  -187532.641   14.587      0.0    
    25       857.64     9.8924     6.7029     9.8272     6.6442     3.1623     4.4274   1500.1455  300113115512397.75 104096.82  205529.48  -236010.0  -235991.91   17.592      0.0    
   500      3338.63     3.9031     2.3977     3.7652     2.3109     1.3435     0.411     234.7977  190634734.3307  47828.07   93507.74  -105689.0  -105626.401   62.104      0.0    
   1000     6180.79     3.7591     2.277      3.6204     2.2051     1.0704      4.35     178.5095  8120042.6193  46310.24   90555.11  -102744.0  -102683.715   60.587      0.0    
   1500     9048.44     3.5921     2.1651     3.4406     2.0786     0.712      3.5412    147.8896  4496396.5563  45084.06   87803.96  -100263.0  -100205.874   57.313      0.0    
   2000     11913.65    3.5124     2.1223     3.3463     2.0177     0.5241     0.3954    134.4713  11043048.6182  44223.83   85839.11   -98395.0  -98340.529   54.062      0.0    
