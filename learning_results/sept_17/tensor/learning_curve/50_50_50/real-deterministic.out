Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  8.716424703598022
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
    0.0          0.0          0.0          0.0       287494.79    1149836.49 
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         0.23    9981.1137    0.9979   10009.1059   0.9979     3.1623     4.4249   18382.4028  19.5781   287823.14   11512.93   -11520.0  -11512.925   6.613    
    10       42.25    9971.2217    0.9969   9998.5743    0.9968     3.1623     4.4274   254302.4389  269.5205  287823.14   11512.93   -11520.0  -11512.925   6.889    
    25       87.22     9951.085    0.9949   9979.1158    0.9949     3.1623     4.4274   684730.2516  770.0327  287823.14   11512.93   -11520.0  -11512.925   7.236    
   500       252.76   4323.4878    0.4209   4359.0637    0.4225     1.8816     0.0326   17914680.8263 679479.7767 287823.14   11512.93   -11592.0  -11512.925   79.548   
   1000      420.32    469.6976    0.0368    448.8469    0.0351     0.3455     0.0057   1261103.9499 1561180.1257 265337.36   10627.3    -11550.0  -11465.375   84.679   
   1500      585.3     280.9554    0.0225    246.8496    0.0199     0.0888     0.0025   288560.8976 1594421.5977 252268.21   9924.29    -11503.0  -11417.841    85.3    
   2000      760.22    258.5353    0.0208    221.5933    0.0179     0.0285     0.0017   112328.2459 1596391.1718  249018.7   9810.11    -11484.0  -11398.228   85.487   
   2500      921.38    256.5159    0.0206    216.9306    0.0176     0.0125     0.0013   63253.6285 1596844.8333 249293.16    9774.3    -11498.0  -11412.906   85.558   
   3000     1086.52    256.5891    0.0206    215.0021    0.0174     0.0079     0.0011   49834.4663 1597009.4947 249391.23    9772.8    -11483.0  -11397.474   85.592   
   3500     1252.47    256.6792    0.0206    213.5093    0.0173     0.0077     0.0008   46391.4576 1597047.2683 248988.86   9757.98    -11488.0  -11402.612   85.613   
   4000     1417.36    256.6781    0.0206    212.1055    0.0172     0.0077     0.0008   45589.7451 1597057.1719 249442.58   9795.18    -11488.0  -11402.464   85.622   
   4500     1600.46    256.6258    0.0206    210.7322    0.0171     0.0076     0.0007   45019.4113 1597046.1097 249128.98   9723.51    -11485.0  -11399.508   85.631   
   5000     1765.41    256.4861    0.0206    209.378     0.017      0.0075     0.0007   44678.7134 1597066.5202 248836.65   9771.61    -11487.0  -11400.943   85.638   
   5500     1924.34    256.3806    0.0206    208.038     0.0169     0.0074     0.0006   44286.6483 1597084.7551 249042.08   9650.04    -11490.0  -11404.013   85.644   
   6000     2089.31    256.2532    0.0206    206.7106    0.0168     0.0076     0.0006   43975.9806 1597120.2597 249131.62    9644.9    -11491.0  -11404.862   85.649   
   6500     2265.01    256.0794    0.0206    205.3951    0.0167     0.0073     0.0005   43655.8905 1597089.8344 249238.96   9621.58    -11482.0  -11396.54    85.655   
   7000     2437.33    255.9451    0.0206    204.0896    0.0166     0.0072     0.0005   43435.1209 1597102.7357 249120.07   9642.47    -11478.0  -11392.104   85.657   
   7500     2608.71    255.8646    0.0206    202.7931    0.0164     0.0072     0.0005   43154.4326 1597121.2264 248837.91    9699.9    -11471.0  -11385.284   85.659   
   8000     2774.64    255.7645    0.0206    201.5045    0.0163     0.0072     0.0004   42791.4027 1597134.0794 248972.18   9643.92    -11487.0  -11401.538   85.661   
   8500     2933.52    255.6848    0.0205    200.2242    0.0162     0.0071     0.0004   42661.6946 1597129.1066 249426.93   9620.75    -11478.0  -11391.925   85.662   
   9000     3103.59    255.5545    0.0205    198.9499    0.0161     0.0071     0.0004   42363.3663 1597087.9961 248894.63   9613.47    -11467.0  -11380.864   85.665   
   9500     3279.71    255.4987    0.0205    197.6812    0.016      0.0071     0.0004   42093.3097 1597108.2782 249012.04   9613.21    -11479.0  -11393.323   85.668   
  10000     3449.57    255.4121    0.0205    196.4176    0.0159     0.007      0.0004   41959.6331 1597096.4448 249063.88   9618.53    -11470.0  -11384.679   85.669   
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         0.41    9980.8444    0.9979   9982.1309    0.9979     3.1623     4.4274   79745.7496 1568209.8609 287823.14   23025.85   -23032.0  -23025.851   6.262    
    10       46.44    9970.9245    0.9969   9972.3212    0.9969     3.1623     4.4274   500619.06  1236805.1368 287823.14   23025.85   -23032.0  -23025.851   6.553    
    25       95.58    9950.6463    0.9948   9952.0856    0.9948     3.1623     4.4274   1361511.3954 772554.9143 287823.14   23025.85   -23033.0  -23025.851   7.024    
   500       350.1    4317.8141    0.4203   4321.9842    0.4206     1.907      0.005    35625781.6528 1358118.3036 287823.14   23025.85   -23107.0  -23025.851   81.461   
   1000      617.36    448.6568    0.0347    435.4182    0.0337     0.3753     0.0008   2442448.4732 3110977.9373 264496.49   21202.23   -22991.0  -22905.639   85.755   
   1500      886.07    268.6206    0.0215    250.9943    0.0201     0.1036     0.0002   494409.8613 3175469.2844 250546.13   19902.36   -22913.0  -22827.167   86.149   
   2000     1154.16    251.093     0.0201    233.3929    0.0188     0.0363     0.0001   167354.2436 3179062.1519 247913.95   19704.57   -22905.0  -22819.067   86.241   
   2500     1423.71    249.0227     0.02     230.8341    0.0186     0.0136     0.0001   94023.5326 3179732.6313  248245.1   19784.58   -22898.0  -22811.552   86.269   
   3000     1690.53    248.5456    0.0199    229.7733    0.0186     0.0063     0.0001   77990.0711 3179969.5969 247549.82   19661.88   -22875.0  -22789.086   86.278   
   3500     1957.41    248.2874    0.0199    228.9003    0.0185     0.0062     0.0001    74431.92  3179956.6333 247741.82   19674.05   -22896.0  -22809.302   86.282   
   4000     2226.12    248.0678    0.0199    228.0638    0.0184     0.006      0.0001   73540.4487 3179980.134 247626.53   19634.01   -22902.0  -22816.131   86.284   
   4500     2493.21    247.864     0.0199    227.2415    0.0183     0.006      0.0001   72595.7179 3179948.5254 247829.54   19712.5    -22887.0  -22800.901   86.284   
   5000     2760.84    247.659     0.0199    226.4295    0.0183     0.0059     0.0001   72248.3775 3179931.5303  247666.4   19459.14   -22891.0  -22804.236   86.285   
   5500     3028.79    247.473     0.0198    225.6269    0.0182     0.0058      0.0     71624.8905 3179939.5102 247535.06   19623.03   -22888.0  -22802.135   86.285   
   6000      3295.7    247.2911    0.0198    224.833     0.0182     0.0058      0.0     71346.0764 3179978.4815 247503.19   19523.11   -22898.0  -22811.858   86.285   
   6500     3562.69    247.1324    0.0198    224.0472    0.0181     0.0057      0.0     70902.0106 3179980.2261 247405.78   19624.98   -22876.0  -22790.013   86.285   
   7000     3830.22    246.9709    0.0198    223.269     0.018      0.0056      0.0     70386.8278 3180009.5   247645.6   19526.98   -22903.0  -22817.198   86.286   
   7500     4098.31    246.8021    0.0198    222.4981    0.018      0.0056      0.0     70059.4572 3180024.2743 247664.13   19464.74   -22884.0  -22798.179   86.285   
   8000     4365.78    246.6437    0.0198    221.7336    0.0179     0.0056      0.0     69621.8475 3179966.0863 247765.17   19518.15   -22900.0  -22813.539   86.286   
   8500     4633.85    246.4923    0.0198    220.9757    0.0178     0.0055      0.0     69158.3887 3179931.8943 247393.43   19541.6    -22868.0  -22781.921   86.287   
   9000     4902.23    246.3373    0.0197    220.2229    0.0178     0.0055      0.0     68852.1136 3179990.6979 247875.93   19428.94   -22897.0  -22811.042   86.288   
   9500      5170.1    246.1868    0.0197    219.4756    0.0177     0.0055      0.0     68463.4672 3179995.9232  247827.2   19527.58   -22876.0  -22789.934   86.288   
  10000     5439.98    246.0441    0.0197    218.7333    0.0177     0.0055      0.0     68238.3302 3180007.3643 247464.84   19423.44   -22896.0  -22809.305   86.288   
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.06     9979.836    0.9978   9977.0842    0.9978     3.1623     4.4274   164834.8657 3118386.8143 287823.14   57564.63   -57573.0  -57564.627   8.405    
    10       61.44    9969.5814    0.9968    9966.826    0.9967     3.1623     4.4274   1263859.3658 2507442.6248 287823.14   57564.63   -57573.0  -57564.627    8.6     
    25       128.63   9948.8555    0.9947   9945.7118    0.9946     3.1623     4.4274   3513918.663 1547960.6284 287823.14   57564.63   -57574.0  -57564.627   8.905    
   500       697.65    4301.045    0.4186   4299.5601    0.4186     1.8931      0.0     88822211.4062 3411173.3983 287823.14   57564.63   -57646.0  -57564.627   81.381   
   1000      1295.4    448.9724    0.0351    442.5243    0.0349     0.3493      0.0     6187444.8974 7769457.7306 265121.92   53272.72   -57358.0  -57271.911   85.754   
   1500      1893.3    259.843     0.0208    253.7372    0.0205     0.0927      0.0     1244283.58 7930743.4978 248863.77   50097.4    -57143.0  -57056.704   86.242   
   2000      2492.7    243.6934    0.0196    237.8802    0.0192     0.0288      0.0     368465.1107 7939856.9124 246924.02   49328.37   -57086.0  -56999.804   86.366   
   2500     3092.66    242.1439    0.0194    236.1379    0.0191     0.0092      0.0     183994.0214 7941601.4918 246735.95   49497.42   -57108.0  -57021.587   86.402   
   3000     3692.73    241.7677    0.0194    235.5089    0.0191     0.005       0.0     151914.2963 7941973.3221 246679.53   49220.03   -57113.0  -57026.546   86.411   
   3500     4292.92    241.5172    0.0194    234.9829    0.019      0.005       0.0     146654.4748 7942108.8376 246822.88   49358.67   -57127.0  -57040.695   86.414   
   4000     4892.47    241.2921    0.0194    234.4728    0.019      0.005       0.0     145215.9996 7942251.7264 247017.93   49205.56   -57119.0  -57032.213   86.415   
   4500     5491.57    241.0804    0.0194    233.9696    0.0189     0.0049      0.0     144396.8759 7942131.5891 246537.71   49256.86   -57158.0  -57071.121   86.415   
   5000     6091.83    240.8687    0.0193    233.4722    0.0189     0.0049      0.0     143131.0795 7942164.8343  246850.9   49298.0    -57136.0  -57049.868   86.414   
   5500     6689.63    240.6569    0.0193    232.9804    0.0189     0.0049      0.0     142272.6553 7942105.5667 246673.18   49291.72   -57108.0  -57021.785   86.414   
   6000     7287.96    240.4492    0.0193    232.4937    0.0188     0.0048      0.0     141367.3297 7942167.8326 246919.08   49349.0    -57134.0  -57047.445   86.414   
   6500     7886.74    240.2491    0.0193    232.0119    0.0188     0.0048      0.0     140581.2936 7942116.7294 246789.81   49157.4    -57120.0   -57033.5    86.413   
   7000      8485.4    240.0447    0.0193    231.5348    0.0187     0.0048      0.0     139791.2339 7942162.4989  246484.4   49161.3    -57083.0  -56996.307   86.412   
   7500     9084.54    239.8471    0.0193    231.0622    0.0187     0.0047      0.0     139123.718 7942084.9864 246755.29   49240.32   -57124.0  -57037.493   86.412   
   8000     9683.68    239.646     0.0192    230.594     0.0187     0.0047      0.0     138215.1642 7942109.9342 246676.38   49308.17   -57124.0  -57037.642   86.411   
   8500     10282.49   239.4571    0.0192    230.1298    0.0186     0.0047      0.0     137558.5838 7942099.446 246388.75   49212.24   -57103.0  -57016.447   86.411   
   9000     10880.96   239.2741    0.0192    229.6694    0.0186     0.0047      0.0     137176.0741 7942163.6597 246750.67   49279.44   -57122.0  -57035.489   86.41    
   9500     11479.45   239.0815    0.0192    229.2125    0.0186     0.0046      0.0     136127.5086 7942138.9014 246532.17   49221.79   -57105.0  -57018.573   86.41    
  10000     12078.0    238.8968    0.0192    228.7592    0.0185     0.0046      0.0     135613.1723 7942172.8092 246527.83   49083.72   -57095.0  -57008.154   86.41    
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.34    9980.3622    0.9978   9985.9037    0.9978     3.1623     4.4274   328744.4181 7782389.5816 287823.14  115129.25  -115136.0  -115129.255    6.98    
    10       77.65    9970.2624    0.9968   9975.9169    0.9968     3.1623     4.4274   2456344.8958 6210590.1333 287823.14  115129.25  -115136.0  -115129.255   7.245    
    25       162.33   9949.7411    0.9947   9955.2584    0.9947     3.1623     4.4274   6898416.0349 3808703.7587 287823.14  115129.25  -115137.0  -115129.255   7.653    
   500       887.09   4312.7103    0.4193   4322.8233    0.4202     1.889       0.0     178008311.7845 6800752.3554 287823.14  115129.25  -115210.0  -115129.255   80.466   
   1000      1651.1    442.3416    0.0348    443.7536    0.035      0.3423      0.0     12718003.4854 15540447.8212 264743.16  106200.78  -114635.0  -114550.019   85.299   
   1500     2414.66    255.9102    0.0206    253.404     0.0204     0.0982      0.0     2603962.9819 15871471.8251 249483.23   99826.57  -114203.0  -114116.646   85.919   
   2000     3179.43    242.6642    0.0195    239.0843    0.0193     0.0312      0.0     910025.0471 15898384.8042 247835.12   98544.31  -114149.0  -114062.896   86.071   
   2500     3942.93    241.7361    0.0195    237.7617    0.0192     0.0251      0.0     724860.1583 15895998.9916 247542.94   98622.5   -114126.0  -114039.841   86.108   
   3000     4706.35    241.4415    0.0194    237.3339    0.0191     0.0217      0.0     693326.495 15897845.2429 247382.47   98448.74  -114121.0  -114035.109   86.131   
   3500     5470.92    241.1617    0.0194    236.9983    0.0191     0.0171      0.0     669763.3385 15895145.9058 247812.05   98397.67  -114128.0  -114042.184   86.136   
   4000     6234.37    240.8235    0.0194    236.6611    0.0191     0.0183      0.0     694065.5198 15909916.2552 247113.54   98035.9   -114064.0  -113977.911   86.144   
   4500     6998.77    240.6255    0.0194    236.3095    0.0191     0.0285      0.0     667258.4325 15894792.1031  247063.7   98516.1   -114096.0  -114010.188   86.139   
   5000     7761.45    240.5242    0.0194    235.9925    0.019      0.0188      0.0     694139.418 15920055.8565 247087.97   98284.6   -114149.0  -114062.398   86.129   
   5500     8526.91    240.4732    0.0194    235.6441    0.019      0.0237      0.0     698171.3381 15893933.7151 247082.34   98525.66  -114123.0  -114037.222   86.136   
   6000     9291.07    240.1212    0.0193    235.3229    0.019      0.0162      0.0     603792.83  15870458.4282 247134.02   98511.8   -114118.0  -114031.385   86.135   
   6500     10056.43   239.8461    0.0193    234.9898    0.0189     0.0177      0.0     653916.2723 15904143.424 247086.11   98311.22  -114107.0  -114020.873   86.135   
   7000     10820.22   239.6648    0.0193    234.7164    0.0189     0.0237      0.0     668211.2334 15879286.4673 247495.07   98381.14  -114143.0  -114057.175   86.137   
   7500     11584.2    239.4407    0.0193    234.3963    0.0189     0.0194      0.0     648753.2975 15901386.4316 247057.63   98233.04  -114125.0  -114038.472   86.138   
   8000     12348.57   239.2933    0.0193    234.0752    0.0189     0.0161      0.0     638945.688 15897677.0449 246828.38   98473.69  -114109.0  -114022.689   86.134   
   8500     13112.41   239.1379    0.0193    233.7669    0.0188     0.022       0.0     667239.5687 15919511.6154 246903.69   98360.13  -114145.0  -114059.311   86.133   
   9000     13877.73   239.0226    0.0192    233.4606    0.0188     0.0206      0.0     609736.8823 15901176.724 246757.83   98082.94  -114131.0  -114044.866   86.131   
   9500     14643.22   238.7891    0.0192    233.1523    0.0188     0.0197      0.0     675325.5003 15887516.6733 246935.83   98225.19  -114104.0  -114017.907   86.135   
  10000     15405.86   238.5142    0.0192    232.8515    0.0188     0.0222      0.0     654141.104 15909663.2551 246754.74   98342.17  -114091.0  -114004.801   86.141   
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.34    9980.1736    0.9978   9977.6987    0.9978     3.1623     4.4274   1020903.5463 15580787.6615 287823.14  230258.51  -230268.0  -230258.509    9.09    
    10       104.42   9970.0045    0.9968   9967.3137    0.9968     3.1623     4.4274   5407398.0327 12477219.2533 287823.14  230258.51  -230268.0  -230258.509   9.217    
    25       216.62   9949.2093    0.9947   9946.4356    0.9946     3.1623     4.4274   14033849.9403 7669586.5998 287823.14  230258.51  -230268.0  -230258.509   9.456    
   500       971.49   4304.5806    0.4193   4300.2692    0.4188     1.8846      0.0     355236560.9951 13645649.5176 287823.14  230258.51  -230339.0  -230258.509   80.494   
   1000     1766.14    447.0369    0.0347    446.6349    0.0347     0.3884      0.0     25281725.2903 31047569.0926  264510.7  211533.69  -229092.0  -229006.151   85.383   
   1500     2561.21    258.6777    0.0207    256.1078    0.0205     0.0971      0.0     4827058.3928 31709259.5593 249188.37  198884.15  -228322.0  -228235.628   86.094   
   2000     3357.68    243.4697    0.0196    240.8068    0.0194     0.0415      0.0     2317145.3932 31755487.7129 247664.77  197468.54  -228241.0  -228154.864   86.289   
   2500     4153.97    242.2545    0.0195    239.4308    0.0193     0.0321      0.0     1910573.3386 31784282.3079 247179.12  196993.51  -228213.0  -228126.4    86.339   
   3000     4947.58    241.7938    0.0194    238.967     0.0192     0.0314      0.0     1928831.7431 31749060.8093 246922.38  196901.04  -228206.0  -228120.143   86.356   
   3500     5741.52    241.7089    0.0194    238.6711    0.0192     0.0412      0.0     1626244.7016 31754935.926 247010.06  197014.05  -228182.0  -228095.92   86.354   
