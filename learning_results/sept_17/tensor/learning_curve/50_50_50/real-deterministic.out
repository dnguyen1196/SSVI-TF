Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  8.716424703598022
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
    0.0          0.0          0.0          0.0       287494.79    1149836.49 
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         0.23    9981.1137    0.9979   10009.1059   0.9979     3.1623     4.4249   18382.4028  19.5781   287823.14   11512.93   -11520.0  -11512.925   6.613    
    10       42.25    9971.2217    0.9969   9998.5743    0.9968     3.1623     4.4274   254302.4389  269.5205  287823.14   11512.93   -11520.0  -11512.925   6.889    
    25       87.22     9951.085    0.9949   9979.1158    0.9949     3.1623     4.4274   684730.2516  770.0327  287823.14   11512.93   -11520.0  -11512.925   7.236    
   500       252.76   4323.4878    0.4209   4359.0637    0.4225     1.8816     0.0326   17914680.8263 679479.7767 287823.14   11512.93   -11592.0  -11512.925   79.548   
   1000      420.32    469.6976    0.0368    448.8469    0.0351     0.3455     0.0057   1261103.9499 1561180.1257 265337.36   10627.3    -11550.0  -11465.375   84.679   
   1500      585.3     280.9554    0.0225    246.8496    0.0199     0.0888     0.0025   288560.8976 1594421.5977 252268.21   9924.29    -11503.0  -11417.841    85.3    
   2000      760.22    258.5353    0.0208    221.5933    0.0179     0.0285     0.0017   112328.2459 1596391.1718  249018.7   9810.11    -11484.0  -11398.228   85.487   
   2500      921.38    256.5159    0.0206    216.9306    0.0176     0.0125     0.0013   63253.6285 1596844.8333 249293.16    9774.3    -11498.0  -11412.906   85.558   
   3000     1086.52    256.5891    0.0206    215.0021    0.0174     0.0079     0.0011   49834.4663 1597009.4947 249391.23    9772.8    -11483.0  -11397.474   85.592   
   3500     1252.47    256.6792    0.0206    213.5093    0.0173     0.0077     0.0008   46391.4576 1597047.2683 248988.86   9757.98    -11488.0  -11402.612   85.613   
   4000     1417.36    256.6781    0.0206    212.1055    0.0172     0.0077     0.0008   45589.7451 1597057.1719 249442.58   9795.18    -11488.0  -11402.464   85.622   
   4500     1600.46    256.6258    0.0206    210.7322    0.0171     0.0076     0.0007   45019.4113 1597046.1097 249128.98   9723.51    -11485.0  -11399.508   85.631   
   5000     1765.41    256.4861    0.0206    209.378     0.017      0.0075     0.0007   44678.7134 1597066.5202 248836.65   9771.61    -11487.0  -11400.943   85.638   
   5500     1924.34    256.3806    0.0206    208.038     0.0169     0.0074     0.0006   44286.6483 1597084.7551 249042.08   9650.04    -11490.0  -11404.013   85.644   
   6000     2089.31    256.2532    0.0206    206.7106    0.0168     0.0076     0.0006   43975.9806 1597120.2597 249131.62    9644.9    -11491.0  -11404.862   85.649   
   6500     2265.01    256.0794    0.0206    205.3951    0.0167     0.0073     0.0005   43655.8905 1597089.8344 249238.96   9621.58    -11482.0  -11396.54    85.655   
   7000     2437.33    255.9451    0.0206    204.0896    0.0166     0.0072     0.0005   43435.1209 1597102.7357 249120.07   9642.47    -11478.0  -11392.104   85.657   
   7500     2608.71    255.8646    0.0206    202.7931    0.0164     0.0072     0.0005   43154.4326 1597121.2264 248837.91    9699.9    -11471.0  -11385.284   85.659   
   8000     2774.64    255.7645    0.0206    201.5045    0.0163     0.0072     0.0004   42791.4027 1597134.0794 248972.18   9643.92    -11487.0  -11401.538   85.661   
   8500     2933.52    255.6848    0.0205    200.2242    0.0162     0.0071     0.0004   42661.6946 1597129.1066 249426.93   9620.75    -11478.0  -11391.925   85.662   
   9000     3103.59    255.5545    0.0205    198.9499    0.0161     0.0071     0.0004   42363.3663 1597087.9961 248894.63   9613.47    -11467.0  -11380.864   85.665   
   9500     3279.71    255.4987    0.0205    197.6812    0.016      0.0071     0.0004   42093.3097 1597108.2782 249012.04   9613.21    -11479.0  -11393.323   85.668   
  10000     3449.57    255.4121    0.0205    196.4176    0.0159     0.007      0.0004   41959.6331 1597096.4448 249063.88   9618.53    -11470.0  -11384.679   85.669   
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         0.41    9980.8444    0.9979   9982.1309    0.9979     3.1623     4.4274   79745.7496 1568209.8609 287823.14   23025.85   -23032.0  -23025.851   6.262    
    10       46.44    9970.9245    0.9969   9972.3212    0.9969     3.1623     4.4274   500619.06  1236805.1368 287823.14   23025.85   -23032.0  -23025.851   6.553    
    25       95.58    9950.6463    0.9948   9952.0856    0.9948     3.1623     4.4274   1361511.3954 772554.9143 287823.14   23025.85   -23033.0  -23025.851   7.024    
   500       350.1    4317.8141    0.4203   4321.9842    0.4206     1.907      0.005    35625781.6528 1358118.3036 287823.14   23025.85   -23107.0  -23025.851   81.461   
   1000      617.36    448.6568    0.0347    435.4182    0.0337     0.3753     0.0008   2442448.4732 3110977.9373 264496.49   21202.23   -22991.0  -22905.639   85.755   
   1500      886.07    268.6206    0.0215    250.9943    0.0201     0.1036     0.0002   494409.8613 3175469.2844 250546.13   19902.36   -22913.0  -22827.167   86.149   
   2000     1154.16    251.093     0.0201    233.3929    0.0188     0.0363     0.0001   167354.2436 3179062.1519 247913.95   19704.57   -22905.0  -22819.067   86.241   
   2500     1423.71    249.0227     0.02     230.8341    0.0186     0.0136     0.0001   94023.5326 3179732.6313  248245.1   19784.58   -22898.0  -22811.552   86.269   
   3000     1690.53    248.5456    0.0199    229.7733    0.0186     0.0063     0.0001   77990.0711 3179969.5969 247549.82   19661.88   -22875.0  -22789.086   86.278   
   3500     1957.41    248.2874    0.0199    228.9003    0.0185     0.0062     0.0001    74431.92  3179956.6333 247741.82   19674.05   -22896.0  -22809.302   86.282   
   4000     2226.12    248.0678    0.0199    228.0638    0.0184     0.006      0.0001   73540.4487 3179980.134 247626.53   19634.01   -22902.0  -22816.131   86.284   
   4500     2493.21    247.864     0.0199    227.2415    0.0183     0.006      0.0001   72595.7179 3179948.5254 247829.54   19712.5    -22887.0  -22800.901   86.284   
   5000     2760.84    247.659     0.0199    226.4295    0.0183     0.0059     0.0001   72248.3775 3179931.5303  247666.4   19459.14   -22891.0  -22804.236   86.285   
   5500     3028.79    247.473     0.0198    225.6269    0.0182     0.0058      0.0     71624.8905 3179939.5102 247535.06   19623.03   -22888.0  -22802.135   86.285   
   6000      3295.7    247.2911    0.0198    224.833     0.0182     0.0058      0.0     71346.0764 3179978.4815 247503.19   19523.11   -22898.0  -22811.858   86.285   
   6500     3562.69    247.1324    0.0198    224.0472    0.0181     0.0057      0.0     70902.0106 3179980.2261 247405.78   19624.98   -22876.0  -22790.013   86.285   
   7000     3830.22    246.9709    0.0198    223.269     0.018      0.0056      0.0     70386.8278 3180009.5   247645.6   19526.98   -22903.0  -22817.198   86.286   
   7500     4098.31    246.8021    0.0198    222.4981    0.018      0.0056      0.0     70059.4572 3180024.2743 247664.13   19464.74   -22884.0  -22798.179   86.285   
   8000     4365.78    246.6437    0.0198    221.7336    0.0179     0.0056      0.0     69621.8475 3179966.0863 247765.17   19518.15   -22900.0  -22813.539   86.286   
   8500     4633.85    246.4923    0.0198    220.9757    0.0178     0.0055      0.0     69158.3887 3179931.8943 247393.43   19541.6    -22868.0  -22781.921   86.287   
   9000     4902.23    246.3373    0.0197    220.2229    0.0178     0.0055      0.0     68852.1136 3179990.6979 247875.93   19428.94   -22897.0  -22811.042   86.288   
   9500      5170.1    246.1868    0.0197    219.4756    0.0177     0.0055      0.0     68463.4672 3179995.9232  247827.2   19527.58   -22876.0  -22789.934   86.288   
  10000     5439.98    246.0441    0.0197    218.7333    0.0177     0.0055      0.0     68238.3302 3180007.3643 247464.84   19423.44   -22896.0  -22809.305   86.288   
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.06     9979.836    0.9978   9977.0842    0.9978     3.1623     4.4274   164834.8657 3118386.8143 287823.14   57564.63   -57573.0  -57564.627   8.405    
    10       61.44    9969.5814    0.9968    9966.826    0.9967     3.1623     4.4274   1263859.3658 2507442.6248 287823.14   57564.63   -57573.0  -57564.627    8.6     
    25       128.63   9948.8555    0.9947   9945.7118    0.9946     3.1623     4.4274   3513918.663 1547960.6284 287823.14   57564.63   -57574.0  -57564.627   8.905    
   500       697.65    4301.045    0.4186   4299.5601    0.4186     1.8931      0.0     88822211.4062 3411173.3983 287823.14   57564.63   -57646.0  -57564.627   81.381   
   1000      1295.4    448.9724    0.0351    442.5243    0.0349     0.3493      0.0     6187444.8974 7769457.7306 265121.92   53272.72   -57358.0  -57271.911   85.754   
   1500      1893.3    259.843     0.0208    253.7372    0.0205     0.0927      0.0     1244283.58 7930743.4978 248863.77   50097.4    -57143.0  -57056.704   86.242   
   2000      2492.7    243.6934    0.0196    237.8802    0.0192     0.0288      0.0     368465.1107 7939856.9124 246924.02   49328.37   -57086.0  -56999.804   86.366   
   2500     3092.66    242.1439    0.0194    236.1379    0.0191     0.0092      0.0     183994.0214 7941601.4918 246735.95   49497.42   -57108.0  -57021.587   86.402   
   3000     3692.73    241.7677    0.0194    235.5089    0.0191     0.005       0.0     151914.2963 7941973.3221 246679.53   49220.03   -57113.0  -57026.546   86.411   
   3500     4292.92    241.5172    0.0194    234.9829    0.019      0.005       0.0     146654.4748 7942108.8376 246822.88   49358.67   -57127.0  -57040.695   86.414   
   4000     4892.47    241.2921    0.0194    234.4728    0.019      0.005       0.0     145215.9996 7942251.7264 247017.93   49205.56   -57119.0  -57032.213   86.415   
   4500     5491.57    241.0804    0.0194    233.9696    0.0189     0.0049      0.0     144396.8759 7942131.5891 246537.71   49256.86   -57158.0  -57071.121   86.415   
   5000     6091.83    240.8687    0.0193    233.4722    0.0189     0.0049      0.0     143131.0795 7942164.8343  246850.9   49298.0    -57136.0  -57049.868   86.414   
   5500     6689.63    240.6569    0.0193    232.9804    0.0189     0.0049      0.0     142272.6553 7942105.5667 246673.18   49291.72   -57108.0  -57021.785   86.414   
   6000     7287.96    240.4492    0.0193    232.4937    0.0188     0.0048      0.0     141367.3297 7942167.8326 246919.08   49349.0    -57134.0  -57047.445   86.414   
   6500     7886.74    240.2491    0.0193    232.0119    0.0188     0.0048      0.0     140581.2936 7942116.7294 246789.81   49157.4    -57120.0   -57033.5    86.413   
   7000      8485.4    240.0447    0.0193    231.5348    0.0187     0.0048      0.0     139791.2339 7942162.4989  246484.4   49161.3    -57083.0  -56996.307   86.412   
   7500     9084.54    239.8471    0.0193    231.0622    0.0187     0.0047      0.0     139123.718 7942084.9864 246755.29   49240.32   -57124.0  -57037.493   86.412   
   8000     9683.68    239.646     0.0192    230.594     0.0187     0.0047      0.0     138215.1642 7942109.9342 246676.38   49308.17   -57124.0  -57037.642   86.411   
   8500     10282.49   239.4571    0.0192    230.1298    0.0186     0.0047      0.0     137558.5838 7942099.446 246388.75   49212.24   -57103.0  -57016.447   86.411   
   9000     10880.96   239.2741    0.0192    229.6694    0.0186     0.0047      0.0     137176.0741 7942163.6597 246750.67   49279.44   -57122.0  -57035.489   86.41    
   9500     11479.45   239.0815    0.0192    229.2125    0.0186     0.0046      0.0     136127.5086 7942138.9014 246532.17   49221.79   -57105.0  -57018.573   86.41    
  10000     12078.0    238.8968    0.0192    228.7592    0.0185     0.0046      0.0     135613.1723 7942172.8092 246527.83   49083.72   -57095.0  -57008.154   86.41    
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.34    9980.3622    0.9978   9985.9037    0.9978     3.1623     4.4274   328744.4181 7782389.5816 287823.14  115129.25  -115136.0  -115129.255    6.98    
    10       77.65    9970.2624    0.9968   9975.9169    0.9968     3.1623     4.4274   2456344.8958 6210590.1333 287823.14  115129.25  -115136.0  -115129.255   7.245    
    25       162.33   9949.7411    0.9947   9955.2584    0.9947     3.1623     4.4274   6898416.0349 3808703.7587 287823.14  115129.25  -115137.0  -115129.255   7.653    
   500       887.09   4312.7103    0.4193   4322.8233    0.4202     1.889       0.0     178008311.7845 6800752.3554 287823.14  115129.25  -115210.0  -115129.255   80.466   
   1000      1651.1    442.3416    0.0348    443.7536    0.035      0.3423      0.0     12718003.4854 15540447.8212 264743.16  106200.78  -114635.0  -114550.019   85.299   
   1500     2414.66    255.9102    0.0206    253.404     0.0204     0.0982      0.0     2603962.9819 15871471.8251 249483.23   99826.57  -114203.0  -114116.646   85.919   
   2000     3179.43    242.6642    0.0195    239.0843    0.0193     0.0312      0.0     910025.0471 15898384.8042 247835.12   98544.31  -114149.0  -114062.896   86.071   
   2500     3942.93    241.7361    0.0195    237.7617    0.0192     0.0251      0.0     724860.1583 15895998.9916 247542.94   98622.5   -114126.0  -114039.841   86.108   
   3000     4706.35    241.4415    0.0194    237.3339    0.0191     0.0217      0.0     693326.495 15897845.2429 247382.47   98448.74  -114121.0  -114035.109   86.131   
   3500     5470.92    241.1617    0.0194    236.9983    0.0191     0.0171      0.0     669763.3385 15895145.9058 247812.05   98397.67  -114128.0  -114042.184   86.136   
   4000     6234.37    240.8235    0.0194    236.6611    0.0191     0.0183      0.0     694065.5198 15909916.2552 247113.54   98035.9   -114064.0  -113977.911   86.144   
   4500     6998.77    240.6255    0.0194    236.3095    0.0191     0.0285      0.0     667258.4325 15894792.1031  247063.7   98516.1   -114096.0  -114010.188   86.139   
   5000     7761.45    240.5242    0.0194    235.9925    0.019      0.0188      0.0     694139.418 15920055.8565 247087.97   98284.6   -114149.0  -114062.398   86.129   
   5500     8526.91    240.4732    0.0194    235.6441    0.019      0.0237      0.0     698171.3381 15893933.7151 247082.34   98525.66  -114123.0  -114037.222   86.136   
   6000     9291.07    240.1212    0.0193    235.3229    0.019      0.0162      0.0     603792.83  15870458.4282 247134.02   98511.8   -114118.0  -114031.385   86.135   
   6500     10056.43   239.8461    0.0193    234.9898    0.0189     0.0177      0.0     653916.2723 15904143.424 247086.11   98311.22  -114107.0  -114020.873   86.135   
   7000     10820.22   239.6648    0.0193    234.7164    0.0189     0.0237      0.0     668211.2334 15879286.4673 247495.07   98381.14  -114143.0  -114057.175   86.137   
   7500     11584.2    239.4407    0.0193    234.3963    0.0189     0.0194      0.0     648753.2975 15901386.4316 247057.63   98233.04  -114125.0  -114038.472   86.138   
   8000     12348.57   239.2933    0.0193    234.0752    0.0189     0.0161      0.0     638945.688 15897677.0449 246828.38   98473.69  -114109.0  -114022.689   86.134   
   8500     13112.41   239.1379    0.0193    233.7669    0.0188     0.022       0.0     667239.5687 15919511.6154 246903.69   98360.13  -114145.0  -114059.311   86.133   
   9000     13877.73   239.0226    0.0192    233.4606    0.0188     0.0206      0.0     609736.8823 15901176.724 246757.83   98082.94  -114131.0  -114044.866   86.131   
   9500     14643.22   238.7891    0.0192    233.1523    0.0188     0.0197      0.0     675325.5003 15887516.6733 246935.83   98225.19  -114104.0  -114017.907   86.135   
  10000     15405.86   238.5142    0.0192    232.8515    0.0188     0.0222      0.0     654141.104 15909663.2551 246754.74   98342.17  -114091.0  -114004.801   86.141   
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.34    9980.1736    0.9978   9977.6987    0.9978     3.1623     4.4274   1020903.5463 15580787.6615 287823.14  230258.51  -230268.0  -230258.509    9.09    
    10       104.42   9970.0045    0.9968   9967.3137    0.9968     3.1623     4.4274   5407398.0327 12477219.2533 287823.14  230258.51  -230268.0  -230258.509   9.217    
    25       216.62   9949.2093    0.9947   9946.4356    0.9946     3.1623     4.4274   14033849.9403 7669586.5998 287823.14  230258.51  -230268.0  -230258.509   9.456    
   500       971.49   4304.5806    0.4193   4300.2692    0.4188     1.8846      0.0     355236560.9951 13645649.5176 287823.14  230258.51  -230339.0  -230258.509   80.494   
   1000     1766.14    447.0369    0.0347    446.6349    0.0347     0.3884      0.0     25281725.2903 31047569.0926  264510.7  211533.69  -229092.0  -229006.151   85.383   
   1500     2561.21    258.6777    0.0207    256.1078    0.0205     0.0971      0.0     4827058.3928 31709259.5593 249188.37  198884.15  -228322.0  -228235.628   86.094   
   2000     3357.68    243.4697    0.0196    240.8068    0.0194     0.0415      0.0     2317145.3932 31755487.7129 247664.77  197468.54  -228241.0  -228154.864   86.289   
   2500     4153.97    242.2545    0.0195    239.4308    0.0193     0.0321      0.0     1910573.3386 31784282.3079 247179.12  196993.51  -228213.0  -228126.4    86.339   
   3000     4947.58    241.7938    0.0194    238.967     0.0192     0.0314      0.0     1928831.7431 31749060.8093 246922.38  196901.04  -228206.0  -228120.143   86.356   
   3500     5741.52    241.7089    0.0194    238.6711    0.0192     0.0412      0.0     1626244.7016 31754935.926 247010.06  197014.05  -228182.0  -228095.92   86.354   
   4000     6537.22    241.4697    0.0194    238.3423    0.0192     0.0281      0.0     1809648.8187 31794330.3434 247161.31  196926.13  -228176.0  -228089.263   86.35    
   4500     7331.88    241.2145    0.0194    238.0548    0.0192     0.0272      0.0     1724868.2624 31751056.2886 247047.47  197146.68  -228252.0  -228165.259   86.337   
   5000     8127.83    240.8739    0.0194    237.7373    0.0191     0.0296      0.0     1781579.1284 31782630.572 247106.41  197204.47  -228218.0  -228131.505   86.341   
   5500     8922.75    240.6219    0.0193    237.4245    0.0191     0.0254      0.0     1740132.84 31720276.3362 247227.01  197551.85  -228251.0  -228164.617   86.338   
   6000     9720.33    240.4187    0.0193    237.1304    0.0191     0.035       0.0     1830299.1841 31761756.9093  246748.0  196943.18  -228141.0  -228054.331   86.334   
   6500     10516.43   240.1773    0.0193    236.826     0.0191     0.0323      0.0     1751659.3174 31770996.9077 247317.42   196906.3  -228207.0  -228120.518   86.338   
   7000     11310.29   239.8452    0.0193    236.5586    0.019      0.0308      0.0     1665184.943 31805068.2137 246639.39  196621.07  -228191.0  -228104.246   86.331   
   7500     12103.11   239.6304    0.0193    236.2866    0.019      0.0251      0.0     1784743.4419 31744026.2776 247416.46  197295.58  -228184.0  -228097.418   86.325   
   8000     12898.66   239.4834    0.0193    235.9895    0.019      0.0335      0.0     1734683.8388 31780466.6427 246717.88  196616.41  -228166.0  -228080.116   86.332   
   8500     13693.65   239.2077    0.0192    235.7414    0.019      0.0291      0.0     1848509.6893 31802288.8171 246316.82   196850.9  -228214.0  -228127.736   86.345   
   9000     14488.59   238.9983    0.0192    235.4507    0.019      0.0222      0.0     1666025.2452 31801105.6613 246825.36  196349.32  -228170.0  -228084.05   86.339   
   9500     15281.57   238.8273    0.0192    235.1622    0.0189     0.0282      0.0     1784647.9488 31753321.1009 246599.45  196537.24  -228231.0  -228145.077   86.322   
  10000     16077.86   238.5328    0.0192    234.9152    0.0189     0.0396      0.0     1751937.216 31742926.7849 246917.93  196325.32  -228129.0  -228042.941   86.33    
Using  0.5  of training data 
Using  0.5 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.35     9982.572    0.9981   9982.3398    0.998      3.1623     4.4274   2607178.1649 31105539.7026 287823.14  575646.27  -575653.0  -575646.273   7.161    
    10       183.94   9973.1033    0.9971   9972.6473    0.9971     3.1623     4.4274   12703853.2219 24741672.5814 287823.14  575646.27  -575654.0  -575646.273   7.411    
    25       377.58   9953.6271    0.9952   9953.1345    0.9951     3.1623     4.4274   33157795.2717 15192442.2727 287823.14  575646.27  -575654.0  -575646.273   7.782    
   500      1218.62   4359.1799    0.4254   4353.9504    0.4249     1.902       0.0     892648119.576 33534121.8604 287823.14  575646.27  -575728.0  -575646.273   81.234   
   1000     2104.85    437.0194    0.0338    435.6546    0.0336     0.3993      0.0     59298215.3085 77610813.4467 263851.77  527275.26  -572565.0  -572479.523   85.821   
   1500     2992.82    257.3019    0.0206    256.842     0.0206     0.1166      0.0     12062503.9301 79412974.0674 248961.35  499093.57  -570760.0  -570674.059   86.312   
   2000     3880.06    242.8936    0.0195    242.5721    0.0195     0.0386      0.0     5991060.6606 79461823.5175  246821.3  493538.93  -570369.0  -570282.243   86.422   
   2500     4767.07    241.7078    0.0194    241.2628    0.0194     0.0343      0.0     5421737.1425 79385893.8076 246910.74  493161.38  -570351.0  -570264.942   86.441   
   3000     5656.18    241.3642    0.0194    240.8348    0.0194     0.0347      0.0     5234525.0606 79447129.2148 246736.81  494271.62  -570425.0  -570338.809   86.457   
   3500     6543.21    241.1294    0.0194    240.5705    0.0193     0.0345      0.0     4690427.648 79430394.1763 247039.95  493512.96  -570439.0  -570352.756   86.446   
   4000     7429.99    240.7526    0.0194    240.1927    0.0193     0.0252      0.0     4754046.0228 79352911.9909 246608.04   493210.1  -570348.0  -570261.613   86.453   
   4500     8316.08    240.4722    0.0193    239.9201    0.0193     0.0322      0.0     4770269.1767 79466845.7976 246567.19  493604.09  -570363.0  -570276.558   86.456   
   5000     9203.09    240.1712    0.0193    239.6078    0.0193     0.0377      0.0     4687794.6272 79431574.5737 247007.25  493217.92  -570382.0  -570295.643   86.454   
   5500     10089.34   239.977     0.0193    239.3619    0.0192     0.0377      0.0     4515797.7484 79480800.6863 247044.71  493099.73  -570407.0  -570320.524   86.447   
   6000     10976.47   239.6492    0.0193    239.065     0.0192     0.0297      0.0     4712501.2887 79345434.7212 246665.13   493220.7  -570392.0  -570305.651   86.451   
   6500     11863.53   239.5242    0.0193    238.7729    0.0192     0.0287      0.0     4901468.8447 79458153.3845 246885.69  492955.92  -570306.0  -570219.491   86.441   
   7000     12751.57   239.2543    0.0192    238.5302    0.0192     0.0346      0.0     4939369.0295 79428503.3143 246434.65   492580.1  -570342.0  -570255.803   86.447   
   7500     13638.73   238.9439    0.0192    238.2456    0.0192     0.0341      0.0     5069620.1628 79488159.5756 246980.53  492965.67  -570232.0  -570145.73   86.453   
   8000     14526.41   238.7997    0.0192    237.9863    0.0191     0.0267      0.0     4909178.1908 79518632.2542 246485.59  492172.39  -570297.0  -570210.44   86.447   
   8500     15413.94   238.5056    0.0192    237.714     0.0191     0.0301      0.0     4728473.6501 79304107.2937 246685.03  492702.05  -570317.0  -570230.567   86.448   
   9000     16301.39   238.1556    0.0191    237.4341    0.0191     0.0359      0.0     5324561.8273 79380311.3483 246803.11  492382.25  -570342.0  -570255.786   86.452   
   9500     17188.05   237.936     0.0191    237.1321    0.0191     0.0323      0.0     4804621.0417 79410272.1255 246421.61  492360.13  -570318.0  -570231.695   86.445   
  10000     18074.2    237.6983    0.0191    236.9242    0.019      0.0302      0.0     4668741.4812 79449796.9483 246435.01  492347.85  -570251.0  -570164.888   86.455   
Using  1  of training data 
Using  1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.35    9982.8804    0.9981   9980.1473    0.9981     3.1623     4.4274   6306938.5604 77847513.7909 287823.14  1151292.55 -1151300.0 -1151292.546   7.684    
    10       317.48   9973.4891    0.9971   9970.6327    0.9971     3.1623     4.4274   26109701.7449 61877007.0958 287823.14  1151292.55 -1151300.0 -1151292.546   7.863    
    25       647.9    9954.2584    0.9952   9951.2888    0.9952     3.1623     4.4274   66339972.6247 38147211.6132 287823.14  1151292.55 -1151301.0 -1151292.546   8.183    
   500      1634.37   4379.4653    0.4261   4372.2908    0.4257     1.9115      0.0     1782757510.3137 66907026.2448 287823.14  1151292.55 -1151374.0 -1151292.546   81.207   
   1000     2671.65    463.8497    0.0359    459.0858    0.0357     0.3653      0.0     127930493.9754 155033168.7333 264987.08  1062326.03 -1145603.0 -1145517.38   85.749   
   1500     3708.44    258.1164    0.0207    257.3917    0.0206     0.1181      0.0     27267685.8284 158745273.804 249512.25  996481.94  -1141260.0 -1141173.836   86.205   
   2000     4744.93    240.6365    0.0194    240.4369    0.0193     0.0414      0.0     12487014.057 158786263.051 247114.77  985700.75  -1140647.0 -1140561.156   86.304   
   2500     5781.82    239.1395    0.0192    238.9419    0.0192     0.034       0.0     10718749.9215 158828753.5967  246805.7  984543.99  -1140515.0 -1140429.182   86.313   
   3000      6821.6    238.8939    0.0192    238.6316    0.0192     0.028       0.0     10236089.9554 158549073.0618 247012.35  984419.96  -1140596.0 -1140510.027   86.316   
   3500     7860.25    238.4971    0.0192    238.3303    0.0191     0.0339      0.0     10504421.5976 158879861.5457  246929.9  984811.68  -1140539.0 -1140452.473   86.314   
   4000     8898.64    238.2507    0.0192    238.1188    0.0191     0.0392      0.0     10166284.3638 159042551.8193 246509.82  983533.83  -1140376.0 -1140290.049   86.337   
   4500      9935.8    238.1233    0.0192    237.8656    0.0191     0.0327      0.0     9656780.8357 158972180.2272 246447.84  984746.89  -1140482.0 -1140395.644   86.335   
   5000     10974.06   237.8411    0.0191    237.6027    0.0191     0.0305      0.0     10296814.1372 158643538.4027 246673.94  984481.57  -1140605.0 -1140518.928   86.327   
   5500     12011.65   237.6735    0.0191    237.4173    0.0191     0.0319      0.0     9508057.9983 158834332.6962  246470.7  983642.12  -1140414.0 -1140328.021   86.326   
   6000     13049.91   237.3535    0.0191    237.1928    0.0191     0.0257      0.0     9479453.5139 158857719.0316  246851.1  984026.36  -1140403.0 -1140316.815   86.333   
   6500     14085.84   237.2535    0.0191    236.979     0.019      0.0345      0.0     10332797.6481 158952470.5221 246547.61   983713.0  -1140488.0 -1140401.347   86.311   
   7000     15125.43   237.0907    0.0191    236.7138    0.019       0.03       0.0     10202969.1232 159093226.0432 246759.56  983961.27  -1140476.0 -1140389.85    86.3    
   7500     16161.18   236.9688    0.0191    236.5237    0.019      0.0427      0.0     10378201.934 158772385.6288 246668.22  983840.27  -1140470.0 -1140383.909   86.307   
   8000     17195.74   236.6838    0.019     236.2704    0.019      0.0273      0.0     9808265.7145 159015778.9258 246584.61   984308.8  -1140466.0 -1140379.746   86.307   
   8500     18233.37   236.3752    0.019     236.0173    0.019      0.0349      0.0     10368594.6343 158893601.7109 246385.58  983624.79  -1140394.0 -1140307.827   86.309   
   9000     19270.39   236.369     0.019     235.8526    0.0189     0.0327      0.0     9447451.2957 158683224.705 246328.53  983550.98  -1140422.0 -1140335.759   86.308   
   9500     20307.94   236.1123    0.019     235.6202    0.0189     0.0376      0.0     9907810.9927 158833502.0394 246190.21  982394.46  -1140373.0 -1140286.713   86.308   
  10000     21342.66   235.7488    0.019     235.3516    0.0189     0.0359      0.0     9264266.7657 158956091.3328  246636.9  983270.76  -1140387.0 -1140300.785   86.322   
