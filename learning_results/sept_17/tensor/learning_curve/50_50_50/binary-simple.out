Generating synthetic binary valued data ... 
Generating synthetic  binary valued data took:  17.983976364135742
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
0.7319016327 0.7379701891   0.13392      0.13615      24593.08     97734.26  
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.23      1.4087     0.4961     1.4213     0.505      3.1623     1.2156     0.2318     0.1212    18377.83    742.99    -4719.0    -4711.07    8.362      0.0044  
    10       88.39      1.4146     0.5002     1.3054     0.426      3.1623     1.7855     2.4026     0.9449    18404.05    662.56    -4323.0   -4314.236    8.337       0.0    
    25       196.07     1.4152     0.5007     1.077       0.29      3.1623     2.5108     5.5307     2.1103    18597.5     576.91    -4025.0   -4017.013    8.258       0.0    
   500       480.89     1.4168     0.5018     0.3847     0.037      2.4402     2.5728    561.5672    2.2274   130616.79    293.85    -2053.0   -2027.014    25.853      0.0    
   1000      819.82     1.4121     0.4985     0.395      0.039      1.9056     6.1255   1767.4455    2.5603   193611.11    478.24    -1847.0    -1813.88    32.652      0.0    
   1500     1151.87     1.4093     0.4966     0.4243     0.045      1.5647     6.3086   3235.1116    2.4341   216753.73    513.14    -1810.0    -1774.37    35.835      0.0    
   2000     1480.66     1.4107     0.4975     0.4147     0.043      1.3843     5.7716   4836.5597    0.579    230038.57    448.73    -1835.0   -1798.288    37.054      0.0    
   2500     1806.17     1.411      0.4978     0.4147     0.043      1.226      10.364   6519.1177    1.9598   235954.43    484.42    -1809.0   -1771.083    37.87       0.0    
   3000     2131.62     1.4107     0.4975     0.4147     0.043      1.1352    11.0189   8274.8559    5.0698   243473.59    480.34    -1808.0   -1769.244    38.461      0.0    
   3500     2456.77     1.4116     0.4982     0.429      0.046      1.0481     1.8326   10054.2168   0.0091   245929.68    581.87    -1796.0   -1756.811    38.908      0.0    
   4000     2782.72     1.4118     0.4983     0.429      0.046      0.9693     1.823    11866.6577   0.0064   249646.22    550.12    -1747.0   -1707.597    39.259      0.0    
   4500     3107.56     1.4132     0.4993     0.4147     0.043      0.9199     1.8146   13712.211    0.0056   251924.72    483.44    -1757.0   -1717.304    39.548      0.0    
   5000     3429.31     1.4121     0.4985      0.4        0.04      0.8882    11.2099   15568.9412   0.0912    256082.8    483.91    -1804.0   -1764.701    39.788      0.0    
   5500     3749.61     1.4092     0.4965     0.4195     0.044      0.8308     1.8005   17439.5775   0.0044   256551.46    479.48    -1799.0   -1759.175    39.987      0.0    
   6000     4075.27     1.4103     0.4972     0.4195     0.044      0.7808     1.7945   19335.0553   0.0049   258660.17    546.44    -1782.0    -1741.75    40.161      0.0    
   6500     4400.57     1.4113     0.498      0.395      0.039      0.7545     1.789    21238.0791   0.0036   260351.03    482.12    -1752.0   -1711.867    40.311      0.0    
   7000     4723.41     1.4108     0.4976     0.4099     0.042      0.7155     1.7839   23142.0505   0.0033   262189.51    513.48    -1811.0   -1770.227    40.443      0.0    
   7500     5042.76     1.4105     0.4974     0.4147     0.043      0.702      1.7792   25047.9589   0.0031    260421.8    514.58    -1732.0   -1691.018    40.559      0.0    
   8000     5368.35     1.4097     0.4968     0.405      0.041      0.6979     1.7749   26984.5807   0.0028   263793.33    481.72    -1732.0   -1691.018    40.662      0.0    
   8500     5688.27      1.41      0.497      0.4099     0.042      0.6596     1.7708   28929.2459   0.0027   264359.27    480.71    -1785.0   -1744.439    40.76       0.0    
   9000     6010.34     1.4087     0.4961     0.4099     0.042      0.628      1.767    30850.8842   0.0025   264269.38    510.15    -1737.0   -1696.545    40.844      0.0    
   9500     6332.57     1.4093     0.4965     0.4099     0.042      0.6243     1.7634   32801.672    0.0023   265893.84    450.86    -1778.0    -1737.07    40.924      0.0    
  10000     6656.36     1.4097     0.4968     0.405      0.041      0.6029      1.76    34769.9813   0.0022   265411.51    449.71    -1743.0   -1702.071    40.994      0.0    
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         0.48      1.4056     0.4939     1.3964     0.4875     3.1623     2.0897   34272.2355   0.1609    18573.13   1464.13    -9780.0   -9770.932     9.2       0.0043  
    10       94.44      1.4101     0.4971     1.3038     0.425      3.1623     2.0897   26972.4176   1.283     18804.35   1368.27    -9053.0   -9043.683    9.211       0.0    
    25       210.99      1.42      0.5041     1.1764     0.346      3.1623     2.0897   16870.5291   3.0042    19348.64   1209.44    -8051.0   -8041.794    9.139       0.0    
   500       643.15     1.4129     0.499      0.6899     0.119      2.4346     1.0014    783.5805    7.5629   231887.33   2982.02    -9137.0   -9103.679    33.415      0.0    
   1000     1117.21     1.4144     0.5001     0.7014     0.123      1.8977     1.6813   2508.1265   12.0867   302745.52   4592.36    -9241.0   -9197.976    42.848      0.0    
   1500     1581.12     1.412      0.4984      0.7       0.1225     1.5704     1.8296   4626.6376   14.6119   326604.93   4934.01    -9039.0   -8992.284    47.151      0.0    
   2000     2042.28     1.411      0.4977     0.6928      0.12      1.395      3.7343   6950.6739   16.0119   337631.81   5514.73    -8971.0   -8921.525    49.761      0.0    
   2500     2499.19     1.4097     0.4968     0.6885     0.1185     1.2556     4.9521   9416.2609   11.7642    343433.0    5460.5    -8971.0   -8920.422    50.52       0.0    
   3000     2956.51      1.41      0.497      0.6928      0.12      1.1248     3.5916   11972.708   22.7224   348633.54   5700.74    -8913.0   -8862.122    51.067      0.0    
   3500     3410.81     1.4075     0.4952     0.6943     0.1205     1.0626     2.8117   14583.6712  10.3362   350479.78    5842.2    -9005.0   -8952.884    52.106      0.0    
   4000     3863.88     1.4062     0.4944     0.6885     0.1185     0.9679     1.352    17253.8154   4.8094   351973.56   5772.37    -8973.0   -8919.875    52.953      0.0    
   4500     4318.14     1.4039     0.4927     0.687      0.118      0.9473     6.9325   19955.9413   5.6849   354573.92   5742.37    -8862.0   -8809.278    53.213      0.0    
   5000      4775.4     1.4031     0.4922     0.687      0.118      0.8759     5.8176   22715.457   22.2335    353348.6   5942.34    -8816.0   -8762.873    53.425      0.0    
   5500     5229.79     1.4012     0.4908     0.6943     0.1205     0.852      6.0416   25506.3806  10.3422    353593.0   5911.44    -8892.0   -8838.022    53.604      0.0    
   6000     5683.63     1.4012     0.4908     0.6943     0.1205     0.8092     1.9731   28308.6054   1.2639   353294.72   6011.88    -8917.0   -8863.439    53.756      0.0    
   6500     6138.13     1.4005     0.4904     0.6856     0.1175     0.7642     3.5593   31149.3062  19.8907   354602.18   6110.47    -8895.0   -8840.778    53.891      0.0    
   7000     6591.22     1.398      0.4886     0.6899     0.119      0.723      5.1892   34030.3862  14.1556   353899.52   6078.67    -8877.0   -8822.637    54.004      0.0    
   7500     7045.19     1.3993     0.4895     0.6914     0.1195     0.7021     0.7907   36897.4027   0.0482   353158.01   6176.97    -8862.0   -8807.435    54.101      0.0    
   8000     7499.14     1.3973     0.4881     0.6914     0.1195     0.6838     3.5559   39801.729    21.855   352952.11   6115.97    -8810.0   -8755.351    54.188      0.0    
   8500     7951.89     1.3947     0.4863     0.6885     0.1185     0.6513     3.5689   42693.7393  19.2223   352298.84   6187.71    -8806.0   -8751.665    54.262      0.0    
   9000     8407.61     1.3949     0.4864     0.6899     0.119      0.6358     4.3986   45650.6051   0.3238   353081.02   6080.16    -8881.0   -8827.118    54.325      0.0    
   9500     8858.56     1.3926     0.4848     0.6856     0.1175     0.629      0.7869   48575.0156   0.0069   351517.05   6158.65    -8823.0   -8768.427    54.382      0.0    
  10000     9309.24     1.3909     0.4837     0.687      0.118      0.6102     0.7861    51539.31    0.0022   352074.25   6120.95    -8877.0   -8822.234    54.429      0.0    
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.22      1.412      0.4984     1.4168     0.5018     3.1623     2.9971   50540.219    0.2672    18586.34   3736.07    -24015.0  -24006.182   8.765      0.0043  
    10       116.2      1.4088     0.4962     1.3647     0.4656     3.1623     2.9971   40254.7399   2.4648    18944.98   3547.15    -20885.0  -20875.82    8.919       0.0    
    25       261.97     1.4125     0.4988     1.2532     0.3926     3.1623     2.9971   24755.6057   5.8491    19871.61   3320.28    -17252.0  -17243.319   9.022       0.0    
   500      1148.06     0.928      0.2153     0.6375     0.1016     2.3895     0.0722    706.2319   110.2779  161269.99   13472.07   -17977.0  -17923.757   53.441      0.0    
   1000     2091.05     0.9107     0.2074     0.6412     0.1028     1.945      0.0499   2463.9646    212.39   175749.82   16882.35   -18948.0  -18880.779   67.064      0.0    
   1500     3018.69     0.9068     0.2056     0.6481     0.105      1.7231     0.0669   5010.0023   299.0764  178757.39   17845.75   -19371.0  -19296.078   74.488      0.0    
   2000      3941.7     0.9026     0.2037     0.6554     0.1074     1.4971     0.0757   8181.9568   389.6031  180493.58   18734.88   -19882.0  -19802.508   79.838      0.0    
   2500     4859.23     0.8994     0.2022     0.6663     0.111      1.3823     0.1293   11819.419   471.6862  180483.22   19444.71   -20455.0  -20371.277   83.423      0.0    
   3000     5771.67     0.8954     0.2004     0.6705     0.1124     1.2756     0.1237   15885.2983  570.5786  179976.71   19868.99   -20736.0  -20648.764   86.772      0.0    
   3500     6680.59     0.8918     0.1988     0.6782     0.115      1.1519     0.1852   20221.4917  612.3372  179259.45   20290.72   -21257.0  -21168.094   89.353      0.0    
   4000     7586.87     0.8906     0.1983     0.6864     0.1178     1.1015     0.0857   24852.4357  728.8098  178837.82   20972.48   -21762.0  -21670.429   91.592      0.0    
   4500     8488.59     0.888      0.1971     0.6917     0.1196     1.0391     0.2137   29738.5845  898.3484  178092.73   21476.2    -22095.0  -22001.496   93.562      0.0    
   5000     9387.37     0.8863     0.1964     0.6951     0.1208     1.0029     0.1349   34925.6078  975.0948  177854.03   21670.94   -22370.0  -22274.745   95.575      0.0    
   5500     10285.81    0.885      0.1958     0.7009     0.1228     0.9727     0.0931   40100.8725  952.369   177443.79   22152.02   -22763.0  -22665.815   97.494      0.0    
   6000     11182.12    0.8825     0.1947     0.7071     0.125      0.9018     0.2112   45556.1312 1078.1885   177257.4   22612.55   -23128.0  -23029.019   99.084      0.0    
   6500     12076.15    0.882      0.1945     0.7127     0.127      1.0223     0.1416   51370.1942  993.2126  177058.55   22945.17   -23452.0  -23352.092   99.801      0.0    
   7000     12970.38    0.8811     0.1941     0.7139     0.1274     0.8534     0.0875   57455.7133 1055.4093  176971.78   23056.5    -23571.0  -23470.532  100.432      0.0    
   7500     13862.31    0.8805     0.1938     0.7189     0.1292     0.8052     0.0908   63578.3226 1162.1077  176233.34   23451.98   -23863.0  -23761.504  101.257      0.0    
   8000     14753.72    0.8791     0.1932     0.7228     0.1306     0.8467     0.1067   70070.5771 1342.6984  175737.74   23713.87   -24145.0  -24042.673  102.491      0.0    
   8500     15643.9     0.8784     0.1929     0.7233     0.1308     0.8197     0.2852   76660.4626 1639.6177   175967.9   23817.22   -24194.0  -24090.702  103.288      0.0    
   9000     16531.39    0.8787     0.193      0.7277     0.1324     0.7697     0.4145   83340.0004 1464.0384  175930.65   23940.37   -24443.0  -24339.246  104.018      0.0    
   9500     17418.39    0.8778     0.1926     0.7272     0.1322     0.742      0.1005   90291.1155 1190.3454  175733.83   24150.05   -24530.0  -24425.823  104.507      0.0    
  10000     18303.43    0.8771     0.1923     0.731      0.1336     0.7623     0.1521   97172.0346  1644.337  175697.72   24264.33   -24728.0  -24622.392  105.194      0.0    
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.54      1.4181     0.5028     1.411      0.4977     3.1623     3.5936   95512.5691 1594.6372   18762.67   7502.04    -50617.0  -50599.995   16.687     0.0054  
    10       141.64     1.4208     0.5046     1.3788     0.4753     3.1623     3.5936   76193.369  1155.8948   19433.34    7441.1    -43622.0  -43604.237   17.464      0.0    
    25       318.56     1.4172     0.5021     1.3262     0.4397     3.1623     3.5936   47627.7738  633.2807   21180.46   7486.91    -35541.0  -35522.033   18.604      0.0    
   500      1440.84     0.9147     0.2092     0.6375     0.1016     1.2618     0.0503    19.8406    65.3321    13821.18   2303.23    -4045.0   -4014.711    30.384      0.0    
   1000     2671.96     0.9236     0.2133     0.6125     0.0938     2.4386     0.0367    106.3867   142.9922   68271.26   5328.35    -13648.0  -13607.827   39.791      0.0    
   1500     3902.71     0.8984     0.2018     0.6096     0.0929     2.2819     0.0513    950.7486   350.5159  152493.35   24486.29   -32558.0  -32498.885   59.088      0.0    
   2000     5120.55     0.8888     0.1975     0.6261     0.098      1.9726     0.0371   2368.7579   505.7565   164725.2   30090.93   -35618.0  -35547.395   70.697      0.0    
   2500     6325.01     0.8877     0.197      0.6197     0.096      1.7913     0.0343   3927.4183   636.8605  169956.63   31660.25   -35296.0  -35218.464   78.024      0.0    
   3000     7515.99     0.8851     0.1958     0.6264     0.0981     1.4884     0.0245   5598.9887   765.1396  172242.95   32945.96   -35963.0  -35879.695   83.448      0.0    
   3500     8699.99     0.8806     0.1939     0.6302     0.0993     1.4601     0.0245   7537.4784   882.3854  172556.32   33960.73   -36664.0  -36576.829   87.67       0.0    
   4000     9879.17     0.8811     0.1941     0.6328     0.1001     1.3517     0.0202   9498.6533  1030.9352  173451.97   34900.86   -36851.0  -36759.452   91.053      0.0    
   4500     11043.32    0.8798     0.1935     0.6422     0.1031     1.3912     0.0166   11636.8821 1144.2027  173579.79   36039.42   -37869.0  -37774.809   94.197      0.0    
   5000     12194.6     0.8769     0.1922     0.6425     0.1032     1.3933     0.0171   14178.2111 1244.0466  173223.99   36571.41   -38060.0  -37963.608   96.733      0.0    
   5500     13335.76    0.8743     0.1911     0.6524     0.1064     1.2468     0.0147   16770.7531 1387.4804  172299.03   37496.37   -39080.0  -38981.307   98.86       0.0    
   6000     14468.69    0.8736     0.1908     0.6536     0.1068     1.2156     0.0112   19273.8386 1510.7963  172120.67   37922.64   -39279.0  -39177.941  100.769      0.0    
   6500     15593.65    0.8721     0.1902     0.6539     0.1069     1.0459     0.0086    21638.52  1715.7863  172520.37   38250.87   -39514.0  -39411.759  102.668      0.0    
   7000     16713.78    0.8715     0.1899     0.6609     0.1092     1.042      0.0129   25043.5592 1617.7879  172007.11   38828.88   -40171.0  -40067.039  104.278      0.0    
   7500     17829.68    0.8695     0.189      0.6615     0.1094     1.2392     0.0142   28284.083  1870.3854  170912.59   39325.99   -40532.0  -40426.32   105.414      0.0    
   8000     18942.29    0.8644     0.1868     0.6696     0.1121     1.0278     0.0148   31732.9588 2023.4947  169918.62   40357.14   -41274.0  -41166.837  106.784      0.0    
   8500     20052.04    0.8643     0.1868     0.675      0.1139     1.0215     0.0141   35597.8753 2209.1649   169668.6   41058.52   -42067.0  -41959.234  108.026      0.0    
   9000     21162.0     0.8617     0.1856      0.68      0.1156     1.0196     0.0122   39084.2617  2298.119  169285.56   41832.53   -42683.0  -42573.827  109.263      0.0    
   9500     22271.74    0.8621     0.1858     0.6859     0.1176     0.959      0.014    43671.8771  2431.762  169088.48   42392.14   -43316.0  -43205.356   110.32      0.0    
  10000     23383.74    0.8598     0.1848     0.6917     0.1196     1.073      0.0129   48869.9702 2509.4355  168426.85   43262.44   -44103.0   -43991.4    111.45      0.0    
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.55      1.4149     0.5005     1.4204     0.5044     3.1623      3.97    47823.7875 2423.2251   18606.67   14925.53   -97789.0  -97778.632   10.151     0.0116  
    10       186.92     1.4108     0.4976     1.3924     0.4847     3.1623      3.97    38518.8397 1913.5755   19539.98   15181.58   -83346.0  -83335.907   10.494      0.0    
    25       418.35     1.4144     0.5001     1.378      0.4748     3.1623      3.97    23989.4933 1191.0885   21829.88   16303.26   -65887.0  -65875.396   11.176      0.0    
   500      1617.16     0.8593     0.1846     0.7836     0.1535     1.3115     0.0447    27.6595    90.1073    10121.62   6733.25    -9094.0   -9069.802    24.171      0.0    
   1000      2976.0     0.8631     0.1862     0.7393     0.1366     1.2203     0.0234    30.6917    101.6691   10178.45    6217.0    -8693.0   -8671.729    20.845      0.0    
   1500     4336.94     0.8546     0.1826     0.7133     0.1272     1.1324     0.0162    31.0883    103.5565   10564.52   5859.48    -8436.0   -8414.186    21.616      0.0    
   2000     5696.54     0.8565     0.1834     0.6944     0.1206     0.9749     0.0128     31.227    105.5355   10683.36   5518.05    -8148.0   -8126.155    22.134      0.0    
   2500     7056.66     0.8596     0.1847     0.6854     0.1174     1.1206     0.0105    32.9801    109.9211   11137.22   5375.07    -8056.0   -8033.587    22.315      0.0    
   3000     8417.47     0.8663     0.1876     0.666      0.1109     0.9849     0.009     33.1368    117.2561   11739.05   5122.38    -7852.0   -7829.255    23.224      0.0    
   3500     9780.31     0.8615     0.1856     0.6699     0.1122     0.9234      0.01     36.4296    123.394    12505.82   5135.55    -8035.0    -8012.03    22.575      0.0    
   4000     11140.23    0.866      0.1875     0.6642     0.1103     1.2044     0.0097     41.596    131.8707   13364.4    5117.78    -8164.0   -8138.902    25.386      0.0    
   4500     12494.17    0.8763     0.192      0.6728     0.1132     1.3352     0.0095    47.1155    146.4853   14508.11   5143.96    -8398.0   -8372.697    25.589      0.0    
   5000     13856.87    0.8785     0.193      0.6765     0.1144     1.6583     0.0093    57.2661    164.8023   16347.22    5386.2    -8973.0   -8945.055    27.697      0.0    
   5500     15212.3     0.8933     0.1995     0.6922     0.1198     1.3149     0.0102    77.4736    195.802    19617.97   5729.48    -10202.0  -10172.317   29.743      0.0    
   6000     16563.65    0.8887     0.1974     0.7294     0.133      1.8019     0.0151    198.0209   368.503    35316.63   12111.66   -22447.0  -22412.071   35.161      0.0    
   6500     17915.35    0.8633     0.1863     0.729      0.1328     2.1254     0.0197    799.0398  1021.4845   93779.69   43423.87   -67786.0  -67735.161   50.369      0.0    
   7000     19262.28    0.8447     0.1784     0.7258     0.1317     2.1935     0.0279    1955.616  1350.7045  134593.15   72691.7    -91393.0  -91329.995   63.34       0.0    
   7500     20600.45    0.8403     0.1765     0.7199     0.1296     2.1729     0.0374   3536.7075  1493.1649  144267.67   80464.82   -93680.0  -93608.035   71.551      0.0    
   8000     21920.9     0.8394     0.1762     0.7212      0.13      1.6974     0.038    5517.3214  1640.0014  149412.67   85057.16   -94943.0  -94865.799   76.993      0.0    
   8500     23226.79    0.8376     0.1754     0.7258     0.1317     1.5986     0.0421   7474.2995  1756.1199  151844.78   90153.08   -96713.0  -96631.84    81.354      0.0    
   9000     24520.62    0.8366     0.175      0.7218     0.1302     1.431      0.041    9364.3099  1974.3661  153039.38   89509.41   -95316.0  -95230.845   85.035      0.0    
   9500     25803.7     0.8344     0.174      0.723      0.1307     1.852      0.0344   11888.9286 2135.0046  155053.67   90957.82   -96061.0  -95973.232   88.034      0.0    
  10000     27076.01    0.8366     0.175      0.7201     0.1296     1.3061     0.0284   13723.5611 2271.2812  155492.13   90616.91   -95302.0  -95211.587   90.806      0.0    
Using  0.5  of training data 
Using  0.5 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.55      1.4177     0.5024     1.4129     0.4991     3.1623     4.2579   13440.8433 2211.5612   18550.15   37073.67  -233979.0  -233963.909   14.636     0.028   
    10       319.33     1.413      0.4991     1.409      0.4963     3.1623     4.2579   10962.086  1707.1264   19415.57   38625.55  -196339.0  -196323.886   15.611      0.0    
    25       714.25     1.4157     0.501      1.3986     0.489      3.1623     4.2579    6920.356  1023.9112   22469.58   44012.51  -154479.0  -154461.571   17.426      0.0    
   500      2116.16     0.861      0.1853     0.8355     0.1745     1.1774     0.0315    64.1916    182.7784   9799.96    18660.32   -22861.0  -22828.141   33.074      0.0    
   1000     3742.83     0.8439     0.178      0.8078     0.1631     1.1857     0.0187    63.2799    193.2002    9522.4    17866.46   -22214.0  -22187.708   26.746      0.0    
   1500     5371.49     0.8394     0.1762     0.7959     0.1584     1.2581     0.013      71.641    204.291    9481.74    17450.65   -21968.0  -21944.955    22.6       0.0    
   2000     7006.47     0.8232     0.1694     0.7806     0.1523     1.0839     0.0102    64.8932    200.4043   9333.68    16847.55   -21383.0  -21357.861   25.488      0.0    
   2500      8644.5     0.8251     0.1702     0.7717     0.1489     1.0157     0.008     67.2909    207.3135   9351.72    16596.66   -21173.0  -21150.048   23.119      0.0    
   3000     10294.25    0.8276     0.1712     0.769      0.1478     1.0797     0.0074    71.8035    210.3091   9365.34    16409.62   -21013.0  -20988.489   24.219      0.0    
   3500     11937.2     0.8145     0.1658     0.7617     0.1451     0.9523     0.0062    66.6338    206.3061   9271.54    16275.46   -20799.0  -20774.74    24.153      0.0    
   4000     13577.2     0.8179     0.1672     0.757      0.1433     0.8135     0.0073    66.7066    208.4974   9275.89    16096.92   -20647.0  -20623.134   23.491      0.0    
   4500     15218.6     0.8207     0.1684     0.7611     0.1448     0.8871     0.0045    69.2997    207.9976   9351.67    16033.23   -20596.0  -20571.517   24.102      0.0    
   5000     16863.86    0.8206     0.1684     0.7514     0.1411     0.7285     0.0046    65.5111    215.6446   9255.11    15845.78   -20369.0  -20344.421   24.088      0.0    
   5500     18506.4     0.8123     0.165      0.7482      0.14      0.7188     0.0049    66.7115    211.7106   9202.53    15723.0    -20243.0  -20218.644   24.831      0.0    
   6000     20153.64    0.8214     0.1687     0.7511     0.141      0.6567     0.0041    67.1339    208.8518   9323.46    15716.38   -20232.0  -20208.433   23.604      0.0    
   6500     21796.43    0.8163     0.1666     0.7474     0.1396     0.621      0.0034    70.5952    206.7517   9242.91    15655.64   -20181.0  -20156.862   24.007      0.0    
   7000     23436.17    0.8158     0.1664     0.7512     0.1411     0.673      0.0033    69.1425    209.387    9234.22    15593.14   -20036.0  -20011.588   24.422      0.0    
   7500     25073.16    0.8202     0.1682     0.7455     0.139      0.5508     0.0032    68.0121    209.3364   9294.71    15524.72   -20010.0  -19986.657   23.52       0.0    
   8000     26708.4     0.8182     0.1674     0.7432     0.1381     0.6857     0.0035    71.1235    217.2703   9252.71    15451.02   -19990.0  -19966.084   24.212      0.0    
   8500     28340.16    0.8159     0.1664     0.7432     0.1381     0.5569     0.0031    68.5566    206.4181   9277.41    15461.82   -19964.0  -19939.312   25.096      0.0    
   9000     29969.88    0.8091     0.1637     0.747      0.1395     0.5333     0.0026     71.067    206.2857   9221.91    15436.39   -19890.0  -19866.009   24.342      0.0    
   9500     31602.39    0.8097     0.1639     0.7426     0.1379     0.5386     0.0028    65.5702    213.6498   9278.93    15397.55   -19833.0  -19808.514   24.726      0.0    
  10000     33231.62    0.8144     0.1658     0.7441     0.1384     0.6565     0.0026    70.9652    212.2596   9278.09    15386.46   -19848.0  -19822.333   25.36       0.0    
Using  1  of training data 
Using  1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     |   dw   |
    0         1.54      1.4116     0.4981     1.4151     0.5007     3.1623     4.3585    77.2308    210.7714   18592.18   74368.04  -482269.0  -482257.374   11.228     0.0505  
    10       540.37     1.4127     0.4989     1.406      0.4942     3.1623     4.3594    157.5156   200.6032   19703.43   78480.14  -415306.0  -415294.34   11.691      0.0    
    25      1202.48     1.4086     0.496      1.3974     0.4882     3.1623     4.3594    273.3888   189.4118   23614.49   93100.06  -328304.0  -328291.1    12.73      0.0001  
   500      2933.78     0.859      0.1845     0.8502     0.1807     1.1936     0.0231    113.0979    394.07    9727.17    38141.78   -43990.0  -43943.134   46.521      0.0    
   1000     5015.64     0.8359     0.1747     0.8253     0.1703     1.0943     0.0163    108.6958   400.7479   9404.05    36572.7    -42394.0  -42357.929   36.114      0.0    
   1500     7113.52     0.826      0.1706     0.8106     0.1642     0.8551     0.0121    117.8989   424.7018   9258.78    35804.16   -41798.0  -41762.336   35.25       0.0    
   2000     9200.07     0.8169     0.1668     0.7964     0.1586     0.7445     0.009     120.1413   418.0321   9129.24    34999.26   -41137.0  -41101.553   35.61       0.0    
   2500     11277.25    0.8133     0.1654     0.7939     0.1576     0.9494     0.008     131.8064   435.1321   9118.92    34794.21   -41046.0  -41010.287   35.252      0.0    
   3000     13351.21    0.8115     0.1646     0.7881     0.1553     0.6969     0.0067    129.8215   432.4184   9094.92    34257.47   -40582.0  -40547.24    35.221      0.0    
   3500     15424.82    0.8039     0.1616     0.7838     0.1536     0.7259     0.0054    129.2526   426.1669   9021.37    34140.35   -40364.0  -40325.91    37.965      0.0    
   4000     17492.56    0.8111     0.1645     0.7823     0.153      0.9267     0.0049    134.443    443.9078   9024.02    33968.84   -40327.0  -40291.117   35.907      0.0    
   4500     19565.09    0.8038     0.1615     0.7762     0.1506     0.8676     0.0043    127.1209   444.6885   8947.67    33652.97   -39933.0  -39899.752   33.569      0.0    
   5000     21636.07    0.8028     0.1611     0.7774     0.1511     0.654      0.0044    139.854    438.4573   8976.95    33491.72   -39746.0  -39711.353   34.339      0.0    
   5500     23701.76    0.8018     0.1607     0.7772     0.151      0.7655     0.0039    124.0557   422.2502   8960.03    33384.73   -39640.0  -39606.344   33.414      0.0    
   6000     25768.68    0.8035     0.1614     0.7728     0.1493     0.8052     0.0037    130.8029   426.0748   8936.34    33337.4    -39629.0  -39595.464   33.577      0.0    
   6500     27840.06    0.8007     0.1603     0.7713     0.1487     0.7721     0.0037    127.0177   414.3025   8867.39    33123.41   -39390.0  -39355.519   34.575      0.0    
   7000     29913.26    0.8047     0.1619     0.7735     0.1496     0.8447     0.0034    131.0185   407.5399   8944.97    33168.15   -39410.0  -39375.445   34.606      0.0    
   7500     31987.12    0.8067     0.1627     0.7715     0.1488     0.7009     0.0029    132.6719   412.0253   8927.19    33125.64   -39382.0  -39348.122   33.551      0.0    
   8000     34062.18    0.8009     0.1604     0.7729     0.1494     0.6605     0.003     124.3724   405.7784   8903.61    33044.93   -39312.0  -39276.089   35.713      0.0    
   8500     36132.15    0.8073     0.1629     0.7727     0.1493     0.5212     0.0025    123.6084   399.9477   8898.59    33081.99   -39306.0  -39272.827   33.644      0.0    
   9000     38203.7     0.8023     0.1609     0.7676     0.1473     0.6534     0.0027    135.4889   400.9347   8887.34    32914.66   -39136.0  -39102.559   33.058      0.0    
   9500     40274.32    0.8019     0.1608     0.7693     0.148      0.4558     0.0023    127.5435   409.7605   8884.96    32847.28   -39073.0  -39038.073   34.737      0.0    
  10000     42351.97    0.8041     0.1616     0.7684     0.1476     0.5684     0.0031    129.1005   394.9283   8910.31    32778.09   -38982.0  -38948.72    33.385      0.0    
