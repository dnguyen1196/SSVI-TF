Generating synthetic binary valued data ... 
Generating synthetic  binary valued data took:  18.15574550628662
Evaluation for true params: 
 test_rsme | train_rsme | rel-te-err | rel-tr-err |  test_nll  |  train_nll |
0.7319016327 0.7379701891   0.13392      0.13615      24593.08     97734.26  
Using  0.01  of training data 
Using  0.01 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         0.27      1.4129     0.499      1.3372     0.447      3.1623     1.2047     0.373      0.1214    18611.94    714.75    -4714.0   -4700.152    14.23    
    10       40.38      1.4091     0.4964     1.2083     0.365      3.1623     1.8177     3.4868     0.9432    18456.45    656.55    -4300.0   -4286.011    14.255   
    25       91.27      1.4108     0.4976     0.9798      0.24      3.1623     2.417      7.9052     2.1274    18401.8     574.63    -3685.0   -3670.835    14.195   
   500       349.75     1.3494     0.4552      0.0        0.0       1.4812     0.7396     5.3812     1.9905    24641.9     46.17      -940.0    -921.002    18.559   
   1000      642.47     1.2832     0.4117      0.0        0.0       1.2495     0.5391     5.3198     1.6548    26978.74    27.15      -724.0    -706.195    18.152   
   1500      932.6      1.2276     0.3767      0.0        0.0       1.392      0.6157     6.2857     1.5999    28472.97    22.34      -686.0    -668.901    17.535   
   2000     1221.31     1.1973     0.3584      0.0        0.0       1.1409     0.5911     6.5638     1.5803    31396.89    19.93      -648.0    -631.235    16.638   
   2500     1507.28     1.171      0.3428      0.0        0.0       1.1143     0.8787     7.6648     1.7418    34341.79    18.97      -594.0    -577.433    16.439   
   3000     1792.81     1.1577     0.3351      0.0        0.0       1.2211     1.2641     8.0484     1.8441    36789.38    17.74      -622.0    -604.973    16.653   
   3500      2079.7     1.1409     0.3254      0.0        0.0       1.2893     0.9522    10.3756     1.8527    39661.34    16.91      -578.0    -560.751    16.79    
   4000     2368.89     1.135      0.3221      0.0        0.0       1.3423     1.7775    11.1719     2.0171    42145.73    15.52      -539.0    -521.324    17.18    
   4500      2653.3     1.1289     0.3186      0.0        0.0       1.055      1.3866    11.8522     1.8456    44978.58    16.04      -563.0    -546.124    17.193   
   5000     2932.66     1.1223     0.3149      0.0        0.0       1.2927     2.3696    13.6358     1.6259    47541.13    16.01      -560.0    -542.995    17.322   
   5500     3212.91     1.1211     0.3142      0.0        0.0       1.2631     2.3173     14.296     1.9849    49374.91    15.87      -598.0    -580.113    17.858   
   6000     3493.74     1.1161     0.3114      0.0        0.0       1.1852     5.0917    15.6339     2.2146    52227.75    15.95      -600.0    -581.822    17.977   
   6500     3774.15     1.1138     0.3102      0.0        0.0       1.2599     2.3723    18.1121     2.0433    54470.48    16.52      -638.0    -620.444    17.848   
   7000     4057.17     1.1084     0.3072      0.0        0.0       1.9001     3.595     19.3514     1.8305    54132.55    17.87      -577.0    -559.074    17.97    
   7500      4340.9     1.1074     0.3066      0.0        0.0       1.2046     4.8765    20.9646     2.7134    56928.28    18.55      -614.0    -595.935    18.098   
   8000     4621.05     1.1041     0.3048      0.0        0.0       1.1679     4.1144    22.5745     1.4768    58805.08    17.36      -614.0    -595.86     18.251   
   8500      4901.5     1.1027     0.304       0.0        0.0       1.276      3.1506    23.4528     1.9428    59125.08    18.35      -636.0    -617.301    18.205   
   9000     5180.74     1.0995     0.3022      0.0        0.0       1.2267     2.7352    26.1382     2.8385    60736.19     18.1      -642.0    -623.367    18.473   
   9500     5460.07     1.1007     0.3029      0.0        0.0       1.1026     6.7536    27.5661     1.6133    63580.91     18.6      -653.0    -634.324    18.507   
  10000     5739.52     1.0973     0.301       0.0        0.0       1.0694    11.9951    30.6893     2.4045    63852.47    18.76      -668.0     -649.3     18.51    
Using  0.02  of training data 
Using  0.02 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         0.57      1.4161     0.5014     1.4121     0.4985     3.1623     2.1154    31.2129     2.5637    18665.19   1469.74    -9727.0   -9709.001    17.555   
    10       45.37      1.4136     0.4996     1.2853     0.413      3.1623     2.1154    29.5291     3.1956    18601.52   1364.61    -8469.0   -8451.472    18.027   
    25       104.32     1.4139     0.4998     1.1349     0.322      3.1623     2.1154    27.4877     4.3683    18604.94   1230.07    -6618.0   -6599.105    18.901   
   500       546.4      1.0443     0.2726      0.0        0.0       1.2312     0.1927     4.8832     8.5469    21096.17    73.55      -701.0    -683.167    17.934   
   1000     1043.19     1.0021     0.251       0.0        0.0       1.3052     0.1212     4.1293     9.0128    26079.37    47.45      -586.0    -567.773    18.379   
   1500     1535.64     0.9911     0.2456      0.0        0.0       1.1589     0.1027     4.3965     9.3219    32098.97    43.38      -629.0    -608.785    20.408   
   2000     2027.22     0.9799      0.24       0.0        0.0       1.3017     0.0915     5.1614     9.4806    38252.76    37.28      -695.0    -672.33     22.412   
   2500     2517.88     0.977      0.2386      0.0        0.0       1.0095     0.0985     5.8256     9.7461    42901.91    35.02      -745.0     -720.7     24.532   
   3000      3002.6     0.9766     0.2384      0.0        0.0       1.2335     0.0971     6.653      10.073    49923.15    33.83      -823.0    -795.835    27.138   
   3500     3486.21     0.9769     0.2386      0.0        0.0       1.1972     0.0877     7.6207    10.2355    56483.18    33.74      -773.0    -743.226    29.926   
   4000     3970.88     0.9769     0.2386      0.0        0.0       1.1041     0.0996     8.4728    10.5726    62834.42    31.52      -849.0    -815.477    33.243   
   4500     4452.84     0.9795     0.2398      0.0        0.0       1.1286     0.1225    10.0338     11.289    65967.88    32.27      -868.0    -832.513    35.39    
   5000     4934.05     0.9761     0.2382      0.0        0.0       0.9728     0.1387     9.8796    11.7299    72483.75    30.17      -859.0    -822.18     37.256   
   5500      5416.6     0.9769     0.2386      0.0        0.0       1.0885     0.1318    10.8525     11.713    76606.68    29.41      -832.0    -792.458    39.099   
   6000     5900.72     0.9792     0.2397      0.0        0.0       1.1188     0.2039    11.3669    12.3304    81375.89    28.67      -888.0     -848.1     40.294   
   6500      6384.3     0.9809     0.2405      0.0        0.0       1.197      0.2206    12.7345    12.8899    84470.62    28.31      -928.0    -886.562    41.69    
   7000     6866.13     0.9801     0.2402      0.0        0.0       1.086      0.1958    15.2795    12.7042    86712.83    28.35      -895.0    -852.093    42.826   
   7500     7347.16     0.9822     0.2412      0.0        0.0       1.1687     0.3337    15.4143    13.3116    89682.95    25.82      -969.0    -924.487    44.155   
   8000     7827.88     0.9833     0.2417      0.0        0.0       0.9091     0.1356     15.208    13.6326    91811.93    25.55      -900.0    -855.196    45.068   
   8500     8311.43     0.9861     0.2431      0.0        0.0       0.9709     0.3396     17.275    14.7684    94504.12    26.29      -915.0    -869.371    46.068   
   9000     8790.75     0.9878     0.2439      0.0        0.0       1.1047     0.4275    16.7245     15.617    96788.23    24.95      -859.0    -811.823    46.914   
   9500     9270.78     0.9872     0.2436      0.0        0.0       0.9098     0.4304    16.7361    15.3271   100197.88     24.0      -812.0    -764.559    47.648   
  10000     9746.77     0.9893     0.2447      0.0        0.0       0.9484     0.5718    19.8758     15.886    100863.6    24.64      -828.0    -779.551    48.615   
Using  0.05  of training data 
Using  0.05 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.45      1.4184     0.503      1.4168     0.5018     3.1623     3.0029    20.4006    15.7809    18580.27   3705.69    -23179.0  -23169.362   9.887    
    10       62.55      1.4176     0.5024     1.3511     0.4564     3.1623     3.0029     27.151    15.1893    18648.24   3540.08    -18702.0  -18692.027   10.297   
    25       144.82     1.4121     0.4985     1.2696     0.403      3.1623     3.0029    32.6549    14.3067    18817.13   3377.13    -13089.0  -13077.682   11.442   
   500      1097.38     0.9197     0.2114     0.4176     0.0436     1.5043     0.041      7.8829    37.1982    12365.46    794.1     -1501.0   -1487.836    13.221   
   1000     2193.14     0.9489     0.2251     0.049      0.0006     1.1316     0.0256     6.975     52.2948    24886.39    215.58     -697.0    -676.321    20.243   
   1500     3300.01     0.959      0.2299      0.0        0.0       0.7771     0.0133     4.9248    63.4087    35413.46    114.17     -445.0    -422.536    22.401   
   2000      4403.3     0.9665     0.2335      0.0        0.0       0.8106     0.0092     4.4575     70.321    41159.49    95.01      -419.0    -396.282    22.487   
   2500     5506.42     0.9645     0.2326      0.0        0.0       0.9295     0.0068     5.2156    75.1021    43799.94    88.96      -429.0    -406.178    22.499   
   3000     6606.24     0.9617     0.2312      0.0        0.0       0.7214     0.0052     4.6319    75.3404    47463.05    80.52      -407.0    -385.072    22.287   
   3500     7704.24     0.9632     0.2319      0.0        0.0       0.7417     0.0048     4.7467    76.3703    49970.13    78.15      -391.0    -368.367    22.203   
   4000      8798.1     0.9587     0.2298      0.0        0.0       0.856      0.0045     5.0416    78.0596    52822.66    79.09      -456.0    -433.899    22.116   
   4500     9890.74     0.9592      0.23       0.0        0.0       0.7033     0.0044     5.5788    78.2423    55852.13    77.47      -491.0    -469.223    22.018   
   5000     10984.18    0.9636     0.2321      0.0        0.0       0.8284     0.0043     5.7546    79.9138    59250.39    81.79      -527.0    -505.337    21.692   
   5500     12078.14    0.9642     0.2324      0.0        0.0       0.8096     0.0046     5.9424    79.4478    62138.69     80.4      -577.0    -555.264    21.55    
   6000     13171.17    0.9685     0.2345      0.0        0.0       1.0237     0.0043     7.5963    79.9109    66140.63    82.56      -681.0    -660.031    21.352   
   6500     14263.93    0.9671     0.2338      0.0        0.0       1.0026     0.0045     8.2651    81.2658    69403.92    86.38      -782.0    -761.371    20.875   
   7000     15357.17    0.9689     0.2347      0.0        0.0       0.821      0.0042     7.8227    82.8186    71772.65    88.75      -869.0    -847.652    21.013   
   7500     16449.71    0.9679     0.2342      0.0        0.0       1.1699     0.0043    10.1073    82.8585    75721.18     95.9     -1113.0   -1092.918     20.4    
   8000     17540.78    0.9686     0.2346     0.0566     0.0008     2.3912     0.0041    16.5642    84.9392    79956.87    112.26    -1356.0   -1334.873    20.767   
   8500     18632.68    0.9737     0.237       0.0        0.0       0.9309     0.0038     9.4138    87.1928    82601.32    92.04     -1382.0   -1361.937    20.357   
   9000     19725.55    0.9723     0.2363      0.0        0.0       0.9278     0.0037    11.0239    88.8413    82021.27    94.42     -1433.0   -1413.239    19.932   
   9500     20825.17    0.9746     0.2374     0.049      0.0006     2.1446     0.0038    14.4847    90.2966    86620.29    99.21     -1519.0   -1498.748    20.128   
  10000     21920.25    0.9727     0.2366      0.0        0.0       1.0663     0.0038    11.3782    93.0045    86348.04    98.81     -1627.0   -1607.423    19.704   
Using  0.1  of training data 
Using  0.1 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.83      1.4072     0.4951     1.4064     0.4945     3.1623     3.6108    13.1713    91.7826    18616.13   7443.68    -48206.0  -48196.042   10.07    
    10       79.19      1.4099     0.497      1.3771     0.4741     3.1623     3.6108    29.6212     76.677    18878.43   7325.41    -37944.0  -37933.894   10.575   
    25       182.61     1.4133     0.4994     1.3415     0.4499     3.1623     3.6108    50.2921     55.443    19319.18   7246.66    -25519.0  -25506.459   12.135   
   500      1366.82     0.8684     0.1885     0.7526     0.1416     1.398      0.0543    13.0714    54.0736    10341.31   3059.41    -3787.0   -3770.602    16.045   
   1000     2709.39     0.8859     0.1962     0.6027     0.0908     1.3535     0.0221    15.7366    71.4865    11724.41   2253.85    -3286.0   -3265.277    21.014   
   1500      4078.6     0.919      0.2112     0.5028     0.0632     1.3138     0.0193    18.1828    87.3838    14626.02   1723.72    -2900.0    -2876.13    23.569   
   2000     5461.35     0.937      0.2195     0.4285     0.0459     1.1329     0.0155    20.6564    99.1153    19170.55   1351.45    -2547.0   -2521.203    26.135   
   2500     6852.12     0.9608     0.2308     0.3527     0.0311     1.1023     0.0145    22.2355    117.0699   25235.24    1080.8    -2321.0   -2291.407    29.141   
   3000     8245.72     0.9597     0.2302     0.3053     0.0233     1.0558     0.0139    23.4564    126.6897   33179.28    875.84    -1996.0   -1964.231    31.539   
   3500     9642.36     0.9676     0.234      0.2877     0.0207     1.1934     0.0117    27.5572    141.1218   41266.82    771.53    -1934.0   -1901.732    32.119   
   4000     11039.03    0.9699     0.2352     0.2349     0.0138     0.9829      0.01     25.4338    153.1103   50145.24    615.87    -1582.0   -1548.811    33.662   
   4500     12435.37    0.9755     0.2379     0.2098     0.011      0.9049     0.0071    24.5502    167.8234   58324.22    524.05    -1424.0    -1388.92    34.853   
   5000     13834.04    0.9801     0.2402     0.1939     0.0094     0.8962     0.0065     25.098    182.3387   65006.95    443.55    -1268.0   -1231.619    36.372   
   5500     15233.96    0.9803     0.2402     0.1673     0.007      0.8841     0.0055    24.0754    193.0051   71419.52    383.7     -1115.0    -1078.47    36.995   
   6000     16630.99    0.9841     0.2421     0.1414     0.005      0.674      0.0046    21.7215    198.8342   77401.51    313.29     -989.0    -950.824    38.038   
   6500     18026.23    0.9886     0.2443     0.1296     0.0042     0.6155     0.0041    21.4747    208.2463   82575.05    279.71     -899.0    -860.269    38.948   
   7000     19421.15    0.9887     0.2444     0.098      0.0024     0.723      0.0039    19.6447    212.4893   87901.28    242.03     -806.0    -765.974    40.104   
   7500     20814.93    0.9913     0.2457     0.0721     0.0013     0.6059     0.0031    17.7643    225.2973   91302.15    207.45     -739.0    -698.365    40.531   
   8000     22207.33    0.9894     0.2447     0.0566     0.0008     0.555      0.0028     17.228    234.0837   95190.01    185.06     -666.0    -625.145    41.068   
   8500     23600.03    0.9915     0.2458     0.0447     0.0005     0.5487     0.0025     17.262    239.1656   98326.18    167.16     -641.0    -599.325    41.663   
   9000     24992.66    0.9882     0.2441      0.04      0.0004     0.585      0.0023    16.2133    244.2141   100850.9    152.04     -591.0    -549.453    41.867   
   9500     26383.28    0.9925     0.2462      0.0        0.0       0.5254     0.0019    15.5896    249.361   102837.07    136.64     -534.0    -491.661    42.196   
  10000     27774.59    0.9896     0.2448      0.0        0.0       0.5146     0.0017    14.1895    252.8282   104314.0    130.12     -505.0    -462.667    42.482   
Using  0.2  of training data 
Using  0.2 of training data
Factorizing with max_iteration = 10000  fixing covariance?:  False
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
Using diagonal covariance?:  False
Random start? True
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |rel-te-err|train_rsme|rel-tr-err|   d_mean  |   d_cov  |avg_grad_m|avg_grad_c| test_nll | train_nll |    VLB   |  E-term  |    KL     
    0         1.85      1.406      0.4942     1.4125     0.4988     3.1623     3.9783    17.6095    244.7242   18652.05   14915.52   -96559.0  -96548.978   9.915    
    10       103.66     1.4085     0.496      1.4005     0.4904     3.1623     3.9783    55.1783    198.4196   19172.56   15056.63   -74022.0  -74011.078    10.5    
    25       238.11     1.4155     0.5009     1.3793     0.4756     3.1623     3.9783    98.6438    137.2396   20209.97   15417.49   -48351.0  -48338.79    12.407   
   500      1451.75     0.8627     0.1861     0.8037     0.1615     1.5619     0.0449    24.2793    79.3768    9902.17     7020.0    -7760.0    -7742.53    17.367   
   1000     2827.46     0.846      0.1789     0.7632     0.1456     1.4319     0.0268    27.5338    100.8449    9985.4    6391.36    -7415.0   -7397.789    17.624   
   1500     4217.46     0.8524     0.1816     0.7291     0.1329     1.4783     0.0169    31.2051    114.0762   10352.31   6003.34    -7203.0   -7183.255    19.365   
   2000     5610.35     0.8548     0.1827     0.6883     0.1184     1.1483     0.017     30.0163    125.7948   10470.55   5550.57    -6785.0   -6762.745    22.235   
   2500     7007.23     0.859      0.1845     0.6759     0.1142     1.0209     0.0099    32.7866    130.1752   10609.69   5353.83    -6636.0   -6613.037    22.535   
   3000     8408.79     0.8568     0.1835     0.6744     0.1137     1.0081     0.0097    34.4776    145.0393   10999.6    5208.23    -6515.0   -6491.428    23.258   
   3500     9813.31     0.8646     0.1869     0.6611     0.1092     0.8172     0.0095    33.5498    155.279    11225.01   5103.43    -6436.0   -6413.039    22.923   
   4000     11217.71    0.8743     0.1911     0.6464     0.1044     0.8274     0.0129    34.4377    162.7871   11500.75   4986.84    -6375.0   -6350.607    24.312   
   4500     12624.99    0.8742     0.191      0.6518     0.1062     0.9021     0.0109     37.039    167.3982   11618.19   4946.19    -6318.0   -6295.118    23.181   
