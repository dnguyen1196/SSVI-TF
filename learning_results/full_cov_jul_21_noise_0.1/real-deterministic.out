Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  7.263838291168213
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       115.06    268.919    269.3195    3.1622     0.2721   
   200       238.84    238.6591   238.7234    2.8304     0.1283   
   300       362.93    233.5617   232.7367    2.1328     0.0512   
   400       488.64    234.0051   232.5608    1.9289     0.042    
   500       612.83    233.9867   232.7584    2.2808     0.0191   
   600       736.97    230.9508   230.3841    1.6149     0.0161   
   700       861.05    230.6754   231.0486    1.4186     0.0087   
   800       985.03    231.7036   230.8224    1.2955     0.0095   
   900      1109.21    231.6657   231.6419    1.4496     0.0053   
   1000     1233.12    230.0617   230.1242    1.3091     0.0057   
   1100     1356.97    229.3363   229.9375    1.3141     0.0036   
   1200     1480.49    230.7614   230.5784    1.5541     0.0038   
   1300     1604.06    230.4324   229.7643    1.3806     0.0027   
   1400     1727.54    230.3195   230.3228    1.1017     0.003    
   1500      1851.2    229.7309   229.552     1.2682     0.0027   
   1600     1974.57    228.9207   229.7454    1.3365     0.0023   
   1700     2097.78    229.184    229.3094    0.9364     0.0022   
   1800     2221.67    228.9944   229.2508    1.1215     0.0019   
   1900     2344.88    229.4279   229.5917    1.1012     0.002    
   2000     2468.04    228.3615   228.9891    1.1528     0.0013   
   2100     2591.11    229.711    229.5284    1.0337     0.0014   
   2200     2714.64    228.9191    228.95     0.8398     0.0012   
   2300     2837.84    228.4437   229.4083    1.2143     0.0009   
   2400     2961.11    229.3883    229.35     1.1661     0.001    
   2500     3084.55    228.3685   228.799     1.2824     0.001    
   2600     3208.18    228.7183   228.8363    1.0531     0.0009   
   2700     3331.46    229.0248   229.0124    0.8096     0.0008   
   2800     3454.74    228.7814   228.8502    0.946      0.0007   
   2900      3578.2    228.909    229.0898    0.9294     0.0007   
   3000     3701.47    229.205    229.2018    0.9056     0.0006   
   3100     3824.59    229.4522   229.2457    1.0483     0.0007   
   3200     3947.83    228.4479   228.5551    0.8256     0.0006   
   3300     4071.87    228.2007   228.885     1.0936     0.0005   
   3400     4195.26    228.1243   228.4191    0.714      0.0005   
   3500     4318.64    228.6474   228.5751     0.86      0.0005   
   3600      4442.1    228.4473   228.378     0.9663     0.0005   
   3700     4565.41    228.9555   229.3535    1.0944     0.0004   
   3800     4688.75    228.9006   228.8891    0.8813     0.0004   
   3900     4811.88    228.6032   228.8197    0.7595     0.0004   
   4000     4934.86    228.5693   228.6157    1.0643     0.0003   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       115.55    262.4326    263.02     3.1622     0.3727   
   200       239.19    240.5933   240.2634    2.9812     0.1028   
   300       361.57    234.5726   234.6041    2.3012     0.0402   
   400       483.45    231.7695   232.1958    1.7434     0.0223   
   500       605.68    231.8389   232.3793    2.0044     0.0125   
   600       728.11    231.0157   231.6041    1.6159     0.0086   
   700       850.39    230.7708   231.7973    1.6705      0.01    
   800       974.3     231.7548   231.9328    1.3612     0.0076   
   900      1097.06    229.9305   230.4523    1.4556     0.0062   
   1000     1219.85    231.0004   231.6894    1.3115     0.0045   
   1100     1342.75    229.868    230.5126    1.075      0.0023   
   1200      1465.5    230.1163   230.6798    1.609      0.0037   
   1300      1588.6    230.7366   230.5336    1.2542     0.0027   
   1400     1711.39    229.9795   229.9261    1.2578     0.0015   
   1500     1834.27    230.3095   229.9151    0.9772     0.0016   
   1600     1957.35    229.3483   229.4447    0.9975     0.0015   
   1700     2080.51    229.1784   230.046     1.5777     0.0015   
   1800     2203.61    229.3014   229.6709    1.0445     0.0013   
   1900     2326.67    229.6854   230.1054    1.0758     0.0011   
   2000     2449.82    230.5283   230.4291    1.5209     0.001    
   2100      2573.0    229.2796   229.6113    0.8078     0.0011   
   2200     2696.97    229.5631   229.6375    1.0602     0.0008   
   2300     2820.23    229.3535   229.6563    1.0056     0.0008   
   2400     2943.61    229.9593   229.6816    1.2763     0.0007   
   2500     3066.62    228.9692   229.6365    1.1144     0.0007   
   2600     3189.68    229.369    229.384     0.8993     0.0007   
   2700     3313.02    229.2486   229.6738    0.9832     0.0006   
   2800     3435.96    229.8048   229.7179    0.9962     0.0005   
   2900     3558.98    229.1483   229.5347    1.1063     0.0005   
   3000     3682.11    228.4934   228.8482    0.8359     0.0006   
   3100     3804.98    228.9922   229.5989    0.7425     0.0005   
   3200     3927.73    229.0703   228.8657    1.0033     0.0003   
   3300     4050.52    229.6249   230.0255    1.069      0.0004   
   3400     4172.74    229.0405   230.1186    1.1011     0.0004   
   3500     4294.82    228.7081   229.4427    0.7911     0.0004   
   3600     4416.86    228.5658   228.8046    0.8505     0.0004   
   3700     4540.06    228.5022   228.7416    0.859      0.0003   
   3800     4661.79    228.9409   229.5494    0.8409     0.0004   
   3900     4783.51    228.9834   229.203     0.8133     0.0003   
   4000     4905.31    228.343    228.6641    0.925      0.0003   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       115.27    263.2883   264.4826    3.1622     0.3419   
   200       240.82    238.9249   238.8855    2.6724     0.0923   
   300       366.57    235.9687   235.4438    2.1333     0.0367   
   400       492.62    233.9328   234.0797    1.8581     0.0324   
   500       618.38    231.3101   232.0927    1.9613     0.0213   
   600       744.14    232.2308   232.0758    1.9269     0.0089   
   700       869.67    231.2821   231.3363    1.7028     0.0107   
   800       995.11    230.6028   230.665     1.6531     0.0074   
   900      1120.46    231.2694   232.0954    1.5129     0.0074   
   1000     1245.72    229.8202   230.2711    1.5031     0.0056   
   1100     1371.17    230.3592   230.8936    1.1426     0.0042   
   1200     1496.88    229.1347   229.5377    1.0221     0.0029   
   1300      1622.1    230.1468   230.4609    1.3871     0.002    
   1400     1747.29    229.3059   230.0805    1.2299     0.0026   
   1500     1872.83    229.9132   230.2086    1.4252     0.0022   
   1600     1998.02    229.091    230.156     1.0745     0.0019   
   1700     2123.58    229.6465   229.9759    1.2248     0.0017   
   1800     2248.96    229.716    230.7855    0.9265     0.0016   
   1900     2374.17    228.8247   229.4252    0.9694     0.0011   
   2000      2499.7    229.5667   229.7063    1.3423     0.0012   
   2100     2624.96    229.5816   230.2594    1.0825     0.0014   
   2200     2750.32    229.2224   229.6926    1.0635     0.0011   
   2300     2875.29    229.994    230.1223    1.0639     0.001    
   2400     3000.48    229.5586   229.067     1.0648     0.0008   
   2500     3127.01    227.9964   228.8807    1.0772     0.0007   
   2600     3256.82    229.1515   229.8655    1.2344     0.0007   
   2700     3382.55    228.9011   229.7328    1.1373     0.0005   
   2800     3509.16    227.9766   228.6789    0.9447     0.0006   
   2900     3635.69    228.8392   229.5629    0.8419     0.0005   
   3000     3761.38    229.2989   230.0618    1.1185     0.0004   
   3100     3886.96    228.6306   228.9225    0.9127     0.0005   
   3200     4013.01    229.0733   229.1985    0.8217     0.0005   
   3300     4138.99    228.7071   228.8788    1.066      0.0004   
   3400     4265.08    229.1507   229.1002    1.1246     0.0003   
   3500     4391.19    229.2924   229.4638    0.9011     0.0005   
   3600     4516.12    228.0273   228.865     0.855      0.0003   
   3700     4641.14    227.837    229.2154    0.8553     0.0003   
   3800     4766.26    228.8256   228.9578    0.7957     0.0003   
   3900     4891.54    228.2762   228.2524    1.0578     0.0003   
   4000     5017.47    228.0297   228.4684    0.7895     0.0003   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       114.15    266.2948   265.8758    3.1621      0.57    
   200       239.07    241.5587   241.7001    3.0265     0.0409   
   300       363.69    235.8311   236.4918    2.5616     0.0166   
   400       488.6     231.8471   232.5982    2.3374     0.0077   
   500       613.49    232.6571   233.2351    1.6608     0.0104   
   600       738.5     231.1079   231.176     1.5832     0.0061   
   700       863.54    230.878    232.076     1.6206     0.0058   
   800       988.84    231.1066   231.6711    1.2928     0.0048   
   900      1113.97    230.2432   230.7961    1.3272     0.0037   
   1000     1239.19    229.8041   230.607     1.5803     0.0022   
   1100      1364.5    229.7778   231.2646    1.5724     0.0033   
   1200     1489.55    229.6591   231.0775    1.301      0.0026   
   1300     1614.48    229.608    230.6747    1.4117     0.0025   
   1400     1739.48    228.8049   229.8383    1.3373     0.0016   
   1500     1865.14    229.4599   230.9817    1.2892     0.0016   
   1600     1990.23    230.5977   231.3202    1.3517     0.001    
   1700     2115.43    230.047    230.7354    1.1769     0.0012   
   1800     2240.49    230.1257   230.9136    1.0856     0.001    
   1900     2365.43    230.6418   230.915     1.3023     0.0009   
   2000     2490.29    229.2579   230.1483    1.497      0.0009   
   2100     2615.05    228.4276   229.7823    1.0909     0.0012   
   2200     2740.15    228.5242   229.8855    1.225      0.0009   
   2300     2865.21    229.5729   230.6937    1.0194     0.0006   
   2400     2990.35    228.8052   229.6325    1.1941     0.0006   
   2500      3115.5    228.5174   229.5362    1.0661     0.0005   
   2600     3240.45    228.987    230.0226    0.9774     0.0006   
   2700     3365.47    228.2163   229.2442    0.8624     0.0004   
   2800     3490.81    228.3471   229.4364    1.0302     0.0005   
   2900      3616.6    229.8505   230.0454    1.3262     0.0005   
   3000     3741.75    228.1413   229.0263    0.8954     0.0005   
   3100      3866.7    228.7193   229.7558    1.0527     0.0005   
   3200     3991.64    228.9741   229.8291    0.9022     0.0004   
   3300     4116.62    228.4806   229.4309    0.7494     0.0004   
   3400     4241.47    229.4443   229.9121    1.0936     0.0004   
   3500     4366.17    228.3439   229.332     1.1175     0.0003   
   3600     4490.93    228.3934   229.739     1.0348     0.0003   
   3700     4615.58    228.0639   229.0728    1.0311     0.0004   
   3800     4740.21    228.5894   229.3903    1.0155     0.0003   
   3900     4864.94    228.9122   229.7914    0.7645     0.0003   
   4000     4989.69    228.1537   229.4741    0.9007     0.0003   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       115.28    259.1425   260.196     3.1607     0.6523   
   200       241.72    237.948    238.3858    2.6872     0.0486   
   300       368.55    234.9514   235.2671    2.4181     0.0226   
   400       495.27    232.6856   232.8941    1.9567     0.0141   
   500       622.34    232.3575   232.4668    1.9366     0.0035   
   600       749.31    232.8502   233.3651    1.7818     0.0106   
   700       876.35    231.2498   231.7232    1.9574     0.0065   
   800      1003.36    230.1308   230.6443    1.6277     0.0058   
   900      1129.96    229.1801   230.4836    1.5878     0.0031   
   1000     1256.51    230.5222   231.6068    1.5574     0.0043   
   1100     1383.39    230.2821   230.6921    1.1558     0.0028   
   1200     1510.03    230.3919   231.1026    1.0112     0.002    
   1300     1636.62    229.392    229.9437    1.1219     0.0023   
   1400     1763.18    230.103    230.6819    1.5975     0.0021   
   1500     1889.83    230.8108   231.5194    1.3023     0.0024   
   1600     2016.83    229.6454   230.414      1.17      0.0017   
   1700     2143.55    229.3855   230.3577    1.176      0.0016   
   1800      2270.5    228.7887   229.4734    1.0623     0.0014   
   1900     2396.99    230.0148   230.6431    1.279      0.001    
   2000     2523.36    229.5919   229.8648    1.1056     0.001    
   2100     2649.67    229.1995   230.0035    1.1475     0.0011   
   2200     2776.13    229.2892   229.9739    1.209      0.0009   
   2300     2902.53    227.9863   229.1852    1.0677     0.0007   
   2400     3028.99    228.9342   229.777     1.3714     0.0008   
   2500     3155.66    229.0823   229.6022     0.88      0.0007   
   2600     3282.64    228.9238   229.2475    1.002      0.0008   
   2700     3409.29    229.0898   229.8846    0.9946     0.0006   
   2800     3535.83    228.5068   229.3134    0.9544     0.0005   
   2900     3662.43    229.0983   229.4164    1.1194     0.0006   
   3000      3788.8    229.6019   230.3962    1.0419     0.0005   
   3100      3915.3    229.1954   229.8287    1.0749     0.0004   
   3200     4042.78    228.8106   229.3987    0.8861     0.0005   
   3300     4169.37    228.7163   229.6407    1.0191     0.0003   
   3400     4295.73    227.9016   228.8119    0.8753     0.0004   
   3500     4422.25    228.4755   229.2188    0.9592     0.0004   
   3600     4548.81    229.0333   229.7218    1.1353     0.0003   
   3700     4675.22    228.2695   228.9045    0.7396     0.0004   
   3800      4801.6    228.7361   229.2349    1.1178     0.0003   
   3900     4928.07    228.9357   229.2701    0.8636     0.0003   
   4000     5054.39    228.3974   229.1088    1.1298     0.0003   
