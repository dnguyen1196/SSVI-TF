Generating synthetic count valued data ... 
Generating synthetic  count valued data took:  9.569128036499023
max_count =  19  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       154.93     4.2238     4.2617     0.3143     0.2851   128071.33  103978.89    0.0001  
   200       515.51     4.1734     4.2111     0.2954     0.0235   118992.84   96557.83     0.0    
   300       875.33     3.9828     4.0187     0.2829     0.0241    96892.46   78566.33     0.0    
   400      1236.18     3.5864     3.6186     0.2632     0.0167    70585.37   57212.2      0.0    
   500      1597.75     3.0697     3.097      0.2244      0.01     51080.02   41391.6      0.0    
   600      1959.94     2.5928     2.6141     0.2101     0.0106    40172.13   32545.12     0.0    
   700      2322.93     2.2138     2.2318     0.2017     0.0107    34509.17   27951.86    0.0001  
   800      2685.52     1.9298     1.9408     0.1506     0.0105    31473.65   25473.57     0.0    
   900      3048.17     1.7137     1.7238     0.1083     0.0107    29725.57   24052.47     0.0    
   1000     3410.46     1.5523     1.5617     0.188      0.0098    28670.91   23195.03     0.0    
   1100     3772.98     1.4343     1.439      0.1173     0.0104    27985.76   22631.24     0.0    
   1200     4135.65     1.3473     1.3502     0.2098     0.0089    27568.47   22289.42     0.0    
   1300     4497.39     1.2839     1.2863     0.1603     0.0084    27273.65   22056.72     0.0    
   1400     4858.37     1.2353     1.2354     0.0588     0.008     27081.07   21893.87     0.0    
   1500     5217.44     1.2049     1.2039     0.117      0.0074    26950.03   21795.78     0.0    
   1600     5576.56     1.1828     1.1779     0.1418     0.0071    26884.74   21729.26     0.0    
   1700     5936.37     1.1601     1.1542     0.0673     0.0067    26784.9    21647.32     0.0    
   1800     6295.45     1.1417     1.1361     0.1705     0.0062    26723.4    21596.21     0.0    
   1900     6654.03     1.1302     1.1262     0.1307     0.0059    26682.77   21570.78     0.0    
   2000     7012.89     1.1258     1.1182     0.1936     0.0057    26692.54   21565.38     0.0    
   2100     7372.15     1.1178     1.1116     0.0982     0.0054    26652.44   21538.38     0.0    
   2200     7730.67     1.1106     1.1041     0.1611     0.0051    26632.89   21517.5      0.0    
   2300     8089.53     1.1029     1.0958      0.11      0.0048    26579.89   21475.12     0.0    
   2400     8448.54     1.1008     1.0931     0.1289     0.0045    26587.23   21487.26     0.0    
   2500     8807.74     1.0988     1.0912     0.0835     0.0044    26586.59   21486.07     0.0    
   2600     9167.29     1.0955     1.0889     0.0651     0.0042    26578.4    21473.86     0.0    
   2700     9526.61     1.0965     1.0876     0.0902     0.0039    26590.81   21480.29     0.0    
   2800     9885.35     1.0925     1.082      0.1136     0.0038    26566.33   21452.57     0.0    
   2900     10244.52    1.0916     1.0819     0.1182     0.0036    26555.4    21458.58     0.0    
   3000     10603.35    1.0882     1.081      0.0668     0.0034    26539.27   21448.88     0.0    
   3100     10962.5     1.0857     1.0784     0.1625     0.0033    26525.99   21431.54     0.0    
   3200     11321.62    1.0864     1.077      0.0505     0.0035    26525.93   21437.5      0.0    
   3300     11680.74    1.0886     1.0828     0.0775     0.003     26553.28   21458.06     0.0    
   3400     12039.5     1.0858     1.0777     0.1119     0.003     26542.38   21445.07     0.0    
   3500     12398.84    1.0827     1.075      0.0675     0.0031    26496.98   21414.51     0.0    
   3600     12757.53    1.0872     1.0763     0.1137     0.0028    26534.72   21436.17     0.0    
   3700     13116.21    1.0883     1.0809     0.1223     0.0026    26537.46   21447.6      0.0    
   3800     13475.24    1.0858     1.0769     0.1144     0.0025    26520.39   21428.0      0.0    
   3900     13834.71    1.0853     1.077      0.087      0.0025    26531.59   21439.56     0.0    
   4000     14193.6     1.0858     1.0766     0.0873     0.0025    26538.82   21438.2      0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       153.78     4.2415     4.2656     0.3132     0.2467   128898.46  208401.86    0.0001  
   200       599.24     4.1971     4.2208     0.3002     0.0225   121334.27  196098.88     0.0    
   300      1043.44     4.0132     4.036      0.2881     0.0203    99822.32  161253.49     0.0    
   400       1487.9     3.6196     3.6393     0.2771     0.0131    72343.34  116858.58     0.0    
   500      1931.45     3.1001     3.1177     0.2209     0.0078    51732.47   83640.15     0.0    
   600      2374.16     2.6254     2.6387     0.1909     0.0087    40533.76   65578.19     0.0    
   700       2817.5     2.2481     2.2581     0.1773     0.0089    34757.21   56243.19     0.0    
   800      3261.09     1.9581     1.9663     0.125      0.0097    31586.65   51115.12     0.0    
   900      3704.56     1.7398     1.7452     0.2245      0.01     29759.42   48159.21     0.0    
   1000     4147.71     1.5761     1.5801     0.0878     0.0098    28642.59   46360.07     0.0    
   1100     4590.98     1.4529     1.4547     0.1643     0.0095    27931.69   45199.17     0.0    
   1200     5032.92     1.3596     1.3622     0.1474     0.0091    27445.58   44446.63     0.0    
   1300     5474.82     1.2923     1.2941     0.1722     0.0087    27159.1    43961.83     0.0    
   1400     5917.34     1.2416     1.2419     0.0768     0.0082    26934.5    43601.8      0.0    
   1500     6359.03     1.2035     1.2038     0.1639     0.0078    26790.01   43374.71     0.0    
   1600     6800.07     1.1723     1.1727     0.1104     0.0074    26665.15   43168.06     0.0    
   1700     7240.81     1.1506     1.1493     0.1621     0.007     26590.18   43042.52     0.0    
   1800     7682.23     1.1317     1.1313     0.0922     0.0067    26518.06   42925.96     0.0    
   1900     8122.99     1.1179     1.1189     0.1425     0.0063    26488.72   42888.08     0.0    
   2000     8564.81     1.1063     1.1063     0.1502     0.006     26435.45   42806.08     0.0    
   2100     9007.28     1.0952     1.0952     0.1665     0.0057    26402.77   42750.4      0.0    
   2200     9448.47     1.0879     1.0865     0.115      0.0055    26374.76   42712.55     0.0    
   2300     9890.07     1.0815     1.0793     0.0923     0.0051    26353.84   42664.61     0.0    
   2400     10331.4     1.0741     1.0728     0.0662     0.0049    26336.09   42632.06     0.0    
   2500     10773.19    1.0702     1.0699     0.096      0.0046    26331.85   42631.04     0.0    
   2600     11214.18    1.0698     1.0671     0.092      0.0044    26320.36   42614.71     0.0    
   2700     11655.23    1.0639     1.0616     0.1047     0.0042    26292.52   42564.95     0.0    
   2800     12096.14    1.0622     1.0618     0.0969     0.0041    26283.6    42566.55     0.0    
   2900     12536.94    1.0618      1.06      0.0584     0.0039    26277.72   42545.66     0.0    
   3000     12978.13    1.0608     1.0596     0.1674     0.0037    26281.82   42562.42     0.0    
   3100     13419.06    1.0573     1.0545     0.1097     0.0036    26263.94   42514.54     0.0    
   3200     13860.14    1.0557     1.0542     0.1156     0.0035    26261.56   42514.66     0.0    
   3300     14302.01    1.0549     1.0545     0.0949     0.0033    26269.37   42521.79     0.0    
   3400     14743.02    1.055      1.0524     0.118      0.0032    26256.05   42511.68     0.0    
   3500     15183.51    1.0523     1.0514     0.0632     0.0031    26247.43   42492.94     0.0    
   3600     15624.24    1.0524     1.0512     0.0926     0.003     26265.12   42500.72     0.0    
   3700     16065.47    1.0533     1.051      0.125      0.0029    26278.66   42523.09     0.0    
   3800     16505.39    1.051      1.0489     0.0859     0.0028    26239.87   42472.75     0.0    
   3900     16946.12    1.0503     1.0494     0.0526     0.0027    26240.8    42481.18     0.0    
   4000     17386.86    1.0529     1.0508     0.0926     0.0026    26266.44   42506.5      0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       154.51     4.2478     4.2654     0.3133     0.227    129064.54  311880.81    0.0001  
   200       688.05     4.2031     4.2207     0.2994      0.02    121754.92  294228.11     0.0    
   300      1219.23     4.017      4.034      0.2922      0.02    100125.13  242008.83     0.0    
   400      1753.51     3.6197     3.6365     0.2745     0.0121    72263.55   174777.4     0.0    
   500       2290.1     3.1022     3.1182      0.27      0.0068    51593.71  124900.91     0.0    
   600      2824.56     2.6284     2.6429     0.2425     0.008     40442.43   97955.4      0.0    
   700      3359.56     2.2543     2.2673     0.1992     0.0089    34740.3    84178.19     0.0    
   800      3894.85     1.9676     1.9784     0.1563     0.0099    31594.36   76536.65     0.0    
   900      4429.52     1.7455     1.7553     0.133      0.0101    29739.61   72020.45     0.0    
   1000     4964.58     1.5794     1.5878     0.1462      0.01     28600.68   69265.89     0.0    
   1100     5498.54     1.4534     1.4601     0.1692     0.0096    27876.97   67487.3      0.0    
   1200     6032.76     1.3614     1.3676     0.1056     0.0093    27421.86   66373.03     0.0    
   1300     6570.93     1.2902     1.295      0.1963     0.0088    27078.47   65558.53     0.0    
   1400     7104.75     1.2372     1.2411     0.1826     0.0084    26862.5    65034.8      0.0    
   1500     7642.25     1.1963     1.2002     0.1368     0.008     26696.39   64613.09     0.0    
   1600      8179.2     1.1677     1.1698     0.135      0.0077    26593.19   64353.72     0.0    
   1700      8714.2     1.1449     1.1457     0.1398     0.0072    26509.32   64149.84     0.0    
   1800     9247.71     1.1257     1.1267     0.0977     0.0068    26434.52   63984.03     0.0    
   1900     9782.22     1.1127     1.1132     0.1099     0.0065    26413.32   63899.49     0.0    
   2000     10319.33    1.0997     1.1001     0.1263     0.0063    26355.62   63781.06     0.0    
   2100     10852.67    1.0901     1.0906     0.1073     0.006     26320.98   63685.9      0.0    
   2200     11387.13    1.083      1.0811     0.067      0.0056    26293.91   63611.51     0.0    
   2300     11920.85    1.0754     1.0745     0.0831     0.0053    26267.28   63546.84     0.0    
   2400     12455.61    1.0702     1.0697     0.1108     0.0051    26258.6    63518.66     0.0    
   2500     12989.99    1.0656     1.0639     0.1418     0.0049    26255.81   63494.71     0.0    
   2600     13524.55    1.0616     1.0604     0.104      0.0047    26228.74   63451.58     0.0    
   2700     14059.68    1.0573     1.0563     0.0997     0.0045    26202.74   63401.73     0.0    
   2800     14594.23    1.0553     1.0534     0.0755     0.0043    26194.46   63381.8      0.0    
   2900     15129.93    1.0543     1.0519     0.1202     0.0041    26198.48   63387.26     0.0    
   3000     15665.0     1.0514     1.0487     0.1221     0.004     26190.3    63356.78     0.0    
   3100     16200.98    1.0489     1.0467     0.132      0.0038    26174.77   63313.74     0.0    
   3200     16737.13    1.0469     1.0458     0.1337     0.0037    26179.57   63309.1      0.0    
   3300     17273.92    1.0461     1.0441     0.1403     0.0036    26177.51   63315.41     0.0    
   3400     17810.37    1.043      1.0412     0.0789     0.0034    26161.49   63271.13     0.0    
   3500     18347.12    1.0427     1.0401     0.0936     0.0034    26154.65   63263.71     0.0    
   3600     18882.58    1.042      1.0393     0.0929     0.0032    26146.28   63230.45     0.0    
   3700     19417.81    1.0433     1.0403     0.1409     0.0032    26169.72   63293.62     0.0    
   3800     19954.01    1.0411     1.0387     0.0993     0.003     26146.89   63242.42     0.0    
   3900     20490.82    1.0406     1.0382     0.1136     0.0029    26143.11   63224.21     0.0    
   4000     21026.96    1.0409     1.0385     0.0741     0.0028    26144.69   63231.15     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       154.45     4.2509     4.2661     0.3125     0.2423   129193.73  415996.92    0.0001  
   200       779.44     4.2084     4.2233     0.3016     0.0182    122367.2  393969.46     0.0    
   300      1403.96     4.0266     4.0409      0.29      0.0184   101154.37  325678.67     0.0    
   400       2027.3     3.6349     3.649      0.2757     0.0111    73120.1   235560.59     0.0    
   500      2651.21     3.1224     3.1353     0.2643     0.0065    52157.35  168207.22     0.0    
   600       3272.4     2.6494     2.6606     0.2057     0.0074    40777.62   131595.7     0.0    
   700      3894.16     2.269      2.2797     0.1795     0.0094    34872.47  112594.09     0.0    
   800       4515.7     1.9875     1.9955     0.2001     0.0101    31738.62  102490.38     0.0    
   900      5140.16      1.77      1.7781     0.1332     0.0103    29884.64   96523.34     0.0    
   1000     5763.54     1.6049     1.6118     0.2331      0.01     28721.46   92739.7      0.0    
   1100     6387.22     1.4853     1.491      0.1551     0.0096    27997.84   90428.64     0.0    
   1200     7011.35     1.3899     1.3954     0.1445     0.0091    27487.28   88785.24     0.0    
   1300     7635.58     1.3199     1.3247     0.1541     0.0087    27164.12   87752.82     0.0    
   1400     8262.05     1.2672     1.2717     0.1988     0.0084    26943.01   87044.77     0.0    
   1500      8886.1     1.2232     1.2265     0.0826     0.008     26754.13   86412.6      0.0    
   1600     9509.55     1.1894     1.1936     0.1929     0.0076    26649.87   86055.47     0.0    
   1700     10132.04    1.1621     1.1668     0.1443     0.0072    26518.51   85687.07     0.0    
   1800     10756.9     1.1422     1.1456     0.1035     0.0069    26452.28   85446.11     0.0    
   1900     11380.22    1.1258     1.1293     0.0929     0.0066    26398.63   85324.24     0.0    
   2000     12003.85    1.1121     1.1155     0.1041     0.0064    26366.87   85178.57     0.0    
   2100     12630.92    1.1002     1.1032     0.0837     0.0059    26317.59   84996.81     0.0    
   2200     13258.28    1.091      1.0929     0.1628     0.0057    26281.66   84880.62     0.0    
   2300     13881.37    1.0808     1.0834     0.1048     0.0055    26243.34   84753.14     0.0    
   2400     14503.73    1.0766     1.0782     0.0818     0.0053    26230.82   84732.96     0.0    
   2500     15130.21    1.0712     1.0728     0.1113     0.005     26215.41   84674.97     0.0    
   2600     15755.17    1.0653     1.0665     0.1034     0.0049    26189.73   84595.78     0.0    
   2700     16378.31    1.0617     1.0626     0.1276     0.0047    26194.02   84574.72     0.0    
   2800     17001.9     1.0583     1.0582      0.12      0.0045    26183.04   84533.06     0.0    
   2900     17627.32    1.056      1.0559     0.1325     0.0044    26166.22   84503.47     0.0    
   3000     18247.83    1.0528     1.0536     0.1408     0.0042    26151.64   84483.95     0.0    
   3100     18867.83    1.0499     1.0503     0.1271     0.004     26144.73   84434.95     0.0    
   3200     19487.4     1.0474     1.0482     0.0966     0.0039    26142.41   84415.69     0.0    
   3300     20109.73    1.0462     1.047      0.0973     0.0038    26133.5    84380.01     0.0    
   3400     20734.6     1.0453     1.0455     0.1388     0.0036    26131.98   84393.61     0.0    
   3500     21358.67    1.0437     1.0446     0.0753     0.0035    26116.32   84361.59     0.0    
   3600     21979.76    1.0413     1.0424     0.0815     0.0034    26104.44   84326.17     0.0    
   3700     22603.64    1.0403     1.0412     0.0753     0.0033    26097.75   84293.57     0.0    
   3800     23229.67    1.0404     1.0402     0.0874     0.0032    26104.89   84296.39     0.0    
   3900     23857.66    1.0408     1.0405     0.0633     0.0031    26115.32   84319.27     0.0    
   4000     24485.21    1.0391     1.0393     0.1127     0.003     26110.1    84296.8      0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       155.31     4.2527     4.2758     0.3134     0.2155   129227.33  521519.63    0.0001  
   200       865.81     4.2097     4.2323     0.303      0.017    122426.38  493938.47     0.0    
   300      1574.85     4.0245     4.0463     0.295      0.016    100965.17  407273.76     0.0    
   400      2284.51     3.6276     3.6477     0.2738     0.0108    72671.0   293243.32     0.0    
   500      2994.88     3.1178     3.1352     0.3059     0.0061    51957.4   209787.65     0.0    
   600      3706.18     2.6436     2.6589     0.1994     0.0073    40641.08   164164.1     0.0    
   700      4416.48     2.2661     2.279      0.1472     0.009     34804.46  140652.58     0.0    
   800      5127.09     1.9846     1.9961     0.1879     0.0097    31709.49   128113.3     0.0    
   900      5838.61     1.7668     1.7778     0.1744     0.0099    29836.47  120597.43     0.0    
   1000      6549.9     1.6037     1.6135     0.2305     0.0097    28703.05  115988.93     0.0    
   1100     7261.25     1.4751     1.4841     0.2516     0.0094    27933.5   112905.79     0.0    
   1200     7970.52     1.3798     1.3894     0.106      0.0091    27444.32  110938.47     0.0    
   1300     8679.26     1.3084     1.3175     0.1723     0.0087    27109.4   109579.42     0.0    
   1400     9391.19     1.254      1.2627     0.1164     0.0083    26879.16  108649.18     0.0    
   1500     10104.32    1.2133     1.2227     0.1729     0.0079    26706.56  108030.76     0.0    
   1600     10814.77    1.1812     1.189      0.1886     0.0076    26590.24  107510.77     0.0    
   1700     11526.41    1.1544     1.1619     0.1605     0.0073    26475.84  107052.75     0.0    
   1800     12237.75    1.1347     1.1412     0.1138     0.007     26413.76   106782.3     0.0    
   1900     12948.45    1.1198     1.1261     0.1318     0.0066    26361.32  106593.06     0.0    
   2000     13659.64    1.1076     1.1127     0.1351     0.0063    26319.94  106374.95     0.0    
   2100     14370.44    1.0955     1.101      0.1979     0.0061    26279.75  106214.19     0.0    
   2200     15082.37    1.087      1.0923     0.1116     0.0058    26252.06  106090.54     0.0    
   2300     15796.37    1.0813     1.0857     0.1242     0.0055    26238.64  106032.86     0.0    
   2400     16509.36    1.0742     1.0786     0.1047     0.0053    26204.01  105917.87     0.0    
   2500     17222.15    1.0692     1.0742     0.1975     0.0052    26199.11  105923.66     0.0    
   2600     17937.7     1.0652     1.0687     0.1119     0.005     26176.78  105798.43     0.0    
   2700     18653.94    1.0622     1.0658     0.1195     0.0048    26183.45  105793.92     0.0    
   2800     19369.37    1.0576     1.0614     0.1698     0.0046    26156.84  105701.68     0.0    
   2900     20082.9     1.0541     1.0573     0.1377     0.0045    26129.98   105625.6     0.0    
   3000     20799.09    1.0501     1.0541     0.0935     0.0043    26120.91   105581.0     0.0    
   3100     21515.57    1.0483     1.0513     0.0556     0.0041    26112.5   105518.91     0.0    
   3200     22231.27    1.0462     1.049      0.0803     0.004     26106.56  105489.73     0.0    
   3300     22945.92    1.0438     1.0473     0.112      0.0039    26096.08  105463.18     0.0    
   3400     23662.28    1.0444     1.0463     0.1049     0.0038    26110.74  105481.35     0.0    
   3500     24376.81    1.0431     1.0447     0.0938     0.0037    26096.2   105431.94     0.0    
   3600     25092.56    1.0415     1.0428     0.0968     0.0036    26087.02  105406.35     0.0    
   3700     25807.91    1.0387     1.0411     0.0697     0.0034    26078.67  105382.04     0.0    
   3800     26523.21    1.0369     1.0401     0.1222     0.0034    26070.91  105353.78     0.0    
   3900     27238.17    1.0374     1.039      0.1154     0.0032    26067.52  105324.19     0.0    
   4000     27953.85    1.0372     1.039      0.0717     0.0032    26070.14  105327.53     0.0    
