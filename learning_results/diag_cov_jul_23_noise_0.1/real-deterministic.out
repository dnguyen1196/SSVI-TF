Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  8.09882116317749
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       67.66     265.4223   265.328     3.1621     0.6922   
   200       136.15    239.3355   239.3432    2.8728     0.2336   
   300       204.71    234.1321   233.2202    1.7908     0.1228   
   400       273.26    234.0234   232.7778    2.2758     0.0799   
   500       341.79    233.4481   232.3188    1.6394     0.0548   
   600       410.33    231.5663   230.9527    1.6007     0.0416   
   700       478.85    230.4142   230.9115    1.6949     0.0319   
   800       547.4     231.7971   230.8772    1.4642     0.0265   
   900       615.94    231.9621   232.0095    1.4973     0.0216   
   1000      684.51    230.2556   230.3587    1.3901     0.0181   
   1100      753.05    229.5838   230.0622    1.4327     0.0159   
   1200      821.6     230.9072   230.6963    1.447      0.0135   
   1300      890.14    230.5164   229.7747    1.1573     0.012    
   1400      958.68    230.5577   230.4702    1.0594     0.0105   
   1500     1027.22    229.7529   229.5189    1.2809     0.0095   
   1600     1095.83    228.9606   229.7922    1.3261     0.0087   
   1700     1164.36    229.4463   229.5324    0.9964     0.0077   
   1800     1232.85    229.1804   229.3704    1.1223     0.0071   
   1900     1301.31    229.3972   229.5319     1.14      0.0066   
   2000     1369.79    228.3842   228.9016    1.1188     0.006    
   2100     1438.24    229.5861   229.4639    1.0402     0.0056   
   2200     1506.73    228.8531   228.8655    0.8326     0.0051   
   2300     1575.18    228.5916   229.5175    1.187      0.0048   
   2400     1643.65    229.3117   229.2422    1.1433     0.0046   
   2500     1712.14    228.3748   228.6909    1.2669     0.0042   
   2600     1780.62    228.6532   228.7278    1.0473     0.004    
   2700     1849.08    228.9422   228.8504    0.8349     0.0038   
   2800     1917.55    228.773    228.7285    0.9362     0.0037   
   2900     1986.02    228.8242   228.9269    0.9148     0.0034   
   3000     2054.51    229.2873   229.1972    0.9166     0.0032   
   3100     2122.98    229.3819   229.0669    1.0338     0.0031   
   3200     2191.49    228.3895   228.4017    0.8091     0.0029   
   3300      2260.0    228.163    228.7698    1.0814     0.0028   
   3400     2328.49    227.9987   228.2272    0.6952     0.0027   
   3500     2396.96    228.6155   228.4924    1.175      0.0025   
   3600     2465.44    228.3446   228.1979    0.9683     0.0024   
   3700      2533.9    228.8496   229.1582    1.1066     0.0023   
   3800     2602.34    228.7896   228.6643    0.9406     0.0022   
   3900     2670.82    228.3994   228.5485    0.7941     0.0021   
   4000     2739.29    228.3956   228.3339    1.0989     0.002    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       67.84     263.9945   263.5577    3.1621     0.6241   
   200       137.27    242.066    240.9926    2.7882     0.3212   
   300       206.87    234.0309   233.8063    2.2255     0.2043   
   400       276.32    232.8984   233.3907    2.7249     0.1419   
   500       345.77    233.0334   233.2977    2.0808     0.106    
   600       415.19    231.6949   232.2089    2.0118     0.0796   
   700       484.65    231.2361   231.9511    1.6762     0.0639   
   800       554.06    231.8562   231.8794    1.3114     0.0531   
   900       623.45    230.2367   230.7261    1.5132     0.0436   
   1000      692.58    231.0783   231.8102    1.3851     0.0366   
   1100      761.34    229.8403   230.6312    1.1969     0.0321   
   1200      830.08    230.2053   230.7978    1.5027     0.0276   
   1300      898.9     230.8377   230.6608    1.4206     0.0243   
   1400      967.6     230.1243   230.0484    1.2521     0.0214   
   1500     1036.32    230.1209   229.8108    0.9294     0.0196   
   1600      1105.1    229.5106   229.553     1.0766     0.0174   
   1700     1173.85    229.1442   230.0374    1.4721     0.0153   
   1800     1242.59    229.3917   229.7548    1.1099     0.0141   
   1900     1311.33    229.7325   230.1671    1.1082     0.013    
   2000     1380.09    230.4479   230.2644    1.5019     0.012    
   2100     1448.84    229.2498   229.5862    0.7934     0.0108   
   2200     1517.62    229.5741   229.6102    1.0626      0.01    
   2300     1586.41    229.2609   229.6181    0.9778     0.0093   
   2400      1655.2    229.9398   229.608     1.3137     0.0086   
   2500     1724.01    228.9122   229.5962    1.1606     0.0079   
   2600     1792.77    229.3228   229.3123    0.9409     0.0075   
   2700     1861.54    229.2392   229.643     0.9803     0.0069   
   2800     1930.32    229.7638   229.6356    0.9714     0.0066   
   2900     1999.08    229.0869   229.4516    1.108      0.0062   
   3000     2067.81    228.5619   228.7924    0.7935     0.0059   
   3100     2136.53    228.8892   229.4617    0.7462     0.0055   
   3200     2205.24    228.9737   228.7871    1.009      0.0051   
   3300     2273.92    229.5481   229.911     1.088      0.005    
   3400     2342.73    228.8498   229.935     1.0842     0.0047   
   3500     2411.53    228.6962   229.3616    0.8173     0.0047   
   3600     2480.32    228.4946   228.6996    0.8315     0.0042   
   3700     2549.09    228.3731   228.608     0.9198     0.004    
   3800     2617.95    228.8452   229.3815     0.78      0.0038   
   3900     2686.72    228.9525   229.1227    0.7999     0.0038   
   4000     2755.43    228.2165   228.5185    0.894      0.0035   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       67.27     262.5762   263.3937    3.1615     0.5014   
   200       136.65    241.4933   241.2006    2.6171     0.3093   
   300       206.05    235.3342   234.9067    2.0461     0.2111   
   400       275.53    233.9289   234.1159    1.9466     0.1528   
   500       345.03    230.6814   231.5463    1.7615     0.1167   
   600       414.48    231.4153   231.2932    1.2652     0.0902   
   700       484.05    231.3888   231.3924    1.6499     0.0745   
   800       553.52    231.042    231.0851    1.6093     0.0639   
   900       623.06     232.08    232.9515    1.6582     0.0507   
   1000      692.5     229.9036   230.2821    1.3918     0.0438   
   1100      761.96    230.3674   230.9173    1.1378     0.0384   
   1200      831.41    229.533    229.8877    1.1537     0.0332   
   1300      900.96    230.2654   230.637     1.3803     0.0294   
   1400      970.42    229.3902   230.0991    1.1928     0.0262   
   1500     1039.91    229.7759   230.096     1.3914     0.0236   
   1600     1109.44    229.0863   230.0819    0.9412     0.0209   
   1700      1179.0    229.7798   230.0609    1.2423     0.0193   
   1800     1248.48    229.6647   230.6922    0.9287     0.0173   
   1900     1318.01    228.8401   229.4497    0.9012     0.0158   
   2000      1387.5    229.3243   229.4824    1.2761     0.015    
   2100     1457.04    229.4829   230.1207    1.1182     0.0134   
   2200     1526.57    229.1003   229.5842    1.0377     0.0124   
   2300     1596.12    230.0228   230.0833    1.112      0.0117   
   2400     1665.64    229.4513   229.0258    0.9758     0.0104   
   2500     1735.16    228.0213   228.8282    1.1053      0.01    
   2600     1804.66    229.0372   229.7971    1.1936     0.0092   
   2700     1874.16    228.9554   229.8012    1.0834     0.0087   
   2800     1943.73    228.0187   228.6829    0.8813     0.0084   
   2900     2013.36    228.8388   229.5313    0.8702     0.0081   
   3000     2082.99    229.1707   229.9606     1.06      0.0074   
   3100      2152.6    228.6055   228.9479    0.9182     0.0069   
   3200     2222.27    229.0843   229.2237    0.8724     0.0067   
   3300     2291.97    228.6523   228.7972    1.0164     0.0062   
   3400     2361.64    229.0963   229.0218    1.1022     0.0057   
   3500     2431.28    229.292    229.4485    0.8872     0.0056   
   3600     2500.98    227.9743   228.8323    0.835      0.0053   
   3700     2570.62    227.7823   229.1062    0.9013     0.0051   
   3800     2640.26    228.7932   228.9277    0.8159     0.0048   
   3900      2709.9    228.2277   228.2094    1.0777     0.0045   
   4000     2779.64    228.0235   228.4723    0.794      0.0045   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       67.51     265.7947   265.2404    3.162      0.4486   
   200       137.91    242.2645   242.4543    2.9186     0.2893   
   300       208.31    235.7347   236.3929    2.1207     0.2034   
   400       278.73    233.1743   234.3296    1.9593     0.1571   
   500       349.15    233.4048   233.9546    1.8273     0.1194   
   600       419.57    230.6394   230.9866    1.6936     0.0976   
   700       490.01    231.1686   232.3941    1.3201     0.0795   
   800       560.52    231.3366   231.8417    1.3529     0.0685   
   900       630.94    230.3091   230.7759    1.2943     0.0588   
   1000      701.39    230.0422   230.9174    1.4435     0.0505   
   1100      771.84    229.8262   231.2969    1.7149     0.0428   
   1200      842.32    229.5359   230.8834    1.3225     0.0379   
   1300      912.77    229.2125   230.4092    1.441      0.0346   
   1400      983.29    228.9307   229.9553    1.2448     0.0295   
   1500     1053.69    229.5338   231.0273    1.2585     0.0271   
   1600      1124.1    230.4376   231.0971    1.152      0.0243   
   1700     1194.53    230.2007   230.8387    1.1542     0.0223   
   1800     1264.93    230.1721   230.8983    1.1277     0.0204   
   1900     1335.33    230.5016   230.8643    1.113      0.0184   
   2000     1405.73    229.1854   230.1023    1.5032     0.0167   
   2100     1476.06    228.4875   229.8638    1.1274     0.0156   
   2200      1546.4    228.4632   229.8408    1.1356     0.0146   
   2300     1616.67    229.6018   230.7161    0.9493     0.0134   
   2400     1686.84    228.8379   229.6452    1.0824     0.0125   
   2500     1757.01    228.4913   229.4428    0.9804     0.012    
   2600     1827.28    228.832    229.8434    0.9674     0.011    
   2700     1897.46    228.1679   229.2053    0.9096     0.0103   
   2800      1967.7    228.3211   229.3401    0.9948     0.0096   
   2900     2037.86    229.7498   229.9611    1.3743     0.0091   
   3000      2108.1    227.9933   228.8881    1.0369     0.0086   
   3100     2178.29    228.7188   229.7754    1.0282     0.0082   
   3200     2248.47    228.8727   229.7194    0.9343     0.0076   
   3300     2318.64    228.4222   229.3604    0.7208     0.0072   
   3400      2388.8    229.355    229.8357    1.0654     0.007    
   3500      2459.0    228.2765   229.2578     1.16      0.0065   
   3600     2529.16    228.194    229.5368    1.0116     0.0062   
   3700     2599.34    228.0174   228.9726    1.0062     0.006    
   3800     2669.58    228.4338   229.2257    1.0357     0.0057   
   3900     2739.75    228.9072   229.713     0.7551     0.0054   
   4000     2810.19    228.1288   229.3942    0.8982     0.0052   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       67.51     257.8609   258.9238    3.1602     0.4047   
   200       138.4     239.1211   239.5306    2.5076     0.2659   
   300       209.29    236.7154   236.5304    2.2869     0.1981   
   400       280.34    234.3291   234.2731    1.899      0.1523   
   500       351.27    233.0958   233.4851    1.7987     0.1217   
   600       422.25    233.1512   233.5863    1.9635     0.101    
   700       493.29    231.1284   231.5646    1.8098     0.082    
   800       564.27    230.4188   230.7738    1.6373     0.0696   
   900       635.26    229.1676   230.5624    1.6487     0.0614   
   1000      706.29    230.1639   231.3391    1.3887     0.0534   
   1100      777.36    230.3448   230.7904    1.1274     0.0482   
   1200      848.45    230.4505   231.0718    1.3733     0.0403   
   1300      919.52    229.2124   229.8385    1.2551     0.037    
   1400      990.52    229.9896   230.6476    1.8532     0.0319   
   1500     1061.56    230.7896   231.4678    1.2512     0.0293   
   1600     1132.63    229.9905   230.7974    1.2295     0.0258   
   1700     1203.69    229.4655   230.3202    1.1275     0.0239   
   1800     1274.66    228.9682   229.5562    1.0617     0.0222   
   1900     1345.69    230.1539   230.6654    1.1849     0.0201   
   2000      1416.7    229.5148   229.7468    1.1248     0.0188   
   2100     1487.81    229.0744   229.8488    1.1137     0.0174   
   2200     1558.78    229.233    229.843     1.3595     0.0163   
   2300     1629.78    228.0073   229.1988    1.0455     0.0148   
   2400     1700.78    228.9137    229.86     1.5059     0.0137   
   2500     1771.89    228.8379   229.3876    0.8666     0.0129   
   2600      1842.9    228.975    229.2814    0.914      0.0123   
   2700     1913.94    229.0519   229.8446    1.1248     0.0116   
   2800     1985.01    228.3274   229.1808    0.9541     0.011    
   2900     2056.02    229.2018   229.5855    1.2391     0.0103   
   3000     2127.19    229.7125   230.4728    1.0138     0.0098   
   3100     2198.29    229.2015   229.8086    1.107      0.0092   
   3200      2269.3    228.7004   229.3275    0.8585     0.0086   
   3300      2340.3    228.7105   229.6689    0.9498     0.008    
   3400     2411.33    227.9702   228.9046    0.902      0.0077   
   3500     2482.33    228.402    229.1225    0.9995     0.0073   
   3600     2552.04    228.9155   229.6488    0.9387     0.0069   
   3700     2620.99    228.2428   228.835     0.7162     0.0068   
   3800     2689.76    228.6423   229.1475    1.1289     0.0065   
   3900     2758.54    228.9936   229.2706    0.8003     0.0061   
   4000      2827.5    228.3548   229.0574    1.1738     0.0059   
