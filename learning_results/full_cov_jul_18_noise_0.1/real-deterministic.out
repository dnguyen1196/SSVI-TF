Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  7.559860706329346
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       124.2     268.919    269.3195    3.1622     0.2721   
   200       251.37    238.6591   238.7234    2.8304     0.1283   
   300       378.68    233.5617   232.7367    2.1328     0.0512   
   400       505.99    234.0051   232.5608    1.9289     0.042    
   500       633.51    233.9867   232.7584    2.2808     0.0191   
   600       760.79    230.9508   230.3841    1.6149     0.0161   
   700       889.86    230.6754   231.0486    1.4186     0.0087   
   800       1019.6    231.7036   230.8224    1.2955     0.0095   
   900      1147.42    231.6657   231.6419    1.4496     0.0053   
   1000     1275.27    230.0617   230.1242    1.3091     0.0057   
   1100     1407.58    229.3363   229.9375    1.3141     0.0036   
   1200     1546.49    230.7614   230.5784    1.5541     0.0038   
   1300     1687.72    230.4324   229.7643    1.3806     0.0027   
   1400      1829.3    230.3195   230.3228    1.1017     0.003    
   1500     1969.78    229.7309   229.552     1.2682     0.0027   
   1600     2108.85    228.9207   229.7454    1.3365     0.0023   
   1700     2251.85    229.184    229.3094    0.9364     0.0022   
   1800     2395.12    228.9944   229.2508    1.1215     0.0019   
   1900     2534.51    229.4279   229.5917    1.1012     0.002    
   2000     2671.84    228.3615   228.9891    1.1528     0.0013   
   2100     2815.74    229.711    229.5284    1.0337     0.0014   
   2200     2963.02    228.9191    228.95     0.8398     0.0012   
   2300     3106.56    228.4437   229.4083    1.2143     0.0009   
   2400     3250.98    229.3883    229.35     1.1661     0.001    
   2500     3396.77    228.3685   228.799     1.2824     0.001    
   2600     3542.84    228.7183   228.8363    1.0531     0.0009   
   2700      3690.4    229.0248   229.0124    0.8096     0.0008   
   2800     3834.27    228.7814   228.8502    0.946      0.0007   
   2900     3979.68    228.909    229.0898    0.9294     0.0007   
   3000     4123.13    229.205    229.2018    0.9056     0.0006   
   3100     4268.04    229.4522   229.2457    1.0483     0.0007   
   3200     4412.88    228.4479   228.5551    0.8256     0.0006   
   3300     4555.63    228.2007   228.885     1.0936     0.0005   
   3400     4699.82    228.1243   228.4191    0.714      0.0005   
   3500     4837.58    228.6474   228.5751     0.86      0.0005   
   3600      4976.1    228.4473   228.378     0.9663     0.0005   
   3700     5114.57    228.9555   229.3535    1.0944     0.0004   
   3800      5250.0    228.9006   228.8891    0.8813     0.0004   
   3900     5376.94    228.6032   228.8197    0.7595     0.0004   
   4000     5503.37    228.5693   228.6157    1.0643     0.0003   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       119.7     248.0212   247.3124    2.7135     0.357    
   200       248.89    235.6645   235.199     1.8848     0.0853   
   300       377.98    231.1377   231.5873    1.7498     0.0345   
   400       507.05    229.767    230.4285    1.4123     0.0187   
   500       636.17    230.906    231.4631    1.6765     0.0117   
   600       764.42    229.6775   230.2444    1.5482     0.0079   
   700       891.86    230.2561   231.0851    1.4605     0.0066   
   800      1019.97    230.7651   230.9572    1.3377     0.0053   
   900      1148.23    229.3607   229.8844    1.5568     0.0041   
   1000     1276.09    230.0879   230.7688    1.2744     0.0033   
   1100     1403.76    229.3923   230.2085    1.1513     0.0023   
   1200     1531.16    229.3513   230.0868    1.3795     0.0025   
   1300     1659.14    230.2544   230.0912    1.2495     0.0021   
   1400     1786.54    229.3568   229.2611    1.2646     0.0016   
   1500     1914.78    229.6676   229.3531    0.8741     0.0014   
   1600     2042.09    228.9688   229.1127    0.9593     0.0013   
   1700     2170.37    228.7052   229.592     1.4071     0.0012   
   1800     2297.72    228.9451   229.2949    0.9379     0.0011   
   1900     2425.45    229.3182   229.7132    1.1671     0.001    
   2000     2552.95    230.0031   229.9335    1.4116     0.0009   
   2100     2680.46    228.9008   229.2546    0.8423     0.0008   
   2200     2808.31    229.1124   229.252     1.0134     0.0007   
   2300     2935.55    229.1212   229.3616    0.843      0.0007   
   2400     3062.97    229.6927   229.4108    1.2004     0.0006   
   2500     3190.28    228.6241   229.3519    1.095      0.0006   
   2600     3317.56    229.076    229.1132    0.7941     0.0005   
   2700     3444.84    229.0253   229.4181    0.8897     0.0005   
   2800     3572.15    229.5917   229.4959    0.9602     0.0004   
   2900      3699.4    228.8762   229.2727    1.0898     0.0004   
   3000      3826.7    228.3399   228.6414    0.8011     0.0004   
   3100     3953.81    228.6383   229.3335    0.8341     0.0004   
   3200     4080.99    228.7566   228.5792    0.8949     0.0003   
   3300     4208.15    229.2103   229.6701    1.0449     0.0003   
   3400      4335.2    228.8603   229.8545    1.0714     0.0003   
   3500     4462.29    228.4137   229.1134    0.7414     0.0003   
   3600     4590.02    228.225    228.5339    0.7884     0.0003   
   3700      4720.4    228.3675   228.6715    0.9812     0.0003   
   3800      4848.2    228.6911    229.36     0.754      0.0003   
   3900     4975.45    228.7848   229.0129    0.7845     0.0002   
   4000      5102.7    228.0636   228.4499    0.8141     0.0003   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       118.1     248.3148   247.6191    2.5491     0.408    
   200       246.24    231.2763   231.4665    1.283      0.0904   
   300       374.58    229.4907   229.5192    1.2187     0.0388   
   400       502.95    229.4961   229.7723    1.2636     0.0229   
   500       631.45    228.7696   229.3023    1.2558     0.0158   
   600       760.0     229.5975   229.6901    1.012      0.0095   
   700       888.3     229.081    229.1914    1.0762     0.0077   
   800      1016.55    229.1085   229.1751    1.2382     0.0061   
   900      1144.78    228.935    229.8544    1.0102     0.0049   
   1000      1273.1    228.482    229.0014    1.4253     0.0039   
   1100     1401.22    228.8412   229.3478    0.7782     0.0032   
   1200      1529.3    228.1919   228.5214    0.8219     0.0026   
   1300     1657.42    228.7503   229.1608    1.0223     0.0021   
   1400     1785.56    227.9245   228.6854    0.958      0.002    
   1500     1913.62    228.8497   229.179     1.1628     0.0017   
   1600     2041.64    228.1153   229.1784    0.8701     0.0016   
   1700     2169.83    228.5352   228.8707    0.8034     0.0014   
   1800     2297.87    228.779    229.6468    1.0501     0.0013   
   1900     2425.94    228.0779   228.6428    0.8173     0.001    
   2000      2554.2    228.5405   228.7002    1.0878     0.001    
   2100     2682.41    228.4609   229.0581    1.1219     0.001    
   2200     2810.53    228.2985   228.7129    0.933      0.0009   
   2300     2938.54    229.0675   229.1345    0.8118     0.0008   
   2400     3066.89    228.7386   228.3564    1.3661     0.0007   
   2500     3194.96    227.4358   228.1585    0.8788     0.0007   
   2600     3322.85    228.5139   229.0813    1.0997     0.0006   
   2700     3450.87    228.1847   228.9628    0.9309     0.0006   
   2800     3579.02    227.3381   228.0194    0.8313     0.0005   
   2900     3707.04    228.0779   228.7527    0.882      0.0005   
   3000     3835.08    228.4381   229.1731    1.0001     0.0004   
   3100      3963.2    228.0619   228.4426    0.8188     0.0004   
   3200      4091.3    228.3111   228.4333    0.6804     0.0004   
   3300     4219.43    228.0531   228.2655    0.9318     0.0004   
   3400     4347.53    228.5658   228.5547    0.9367     0.0004   
   3500      4475.6    228.6584   228.8085    0.7603     0.0004   
   3600     4603.57    227.4789   228.3045    0.7464     0.0003   
   3700      4731.6    227.2674   228.5898    0.8502     0.0003   
   3800     4859.83    228.199    228.3971    0.7182     0.0003   
   3900     4987.82    227.7749   227.8047    0.9377     0.0003   
   4000     5115.74    227.5573   227.9876    0.6861     0.0003   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       118.64    253.1615   252.9701    2.4195     0.4915   
   200       247.83    232.5352   233.1722    1.0059     0.0773   
   300       376.51    229.3979   230.3268    1.4421     0.0325   
   400       505.35    228.4029   229.4244    1.039      0.0169   
   500       634.33    228.1739   229.0095    0.9574     0.0124   
   600       763.31    228.0493   228.6476    0.836      0.0084   
   700       892.21    228.2188   229.3535    0.8509     0.0065   
   800      1021.13    228.225    228.9454    0.6788     0.005    
   900      1150.15    228.5095   228.9916    0.8528     0.0042   
   1000      1279.0    228.0066   228.8189    1.0719     0.0033   
   1100     1407.84    227.9558   229.0862    1.1499     0.0029   
   1200     1536.92    227.9792   229.2111    0.8338     0.0026   
   1300     1665.67    227.5949   228.6357    1.1183     0.0023   
   1400     1794.35    227.6226   228.4057    0.8723     0.0018   
   1500      1923.1    227.9722   229.1828    0.9051     0.0017   
   1600     2051.85    228.7593   229.4891    1.1841     0.0014   
   1700     2180.57    228.3165   229.0812    0.8208     0.0013   
   1800     2309.39    228.2994   229.2103    0.8259     0.0011   
   1900     2438.27    229.059    229.2612    0.9112     0.001    
   2000     2567.14    228.0992   228.9007    1.0953     0.0009   
   2100     2696.06    227.5582   228.6924    0.9326     0.001    
   2200     2824.85    227.4071   228.7679    1.0378     0.0009   
   2300     2953.64    228.2822   229.2714    0.705      0.0008   
   2400     3082.28    227.5987   228.4687    0.8334     0.0007   
   2500     3210.94    227.3337   228.4772    0.7533     0.0006   
   2600     3339.95    227.7828   228.7876    0.785      0.0006   
   2700     3468.67    227.2788   228.3222    0.6289     0.0005   
   2800     3597.32    227.399    228.3875    0.7423     0.0005   
   2900     3726.12    228.6114   228.9318    0.8919     0.0005   
   3000     3854.86    227.4785   228.3123    0.6727     0.0005   
   3100     3983.72    227.7416   228.803     0.8597     0.0005   
   3200      4112.5    228.1373   228.9236    0.9354     0.0004   
   3300     4241.44    227.5133   228.4686    0.5989     0.0004   
   3400     4370.17    228.3399   228.8315    0.768      0.0004   
   3500     4498.81    227.4469   228.4074    0.6857     0.0003   
   3600     4627.48    227.4289   228.6856    0.7046     0.0003   
   3700     4756.28    227.248    228.2062    0.7738     0.0003   
   3800     4885.49    227.5903   228.4333    0.7198     0.0003   
   3900     5014.51    227.908    228.7635    0.6377     0.0003   
   4000     5144.12    227.2916   228.5541    0.7172     0.0003   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       117.67    258.1576   257.6768    2.0252     0.4138   
   200       246.65    233.4763   233.8718     0.8       0.0806   
   300       375.72    229.5568   229.8721    1.0976     0.034    
   400       504.82    228.5458   228.8233    0.8146     0.0197   
   500       633.8     228.0897   228.4947    0.7954     0.0118   
   600       763.16    228.211    228.9138    1.4821     0.0091   
   700       892.26    227.9743   228.5159    0.9338     0.0066   
   800      1021.41    227.7121   228.1579    0.8738     0.0055   
   900      1150.48    227.1469    228.1      1.1148     0.0041   
   1000     1279.75    227.8419   228.7591    0.717      0.0037   
   1100     1408.84    227.8397   228.3885    0.7793     0.0028   
   1200     1537.78    227.8268   228.4527    0.838      0.0025   
   1300     1666.86    227.7627   228.5169    0.6708     0.0022   
   1400     1795.99    227.7277   228.4472    0.7281     0.002    
   1500     1924.84    228.1862   228.8508    0.7464     0.0018   
   1600      2053.7    227.7133   228.5214    0.8114     0.0015   
   1700     2183.01    227.2048   228.1608    0.7368     0.0014   
   1800      2312.2    227.4017   228.1115    0.5131     0.0012   
   1900      2441.2    227.9658   228.6184    0.8862     0.0011   
   2000     2570.03    227.8344   228.1946    0.8363     0.001    
   2100     2699.24    227.649    228.4238    0.7303     0.0009   
   2200     2827.97    227.5512   228.2958    0.711      0.0009   
   2300     2956.77    227.0772   228.2493    0.8421     0.0008   
   2400     3085.54    227.3953   228.344     0.9997     0.0008   
   2500      3214.2    227.6851   228.2328    0.6265     0.0007   
   2600     3342.89    227.6754   228.1062    0.5793     0.0007   
   2700      3471.6    227.5455   228.4043    0.7331     0.0006   
   2800      3600.7    227.671    228.3793    0.9746     0.0005   
   2900     3729.32    227.7777   228.1973    0.7429     0.0005   
   3000     3857.99    227.8632   228.5919    0.6793     0.0005   
   3100     3986.77    227.9582   228.5488    0.6825     0.0004   
   3200     4115.61    227.4568   228.0701    0.8935     0.0004   
   3300     4244.26    227.606    228.3008    0.6537     0.0004   
   3400     4373.02    226.9977   227.8249    0.7022     0.0004   
   3500     4501.85    227.3557   228.0445    0.7498     0.0004   
   3600      4630.7    227.5877   228.3036    0.9284     0.0003   
   3700      4759.4    227.4321   228.0066    0.5561     0.0003   
   3800     4887.99    227.4197   228.0228    0.957      0.0003   
   3900     5016.68    227.697    228.1063    0.6168     0.0003   
   4000     5145.32    227.2949   227.9991    0.683      0.0003   
