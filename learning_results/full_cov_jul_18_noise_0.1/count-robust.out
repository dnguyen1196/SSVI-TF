Generating synthetic count valued data ... 
Generating synthetic  count valued data took:  8.862315893173218
max_count =  19  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       468.81     4.1433     4.1796     0.3071     2.6068   128953.55  104739.46     0.0    
   200       1106.0     4.1015     4.138      0.2955     1.3846   122212.48   99240.34     0.0    
   300      1740.45     3.9485     3.9832     0.2842     0.7938    103091.4   83676.5      0.0    
   400      2372.96     3.6258     3.6569     0.2602     0.5852    76564.76   62096.75     0.0    
   500      3004.95     3.1617     3.1875     0.223      0.7393    54713.79   44341.06     0.0    
   600      3633.82     2.6659     2.6859     0.2299     0.7642    41761.04   33791.89     0.0    
   700      4259.82     2.225      2.2373     0.1989     0.8824    34839.86   28160.48     0.0    
   800      4887.09     1.8731     1.8787     0.2074     0.6787    31179.83   25199.69     0.0    
   900      5513.75     1.6215     1.6245     0.2278     1.5348    29242.47   23629.04     0.0    
   1000     6139.05     1.4491     1.4476     0.2552     0.5121    28191.11   22776.24     0.0    
   1100     6757.97     1.3296     1.3276     0.1604     0.428     27606.3    22306.6      0.0    
   1200     7379.69     1.2499     1.2436     0.1282     0.1303    27206.91   21972.35     0.0    
   1300     8003.62     1.1959     1.1907     0.1576     0.3727    26973.58   21803.47     0.0    
   1400     8627.08     1.1608     1.1543     0.1457     0.539     26814.37   21667.07     0.0    
   1500     9252.04     1.139      1.1322     0.1192     0.0309    26762.23   21625.76     0.0    
   1600     9874.65     1.1217     1.1133     0.1259     0.3716    26682.35   21557.17     0.0    
   1700     10494.99    1.1073     1.1018     0.0852     0.2356    26598.48   21489.99     0.0    
   1800     11119.04     1.1       1.0914     0.1504     0.0122    26586.35   21469.47     0.0    
   1900     11741.28    1.0901     1.082      0.0733     0.4077    26537.93   21432.79     0.0    
   2000     12360.39    1.0855     1.0778     0.1212     0.4433    26498.12   21400.38     0.0    
   2100     12979.5     1.0791     1.0707     0.0814     0.2672    26485.49   21389.07     0.0    
   2200     13603.57    1.0759     1.0678     0.1488     0.4079    26454.41   21369.41     0.0    
   2300     14226.94    1.0722     1.0643     0.0991     0.0219    26440.07   21362.61     0.0    
   2400     14849.69     1.07      1.0639     0.1086     0.0122    26429.93   21353.93     0.0    
   2500     15471.61    1.0685     1.0597     0.1802     0.1721    26413.48   21337.19     0.0    
   2600     16093.21    1.0677     1.0588     0.1042     0.0156    26412.91   21329.08     0.0    
   2700     16714.38    1.0654     1.058      0.1218     0.0116    26408.56   21335.46     0.0    
   2800     17335.5     1.065      1.0563     0.0589     0.014     26379.29   21316.36     0.0    
   2900     17956.7     1.0633     1.0554     0.1142     0.4353    26375.45   21316.46     0.0    
   3000     18578.42    1.0624     1.0536     0.0666     0.0139    26376.81   21307.11     0.0    
   3100     19198.95    1.0645     1.0545     0.1128     0.4963    26390.31   21321.35     0.0    
   3200     19820.31    1.0639     1.0534     0.0636     0.0113    26376.42   21301.76     0.0    
   3300     20441.28    1.0598     1.051      0.0768     0.1093    26372.27   21306.27     0.0    
   3400     21061.34    1.0577     1.0499     0.0922     0.4849    26348.57   21290.67     0.0    
   3500     21682.6     1.0602     1.052      0.1092     0.0135    26341.35   21275.62     0.0    
   3600     22303.38    1.0573     1.0487     0.079      0.2558    26342.88   21277.26     0.0    
   3700     22924.68    1.0576     1.0479     0.0736     0.0139    26330.96   21268.18     0.0    
   3800     23545.31    1.059      1.0517     0.088      0.5197    26312.4    21259.83     0.0    
   3900     24166.27    1.0588     1.0485     0.0722     0.0127    26324.89   21255.94     0.0    
   4000     24785.01    1.0581     1.0503     0.0964     0.0491    26324.08   21259.71     0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       469.08     4.1466     4.1693     0.0505     1.8184   129135.78  208796.17     0.0    
   200      1177.11     4.1459     4.169      0.0555     1.8251   129252.95  208994.28     0.0    
   300      1884.66     4.1451     4.1684     0.0556     0.9222   129285.99  209046.69     0.0    
   400      2590.08     4.1449     4.1679     0.0562     1.175    129293.58  209057.85     0.0    
   500      3301.01     4.1446     4.1675     0.0536     0.9228   129248.44  208983.47     0.0    
   600      4007.82     4.1441     4.1677     0.0531     0.5418   129148.29  208820.47     0.0    
   700      4719.75     4.1435     4.1664     0.0526     0.764    128957.39  208510.88     0.0    
   800      5429.46     4.1411     4.1644     0.0551     0.2961   128572.75  207889.91     0.0    
   900      6149.65     4.1372     4.1606     0.0707     0.0761   127855.02  206728.39     0.0    
   1000     6866.46     4.1292     4.1522     0.0893     0.8455   126500.22  204533.47     0.0    
   1100     7590.13     4.1131     4.1363     0.1091     0.6879   123877.32  200295.36     0.0    
   1200     8319.11     4.0795     4.1028     0.1333     0.4845   118771.11  192037.54     0.0    
   1300      9046.4     4.0106     4.0333     0.1676     0.5385   109438.55  176927.09     0.0    
   1400      9759.1     3.8766     3.8992     0.1765     0.8425    94842.45  153295.06     0.0    
   1500     10480.95    3.6559     3.6759     0.1754     0.0941    77110.77  124610.42     0.0    
   1600     11203.03    3.3523     3.3704     0.161      0.2094    60841.12   98313.98     0.0    
   1700     11915.03    3.002      3.018      0.1514     0.9792    48771.7    78842.48     0.0    
   1800     12623.93    2.6552     2.6675     0.1343     0.8568    40867.76   66083.45     0.0    
   1900     13330.3     2.3351     2.3465     0.127      1.6341    35842.07   57972.22     0.0    
   2000     14033.19    2.0608     2.0685     0.099      0.6728    32698.37   52895.44     0.0    
   2100     14745.61    1.8371     1.8406     0.0873     0.5795    30691.14   49654.78     0.0    
   2200     15448.13    1.6555     1.6596     0.1363     0.2132    29369.07   47521.68     0.0    
   2300     16151.19    1.5204     1.5233     0.0865     0.4173    28527.51   46175.22     0.0    
   2400     16853.49    1.4175     1.4195     0.1646     0.3546    27963.24   45264.5      0.0    
   2500     17562.71    1.3414     1.3417     0.0991     0.3301    27609.23   44685.12     0.0    
   2600     18267.5     1.2793     1.278      0.0784     0.3027    27312.63   44205.33     0.0    
   2700     18967.49    1.2332     1.2325     0.0642     0.3427    27116.79   43905.83     0.0    
   2800     19668.27    1.1999     1.1996     0.1047     0.147     26989.01   43701.37     0.0    
   2900     20367.48    1.1741     1.1709     0.1042     0.3119    26890.41   43557.09     0.0    
   3000     21066.71    1.1494     1.1494     0.0635     0.3692    26805.6    43402.56     0.0    
   3100     21767.66    1.1379     1.1353     0.1686     0.0483    26749.06   43312.37     0.0    
   3200     22469.5     1.1213     1.1201     0.1059     0.0556    26690.61   43221.97     0.0    
   3300     23167.11    1.1107     1.1079     0.0797     0.007     26641.08   43144.16     0.0    
   3400     23861.89    1.1015     1.099      0.0897     0.1715    26611.49   43098.18     0.0    
   3500     24555.56    1.0948     1.0927     0.0628     0.243     26606.12   43095.33     0.0    
   3600     25250.53    1.0881     1.0871     0.0784     0.3713    26565.97   43026.72     0.0    
   3700     25952.61    1.083      1.0795     0.1303     0.015     26536.33   42989.5      0.0    
   3800     26651.76    1.0814     1.0787     0.1276     0.3084    26523.0    42959.7      0.0    
   3900     27352.64    1.0774     1.0769     0.0743     0.0295    26510.41   42926.88     0.0    
   4000     28051.32    1.0745     1.0742      0.09      0.0336    26509.65   42924.37     0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       479.67     4.1457     4.1627     0.0259     2.3262   129097.93  311900.57     0.0    
   200      1265.68     4.1456     4.1621     0.0272     1.3144   129224.45  312222.67     0.0    
   300      2050.53     4.1459     4.162      0.0274     0.9315   129278.41  312360.34     0.0    
   400      2841.86     4.1458     4.1618     0.0268     0.8345   129302.32  312425.57     0.0    
   500      3627.52     4.1454     4.1617     0.0275     0.6583   129318.06  312470.09     0.0    
   600      4417.99     4.1454     4.1618     0.0273     1.2532   129336.58  312516.17     0.0    
   700      5198.68     4.1452     4.1622     0.028      0.8608   129342.44  312532.34     0.0    
   800      5980.06     4.1447     4.1615     0.0253     0.3058    129339.5  312526.02     0.0    
   900      6763.01     4.1448     4.1614     0.028      0.0879   129325.08  312491.84     0.0    
   1000     7545.02     4.1442     4.1613     0.0286     0.3411   129302.68  312438.08     0.0    
   1100     8327.12     4.1445     4.1614     0.0263     0.7619   129259.92  312336.73     0.0    
   1200     9105.71     4.1439     4.1607     0.0264     0.6951   129195.79  312181.83     0.0    
   1300     9887.08     4.1434     4.1602     0.0263     0.3597   129095.27  311939.37     0.0    
   1400     10672.1     4.1425     4.1594     0.0289     0.0559   128942.15  311568.97     0.0    
   1500     11454.42    4.1418     4.158      0.0347     0.3233   128705.77  310998.65     0.0    
   1600     12238.97    4.1392     4.1559     0.0389     0.5537   128322.84  310074.63     0.0    
   1700     13013.52    4.1356     4.1522     0.0478     0.6411   127684.79  308534.87     0.0    
   1800     13795.9     4.1294     4.1457     0.0586     0.604     126561.8  305824.94     0.0    
   1900     14578.34    4.117      4.1334     0.0739     0.0815   124500.74  300848.87     0.0    
   2000     15361.14    4.0932     4.1102     0.086      0.6741   120829.71  291988.29     0.0    
   2100     16150.51    4.0531     4.0697     0.0941     0.3596    114793.3  277419.15     0.0    
   2200     16948.82    3.987      4.0036     0.0993     0.2036   106171.92   256605.9     0.0    
   2300     17730.22    3.8874     3.9042     0.1055     0.1065    95346.44  230468.14     0.0    
   2400     18498.93    3.7526     3.7692     0.1051     0.6516    83443.45  201760.23     0.0    
   2500     19265.32    3.5844     3.6009     0.1015     0.7024    71978.26  174079.42     0.0    
   2600     20030.23    3.388      3.4051     0.0903     0.1606    61874.19  149698.92     0.0    
   2700     20793.94    3.1779     3.1933     0.0877     1.1565    53668.06  129882.13     0.0    
   2800     21556.8     2.9602     2.9761     0.0846     0.0509    47284.95  114472.97     0.0    
   2900     22317.39    2.7512     2.7665     0.0729     0.1086    42500.79  102902.94     0.0    
   3000     23077.63    2.5486     2.5626     0.0868     1.298     38823.58   94002.0      0.0    
   3100     23837.54    2.3587     2.3709     0.0611     0.0672    36024.29   87228.52     0.0    
   3200     24597.46    2.1855     2.1979     0.0701     0.5737    33928.4    82138.35     0.0    
   3300     25356.7     2.0321     2.0421     0.0662     0.0407    32333.72   78272.41     0.0    
   3400     26115.25    1.8947     1.9044     0.0562     0.0031    31121.82   75329.91     0.0    
   3500     26877.96    1.7751     1.7829     0.0703     0.0083    30165.48   73016.02     0.0    
   3600     27646.19    1.6709     1.6786     0.0871     0.0963    29441.55   71260.94     0.0    
   3700     28427.32    1.5815     1.5882     0.0588     0.0753    28881.22   69902.82     0.0    
   3800     29199.52    1.5063     1.5123     0.0708     0.3597    28443.47   68846.97     0.0    
   3900     29986.92    1.4423     1.4482     0.049      0.3062    28110.06   68024.08     0.0    
   4000     30766.56    1.3884     1.3921     0.0669     0.2082    27840.64   67405.01     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       482.63     4.1459     4.1599     0.0165     1.9614   128884.88  414713.68     0.0    
   200      1360.17     4.1457     4.1597     0.0178     1.4495   129106.53  415533.36     0.0    
   300      2236.15     4.1449     4.1599     0.017      0.9782    129192.7  415860.12     0.0    
   400      3112.32     4.1447     4.1595     0.0188     0.8644   129225.69  415990.49     0.0    
   500      3986.65     4.1451     4.1593     0.0191     0.5167   129257.88  416106.56     0.0    
   600      4862.28     4.1452     4.1593     0.0188     0.6594   129277.79  416183.68     0.0    
   700      5729.14     4.1446     4.1591     0.0193     0.6563   129296.35  416253.24     0.0    
   800      6586.05     4.1453     4.1594     0.0191     0.8337   129304.15  416282.55     0.0    
   900      7457.96     4.1446     4.1592     0.0176     0.1274    129311.2   416313.5     0.0    
   1000     8333.32     4.1446     4.1593     0.0179     0.2076   129314.07  416325.91     0.0    
   1100     9199.51     4.1445     4.1592     0.018      0.7245   129308.03  416307.59     0.0    
   1200     10047.0     4.1447     4.1591     0.0194     0.0773   129294.97   416266.3     0.0    
   1300     10891.14    4.1443     4.1585     0.0197     0.1093   129275.58  416206.24     0.0    
   1400     11733.21    4.1443     4.1586     0.019      0.0715   129247.45  416117.04     0.0    
   1500     12575.71    4.1441     4.1581     0.0206     0.2729   129208.35   415995.0     0.0    
   1600     13418.1     4.1438     4.158      0.0211     0.0263   129149.19  415808.21     0.0    
   1700     14273.54    4.1437     4.1576     0.0225     0.0095   129060.07  415522.54     0.0    
   1800     15116.44    4.1423     4.1568     0.0271     0.015    128935.58  415123.93     0.0    
   1900     15957.7     4.1415     4.1557     0.0303     0.0707    128756.8  414550.03     0.0    
   2000     16799.5     4.1403     4.1543     0.0324     0.4754   128496.87  413713.32     0.0    
   2100     17641.61    4.1387     4.1522      0.04      0.0231   128108.75  412464.28     0.0    
   2200     18484.46    4.1346     4.1483     0.0471     0.3268   127524.41  410587.79     0.0    
   2300     19327.52    4.129      4.1434     0.0567     0.2349   126589.59   407577.1     0.0    
   2400     20169.29    4.1194     4.1341     0.0699     0.0269   125068.29  402678.39     0.0    
   2500     21011.69    4.1043     4.118      0.0875     0.0519   122495.58  394390.83     0.0    
   2600     21853.88    4.0751     4.089      0.0958     0.3297   118110.59  380271.51     0.0    
   2700     22697.38    4.0226     4.0369     0.1133     0.362    110926.18  357143.01     0.0    
   2800     23539.41    3.9336     3.9477     0.1263     0.253    100321.91  323006.78     0.0    
   2900     24380.57    3.7947     3.8085     0.1315     0.0622    87014.25  280201.33     0.0    
   3000     25220.24    3.6017     3.6149     0.1436     0.0408    73121.21  235504.38     0.0    
   3100     26058.22    3.3625     3.376      0.1309     0.1755    60784.46  195875.24     0.0    
   3200     26894.16    3.0991     3.1117     0.1126     0.1008    51136.17  164868.63     0.0    
   3300     27730.32    2.8325     2.8438     0.1022     0.186     44163.78  142439.15     0.0    
   3400     28564.53    2.5735     2.5845     0.1082     0.1172    39142.09  126322.66     0.0    
   3500     29397.42    2.3394     2.3484     0.1007     0.0113    35692.96  115233.33     0.0    
   3600     30230.75    2.1273     2.1372     0.1113     1.2948    33226.86  107282.17     0.0    
   3700     31062.28    1.9458     1.9536     0.1509     1.6644    31499.16  101716.07     0.0    
   3800     31893.79    1.7926     1.8001     0.1289     0.3189    30266.62   97774.34     0.0    
   3900     32725.71    1.6642     1.6714     0.1147     0.0356    29368.31   94861.22     0.0    
   4000     33557.19    1.5577     1.5644     0.0985     0.3282    28729.22   92821.4      0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       462.53     4.1463     4.168      0.009      2.246    128921.89  519885.01     0.0    
   200      1374.88     4.1465     4.1679     0.0101     1.0098   129094.74  520724.45     0.0    
   300      2287.78     4.1459     4.1677     0.0095     1.0747   129163.48  521053.32     0.0    
   400      3199.87     4.1456     4.1674     0.0088     0.8423   129201.77  521229.18     0.0    
   500      4111.53     4.1448     4.1674     0.0086     0.6897   129245.45  521435.58     0.0    
   600      5023.51     4.1451     4.1674     0.0085     0.3472    129279.7  521601.79     0.0    
   700      5933.98     4.1457     4.1675      0.01      0.6989   129303.13  521715.26     0.0    
   800      6846.97     4.1453     4.1674     0.0083     0.1244   129311.16  521755.22     0.0    
   900       7759.8     4.1456     4.1668     0.0084     0.1265   129322.34  521803.41     0.0    
   1000     8672.15     4.1452     4.1671     0.0079     0.5845   129334.95  521858.14     0.0    
   1100     9585.37     4.1441     4.1668     0.0102     0.7252   129347.87  521919.81     0.0    
   1200     10498.73    4.1448     4.1671     0.0092      0.05    129352.13  521940.15     0.0    
   1300     11411.36    4.1449     4.1669     0.009      0.1984   129356.53   521960.7     0.0    
   1400     12324.66    4.1449     4.1666     0.0084     0.5106   129359.68  521976.71     0.0    
   1500     13236.73    4.1448     4.1667     0.0084     0.6504   129361.39  521985.22     0.0    
   1600     14149.37    4.1445     4.1669     0.0087     0.0792    129364.2  522001.46     0.0    
   1700     15061.58    4.1447     4.1669     0.0094     0.0449   129362.22  521994.24     0.0    
   1800     15974.19    4.1449     4.1667     0.0096     0.1041   129357.34  521977.29     0.0    
   1900     16887.75    4.1445     4.1666      0.01      0.6714   129353.06  521958.61     0.0    
   2000     17800.76    4.1446     4.1666     0.0097     0.0408   129342.39  521917.52     0.0    
   2100     18714.11    4.1444     4.1665     0.0107     0.2979   129328.48  521863.17     0.0    
   2200     19628.05    4.1441     4.1664     0.012      0.2781   129308.16  521783.98     0.0    
   2300     20541.23    4.1439     4.1659     0.0115     0.0142   129277.66  521662.08     0.0    
   2400     21454.24    4.144      4.1658     0.0139     0.5254    129237.6  521502.69     0.0    
   2500     22368.91    4.1436     4.1655     0.017      0.3563   129180.91  521274.71     0.0    
   2600     23281.92    4.1434     4.1649     0.0178     0.5437   129098.54  520942.95     0.0    
   2700     24195.22    4.1431     4.1645     0.021      0.1146   128980.54  520470.05     0.0    
   2800     25116.66    4.1415     4.1633     0.0252     0.0659   128789.71  519701.78     0.0    
   2900     26032.72    4.1397     4.1616     0.0291     0.0267   128485.05  518474.16     0.0    
   3000     26947.0     4.1363     4.1584     0.0354     0.017    127965.59  516380.84     0.0    
   3100     27860.55    4.1316     4.1534     0.0496     0.2101   127049.79  512689.51     0.0    
   3200     28775.08    4.1215     4.1435     0.0553     0.0211   125387.16  505985.11     0.0    
   3300     29689.36    4.1037     4.1255     0.0701     0.0296   122448.56  494128.49     0.0    
   3400     30604.46    4.0734     4.0954      0.07      0.5167   117760.17  475200.92     0.0    
   3500     31519.19    4.0264     4.0482     0.0742     0.1257   111064.33  448181.44     0.0    
   3600     32433.51    3.9595     3.9813     0.078      0.1122   102707.85  414460.49     0.0    
   3700     33346.59    3.8709     3.8925     0.0789     0.0949    93329.59  376648.92     0.0    
   3800     34258.2     3.7601     3.7816     0.0724     0.0409    83599.99  337432.64     0.0    
   3900     35168.85    3.631      3.6524     0.071      0.024     74412.87  300415.99     0.0    
   4000     36077.46    3.4865     3.5064     0.0793     0.057     66141.3   267075.36     0.0    
