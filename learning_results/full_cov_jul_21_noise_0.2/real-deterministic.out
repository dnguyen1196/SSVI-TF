Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  7.467931509017944
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       118.6     445.2366   446.0632    3.1622     0.3038   
   200       246.55    427.0756   427.7789    2.9405     0.1323   
   300       374.38    425.5091   424.2511    2.6287     0.0503   
   400       502.42    423.5533   422.5452    2.2429     0.0422   
   500       630.43    424.7778   423.2843    2.4915     0.0179   
   600       758.53    422.3764   421.486     1.7126     0.0157   
   700       886.43    420.7032   421.9065    1.6723     0.0079   
   800      1014.19    422.8866   421.7619    1.7356     0.0092   
   900      1141.82    421.6488   421.9179    2.2924     0.0053   
   1000     1269.43    420.3101   420.5745    1.6604     0.0052   
   1100     1397.05    420.1162   420.7297    1.6226     0.003    
   1200     1525.35    420.7273   420.7032    1.5046     0.0034   
   1300     1652.94    420.9367   420.1168    1.6886     0.0024   
   1400     1780.59    420.9243   421.1474    1.2138     0.0029   
   1500     1908.11    419.2281   419.7338    1.4415     0.0027   
   1600     2035.66    418.6694   420.1088    1.644      0.0023   
   1700     2163.15    419.5629   419.8149    1.1026     0.0021   
   1800     2290.58    418.7711   419.4879    1.1851     0.002    
   1900     2418.02    418.791    419.6181    1.3829     0.0021   
   2000     2545.43    418.3691   419.2263    1.4145     0.0015   
   2100     2672.86    419.7603   420.1024    1.4445     0.0015   
   2200     2800.63    418.5928   419.0008    1.0161     0.0012   
   2300     2928.32    417.8296   419.5997    1.4388     0.001    
   2400     3055.68    419.1964   419.3939    1.2974     0.001    
   2500     3183.28    417.9618   418.7449    1.4387     0.001    
   2600     3311.08    418.4603   418.9601    1.2091     0.001    
   2700     3438.31    418.8233   419.0729    1.074      0.0009   
   2800     3565.55    418.2263   418.7738    0.9442     0.0007   
   2900      3692.7    418.3815   419.4015    1.253      0.0008   
   3000     3820.09    418.9012   419.207     1.1813     0.0007   
   3100     3947.38    419.4007   419.373     1.2798     0.0008   
   3200     4074.67    418.0996   418.525     0.8779     0.0006   
   3300     4201.92    417.7307   418.8339    1.0324     0.0006   
   3400     4329.12    418.0508   418.6911    1.1657     0.0006   
   3500      4456.4    418.5909   418.8905    1.2338     0.0006   
   3600      4583.8    418.162    418.3897    1.0339     0.0005   
   3700     4711.13    418.4283   419.2388    1.362      0.0005   
   3800     4838.56    418.421    418.8787    0.9651     0.0005   
   3900     4965.59    418.5529   418.819     1.0413     0.0005   
   4000     5093.36    418.1916   418.6083    1.1331     0.0004   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       119.09    436.9535   439.0173    3.1621     0.4488   
   200       247.27    428.078    429.0254    3.1363     0.0915   
   300       375.05    423.908    425.2829    2.3996     0.0367   
   400       502.37    421.106    422.8413    1.979      0.0201   
   500       628.6     421.9916   423.6111    2.4259     0.0115   
   600       753.63    420.7402    422.55     1.9737     0.0078   
   700       878.48    421.0552   423.4869    1.816      0.0089   
   800      1003.31    422.2151   423.2246    1.7812     0.0067   
   900      1128.02    420.1588   421.6294    1.7971     0.0055   
   1000     1252.59    420.2235   422.2302    1.6865     0.0039   
   1100     1377.15    419.1411   420.9286    1.5465     0.0021   
   1200     1501.62    419.3355   420.8878    2.0355     0.0033   
   1300     1626.19    420.9782   421.4338    1.6341     0.0024   
   1400     1750.64    419.9213   420.8427    1.8149     0.0014   
   1500     1875.13    420.4673   420.4467    1.265      0.0014   
   1600     1999.59    419.6174   420.4721    1.3239     0.0013   
   1700     2123.78    418.621    420.555     1.643      0.0013   
   1800     2247.78    419.4145   420.5889    1.3736     0.0011   
   1900     2371.76    419.6804   420.7133    1.5453     0.001    
   2000     2495.72    420.0064   420.9026    1.6318     0.0009   
   2100     2619.56    419.1325   420.4199    1.1309     0.001    
   2200     2743.34    419.4164   420.2873    1.4115     0.0007   
   2300     2867.15    419.0085   420.4271    1.1827     0.0007   
   2400     2991.21    419.7379   420.2328    1.2033     0.0006   
   2500     3114.88    418.0997   420.0596    1.5174     0.0006   
   2600     3238.39    419.035    420.0203    1.1814     0.0006   
   2700     3361.85    418.5298   420.3768    1.3755     0.0005   
   2800      3485.3    419.2665   420.0493    1.2338     0.0005   
   2900     3608.87    418.378    419.5125    1.4595     0.0004   
   3000     3732.61    417.9757   419.5379    1.0218     0.0005   
   3100     3856.09    418.2418   419.9991    1.0501     0.0004   
   3200     3979.64    418.6533   419.0807    1.1364     0.0003   
   3300     4103.03    418.9532   420.2685    1.1741     0.0004   
   3400     4226.48    417.9162   420.2262    1.4081     0.0004   
   3500     4349.78    417.9103   419.5909    0.9314     0.0004   
   3600     4473.24    417.6257   418.9306    1.026      0.0004   
   3700     4596.61    417.7398   418.8086    1.2205     0.0002   
   3800     4720.11    418.2126   419.8908    0.9493     0.0003   
   3900     4843.49    418.9388   419.3696    1.0253     0.0002   
   4000     4966.78    417.3771   418.8258    1.0869     0.0003   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       117.25    437.3772   440.5281    3.1623     0.3229   
   200       244.77    426.7498   427.6928    2.8648     0.0874   
   300       371.85    424.2248   424.7033    2.447      0.0358   
   400       499.63    423.1443   424.4317    2.1312     0.0321   
   500       626.81    420.583    422.6923    2.1093     0.0211   
   600       754.0     423.1467   423.9541    1.8801     0.0086   
   700       880.99    420.3093   421.6345    1.6641     0.0103   
   800      1008.05    420.6283   421.6167    1.5572     0.0072   
   900      1135.01    419.8039   422.6724    1.9032     0.0071   
   1000     1261.87    419.4238   421.1428    1.745      0.0053   
   1100     1388.75    419.8752   422.1015    1.3572     0.0041   
   1200     1515.73    419.0982   420.4005    1.4618     0.0029   
   1300     1642.59    420.2335   421.6023    1.4242     0.0019   
   1400      1769.5    418.5862   420.5569    1.9026     0.0025   
   1500     1896.49    419.5145   420.723     1.723      0.0022   
   1600     2023.21    418.221    420.8733    1.3394     0.0019   
   1700     2150.01    419.8219   421.0359    1.5069     0.0017   
   1800     2277.07    419.2047   421.4672    1.3592     0.0015   
   1900     2403.48    418.3947   420.1944    1.3429     0.0011   
   2000      2529.8    418.9436   420.0339    1.5031     0.0012   
   2100      2656.3    418.9183   420.7431    1.4414     0.0014   
   2200     2782.95    418.3834   420.0926    1.4671     0.0011   
   2300     2909.52    419.8702   420.7443    1.1977     0.0009   
   2400     3035.86    418.9348   419.4696    1.3008     0.0008   
   2500     3162.17    416.9311   419.0324    1.3817     0.0007   
   2600     3288.53    418.9279   420.6251    1.5427     0.0007   
   2700     3414.74    417.9871   420.2404    1.2676     0.0005   
   2800     3541.09    416.8978   419.0663    1.3014     0.0006   
   2900     3667.32    417.8598   420.0725    1.168      0.0004   
   3000     3793.41    418.0941   420.2523    1.1817     0.0004   
   3100     3919.54    417.6974   419.2886    1.169      0.0005   
   3200     4045.93    418.7252   419.6665    1.0236     0.0005   
   3300     4172.13    417.9604   419.0008    1.0839     0.0004   
   3400     4298.04    418.7912   419.3537    1.3552     0.0003   
   3500     4423.93    418.4741   419.8402    0.9129     0.0004   
   3600     4549.76    416.7776   418.9548    0.9618     0.0003   
   3700     4675.55    416.5082   419.6516    1.034      0.0003   
   3800     4801.48    417.9025   419.1606    1.0181     0.0003   
   3900     4927.29    417.5648   418.4632    1.2208     0.0003   
   4000     5053.06    416.7509   418.6365    0.9709     0.0003   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       116.88    443.0974   444.4315    3.1622     0.6981   
   200       244.14    426.2074   427.9656    2.6826     0.0412   
   300       370.85    422.4855   425.036     2.7904     0.0174   
   400       497.27    421.6809   423.7659    2.4071     0.0082   
   500       623.75     422.87    424.5265    2.4173      0.01    
   600       750.19    421.1029   421.9087    2.409      0.0056   
   700       876.46    420.6245   423.4668    1.7837     0.0055   
   800      1002.73    421.2624   422.8555    1.627      0.0045   
   900      1128.93    420.1681   421.7837    1.4144     0.0036   
   1000     1255.03    419.9923   421.7227    1.8474     0.0021   
   1100     1381.17    419.0514   421.9486    1.9004     0.0032   
   1200     1507.28    419.3249   421.8476    1.5018     0.0025   
   1300     1633.23    418.8407   421.3048    1.5385     0.0024   
   1400     1759.09    418.712    420.2559    1.4093     0.0015   
   1500     1885.22    419.3661   422.0516    1.6302     0.0015   
   1600     2010.95    419.9799   421.7034    1.5401     0.001    
   1700     2136.59    419.0379   421.0215    1.7437     0.0011   
   1800      2262.4    419.372    421.5571    1.5884     0.001    
   1900      2388.1    420.6276   421.5533    1.6359     0.0009   
   2000     2513.74    418.6018   420.7535    1.7394     0.0009   
   2100     2639.46    418.0243   420.4158    1.3559     0.0012   
   2200     2764.99    417.2666   420.257     1.5192     0.0009   
   2300     2890.46    419.0505   421.5385    1.1715     0.0006   
   2400     3015.86    418.1401   420.0729    1.5791     0.0006   
   2500     3141.67    417.5575   419.8951    1.1344     0.0005   
   2600     3267.29    418.129    420.2538    1.1214     0.0006   
   2700      3392.6    417.6186   419.8062    1.0353     0.0004   
   2800      3518.0    417.6353   419.8023    1.3419     0.0005   
   2900     3643.33    419.4062   420.3426    1.1822     0.0005   
   3000     3768.62    417.2864   419.1695    0.9597     0.0004   
   3100     3893.97    418.2189   420.4141    1.2649     0.0005   
   3200     4019.18    418.2884   420.1874    1.1208     0.0004   
   3300     4144.39    417.5762   419.6492    0.9938     0.0004   
   3400     4269.49    418.9705   420.1663    1.278      0.0004   
   3500     4395.06    417.0597   419.2473    1.3349     0.0003   
   3600     4520.24    417.2157   419.9414    1.2708     0.0003   
   3700      4645.4    417.1705   419.2105    0.9962     0.0003   
   3800     4770.73    417.411    419.385     1.2264     0.0003   
   3900     4896.09    418.159    420.2799    1.0631     0.0003   
   4000     5021.25    417.0935   419.7145    1.0264     0.0003   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       117.71    437.0514   439.8672    3.1615     0.6634   
   200       246.79    425.9932   428.4149    2.5242     0.0454   
   300       375.52    425.7336   426.8418    2.4936     0.023    
   400       504.31    423.7692   424.7672    2.4424     0.014    
   500       632.63    423.0058   424.199     2.1194     0.004    
   600       760.92    423.1488   424.3035    2.5489     0.0103   
   700       889.08    420.9525   422.4989    2.0718     0.0063   
   800       1017.2    420.0507   421.4562    1.8393     0.0057   
   900      1145.92    418.5243   421.112     1.8458     0.0031   
   1000     1274.21    419.961    422.4434    1.6164     0.0041   
   1100     1402.16    420.2407   421.8278    1.5416     0.0027   
   1200     1530.01    419.7456   421.6325    1.873      0.0019   
   1300     1657.86    419.2018   421.0272    1.3955     0.0023   
   1400     1785.55    419.4462   421.1738    1.5517     0.002    
   1500     1913.06    420.8075   422.6721    1.6851     0.0023   
   1600     2040.51    418.6927   420.8622    1.4314     0.0016   
   1700     2167.71    418.6389   421.0718    1.7195     0.0016   
   1800     2294.96    418.4245   420.1108    1.2652     0.0014   
   1900     2422.15    419.463    421.3289    1.5222     0.0009   
   2000     2549.49    418.8498   419.9846    1.2671     0.001    
   2100     2676.83    418.6945   420.4516    1.4501     0.0011   
   2200     2804.28    418.5123   420.1977    1.4025     0.0009   
   2300     2932.23    417.3009   419.9764    1.1862     0.0007   
   2400     3059.53    418.0163   420.2665    1.671      0.0008   
   2500     3187.13    418.8059   420.365     1.2377     0.0007   
   2600      3314.5    418.1393   419.6843    1.0663     0.0008   
   2700     3441.81    418.0204   420.2947    1.2168     0.0006   
   2800     3569.03    418.2596   419.9255    1.2105     0.0005   
   2900     3696.55    418.6603   419.9125    1.2264     0.0006   
   3000     3823.63    418.8291   420.6841    1.3615     0.0005   
   3100     3950.85    418.6995   420.2563    1.0753     0.0004   
   3200     4078.25    417.9586   419.5543    1.1953     0.0005   
   3300     4205.52    418.209    420.0292    1.0775     0.0003   
   3400     4332.64    416.9689   418.7989    1.1513     0.0004   
   3500     4459.99    417.6603   419.3864    1.1226     0.0004   
   3600     4587.11    417.9461   419.8868    1.2474     0.0003   
   3700     4714.32    417.5358   419.1486    1.0351     0.0004   
   3800     4841.84    417.5037   419.1724    1.4556     0.0003   
   3900     4968.97    418.2272   419.408     1.0384     0.0003   
   4000     5095.95    417.1087   419.0179    1.1199     0.0003   
