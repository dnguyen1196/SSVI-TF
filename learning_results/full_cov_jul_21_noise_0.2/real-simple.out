Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  7.503617763519287
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       118.78    443.1319   443.9418    3.1615     0.2515      0.0    
   200       246.19    429.5765   428.2968    2.7853     0.1456      0.0    
   300       373.75    423.8532   424.8312    2.467      0.0457      0.0    
   400       501.42    422.8455   423.806     1.9886     0.0169      0.0    
   500       629.02    422.1949   423.2961    2.134      0.018       0.0    
   600       756.73    422.4361   422.5544    2.0072     0.0083      0.0    
   700       884.48    422.7066   422.0947    1.8958     0.0079      0.0    
   800      1012.14    421.9885   421.3094    1.714      0.0063      0.0    
   900      1139.55    421.9733   422.5079    1.7402     0.0042      0.0    
   1000     1266.96    420.6714   420.5924    1.3206     0.0038      0.0    
   1100     1394.19    420.1116   420.2898    1.6552     0.0036      0.0    
   1200     1521.84    419.2785   420.2875    1.4312     0.0033      0.0    
   1300      1649.4    420.833    420.3629    1.7501     0.0026      0.0    
   1400     1777.07    419.2183   420.0087    1.4255     0.0021      0.0    
   1500     1904.48    419.1572   420.4126    1.3926     0.0019      0.0    
   1600     2031.76    418.5238   419.959     1.3303     0.0016      0.0    
   1700      2159.3    418.6902   419.4117    1.2839     0.0015      0.0    
   1800     2286.75    418.1382   418.763     1.3026     0.0015      0.0    
   1900     2413.96    420.7054   420.4662    1.3996     0.0013      0.0    
   2000     2541.17    418.6062   418.8934    0.9722     0.0011      0.0    
   2100     2668.33    419.6073   421.0944    1.5726     0.001       0.0    
   2200     2795.63    418.8794   419.1662    1.0363     0.0008      0.0    
   2300     2922.93    419.2886   420.0955    1.2577     0.0008      0.0    
   2400      3050.1    418.5977   419.2236     1.01      0.0008      0.0    
   2500     3177.76    418.1627   418.8514    1.3342     0.0007      0.0    
   2600     3306.09    417.842    420.2101    1.1608     0.0006      0.0    
   2700     3433.14    418.3371   419.5849    1.5858     0.0007      0.0    
   2800      3560.3    418.4671    419.88     1.2962     0.0006      0.0    
   2900     3687.42    419.6615   419.5779    1.2886     0.0006      0.0    
   3000     3814.51    418.6889   419.5038    1.1894     0.0005      0.0    
   3100     3941.49    419.0836   419.207     0.9138     0.0005      0.0    
   3200      4068.7    419.0682   419.1006    1.201      0.0005      0.0    
   3300     4195.66    418.023    419.4361    1.0803     0.0004      0.0    
   3400     4322.87    418.8866   419.1273    1.0516     0.0005      0.0    
   3500     4449.74    417.1157   418.6202    1.0832     0.0004      0.0    
   3600     4576.63    418.7084   418.7223    1.0702     0.0004      0.0    
   3700     4703.55    419.1172   419.1621    1.0522     0.0003      0.0    
   3800     4830.34    418.8713   418.6561    0.9574     0.0003      0.0    
   3900      4957.3    419.0851   418.7211    1.0813     0.0003      0.0    
   4000     5084.47    418.7052   419.3195    1.1562     0.0003      0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       118.53    434.9388   438.0048    3.1616     0.183       0.0    
   200       246.84    423.8882   426.8827    2.8698     0.086       0.0    
   300       374.98    423.0525   425.6536    3.034      0.0296      0.0    
   400       503.14    421.2392   422.977     2.3229     0.0186      0.0    
   500       631.45    421.7636   423.8759    2.0391     0.0104      0.0    
   600       759.68    421.0356   422.4791    1.9926     0.0054      0.0    
   700       888.09    420.2209   422.8151    1.9356     0.0076      0.0    
   800       1016.5    418.6395   421.1052    1.9359     0.0048      0.0    
   900      1144.99    419.8366   420.9364    1.4983     0.0032      0.0    
   1000     1273.49    420.0657   421.0951    1.3713     0.0035      0.0    
   1100     1402.07    421.3673   422.5609    1.9358     0.003       0.0    
   1200     1530.54    419.8766   421.4583    1.6855     0.002       0.0    
   1300     1658.15    420.2353   422.4426    1.3524     0.0014      0.0    
   1400     1786.01    419.8804   421.7644    1.7727     0.0012      0.0    
   1500     1913.41    418.1868   420.2674    1.6505     0.0016      0.0    
   1600      2040.9    419.645    421.1147    1.3134     0.0017      0.0    
   1700     2168.49    420.5401   422.3157    1.2946     0.001       0.0    
   1800     2295.96    418.5907   420.2704    1.5086     0.0011      0.0    
   1900     2423.41    420.205    421.0823    1.346      0.0008      0.0    
   2000     2550.94    419.314    420.8159    1.613      0.0008      0.0    
   2100     2678.24    418.4593   420.3435    1.0263     0.0007      0.0    
   2200     2805.66    418.061    420.0955    1.3033     0.0007      0.0    
   2300     2932.98    418.3117   419.8746    1.3075     0.0006      0.0    
   2400     3060.36    417.7257   419.6438    1.3619     0.0006      0.0    
   2500      3187.7    418.1062   419.3058    1.0771     0.0006      0.0    
   2600     3315.09    418.025    419.268     1.248      0.0005      0.0    
   2700     3442.43    419.1576   420.1881    1.112      0.0004      0.0    
   2800     3569.87    418.9473   419.9053    1.1498     0.0005      0.0    
   2900     3697.55    419.0339   420.3503    1.2065     0.0004      0.0    
   3000     3824.92    418.1639   419.6242    0.9695     0.0004      0.0    
   3100     3952.33    417.6544   419.4805    1.2989     0.0004      0.0    
   3200     4079.72    417.6281   419.3504    1.0379     0.0004      0.0    
   3300     4207.01    419.3186   420.2715    1.1642     0.0004      0.0    
   3400     4334.62    417.9071   419.4959     1.02      0.0003      0.0    
   3500     4461.89    417.5998   419.1686    1.0771     0.0003      0.0    
   3600     4588.97    417.5448   419.2143    0.8847     0.0003      0.0    
   3700     4715.92    418.3834   419.8909    0.9254     0.0003      0.0    
   3800     4842.88    417.6988   418.9701    1.1072     0.0003      0.0    
   3900     4969.92    418.6315   419.5823    0.9123     0.0003      0.0    
   4000     5096.81    418.8081   419.8428    0.9442     0.0002      0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       118.14    440.4519   441.1277    3.1621     0.3955     0.0001  
   200       246.27    426.169    427.5624    2.8974     0.0664      0.0    
   300       374.33    426.5299   427.371     2.6491     0.0316      0.0    
   400       502.32    422.4224   424.1744    2.3076     0.0205      0.0    
   500       630.1     420.702    423.0728    2.0297     0.0102      0.0    
   600       758.16    421.8794   422.9872    2.228      0.0101      0.0    
   700       885.91    420.3198   422.1307    1.6161     0.007       0.0    
   800      1013.54    419.4522   421.252     1.6388     0.0049      0.0    
   900      1141.27    420.182    422.7102    1.5496     0.0053      0.0    
   1000     1268.77    420.0151   421.1174    1.5645     0.0051      0.0    
   1100     1396.39    420.6922   422.0523    1.4918     0.0027      0.0    
   1200     1524.24    420.7026   422.4739    1.6527     0.0021      0.0    
   1300     1651.72    419.1446   420.1712    1.4855     0.0025      0.0    
   1400      1779.2    418.776    420.3918    1.7572     0.0016      0.0    
   1500     1906.85    419.0132   420.3253    1.4678     0.0016      0.0    
   1600     2034.31    418.7116   420.929     1.7155     0.0015      0.0    
   1700     2161.73    419.7153   420.6851    1.544      0.0013      0.0    
   1800     2289.01    419.351    420.627     1.3353     0.0013      0.0    
   1900     2416.06    418.4247   419.4732    1.3596     0.0011      0.0    
   2000     2543.28    419.6793   421.0597    1.3516     0.001       0.0    
   2100     2670.41    418.3638   421.067     1.5015     0.0006      0.0    
   2200     2797.57    418.6372   420.0189    1.3586     0.0008      0.0    
   2300     2924.66    417.8808   419.7852    1.2352     0.0008      0.0    
   2400     3051.54    418.5884   419.9098    1.1386     0.0008      0.0    
   2500     3178.68    417.8977   419.3744    1.2311     0.0008      0.0    
   2600     3305.79    419.1476   420.2909    1.2422     0.0005      0.0    
   2700     3432.69    418.4611   419.9616    1.1045     0.0006      0.0    
   2800     3559.55    418.2225   419.1498    1.0516     0.0005      0.0    
   2900     3686.66    418.2219   419.5128    1.2451     0.0004      0.0    
   3000     3813.68    417.3794   419.5157    1.4116     0.0005      0.0    
   3100     3940.93    417.8246   419.6931    0.8901     0.0004      0.0    
   3200     4067.59    419.0961   420.1309    1.2679     0.0003      0.0    
   3300     4194.26    416.9993   419.3902    1.2418     0.0004      0.0    
   3400     4320.89    418.3592   420.6122    1.0387     0.0004      0.0    
   3500      4447.6    417.4116   419.3331    0.9549     0.0003      0.0    
   3600     4574.39    417.1788   419.5034    0.9365     0.0003      0.0    
   3700     4701.03    417.1769   419.2451    1.0948     0.0003      0.0    
   3800     4827.64    417.7805   419.0331    1.1199     0.0003      0.0    
   3900     4954.34    417.5714   419.0749    1.1028     0.0002      0.0    
   4000     5080.97    417.527    419.6518    1.0929     0.0002      0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       117.92    440.7391   441.6468    3.1622     0.5708     0.0001  
   200       246.39    428.3689   430.2145    2.9864     0.062       0.0    
   300       374.61    423.4025   425.1805    2.5543     0.0193      0.0    
   400       502.63    421.7485   423.8515    2.7067     0.0207      0.0    
   500       631.09    420.5058   422.8106    2.1354     0.007       0.0    
   600       758.49    420.2355   422.8216    1.7371     0.009       0.0    
   700       885.88    420.3331   422.6628    1.663      0.0081      0.0    
   800      1013.16    419.8441   422.6044    1.6552     0.0056      0.0    
   900      1140.45    419.8583   421.6133    1.6725     0.0031      0.0    
   1000     1267.62    421.0541   422.4073    1.8763     0.0027      0.0    
   1100      1394.8    420.5854   422.857     1.5714     0.004       0.0    
   1200     1522.03    418.6142   421.3385    1.7022     0.0015      0.0    
   1300     1649.09    418.248    420.4283    1.7233     0.0015      0.0    
   1400     1776.26    420.6164   422.128     1.6081     0.0019      0.0    
   1500     1903.23    420.0121   421.1088    1.7136     0.002       0.0    
   1600     2030.11    419.3602   421.5937    1.3769     0.0017      0.0    
   1700     2156.96    419.1517   421.3226    1.4159     0.0013      0.0    
   1800     2284.16    417.7457   420.2476    1.1882     0.0011      0.0    
   1900     2411.68    418.9032   421.0146    1.3677     0.001       0.0    
   2000     2538.87    417.826    420.0948    1.0919     0.0012      0.0    
   2100     2665.86    418.2838   421.2446    1.2302     0.0012      0.0    
   2200     2792.82    419.0643   420.8897    1.6514     0.0008      0.0    
   2300     2919.81    418.056    420.2444    1.6274     0.0006      0.0    
   2400     3046.84    419.8731   421.754     1.4459     0.0008      0.0    
   2500     3174.04    418.4955   420.1376    1.3165     0.0008      0.0    
   2600     3301.02    419.2638   421.8551    1.4036     0.0007      0.0    
   2700     3427.88    417.8643   420.4586    1.2666     0.0005      0.0    
   2800     3554.75    417.8468   420.4439    1.6151     0.0005      0.0    
   2900     3681.58    420.7127   421.5446    1.1125     0.0005      0.0    
   3000     3808.36    417.7162   419.9668    0.946      0.0005      0.0    
   3100      3935.1    417.8195   419.946     1.0604     0.0004      0.0    
   3200     4061.84    418.5082   420.1535    1.0804     0.0004      0.0    
   3300     4188.55    417.4574   419.8275    1.0738     0.0004      0.0    
   3400     4315.53    417.2535   420.3667    1.0883     0.0003      0.0    
   3500     4442.29    416.7022   419.2986    1.2268     0.0004      0.0    
   3600     4568.99    417.3851   419.7741    1.0186     0.0003      0.0    
   3700      4695.7    416.4367   419.5682     0.96      0.0003      0.0    
   3800     4822.41    417.0359   419.3644    1.3128     0.0003      0.0    
   3900     4949.45    416.9949   419.5866    1.066      0.0003      0.0    
   4000      5076.0    417.3717   419.7294    1.1453     0.0003      0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       118.47    439.8355   441.0633    3.1621     0.5507     0.0001  
   200       248.38    425.082    425.9736    2.7457     0.0969      0.0    
   300       378.15    425.7084   426.7782    2.7949     0.0331      0.0    
   400       507.81    425.1102   425.1195    2.256      0.0255      0.0    
   500       637.76    419.7905   422.0197    1.9567     0.0112      0.0    
   600       767.5     422.2216   424.5467    2.0962     0.0077      0.0    
   700       897.19    420.1398   422.496     1.8288     0.0069      0.0    
   800      1027.15    419.1058   421.4272    1.5953     0.0087      0.0    
   900      1156.76    419.7466   422.1187    1.7679     0.0042      0.0    
   1000     1286.27    418.7133   421.6148    1.8946     0.003       0.0    
   1100     1415.88    419.2656   421.9414    1.2951     0.0027      0.0    
   1200     1545.38    418.5662   421.1826    1.4833     0.0035      0.0    
   1300     1674.81    420.2483   421.9548    1.4524     0.0026      0.0    
   1400     1804.26    419.826    420.8034    1.4861     0.0023      0.0    
   1500     1933.79    418.3235   421.5142    1.6586     0.0022      0.0    
   1600     2062.99    419.5277   420.4781    1.5179     0.0017      0.0    
   1700     2192.25    419.2723   421.1494    1.6124     0.0019      0.0    
   1800     2321.48    418.563    420.2561    1.3134     0.0014      0.0    
   1900      2450.7    417.5663   420.033     1.6756     0.0006      0.0    
   2000     2579.76    419.1798   420.902     1.4391     0.0007      0.0    
   2100     2709.29    418.839    420.4278    1.5269     0.0009      0.0    
   2200     2838.74    420.7232   421.8507    1.4002     0.0007      0.0    
   2300     2968.03    419.0039   420.3186    1.4027     0.0008      0.0    
   2400     3097.51    419.3603   421.0206    1.2759     0.0009      0.0    
   2500     3226.74    417.6758   419.7326    1.0599     0.0008      0.0    
   2600     3355.87    418.7997   420.7509    0.9015     0.0007      0.0    
   2700     3485.07    418.1446   419.9685    1.2172     0.0007      0.0    
   2800     3614.12    418.5239   420.347     1.1965     0.0006      0.0    
   2900     3743.19    417.9709   420.2402    1.185      0.0006      0.0    
   3000     3872.17    418.1593   419.9009    1.0945     0.0005      0.0    
   3100     4001.53    418.7654   420.0478    1.1233     0.0004      0.0    
   3200     4130.62    417.8199   419.3808    1.0327     0.0003      0.0    
   3300     4259.74    418.8769   419.8287    1.1618     0.0004      0.0    
   3400     4388.85    417.6477   419.451     1.1697     0.0004      0.0    
   3500     4518.03    417.1841   419.6201    1.4581     0.0003      0.0    
   3600     4647.01    418.1026   419.556     1.0526     0.0004      0.0    
   3700     4776.02    417.1712   419.614     1.067      0.0003      0.0    
   3800     4905.06    417.8833   420.1963    1.1354     0.0004      0.0    
   3900     5033.95    417.6567   419.1756    1.0133     0.0004      0.0    
   4000     5162.73    417.0779   418.9316    0.9856     0.0003      0.0    
