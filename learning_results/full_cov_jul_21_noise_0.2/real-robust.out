Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  7.502399444580078
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       300.08    436.1004   438.047     3.1621     0.2111      0.0    
   200       607.82    425.4116   425.9633    2.7904      0.0        0.0    
   300       915.35    421.3847   421.9326    2.3651      0.0        0.0    
   400      1224.42    420.8172   420.8206    2.2187      0.0        0.0    
   500      1534.97    420.667    420.8124    2.1303      0.0        0.0    
   600      1844.36    421.033    420.9382    2.1526      0.0        0.0    
   700      2154.06    419.166    419.6981    1.6075      0.0        0.0    
   800      2463.38    420.5035   420.552     1.8969      0.0        0.0    
   900      2772.27    419.557    419.5669    1.6824      0.0        0.0    
   1000      3080.1    420.0516   419.3316    1.4714      0.0        0.0    
   1100      3386.3    419.9951    420.5      1.3505      0.0        0.0    
   1200     3693.23    420.0449   420.1696    1.3819      0.0        0.0    
   1300     3999.32    419.0218   419.6954    1.2648      0.0        0.0    
   1400     4305.11    419.2813   419.7134    1.4441      0.0        0.0    
   1500     4610.59    418.8557   419.3511    1.6478      0.0        0.0    
   1600     4916.59    419.7735   419.9472    1.0815      0.0        0.0    
   1700     5222.46    419.1151   419.4829    1.2248      0.0        0.0    
   1800     5527.67    418.9784   419.065     1.454       0.0        0.0    
   1900     5834.94    418.8831   419.3232    1.2573      0.0        0.0    
   2000      6141.2    417.9821   418.9567    1.1537      0.0        0.0    
   2100     6446.84    418.4011   418.9471    1.4476      0.0        0.0    
   2200     6752.69    417.593    419.1339    1.0294      0.0        0.0    
   2300     7059.01    417.5253   418.9376    1.0964      0.0        0.0    
   2400     7364.94    418.2109   418.642     0.9569      0.0        0.0    
   2500     7671.57    418.4993   419.2846    1.6196      0.0        0.0    
   2600     7977.84    418.8908   418.7288    1.1749      0.0        0.0    
   2700     8284.13    417.7114   418.7367    1.1787      0.0        0.0    
   2800     8589.79    419.1744   418.8589    1.0518      0.0        0.0    
   2900     8895.07    418.7955   419.0982    1.0503      0.0        0.0    
   3000     9200.71    417.4821   418.6001    0.9422      0.0        0.0    
   3100     9506.18    418.2164   418.4753    0.9868      0.0        0.0    
   3200     9813.17    417.8703   418.6785    1.1892      0.0        0.0    
   3300     10120.47   417.6575    418.17     1.0817      0.0        0.0    
   3400     10427.79   418.0788   418.2719    1.0603      0.0        0.0    
   3500     10734.72   417.8101   418.4306    0.972       0.0        0.0    
   3600     11041.27   417.8207   418.6505    1.0284      0.0        0.0    
   3700     11348.3    417.5178   418.3006    0.9676      0.0        0.0    
   3800     11654.75   418.4284   417.9503    1.2582      0.0        0.0    
   3900     11960.36   418.0318   418.4307    0.9132      0.0        0.0    
   4000     12265.96   417.4062   418.3746    1.2332      0.0        0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       297.89    438.147    440.5765    3.1623     0.2724      0.0    
   200       605.34    428.6542   428.017     3.0972      0.0        0.0    
   300       912.26    423.9289   424.4503    2.3719      0.0        0.0    
   400      1219.81    421.9234    423.24     2.1655      0.0        0.0    
   500      1526.95    420.5026   422.6478    1.7094      0.0        0.0    
   600      1833.82    421.0796   422.648     1.9632      0.0        0.0    
   700      2140.69    420.164    421.3031    1.7004      0.0        0.0    
   800      2447.23    420.5703   421.4195    1.9676      0.0        0.0    
   900      2754.13    418.6071   420.1871    1.7914      0.0        0.0    
   1000     3061.45    418.3633   420.1626    1.5668      0.0        0.0    
   1100     3369.18    418.7575   420.4288    1.7014      0.0        0.0    
   1200     3676.67    418.875    419.7192    1.7834      0.0        0.0    
   1300      3983.9    420.2878   420.8984    1.378       0.0        0.0    
   1400     4291.71    418.2808   420.7678    1.1958      0.0        0.0    
   1500     4599.22    418.8312   419.8711    1.1518      0.0        0.0    
   1600     4907.76    417.2766   419.6331    1.5834      0.0        0.0    
   1700     5216.73    418.728    419.2525    1.1375      0.0        0.0    
   1800     5523.67    419.6443   419.8324    1.2878      0.0        0.0    
   1900     5830.44    418.4298   419.9748    1.3609      0.0        0.0    
   2000     6137.86    417.8719   419.9938    1.2497      0.0        0.0    
   2100     6444.95    418.1751   419.2433    1.3242      0.0        0.0    
   2200     6752.51    417.6338   419.4996    1.2289      0.0        0.0    
   2300     7059.61    418.9144   419.9723    1.1916      0.0        0.0    
   2400     7366.99    417.9934   419.0792    1.1782      0.0        0.0    
   2500     7674.06    417.7529   419.9413    1.1346      0.0        0.0    
   2600     7981.48    417.6329   419.2371    0.9074      0.0        0.0    
   2700     8288.02    417.8968   419.0866    0.9221      0.0        0.0    
   2800      8595.6    418.0714   419.1931    1.0045      0.0        0.0    
   2900      8903.4    418.3014   419.2527    0.9876      0.0        0.0    
   3000     9210.78    417.3445   419.2804    1.2737      0.0        0.0    
   3100     9518.18    418.6585   419.3731    1.054       0.0        0.0    
   3200     9826.02    417.5429   419.5894    0.9407      0.0        0.0    
   3300     10133.83   417.7301   418.5172    0.975       0.0        0.0    
   3400     10440.92   418.089    418.9838    1.0366      0.0        0.0    
   3500     10747.87   416.7921   418.9848    0.9843      0.0        0.0    
   3600     11054.85   418.2081   419.3745    1.0878      0.0        0.0    
   3700     11362.22   417.8194   419.1768    1.442       0.0        0.0    
   3800     11669.45   417.2906   418.7734    0.9684      0.0        0.0    
   3900     11976.43   417.5833   418.8022    0.7439      0.0        0.0    
   4000     12283.41   416.4174   418.2435    1.1713      0.0        0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       297.89    440.8757   441.3621    3.1623    21.5498      0.0    
   200       605.39    427.5845   427.7859    3.0003      0.0        0.0    
   300       913.06    425.9638   425.8351    2.4938      0.0        0.0    
   400      1220.64    421.6591   423.5366    2.0077      0.0        0.0    
   500      1528.08    420.3846   422.5601    2.4077      0.0        0.0    
   600      1836.72    420.4053   421.3785    1.7808      0.0        0.0    
   700      2144.27    419.2299   420.6487    1.6504      0.0        0.0    
   800      2451.23    419.4151   420.5495    1.9482      0.0        0.0    
   900      2757.96    418.5686   419.8644    1.3891      0.0        0.0    
   1000     3064.77    418.4329   420.482     1.384       0.0        0.0    
   1100      3371.6    419.1058   421.0623    1.6701      0.0        0.0    
   1200     3679.24    417.8843   420.114     1.5699      0.0        0.0    
   1300     3987.38    419.3268   420.8508    1.5696      0.0        0.0    
   1400     4294.77    418.4647   420.2997    1.4846      0.0        0.0    
   1500     4602.05    418.7603   419.9637    1.4709      0.0        0.0    
   1600     4908.63    417.8042   419.6762    1.3288      0.0        0.0    
   1700     5215.25    418.6736   419.7642    1.3336      0.0        0.0    
   1800     5522.11    418.8757   420.1776    1.2684      0.0        0.0    
   1900     5829.26    417.9353   419.7066    1.3353      0.0        0.0    
   2000     6136.69    417.764    419.4648    1.2494      0.0        0.0    
   2100     6443.74    417.7857   419.4938    1.3068      0.0        0.0    
   2200     6750.33    417.6402   419.4066    1.5873      0.0        0.0    
   2300     7057.48    417.7962   418.9342    1.1461      0.0        0.0    
   2400     7364.69    417.4865   419.0522    1.2712      0.0        0.0    
   2500     7671.44    417.2545   419.1747    1.0443      0.0        0.0    
   2600     7979.53    417.5221   419.1093    0.9106      0.0        0.0    
   2700     8288.27    416.5929   419.1042    1.2108      0.0        0.0    
   2800     8597.97    417.803    419.2736    1.2672      0.0        0.0    
   2900      8907.9    417.2635   419.1529    0.8819      0.0        0.0    
   3000     9216.03    417.0155   419.4566    1.0168      0.0        0.0    
   3100     9526.64    418.5928   420.0823    1.0208      0.0        0.0    
   3200      9836.1    418.0205   419.8026    0.8862      0.0        0.0    
   3300     10144.55   417.0753   418.746     1.1231      0.0        0.0    
   3400     10459.1    416.8646   418.4916    0.9422      0.0        0.0    
   3500     10775.26   417.6924   419.4524    1.1045      0.0        0.0    
   3600     11087.74   417.8585   418.9055    0.9884      0.0        0.0    
   3700     11400.03   417.368    418.6388    0.8797      0.0        0.0    
   3800     11710.97   417.3546   419.0199    1.1713      0.0        0.0    
   3900     12021.44   417.3846   418.7021    0.9869      0.0        0.0    
   4000     12331.96   417.6774   418.5849    0.9369      0.0        0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       298.84    439.1165   442.0771    3.1622     0.6801      0.0    
   200       607.18    423.9497   424.9686    2.7606      0.0        0.0    
   300       918.26    423.2651   423.5795    2.548       0.0        0.0    
   400      1228.08    424.241    425.7319    2.4818      0.0        0.0    
   500      1551.19    421.6953   423.8598    1.8272      0.0        0.0    
   600       1868.5    419.9204   421.7018    1.8095      0.0        0.0    
   700      2182.25    418.7288   421.2461    1.8924      0.0        0.0    
   800      2496.83    419.7072   421.7337    1.6544      0.0        0.0    
   900      2812.41    418.2532   420.608     1.573       0.0        0.0    
   1000     3125.47    419.4683   421.818     1.697       0.0        0.0    
   1100     3437.28    418.7877   420.6952    1.4213      0.0        0.0    
   1200     3747.23    419.011    421.1046    1.9573      0.0        0.0    
   1300     4057.35    417.9114   420.2395    1.5894      0.0        0.0    
   1400     4367.15    418.5182   420.133     1.5536      0.0        0.0    
   1500     4678.58    418.3313   419.7462    1.5808      0.0        0.0    
   1600     4988.93    418.2461   419.5922    1.0401      0.0        0.0    
   1700     5305.45    418.8298   420.9505    1.5126      0.0        0.0    
   1800     5619.03    417.9484   419.6635    1.0828      0.0        0.0    
   1900      5931.5    418.3829   419.5171    1.5375      0.0        0.0    
   2000     6242.94    419.0156   420.5119    1.4505      0.0        0.0    
   2100     6552.76    418.2477   420.4004    1.1574      0.0        0.0    
   2200     6864.02    417.814    420.2349    1.1597      0.0        0.0    
   2300     7175.61    418.5548   420.6925    1.6116      0.0        0.0    
   2400     7482.57    417.7173   419.5855    1.0523      0.0        0.0    
   2500     7789.18    417.6084   419.5165    1.3202      0.0        0.0    
   2600     8095.38    417.9641   419.6188    1.0041      0.0        0.0    
   2700      8401.4    418.0949   419.8027    1.1781      0.0        0.0    
   2800      8707.9    418.3514   420.4863    1.1867      0.0        0.0    
   2900     9013.96    417.927    420.1206    1.128       0.0        0.0    
   3000     9320.32    417.7566   419.4508    0.9398      0.0        0.0    
   3100      9627.0    416.811    418.8571    1.2751      0.0        0.0    
   3200     9933.64    416.2866   419.1345    0.8776      0.0        0.0    
   3300     10240.34   417.1762   419.4372    0.8839      0.0        0.0    
   3400     10546.49   417.1478   419.4017    0.9996      0.0        0.0    
   3500     10852.94   418.2637   419.9491    1.455       0.0        0.0    
   3600     11159.26   417.2545   419.4654    1.216       0.0        0.0    
   3700     11465.55   417.723    419.4757    1.1405      0.0        0.0    
   3800     11771.66   416.9646   419.0484    1.0091      0.0        0.0    
   3900     12079.37   417.0629   419.1335    1.1052      0.0        0.0    
   4000     12387.3    417.0743   419.4322    0.8493      0.0        0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       298.69    440.2642   441.2293    3.1621     2.5923      0.0    
   200       608.3     427.4646   428.4339    3.0571      0.0        0.0    
   300       918.34    421.6642   424.0567    2.5153      0.0        0.0    
   400      1228.86    420.2432   423.7394    2.3745      0.0        0.0    
   500      1538.95    422.3103   422.7913    2.2064      0.0        0.0    
   600      1849.85    420.9705   422.092     1.9427      0.0        0.0    
   700       2161.2    420.3276   421.2353    1.7574      0.0        0.0    
   800      2471.83    419.5091   420.793     1.7322      0.0        0.0    
   900      2783.33    421.1639   422.4783    1.8292      0.0        0.0    
   1000     3093.65    418.9898   420.8069    1.8594      0.0        0.0    
   1100     3403.26    418.0122   420.5749    1.8057      0.0        0.0    
   1200     3712.38    419.3652   420.881     1.8454      0.0        0.0    
   1300     4021.21    418.4417   420.4339    1.3978      0.0        0.0    
   1400     4329.95    418.696    420.2684    1.4834      0.0        0.0    
   1500      4638.7    418.9587   420.7747    1.2035      0.0        0.0    
   1600     4947.82    417.1536   419.3732    1.3096      0.0        0.0    
   1700      5256.7    418.5336   420.3538    1.3971      0.0        0.0    
   1800     5565.48    418.8931    419.91     1.1743      0.0        0.0    
   1900     5874.18    418.4533   420.0088    1.5162      0.0        0.0    
   2000     6183.14     418.98    420.0856    1.1286      0.0        0.0    
   2100     6491.89    418.1627   419.9096    1.4337      0.0        0.0    
   2200     6801.11    417.9166   419.7375    1.2393      0.0        0.0    
   2300     7109.65    418.3102   419.6475    1.2331      0.0        0.0    
   2400      7418.4    417.1274   419.6614    1.2492      0.0        0.0    
   2500     7726.96    417.3493   419.1871    1.0234      0.0        0.0    
   2600      8035.7    417.2347   419.5193    1.3551      0.0        0.0    
   2700     8344.07    417.5835   419.5959    1.2235      0.0        0.0    
   2800     8656.92    417.2654   419.1824    0.7756      0.0        0.0    
   2900     8969.67    417.1076   418.7635    1.0676      0.0        0.0    
   3000     9280.62    417.3374   419.2581    1.1449      0.0        0.0    
   3100     9589.98    417.5474   419.3918    1.0119      0.0        0.0    
   3200     9901.75    418.4215   419.3117    1.089       0.0        0.0    
   3300     10212.9    417.026    419.2599    1.1864      0.0        0.0    
   3400     10522.78   417.7945   419.2576    1.0587      0.0        0.0    
   3500     10831.89   417.0737   419.0457    1.1453      0.0        0.0    
   3600     11141.1    417.397    418.9625    0.9427      0.0        0.0    
   3700     11450.43   417.123    419.1532    0.9515      0.0        0.0    
   3800     11760.06   417.3845   419.2007    1.0697      0.0        0.0    
   3900     12078.65   417.4767   419.1355    1.2327      0.0        0.0    
   4000     12397.51   417.376    418.8712    0.8785      0.0        0.0    
