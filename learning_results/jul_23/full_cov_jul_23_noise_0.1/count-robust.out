Generating synthetic count valued data ... 
Generating synthetic  count valued data took:  10.479881763458252
max_count =  19  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       644.62     4.1442     4.1804     0.3031     2.4047   128578.01  104428.24     0.0    
   200      1477.72     4.1039     4.1406     0.2934     1.6632   121747.77   98833.92     0.0    
   300      2309.57     3.9496     3.9848     0.286      1.1585   101895.99   82650.91     0.0    
   400      3137.46     3.6195     3.6508     0.2609     0.8816    74988.5    60773.34     0.0    
   500      3961.18     3.1448     3.1705     0.2267     0.6753    53474.06   43309.02     0.0    
   600      4786.48     2.6403     2.6595     0.2349     0.759     40989.83   33153.12     0.0    
   700      5608.11     2.1943     2.2072     0.1945     0.6717    34418.42   27812.66     0.0    
   800      6429.35     1.8447     1.8494     0.2058     0.6643    31009.71   25059.08     0.0    
   900      7248.08     1.5977     1.6017     0.2233     0.9408    29221.82   23612.44     0.0    
   1000      8066.3     1.4325     1.4307     0.2556     0.5206    28261.11   22834.71     0.0    
   1100     8886.61     1.3191     1.3162     0.1569     0.2269    27721.34   22404.19     0.0    
   1200      9693.0     1.2453     1.239      0.1226     0.8624    27359.11   22101.06     0.0    
   1300     10485.84    1.1951     1.1897     0.1636     0.5835    27151.48   21951.71     0.0    
   1400     11277.55    1.1615     1.1568     0.1525     0.6033    27007.28   21827.25     0.0    
   1500     12053.31    1.1417     1.1333     0.1199     0.1492    26959.59   21790.61     0.0    
   1600     12845.2     1.1244     1.1174     0.1218     0.0798    26873.88   21717.54     0.0    
   1700     13658.24    1.113      1.1051     0.0887     0.1856    26793.57   21653.06     0.0    
   1800     14469.83    1.1045     1.095      0.1513     0.5964    26772.44   21626.3      0.0    
   1900     15280.96    1.0947     1.0865     0.0759     0.0315    26725.55   21591.3      0.0    
   2000     16058.53    1.0897     1.0832      0.12      0.8234    26691.5    21562.84     0.0    
   2100     16798.65    1.0819     1.0753     0.0823     0.0364    26679.12   21552.38     0.0    
   2200     17517.39    1.0811     1.0732     0.151      0.5573    26648.92   21533.38     0.0    
   2300     18235.53    1.0756     1.0689     0.0904     0.0103    26635.21   21526.48     0.0    
   2400     18953.13    1.0756     1.0702     0.111      0.0063    26626.94   21520.26     0.0    
   2500     19671.29    1.0724     1.0655     0.1812     0.0011    26602.49   21496.75     0.0    
   2600     20386.81    1.0729     1.0645     0.102      0.0068    26601.96   21488.33     0.0    
   2700     21104.34    1.0726     1.0627     0.1183     0.0009    26598.89   21494.82     0.0    
   2800     21821.44    1.0689     1.0629     0.0604     0.0079    26571.41   21477.8      0.0    
   2900     22538.75    1.0678     1.0596     0.1066     0.4427    26568.58   21479.15     0.0    
   3000     23256.16    1.0671     1.0571     0.0641     0.001     26568.05   21468.97     0.0    
   3100     23973.54    1.0691     1.0619     0.1138     0.2049    26587.0    21486.32     0.0    
   3200     24691.48    1.0671     1.0585     0.0574     0.008     26572.7    21467.06     0.0    
   3300     25409.04    1.0645     1.0556     0.0717     0.7502    26567.09   21470.86     0.0    
   3400     26125.61    1.0629     1.0559     0.1003     0.0438    26554.5    21463.52     0.0    
   3500     26842.19    1.0661     1.0569     0.1089     0.0079    26546.66   21447.63     0.0    
   3600     27559.0     1.0623     1.0559     0.0866     0.072     26547.5    21449.57     0.0    
   3700     28275.81    1.0644     1.0544     0.0721     0.0019    26536.39   21440.81     0.0    
   3800     28992.19    1.0646     1.0553     0.0913     0.0016    26522.37   21436.21     0.0    
   3900     29709.11    1.0627     1.0552     0.0688     0.0124    26533.5    21431.89     0.0    
   4000     30425.61    1.0632     1.0557     0.0975     0.0024    26531.2    21435.42     0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       569.1       4.16      4.1831     0.3023     1.9148   129038.24  208662.51     0.0    
   200      1371.04     4.1247     4.1474     0.3038     1.4068   123198.54  199176.47     0.0    
   300      2173.04     3.974      3.9962     0.2885     0.6967   103899.13  167953.12     0.0    
   400      2973.06     3.6477     3.6681     0.286      0.7601    76588.08  123812.24     0.0    
   500      3770.54     3.1769     3.1937     0.2243     0.2381    54432.82   87984.12     0.0    
   600      4567.15     2.6722     2.6855     0.2375     1.0206    41434.69   67009.41     0.0    
   700      5361.12     2.224      2.2339     0.2023      1.07     34561.63   55890.0      0.0    
   800      6152.87     1.877      1.8827     0.2819     0.5025    31032.99   50205.63     0.0    
   900      6944.59     1.6296     1.6343     0.2192     2.2977    29197.91   47228.81     0.0    
   1000     7733.46     1.459      1.4601     0.2439     1.3757    28206.59   45631.68     0.0    
   1100     8520.75     1.3439     1.3463     0.131      0.7434    27574.26   44631.14     0.0    
   1200     9309.71     1.2643     1.2639     0.1891     0.1034    27184.09   44006.57     0.0    
   1300     10097.07    1.2073     1.209      0.1073     0.5468    26953.65   43640.16     0.0    
   1400     10883.23    1.1696     1.1703     0.1527     0.0397    26818.45   43402.98     0.0    
   1500     11669.52    1.1475     1.1476     0.1546     0.5563    26721.83   43248.36     0.0    
   1600     12456.09    1.1224     1.1223     0.1048     0.5716    26624.44   43090.26     0.0    
   1700     13244.18    1.1068     1.1062     0.1233     0.7992    26575.21   43024.59     0.0    
   1800     14031.77    1.0969     1.0957     0.1043     0.8567    26537.82   42947.04     0.0    
   1900     14818.14    1.0904     1.0887     0.1443     0.3015    26484.43   42871.45     0.0    
   2000     15608.89    1.0811     1.0808     0.0621     0.0209    26469.72   42845.98     0.0    
   2100     16406.7     1.0745     1.071      0.0986     0.0239    26449.6    42809.6      0.0    
   2200     17193.52    1.0667     1.0672     0.139      0.0094    26408.07   42736.93     0.0    
   2300     17979.95    1.0645     1.0641     0.0659     0.1102    26392.62   42720.9      0.0    
   2400     18766.35    1.0629     1.0619     0.1439     0.0029    26371.3    42682.73     0.0    
   2500     19553.54    1.0649     1.0614     0.1362     0.0935    26387.15   42696.7      0.0    
   2600     20339.01    1.0585     1.0557     0.0714     0.0067    26357.2    42647.55     0.0    
   2700     21124.38    1.0563     1.0572     0.0813     0.012     26350.13   42651.64     0.0    
   2800     21910.5     1.0557     1.0533     0.0868     0.0069    26347.87   42644.33     0.0    
   2900     22697.27    1.0553     1.0528     0.0891     0.1709    26343.12   42650.08     0.0    
   3000     23484.42    1.0526     1.0519     0.0792     0.0053    26338.5    42625.05     0.0    
   3100     24303.5     1.0559     1.0523     0.1421     0.0838    26332.75   42615.56     0.0    
   3200     25116.83    1.0518     1.049      0.1059     0.0023    26316.68   42592.87     0.0    
   3300     25935.89    1.0504     1.0472     0.0811     0.0084    26300.49   42567.18     0.0    
   3400     26744.8     1.0481     1.046      0.0668     0.0027    26298.52   42561.63     0.0    
   3500     27529.95    1.0488     1.0462     0.0642     0.2116    26305.2    42578.56     0.0    
   3600     28316.89    1.0464     1.0452     0.0701     0.4375    26283.41   42540.7      0.0    
   3700     29104.09    1.0479     1.0445     0.1087     0.0293    26270.66   42526.47     0.0    
   3800     29891.04    1.0487     1.047      0.1202     0.3671    26266.92   42513.72     0.0    
   3900     30698.81    1.0491     1.0452     0.0765     0.0317    26264.44   42495.84     0.0    
   4000     31512.48    1.0471     1.0452     0.0696     0.2447    26264.89   42493.74     0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       594.57     4.165      4.1822     0.3047     2.6364   129239.77  312300.67     0.0    
   200      1532.86     4.1329     4.1495     0.3045     2.4563   124027.89  299676.37     0.0    
   300      2470.85     3.9875     4.0039     0.2957     1.0318   105284.41  254422.07     0.0    
   400      3408.71     3.6631     3.6784     0.2605     1.1116    77684.52  187795.97     0.0    
   500      4347.09     3.1825     3.197      0.3005     0.5432    54708.74  132392.13     0.0    
   600      5275.26     2.6647     2.6781     0.2199     1.3628    41279.12   99917.66     0.0    
   700      6187.71     2.2218     2.2324     0.2649     0.2173    34469.92   83433.1      0.0    
   800      7107.54     1.8824     1.8913     0.2084     1.1398    30973.42   74982.85     0.0    
   900      8037.71     1.6352     1.641      0.2307     0.7635    29110.27   70428.67     0.0    
   1000     8954.37     1.4633     1.4691     0.1652     0.8309    28087.49   67982.71     0.0    
   1100     9850.77     1.3475     1.3507     0.2035     0.0559    27493.4    66540.79     0.0    
   1200     10728.49    1.2692     1.2726     0.1905     0.101     27142.84   65694.07     0.0    
   1300     11622.7     1.2138     1.2141     0.1768     0.0207    26883.25   65078.34     0.0    
   1400     12518.85    1.1756     1.1761     0.2228     0.6742    26729.97   64665.84     0.0    
   1500     13391.45    1.1487     1.1474     0.1187     0.0884    26629.11   64413.1      0.0    
   1600     14255.01    1.1261     1.1235     0.1299     0.2583    26550.36   64225.53     0.0    
   1700     15160.89    1.1056     1.1043     0.1514     0.2894    26474.78   64042.75     0.0    
   1800     16081.6     1.0945     1.0915     0.0983     0.0429    26435.47   63942.46     0.0    
   1900     17000.35    1.0865     1.0839     0.1367     0.0019    26416.97   63956.01     0.0    
   2000     17914.35    1.0793     1.0773     0.0888     0.0087    26376.9    63808.69     0.0    
   2100     18793.03    1.073      1.0698     0.1473     0.035     26336.69   63724.75     0.0    
   2200     19681.81    1.0661     1.0635     0.0928     0.0399    26315.16   63669.14     0.0    
   2300     20571.86    1.0626     1.0616     0.0569     0.0034    26304.77   63631.25     0.0    
   2400     21462.48    1.0609     1.0582     0.0765     0.796     26283.59   63586.16     0.0    
   2500     22355.85    1.0572     1.0541     0.1634     0.0066    26299.43   63595.97     0.0    
   2600     23259.93    1.0548     1.0504     0.1135     0.1771    26272.5    63544.4      0.0    
   2700     24152.89    1.0569     1.051      0.1036     0.0037    26269.1    63528.47     0.0    
   2800     25047.08    1.0508     1.0476     0.0948     0.0813    26254.44   63497.96     0.0    
   2900     25945.93    1.051      1.0475     0.1088     0.0409    26250.37   63500.41     0.0    
   3000     26848.0     1.0475     1.0451     0.1213     0.0212    26233.86   63448.17     0.0    
   3100     27745.11    1.0483     1.0442     0.0906     0.0076    26227.87   63439.56     0.0    
   3200     28639.45    1.0478     1.0434     0.0914     0.0838    26227.87   63423.88     0.0    
   3300     29537.55    1.0449     1.0414     0.0548     0.264     26213.73   63398.32     0.0    
   3400     30429.65    1.0466     1.0434     0.0828     0.0069    26226.82   63418.45     0.0    
   3500     31317.15    1.0479     1.0422     0.0588     0.0018    26206.29   63368.3      0.0    
   3600     32181.52    1.0454     1.0406     0.0831     0.0099    26193.29   63341.52     0.0    
   3700     33077.61    1.043      1.0387     0.0782     0.0796    26184.64   63324.44     0.0    
   3800     33964.63    1.0446     1.0409     0.0621     0.0198    26190.71   63345.97     0.0    
   3900     34853.46    1.0431     1.0395     0.0774     0.0102    26184.25   63311.96     0.0    
   4000     35738.88    1.0441     1.0388     0.1024     0.4461    26177.61   63325.23     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       588.77     4.1664     4.1808     0.3042     2.6196   129281.03  416248.69     0.0    
   200      1576.51     4.1414     4.1554     0.3059     1.117    125198.26  403046.36     0.0    
   300      2568.49     4.0122     4.0268     0.2885     0.8199   108141.03  348133.71     0.0    
   400      3557.54     3.7107     3.7243     0.2745     0.8962    80877.96  260493.72     0.0    
   500      4540.96     3.254      3.266      0.2306     0.4416    57215.21  184405.11     0.0    
   600      5519.53     2.7522     2.7624     0.226      0.9949    42972.8   138638.05     0.0    
   700      6503.86     2.305      2.3136     0.2877     0.3485    35534.05  114688.98     0.0    
   800      7461.93     1.9495     1.9577     0.2235     0.4039    31637.61  102179.16     0.0    
   900      8392.09     1.6877     1.6944     0.1327     0.6128    29523.73   95373.56     0.0    
   1000     9320.88     1.4995     1.5068     0.2001     1.1063    28337.86   91585.33     0.0    
   1100     10249.3     1.372      1.3798     0.2762     1.8828    27664.46   89366.91     0.0    
   1200     11177.2     1.2886     1.2936     0.1987     0.2533    27274.27   88113.52     0.0    
   1300     12105.87    1.2251     1.2317     0.168      0.0433    26994.25   87234.81     0.0    
   1400     13032.66    1.1826     1.1867     0.1406     0.5682    26819.6    86638.28     0.0    
   1500     13960.08    1.1493     1.1527     0.1145     0.6092    26650.39   86093.96     0.0    
   1600     14887.23    1.1263     1.1294     0.1489     0.1003    26580.06   85872.84     0.0    
   1700     15812.96    1.1078     1.112       0.12      0.076     26519.21   85700.52     0.0    
   1800     16738.55    1.0971     1.0984     0.1935     0.0857    26528.63   85713.07     0.0    
   1900     17666.18    1.0894     1.0922     0.1176     0.6219    26449.57   85420.52     0.0    
   2000     18592.68    1.0808     1.0816     0.1321     0.4738    26399.37   85284.84     0.0    
   2100     19519.08    1.0749     1.0775     0.1025     0.0432    26372.19   85183.55     0.0    
   2200     20446.21    1.0678     1.0707     0.1296     0.2915    26350.63   85149.71     0.0    
   2300     21373.51    1.0629     1.0631     0.1047     0.0202    26346.83   85113.45     0.0    
   2400     22300.1     1.0617     1.0619     0.1359     0.7084    26322.86   85016.33     0.0    
   2500     23226.05    1.0582     1.0587     0.1495     0.0034    26298.69   84962.5      0.0    
   2600     24153.64    1.0533     1.0529     0.0949     0.0114    26290.11   84907.55     0.0    
   2700     25080.02    1.0536     1.0538     0.1313     0.3293    26287.14   84900.08     0.0    
   2800     26006.16    1.0503     1.0506     0.1219     0.0093    26249.94   84785.17     0.0    
   2900     26932.73    1.0499     1.0491     0.1132     0.0048    26230.95   84735.95     0.0    
   3000     27860.17    1.0463     1.0475     0.0983     0.0876    26231.56   84731.64     0.0    
   3100     28786.41    1.0459     1.0463     0.104      0.0964    26235.19   84750.83     0.0    
   3200     29712.71    1.0438     1.0445     0.1107     0.0056    26221.89   84705.39     0.0    
   3300     30639.84    1.0436     1.0443     0.1148     0.0617    26209.35   84651.51     0.0    
   3400     31566.17    1.0412     1.0425     0.0759     0.0664    26204.27   84638.86     0.0    
   3500     32492.94    1.0406     1.0421     0.1194     0.0028    26202.97   84648.11     0.0    
   3600     33419.82    1.0431     1.0424     0.1347     0.0308    26202.42   84605.1      0.0    
   3700     34347.03    1.0395     1.0398     0.1524     0.0079    26183.55   84555.35     0.0    
   3800     35273.69    1.0403     1.041       0.1       0.4535    26184.77   84574.98     0.0    
   3900     36200.61    1.0398     1.0397     0.0926     0.0086    26178.69   84526.24     0.0    
   4000     37127.63    1.0388     1.0395     0.0876     0.0029    26175.58   84524.79     0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.001  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       568.85     4.1676     4.1899     0.3035     1.9003   129263.65  521639.55     0.0    
   200      1623.93     4.1428     4.1644     0.3057     1.3853   125201.92  505124.24     0.0    
   300      2679.27     4.0145     4.0358     0.2901     1.2526   108199.29  436412.45     0.0    
   400      3707.53     3.7121     3.7319     0.2756     0.6176    80832.51  326071.86     0.0    
   500      4718.79     3.2457     3.2641     0.2932     0.5741    56829.03   229416.7     0.0    
   600      5725.21     2.7392     2.7536     0.201      1.3411    42655.14  172215.57     0.0    
   700      6730.83     2.2866     2.297      0.2371     0.847     35218.13  142185.24     0.0    
   800      7734.68     1.9322     1.942      0.2115     0.6893    31414.96   126872.3     0.0    
   900      8736.98      1.67      1.679      0.1883     1.3338    29326.27  118530.11     0.0    
   1000     9737.79     1.4848     1.4948     0.2469     0.1661    28182.51  113918.34     0.0    
   1100     10737.24    1.3587     1.3691     0.0909     0.7104    27532.03   111346.8     0.0    
   1200     11737.03    1.2751     1.2849     0.122      0.1028    27136.56  109725.65     0.0    
   1300     12796.62    1.2141     1.2238     0.1344     0.052     26896.52  108789.24     0.0    
   1400     13845.47    1.176      1.1821     0.1017     0.0548    26738.68  108055.96     0.0    
   1500     14898.65    1.1446     1.1536     0.1457     0.2246    26639.19  107742.36     0.0    
   1600     15908.16    1.1208     1.1284     0.1539     0.4404    26541.18  107319.72     0.0    
   1700     16907.9     1.1048     1.1111     0.1133     0.592     26483.97  107077.11     0.0    
   1800     17907.18    1.0935     1.0991     0.1081     0.0482    26436.29  106865.54     0.0    
   1900     18906.42    1.0846     1.0898     0.1526     0.0548    26439.72  106857.71     0.0    
   2000     19904.47    1.0773     1.0818     0.1028     0.0118    26400.07  106700.03     0.0    
   2100     20901.98    1.0695     1.0752     0.0943     0.5504    26360.42   106582.4     0.0    
   2200     21901.06    1.0651     1.0693     0.0947     0.1363    26316.36  106348.93     0.0    
   2300     22898.98    1.0601     1.0644     0.1009     0.0044    26290.7   106259.04     0.0    
   2400     23898.68    1.0574     1.063      0.1015     0.4886    26281.82  106255.66     0.0    
   2500     24897.9     1.0541     1.0573     0.1333     0.003     26260.07  106157.84     0.0    
   2600     25895.94    1.0516     1.0563     0.1649     0.0147    26257.08  106132.21     0.0    
   2700     26894.82    1.0517     1.0547     0.114      0.2164    26265.68  106121.87     0.0    
   2800     27894.85    1.0476     1.0519     0.1449     0.005     26243.96  106044.18     0.0    
   2900     28892.69    1.0451     1.0487     0.0751     0.034     26227.27  105987.64     0.0    
   3000     29891.3     1.045      1.0478     0.0923     0.2494    26210.12  105933.75     0.0    
   3100     30890.79    1.0418     1.0457     0.1161     0.7062    26207.9   105936.26     0.0    
   3200     31888.63    1.0434     1.0453     0.0837     0.0087    26204.69  105903.98     0.0    
   3300     32886.11    1.0417     1.0438     0.0695     0.048     26200.14  105901.15     0.0    
   3400     33884.63    1.0414     1.0423     0.1339     0.0218    26191.98  105838.28     0.0    
   3500     34883.08    1.0392     1.043      0.1113     0.0106    26183.28  105785.94     0.0    
   3600     35881.03    1.0405     1.0426     0.0913     0.0437    26181.31  105792.73     0.0    
   3700     36878.99    1.0374     1.0394     0.0813     0.0642    26155.35   105680.2     0.0    
   3800     37876.37    1.0381     1.0401     0.1208     0.0051    26162.81  105700.49     0.0    
   3900     38873.62    1.0369     1.0391     0.0872     0.0077    26143.49  105603.18     0.0    
   4000     39872.0     1.0363     1.0382     0.0725     0.0154    26134.51  105589.86     0.0    
