Generating synthetic  count valued data ... 
Generating synthetic  count valued data took:  7.740078687667847
max_count =  16  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       102.2      4.2006     4.234      0.3162     4.415    128772.22  104392.59    0.0006  
   100       408.56     4.2029     4.2363     0.3136     0.2913   127950.55  103720.16    0.0001  
   150       715.48     4.1895     4.2222     0.3004     0.0588   125126.06  101412.68     0.0    
   200      1022.51     4.1543     4.1865     0.2959     0.0258   119176.96   96559.11     0.0    
   250      1329.26     4.0836     4.1151     0.2865     0.0273   109548.16   88727.1      0.0    
   300      1635.88     3.9662     3.9974     0.2855     0.0234    97277.78   78761.55     0.0    
   350      1943.27     3.7942     3.8241     0.2805     0.0205    83827.95   67845.2      0.0    
   400      2250.89     3.5719     3.5995     0.2645     0.017     70936.73   57406.28     0.0    
   450      2558.59     3.3152     3.3407     0.2507     0.0138    59824.69   48403.86     0.0    
   500      2866.35     3.0483     3.0723     0.2294     0.0103    51083.24   41330.62     0.0    
   550       3174.2     2.7961     2.8173     0.2205     0.0107    44698.72   36160.04     0.0    
   600      3481.46     2.5671     2.5842     0.1979     0.0115    40098.51   32437.64     0.0    
   650      3788.58     2.3628     2.3775     0.2111     0.0114    36804.19   29760.46    0.0001  
   700      4096.43     2.1843     2.1957     0.1735     0.0115    34403.56   27811.65    0.0001  
   750      4404.37     2.0231     2.0323     0.1694     0.011     32597.38   26344.09    0.0001  
   800      4712.33     1.8829     1.8914     0.208      0.0116    31245.24   25250.15     0.0    
   850      5020.25     1.7634     1.7696     0.1007     0.011     30233.45   24434.11     0.0    
   900      5328.71     1.6581     1.6617     0.1618     0.0107    29452.91   23791.52     0.0    
   950      5636.06     1.5719     1.5735     0.1202     0.0104    28873.32   23317.13     0.0    
   1000     5941.93     1.4935     1.4942     0.1323     0.011     28401.43   22943.15     0.0    
   1050     6248.24     1.4269     1.4256     0.1499     0.0094    28021.95   22628.32     0.0    
   1100      6554.4     1.3705     1.3664     0.1023     0.0092    27728.78   22385.77     0.0    
   1150      6860.5     1.3187     1.316      0.0942     0.0089    27486.83   22186.81     0.0    
   1200     7166.28     1.279      1.2731     0.0935     0.0088    27301.34   22040.45     0.0    
   1250      7472.3     1.2419     1.2369     0.1139     0.0089    27148.12   21918.6      0.0    
   1300     7778.25     1.209      1.2029     0.1281     0.0083    27026.4    21813.51     0.0    
   1350      8084.1     1.1829     1.1758     0.0696     0.0081    26920.72   21729.7      0.0    
   1400     8389.42     1.1595     1.1528     0.1332     0.008     26824.23   21655.73     0.0    
   1450     8694.84     1.1371     1.1295     0.0962     0.0078    26730.09   21577.22     0.0    
   1500     9000.98     1.1207     1.1121     0.1077     0.0074    26688.36   21542.52     0.0    
   1550     9307.12     1.1029     1.0937     0.1146     0.0071    26618.48   21480.61     0.0    
   1600     9613.45     1.0915     1.0803     0.1358     0.0073    26588.99   21456.0      0.0    
   1650     9919.54     1.0789     1.0717     0.1609     0.0067    26553.59   21429.79     0.0    
   1700     10225.87    1.0707     1.0597     0.1765     0.0066    26526.33   21416.6      0.0    
   1750     10531.94    1.0615     1.0502     0.1158     0.0063    26504.31   21401.19     0.0    
   1800     10838.27    1.0527     1.0433     0.0913     0.0063    26476.31   21368.63     0.0    
   1850     11145.28    1.0476     1.037      0.0832     0.0061    26465.58   21363.55     0.0    
   1900     11452.39    1.0382     1.027      0.0972     0.0058    26414.03   21328.1      0.0    
   1950     11759.09    1.0328     1.0216     0.1666     0.006     26392.42   21304.42     0.0    
   2000     12065.73    1.0264     1.0129     0.0874     0.0055    26365.56   21280.71     0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       102.79     4.1402     4.1625     0.0697     3.5915    84672.4   136786.11    0.0001  
   100       496.63     4.1745     4.1957      0.03      0.7942   107066.59  173054.43    0.0001  
   150       890.37     4.1825     4.2038     0.0258     0.3844   115325.41  186389.46    0.0001  
   200      1284.22     4.1868     4.2093     0.0239     0.2549   119264.17  192744.48    0.0001  
   250      1677.15     4.1907     4.2127     0.0281     0.1893   121473.97  196307.07    0.0001  
   300      2070.97     4.1935     4.2156     0.0288     0.1473   122890.12  198589.54    0.0001  
   350      2463.91     4.1957     4.2179     0.0287     0.1169   123857.39  200147.42     0.0    
   400      2856.29     4.1973     4.2197     0.0306     0.0959   124558.58  201276.07     0.0    
   450      3248.75     4.1995     4.2215     0.0327     0.0818   125086.23  202125.67     0.0    
   500      3641.47     4.2006     4.2228     0.0334     0.0701   125497.42  202787.39     0.0    
   550      4033.59     4.2022     4.2244     0.0328     0.0611   125828.09  203319.46     0.0    
   600      4425.72     4.2031     4.2257     0.0324     0.0542   126096.41   203751.3     0.0    
   650      4818.07     4.2044     4.2263     0.034      0.0482   126318.41  204108.59     0.0    
   700      5210.25     4.2054     4.2274     0.0319     0.0439   126504.67   204408.3     0.0    
   750      5602.05     4.2061     4.2285     0.0345     0.039    126660.01  204658.07     0.0    
   800       5993.7     4.2067     4.2291     0.0321     0.0357   126792.03  204870.34     0.0    
   850      6385.16     4.2075     4.2299     0.0361     0.0325    126904.2  205050.73     0.0    
   900      6776.71     4.2083     4.2304     0.038      0.0301   126997.01  205199.93     0.0    
   950      7166.91     4.2085     4.231      0.0388     0.0278   127075.08  205325.38     0.0    
   1000     7558.82     4.2092     4.2316     0.0359     0.0258   127138.17   205426.7     0.0    
   1050     7949.35     4.2096     4.232      0.0365     0.0237   127186.66  205504.52     0.0    
   1100     8340.11     4.2101     4.2323     0.038      0.0221   127221.78  205560.74     0.0    
   1150     8730.26     4.2103     4.2327     0.0399     0.0207   127241.75  205592.53     0.0    
   1200     9121.41     4.2104     4.2327     0.0415     0.0194    127244.2  205595.97     0.0    
   1250     9512.04     4.2105     4.2327     0.0426     0.0182   127229.47  205571.68     0.0    
   1300     9903.08     4.2105     4.2328     0.0441     0.017    127192.72  205511.75     0.0    
   1350     10294.39    4.2102     4.2328     0.0478     0.0162    127130.4  205410.37     0.0    
   1400     10686.25    4.2101     4.2324     0.0517     0.0152   127034.83  205255.57     0.0    
   1450     11076.85    4.2096     4.2321     0.0536     0.0145   126895.48  205029.44     0.0    
   1500     11466.96    4.2088     4.2313     0.0583     0.0136   126703.64  204719.22     0.0    
   1550     11858.17    4.2074     4.2299     0.0665     0.0133   126432.91   204280.8     0.0    
   1600     12248.83    4.2058     4.2282     0.0724     0.0124   126063.57  203682.68     0.0    
   1650     12639.76    4.2032     4.2256     0.0807     0.012     125548.4  202849.52     0.0    
   1700     13029.99    4.1995     4.222      0.0831     0.0117   124834.86  201695.53     0.0    
   1750     13418.86    4.1939     4.216      0.1028     0.0113   123805.53  200031.89     0.0    
   1800     13806.98    4.1861     4.208      0.112      0.0112   122393.25  197746.66     0.0    
   1850     14196.45    4.1737     4.1957     0.1216     0.0113   120304.83  194375.71     0.0    
   1900     14586.49    4.1547     4.1768     0.1459     0.0118   117379.01  189645.43     0.0    
   1950     14977.79    4.1259     4.1477     0.1621     0.0125   113220.79  182915.68     0.0    
   2000     15369.61    4.0838     4.1051     0.1724     0.0144   107708.68  174014.35     0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       101.06     4.1508     4.1653     0.0705     3.4293    78519.45  189639.49     0.0    
   100       580.7      4.1993     4.2154     0.0426     0.8915   102033.98  246455.23     0.0    
   150      1060.13     4.2092     4.2239     0.0265     0.4053    112031.1  270564.65     0.0    
   200      1540.81     4.2123     4.2274     0.0244     0.2704   116917.44   282325.0     0.0    
   250      2019.68     4.2141     4.2288     0.0254     0.1921   119733.53   289098.5     0.0    
   300      2499.13     4.2151     4.2301     0.0238     0.1494   121531.92   293424.3     0.0    
   350      2977.94     4.2158     4.2308     0.0238     0.1208   122766.84  296393.22     0.0    
   400      3456.89     4.2165     4.2313     0.0235     0.0995   123656.67  298532.95     0.0    
   450      3937.05     4.2172     4.2319     0.0276     0.0831   124331.71  300155.45     0.0    
   500      4417.08     4.2172     4.2323     0.026      0.073    124857.99   301420.2     0.0    
   550      4897.12     4.2177     4.2327      0.03      0.0631   125277.22  302428.02     0.0    
   600      5377.47     4.2178     4.2331     0.0262     0.0556   125621.72   303255.9     0.0    
   650      5857.67     4.2182     4.2334     0.0267     0.0498   125906.92   303941.1     0.0    
   700      6336.74     4.2187     4.2337     0.0264     0.0445   126146.78  304517.45     0.0    
   750       6816.5     4.2189     4.2342     0.0305     0.0408   126350.62   305007.2     0.0    
   800      7295.99     4.2191     4.2342     0.0263     0.0371    126525.9  305428.26     0.0    
   850      7775.24     4.2193     4.2344     0.0272     0.0339   126677.53  305792.49     0.0    
   900      8253.58     4.2197     4.2347     0.0298     0.0318    126810.0  306110.52     0.0    
   950      8732.57     4.2198     4.2349     0.0304     0.0289   126925.34  306387.63     0.0    
   1000     9211.16     4.2201     4.2351     0.0292     0.027    127025.47  306628.03     0.0    
   1050     9689.53     4.2201     4.2352     0.0337     0.025    127112.48  306836.93     0.0    
   1100     10168.93    4.2205     4.2354     0.0288     0.0236   127187.51  307016.99     0.0    
   1150     10647.79    4.2204     4.2354     0.0307     0.0221   127250.54  307168.23     0.0    
   1200     11125.84    4.2205     4.2357     0.0316     0.0209   127302.82  307293.62     0.0    
   1250     11603.79    4.2204     4.2356     0.0316     0.0197   127343.89  307391.94     0.0    
   1300     12081.82    4.2207     4.2356     0.0317     0.0187   127372.96  307461.44     0.0    
   1350     12560.19    4.2207     4.2358     0.0333     0.0177   127390.48  307503.05     0.0    
   1400     13038.66    4.2204     4.2357     0.0338     0.0168   127393.69  307510.23     0.0    
   1450     13516.82    4.2206     4.2355     0.0371     0.0161   127381.05  307479.33     0.0    
   1500     13994.62    4.2202     4.2353      0.04      0.0152   127346.95  307396.38     0.0    
   1550     14471.98     4.22      4.235      0.0398     0.0146    127287.9  307253.64     0.0    
   1600     14950.93    4.2194     4.2345     0.0431     0.0141   127194.54  307027.65     0.0    
   1650     15429.62    4.2188     4.2337     0.047      0.0135   127053.92  306688.21     0.0    
   1700     15908.52    4.2176     4.2327     0.054      0.013    126848.69  306192.68     0.0    
   1750     16389.36    4.2161     4.2312     0.0617     0.0127   126555.47  305485.28     0.0    
   1800     16869.35    4.2139     4.2289     0.0709     0.0123   126119.79  304434.42     0.0    
   1850     17350.67    4.2101     4.2255     0.0766     0.0121   125476.49  302882.39     0.0    
   1900     17832.21    4.2051     4.2201     0.0967     0.012     124504.2  300537.59     0.0    
   1950     18312.84    4.1965     4.2118     0.1078     0.012    123024.43  296968.61     0.0    
   2000     18790.89    4.1831     4.1981     0.1292     0.0126   120746.96  291475.74     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       100.86     4.1492     4.1603     0.0827     3.3463    76094.11  244962.59     0.0    
   100       665.78     4.2032     4.2162     0.0519     0.9911    99449.69  320182.14     0.0    
   150      1230.32     4.2142     4.2271     0.0337     0.4143    110288.9  355042.23     0.0    
   200      1797.63     4.2182     4.2309     0.0314     0.2666   115702.25  372429.49     0.0    
   250      2363.42     4.2197     4.2325     0.0258     0.1972   118811.96  382408.13     0.0    
   300      2927.24     4.2209     4.2337     0.0258     0.1517   120802.38  388794.59     0.0    
   350      3492.49     4.2215     4.2345     0.0259     0.1238   122178.78  393207.44     0.0    
   400      4058.58     4.2223     4.2351     0.0244     0.1006   123177.82  396410.42     0.0    
   450      4624.32     4.2228     4.2354     0.0281     0.0854   123925.95  398808.31     0.0    
   500       5188.9     4.2227     4.2355     0.0228     0.0732   124509.99  400679.72     0.0    
   550      5754.02     4.2233     4.2361     0.0251     0.0642   124978.19  402179.48     0.0    
   600       6318.3     4.2234     4.2361     0.0237     0.0569   125360.53  403403.74     0.0    
   650      6883.77     4.2236     4.2363     0.0248     0.0507   125679.28  404425.01     0.0    
   700      7448.74     4.2238     4.2365     0.0259     0.0451   125947.53   405284.2     0.0    
   750      8013.73     4.2242     4.2368     0.0261     0.0417   126177.08  406019.42     0.0    
   800      8577.99     4.2241     4.2369     0.0247     0.0381   126374.38  406651.34     0.0    
   850      9142.44     4.2243     4.237      0.0261     0.0345   126546.26  407201.88     0.0    
   900      9707.18     4.2244     4.2371     0.0269     0.0319   126695.74  407680.32     0.0    
   950      10271.24    4.2246     4.2373     0.0281     0.0299   126826.82  408099.96     0.0    
   1000     10836.34    4.2246     4.2374     0.0268     0.0277   126942.34   408469.6     0.0    
   1050     11400.24    4.2246     4.2375     0.027      0.026    127044.26  408795.69     0.0    
   1100     11964.73    4.2249     4.2374     0.0276     0.0241   127133.71  409081.78     0.0    
   1150     12530.08    4.2249     4.2377     0.0295     0.0227   127212.19   409332.8     0.0    
   1200     13096.29    4.2247     4.2377     0.0294     0.0215   127280.97  409552.65     0.0    
   1250     13662.45    4.225      4.2378     0.0271      0.02    127338.85  409737.55     0.0    
   1300     14229.84    4.2249     4.2377     0.0299     0.0192   127386.56  409889.86     0.0    
   1350     14796.36    4.225      4.2378     0.0287     0.0182   127423.31  410007.04     0.0    
   1400     15362.59    4.2249     4.2378     0.0321     0.0173   127449.01  410088.49     0.0    
   1450     15929.28    4.2247     4.2377     0.0298     0.0165   127463.14  410132.91     0.0    
   1500     16498.59    4.2247     4.2375     0.033      0.0158   127462.07  410128.55     0.0    
   1550     17065.5     4.2247     4.2373     0.0367     0.0151   127443.36  410067.31     0.0    
   1600     17632.47    4.2245     4.2371     0.0378     0.0146   127401.69  409932.33     0.0    
   1650     18199.73    4.2238     4.2366     0.0435     0.0139   127328.28  409695.01     0.0    
   1700     18766.01    4.2233     4.236      0.0481     0.0134   127211.78  409318.47     0.0    
   1750     19332.06    4.2222     4.235      0.0497     0.0131   127036.02  408751.19     0.0    
   1800     19900.11    4.2209     4.2335     0.0632     0.0126   126766.62  407882.31     0.0    
   1850     20466.97    4.2186     4.2314     0.0724     0.0126   126351.17  406543.15     0.0    
   1900     21032.44    4.2151     4.2279     0.0871     0.0124   125701.65  404452.34     0.0    
   1950     21600.65    4.2096     4.2223     0.099      0.0124   124696.93  401214.27     0.0    
   2000     22168.75    4.2003     4.2131     0.1225     0.0127   123080.88  396007.88     0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       101.05     4.1452     4.1629     0.0948     3.2688    74894.2    301852.9     0.0    
   100       758.07     4.205      4.2239     0.0553     0.9328    98063.56  395361.51     0.0    
   150      1415.09     4.2171     4.2358     0.0386     0.4368   109252.67  440469.94     0.0    
   200      2073.37     4.2213     4.2398     0.0353     0.2788   114960.42  463459.29     0.0    
   250      2729.14     4.2226     4.2418     0.029      0.2008   118264.79  476776.17     0.0    
   300      3384.29     4.224      4.2428     0.0267     0.1549   120379.92  485296.27     0.0    
   350      4042.11     4.2248     4.2437     0.0235     0.126    121834.85  491156.59     0.0    
   400      4697.27     4.225      4.2441     0.0291     0.1026   122894.06   495423.7     0.0    
   450      5351.48     4.2255     4.2446     0.0266     0.086     123687.0  498616.21     0.0    
   500      6009.98     4.226      4.2448     0.0237     0.075    124310.32   501125.4     0.0    
   550      6664.12     4.2262     4.2451     0.0268     0.0648   124810.76  503139.61     0.0    
   600      7317.95     4.2262     4.2453     0.0263     0.0573   125215.54  504769.25     0.0    
   650      7971.09     4.2264     4.2454     0.0269     0.0512   125554.88  506134.91     0.0    
   700      8623.92     4.2266     4.2457     0.0271     0.0454   125840.41  507284.03     0.0    
   750      9278.64     4.2268     4.2458     0.0282     0.042    126084.72  508267.18     0.0    
   800      9932.12     4.2267     4.2459     0.026      0.0378   126294.61  509111.53     0.0    
   850      10584.46    4.2268     4.246      0.0237     0.0353   126477.11  509845.67     0.0    
   900      11240.09    4.2271     4.2462     0.0249     0.0327   126636.86  510488.38     0.0    
   950      11894.46    4.2272     4.2462     0.027      0.0303   126777.48  511054.09     0.0    
   1000     12549.8     4.2272     4.2463     0.0321     0.0278   126902.31  511556.32     0.0    
   1050     13204.27    4.2273     4.2463     0.0243     0.0262   127013.26  512002.75     0.0    
   1100     13858.49    4.2273     4.2465     0.0246     0.0245   127111.64  512398.36     0.0    
   1150     14514.35    4.2274     4.2466     0.028      0.0231   127198.26  512746.57     0.0    
   1200     15168.94    4.2275     4.2466     0.0254     0.0215   127275.53   513057.3     0.0    
   1250     15825.21    4.2274     4.2466     0.0285     0.0204   127343.35  513329.96     0.0    
   1300     16478.94    4.2275     4.2466     0.0258     0.0194    127401.3  513562.62     0.0    
   1350     17132.57    4.2274     4.2467     0.0263     0.0185   127450.47  513759.82     0.0    
   1400     17786.03    4.2276     4.2466     0.0281     0.0175   127490.29  513919.55     0.0    
   1450     18438.18    4.2275     4.2467     0.0266     0.0167   127519.65  514037.07     0.0    
   1500     19089.45    4.2274     4.2465     0.0325     0.0161   127536.26  514103.19     0.0    
   1550     19741.52    4.2273     4.2463     0.0307     0.0153   127539.75  514116.33     0.0    
   1600     20396.0     4.227      4.2462     0.0338     0.0146    127526.4  514061.97     0.0    
   1650     21051.74    4.2269     4.2459     0.0367     0.0142   127490.46  513916.73     0.0    
   1700     21705.75    4.2265     4.2454     0.0393     0.0136   127425.86  513654.69     0.0    
   1750     22360.34    4.2257     4.2448     0.0442     0.0132   127318.18  513218.82     0.0    
   1800     23013.76    4.2249     4.2438     0.0495     0.0128   127146.59   512524.6     0.0    
   1850     23665.76    4.2235     4.2425     0.0586     0.0125   126881.25  511455.13     0.0    
   1900     24319.23    4.2211     4.2402     0.0728     0.0125   126456.78  509743.15     0.0    
   1950     24972.03    4.2174     4.2365     0.0875     0.0125   125759.38  506928.34     0.0    
   2000     25625.02    4.2111      4.23      0.1035     0.0126   124599.56  502253.06     0.0    
