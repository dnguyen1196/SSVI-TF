Generating synthetic  binary valued data ... 
Generating synthetic  binary valued data took:  5.407783508300781
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       135.1      1.2727     1.2047     3.1623     4.0128   
   100       276.45     0.7668     0.7279     3.1239     0.2316   
   150       417.96     0.7635     0.732      2.5554     0.1459   
   200       556.55     0.7346     0.6892     2.6882     0.1203   
   250       695.78     0.6884     0.6459     2.5261     0.0908   
   300       835.39     0.6906     0.6106     2.0299     0.091    
   350       973.89     0.6736     0.607      2.1206     0.0795   
   400      1112.31     0.6614     0.5741     2.3325     0.0697   
   450      1251.59     0.6412     0.5662     1.9338     0.0592   
   500      1390.78     0.6447     0.5474     1.8157     0.0563   
   550      1529.58     0.6385     0.5535     2.1555     0.0516   
   600      1668.23     0.627      0.524      2.0237     0.0457   
   650      1806.89     0.6162     0.5257     1.8915     0.0488   
   700       1945.4     0.6151     0.4982     1.8023     0.0565   
   750      2084.47     0.6108     0.4874     1.7329     0.0409   
   800      2223.85     0.6025     0.4812     1.9356     0.0382   
   850      2361.93     0.6001     0.4779     1.6707     0.0398   
   900      2500.05     0.6056     0.4994     1.6583     0.0343   
   950      2637.76     0.6094     0.4743     1.8863     0.0346   
   1000     2775.49     0.5899     0.4632     1.6241     0.0311   
   1050     2913.63     0.5909     0.4492     1.7456     0.0345   
   1100     3051.02     0.5946     0.4578     1.7341     0.0327   
   1150     3189.87     0.5993     0.4539     1.9117     0.0307   
   1200     3327.39     0.5842     0.4379     2.0045     0.0314   
   1250     3465.27     0.6012     0.4463     1.5186     0.0307   
   1300     3603.48     0.5806     0.4429     1.8408     0.0293   
   1350     3740.84     0.5828     0.431      1.716      0.028    
   1400      3878.9     0.5819     0.4427     1.6503     0.0309   
   1450     4016.65     0.6039     0.4583     2.1208     0.0274   
   1500     4154.71     0.5814     0.429      1.7762     0.0302   
   1550     4292.21     0.583      0.4308     1.9655     0.0309   
   1600     4430.09     0.5801     0.432      1.7287     0.0289   
   1650     4569.65     0.5838     0.437      1.6019     0.0299   
   1700     4708.19     0.5981     0.4545     1.687       0.03    
   1750     4845.17     0.5932     0.4682     2.0972     0.0325   
   1800     4983.44     0.6004     0.4756     2.2254     0.0309   
   1850     5121.08     0.5989     0.4552     2.5948     0.029    
   1900     5258.71     0.5907     0.4652     1.8693     0.0333   
   1950      5396.0     0.6249     0.5146     2.5347     0.0352   
   2000     5533.78     0.6545     0.5771     2.6462     0.0341   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       133.44     1.4095     1.4135     1.4685     1.291    
   100       273.97     1.3711     1.3631     1.7137     0.8691   
   150       413.34      1.23      1.2156     1.2679     0.5463   
   200       553.16     0.773      0.769      1.5507     0.3584   
   250       692.19     0.7209     0.7114     1.8802     0.3163   
   300       831.08     0.7701     0.759      1.6877     0.2122   
   350       969.55     0.7481     0.7375     1.5565     0.1541   
   400      1108.29     0.7304     0.7137     1.3901     0.1029   
   450      1247.28     0.738      0.7301     1.1441     0.112    
   500      1385.98     0.7354     0.721      1.1987     0.0918   
   550      1524.09     0.7269     0.7191     1.2279     0.0676   
   600      1663.12     0.7032     0.6911     1.4753     0.0631   
   650      1801.84     0.7171     0.7062     1.0752     0.0525   
   700       1940.8     0.7139     0.6916     1.1836     0.0573   
   750      2079.93     0.6937     0.6793     1.3228     0.0509   
   800      2218.25     0.6969     0.6873     0.9929     0.0547   
   850      2357.05     0.6804     0.6568     0.9245     0.039    
   900      2496.01     0.6793     0.6617     1.1078     0.0434   
   950       2635.2     0.6706     0.6448     1.4222     0.0491   
   1000     2774.19     0.6567     0.6384     0.8233     0.0342   
   1050     2912.88     0.6663     0.6324     1.051      0.0338   
   1100     3052.13     0.6519     0.6283     0.9822     0.0277   
   1150     3190.33     0.6758     0.6518     1.2421     0.0261   
   1200     3329.06     0.6355     0.6122     1.1797     0.031    
   1250     3467.92     0.6396     0.6122     0.8785     0.0223   
   1300     3606.65     0.6323     0.6017     0.8092     0.0204   
   1350     3745.48     0.6407     0.6065     1.2041     0.0234   
   1400     3883.25     0.6148     0.5818     0.7507     0.0218   
   1450     4022.04     0.6237     0.5758     0.895      0.0215   
   1500     4161.03     0.6266     0.5951     0.8994     0.0203   
   1550     4299.84     0.6328     0.5977     1.2439     0.0196   
   1600      4438.5     0.6158     0.5846     1.0518      0.02    
   1650     4577.42     0.6148     0.576      1.1409     0.0223   
   1700     4716.66     0.6015     0.5769     1.0869     0.0183   
   1750     4856.05     0.6123     0.5679     0.9445     0.0179   
   1800     4994.94     0.6081     0.5707     1.051      0.0228   
   1850     5134.73     0.5918     0.5496     0.813      0.0166   
   1900     5274.13     0.6017     0.5655     1.2926     0.0232   
   1950     5413.05     0.5999     0.5575     1.0266     0.0179   
   2000     5553.19     0.5988     0.5625     0.8836     0.0134   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       134.62      1.42      1.4139     1.2389     1.0443   
   100       275.73     1.3783     1.3755     1.3463     0.7718   
   150       416.69     1.3239     1.3212     1.2382     0.5496   
   200       557.58     1.1449     1.1529     1.0427     0.3737   
   250       698.17     0.7795     0.7722     1.4041     0.2582   
   300       837.17     0.7296     0.7162     1.6414     0.2726   
   350       976.12     0.7861     0.7753     1.5977     0.2226   
   400      1114.38     0.745      0.7333     1.4637     0.1395   
   450      1253.29     0.7513     0.7421     1.332      0.1108   
   500      1392.49     0.7529     0.7435     1.3497     0.0948   
   550      1532.52     0.7267     0.7188     1.1622     0.0735   
   600      1672.59     0.7144     0.705      0.9146     0.0641   
   650       1813.7     0.7097     0.6993     0.8571     0.0569   
   700      1954.05     0.7415     0.7271     0.8749     0.0535   
   750      2093.76     0.7171     0.7029     1.0048     0.0497   
   800      2233.07     0.7094     0.6917     1.0185     0.0432   
   850       2372.5     0.692      0.6816     0.9293     0.0409   
   900      2511.61     0.6884     0.6597     1.0651     0.0455   
   950      2651.33     0.6921     0.6777     0.8625     0.0362   
   1000     2791.21     0.6936     0.6743     0.928      0.0324   
   1050     2930.92     0.6714     0.6556     0.9012     0.0312   
   1100     3069.96      0.67      0.6536     1.0898     0.0345   
   1150      3208.9     0.6567     0.6428     0.9229     0.0298   
   1200     3347.71     0.6565     0.6327     0.9123     0.0255   
   1250      3487.5     0.6437     0.6209     0.6901     0.0247   
   1300      3626.4     0.6412     0.623      0.8641     0.0221   
   1350     3765.94     0.6429     0.6194     1.0074     0.0225   
   1400     3905.82     0.6473     0.6273     0.9378     0.0198   
   1450      4045.7     0.6322     0.6132     1.174      0.023    
   1500     4184.93     0.6284     0.609      0.8229     0.0184   
   1550     4323.99     0.6265     0.6065     0.7448     0.0156   
   1600     4463.08     0.6338      0.61      1.0134     0.0254   
   1650     4602.25     0.6281     0.605      0.9514     0.0197   
   1700     4741.74     0.6361     0.6155     0.849      0.0149   
   1750     4880.82     0.6163     0.5961     0.8201     0.0157   
   1800      5020.1     0.6272     0.6034     0.7552     0.0144   
   1850     5159.48     0.6149     0.5941     0.8888     0.0128   
   1900     5299.47     0.6153     0.5908     0.6939     0.0204   
   1950     5438.55     0.6248     0.6018     0.7298     0.0161   
   2000     5577.75     0.6127     0.5901     0.8002     0.014    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       133.43     1.4104     1.4119     0.986      0.9516   
   100       273.92     1.4154     1.4066     1.0599     0.7276   
   150       414.11     1.4039     1.4037     1.2308     0.5393   
   200       553.69     1.3379     1.3323     0.9389     0.3849   
   250       693.84     1.1744     1.1718     0.6511     0.2671   
   300       833.93     0.8106     0.807      1.0049     0.1927   
   350       973.68     0.7172     0.7035     1.4348     0.2456   
   400      1112.73     0.7276     0.7161     1.3937     0.2097   
   450      1251.48     0.7735     0.763      1.2383     0.119    
   500      1389.96     0.7262     0.7143     1.2589     0.0972   
   550      1529.36     0.7248     0.7141     1.0262     0.0763   
   600      1668.14     0.731      0.721      0.984      0.0679   
   650      1807.22     0.7388     0.7328     1.2938     0.0736   
   700      1946.63     0.7253      0.71      0.7589     0.0501   
   750      2086.34     0.7549     0.752      0.9452     0.0446   
   800      2225.45     0.7098     0.6931     0.9709     0.0414   
   850      2364.79     0.6924     0.6791     0.8698     0.038    
   900      2503.43     0.6969     0.6839     1.0008     0.0354   
   950      2642.72     0.6911     0.6771      0.67      0.0375   
   1000     2781.84     0.6974     0.6785     0.6952     0.0272   
   1050     2921.02     0.6951     0.6856     0.9066     0.029    
   1100      3060.5     0.7018     0.6825     0.8339     0.0274   
   1150     3200.04     0.6708     0.6557     0.8487     0.0234   
   1200     3339.15     0.6749     0.6498     0.8319     0.0232   
   1250     3479.02     0.6615     0.6439     0.8658     0.0197   
   1300     3618.92     0.6743     0.6507     0.7205     0.0184   
   1350     3758.11     0.6818     0.6612     0.7733     0.0209   
   1400     3897.54     0.6582     0.638      0.9209     0.0261   
   1450     4036.81     0.6661     0.6409     0.8658     0.0178   
   1500     4176.55     0.6492     0.6308     0.6146     0.019    
   1550     4316.27     0.6519     0.625      0.5621     0.0168   
   1600     4455.97     0.6394     0.6241     0.7638     0.0188   
   1650     4595.84     0.6406     0.6187     0.7265     0.0178   
   1700     4735.09     0.6475     0.6205     0.7525     0.0147   
   1750     4874.84     0.6371     0.6058     0.7536     0.0217   
   1800     5013.65     0.6355     0.6061     0.7994     0.0268   
   1850     5153.51     0.6396     0.6129     0.6458     0.015    
   1900     5292.82     0.6327     0.6086     0.8008     0.0153   
   1950     5432.44     0.6272     0.602      0.838      0.0206   
   2000     5573.92     0.6158     0.593      0.7107     0.0163   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       135.48     1.4129     1.4145     0.918      0.8984   
   100       278.68     1.4117     1.4056     1.1635     0.7011   
   150       421.46     1.3679     1.3641     1.0303     0.5327   
   200       563.86     1.1166     1.1116     0.7478     0.3894   
   250       706.59     0.7375     0.7272     0.9431     0.2758   
   300       847.83     0.7172     0.7044     0.8745     0.2505   
   350       988.16     0.7356     0.7259     0.743      0.1964   
   400      1129.01     0.7443     0.7357     0.6963     0.1158   
   450      1269.56     0.7295     0.7194     0.6748     0.0994   
   500      1410.34     0.7393     0.7266     0.6661     0.0892   
   550      1551.75     0.7253     0.7131     0.6303     0.079    
   600      1692.11     0.7515     0.7388     0.6267     0.0657   
   650      1832.46     0.7217     0.7081     0.6932     0.0604   
   700      1972.68     0.7312     0.7224     0.5111     0.0507   
   750      2114.63     0.7305     0.7166     0.4507     0.0479   
   800      2258.11     0.734      0.7199      0.4       0.0428   
   850      2400.87     0.7172     0.7044     0.3639     0.0362   
   900       2544.0     0.726      0.7113     0.3574     0.034    
   950       2685.1     0.7253     0.7131     0.3786     0.0348   
   1000     2827.46     0.726      0.7113     0.5115     0.0376   
   1050     2968.83     0.7209     0.7095     0.5055     0.0297   
   1100     3110.34     0.7284     0.714      0.3798     0.0252   
   1150     3252.87     0.7172     0.7044     0.3405     0.0283   
   1200     3395.27     0.7172     0.7022     0.4168     0.0268   
   1250     3536.24     0.7271     0.7183     0.3845     0.0223   
   1300     3677.02     0.7203     0.713      0.3931     0.0218   
   1350     3818.14     0.7206     0.7071      0.34      0.0246   
   1400     3958.75     0.7244     0.7126     0.4129     0.0202   
   1450     4099.11     0.7115     0.6977     0.4521     0.0198   
   1500     4239.93     0.7253     0.7143     0.5331     0.0232   
   1550     4380.58     0.7136     0.7059     0.5385     0.0218   
   1600     4521.66     0.7198     0.7017     0.6076     0.0209   
   1650     4662.94     0.703      0.6846     0.5918     0.0213   
   1700     4803.38     0.7068     0.6891     0.638      0.0229   
   1750     4944.26     0.6996     0.684      0.6675     0.0192   
   1800     5085.04     0.6932     0.6843     0.8253     0.0249   
   1850     5225.31     0.691      0.6741     0.6075     0.0222   
   1900     5365.93     0.685      0.6729     0.6716     0.0175   
   1950     5506.45     0.6767     0.6631     0.7705     0.0217   
   2000     5646.52     0.7022     0.6848     0.8478     0.0247   
