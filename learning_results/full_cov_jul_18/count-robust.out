Generating synthetic  count valued data ... 
Generating synthetic  count valued data took:  7.92006254196167
max_count =  16  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       289.1      4.1224     4.1542     0.3162     4.4721    129165.0  104733.21     0.0    
   100       764.87     4.119      4.1514     0.3111     2.7105   128634.36  104305.62     0.0    
   150      1242.35     4.1058     4.1381     0.3016     1.0711   126287.43  102406.17     0.0    
   200      1719.03     4.0729     4.1043     0.2959     1.0863   121155.48   98254.21     0.0    
   250       2194.7     4.0098     4.0409     0.292      0.5293   112770.38   91465.42     0.0    
   300      2669.67     3.9103     3.9414     0.2859     1.2091   101464.55   82292.3      0.0    
   350      3142.31     3.7667     3.7966     0.2706     0.7859    88288.79   71602.36     0.0    
   400      3614.14     3.5784     3.6061     0.2576     0.211     74959.93   60784.84     0.0    
   450      4085.08     3.3517     3.3793     0.241      0.5625    63093.93   51155.25     0.0    
   500      4555.29     3.1028     3.1274     0.2255      0.13     53458.48   43320.24     0.0    
   550      5025.03     2.8429     2.8648     0.2351     1.0181    46117.15   37349.84     0.0    
   600      5494.24     2.5954     2.6127     0.2998     0.4935    40780.21   33006.1      0.0    
   650      5962.68     2.3597     2.3734     0.2272     0.7941    36897.37   29831.82     0.0    
   700      6431.05     2.1462     2.1568     0.1937     1.484     34071.37   27544.82     0.0    
   750      6899.03     1.959      1.9659     0.1724     1.1151    32072.01   25912.6      0.0    
   800      7366.56     1.7935      1.8       0.1377     1.2076    30607.19   24721.93     0.0    
   850      7833.64     1.6565     1.6598     0.1971     0.5424    29541.47   23864.64     0.0    
   900       8306.7     1.5391     1.5399     0.1882     0.5466    28765.36   23227.31     0.0    
   950      8777.12     1.4434     1.4417     0.1969     0.6484    28185.25   22748.6      0.0    
   1000     9243.77     1.3605     1.3574     0.2187     0.6163    27735.6    22396.22     0.0    
   1050     9710.33     1.2933     1.2891     0.1695     0.2139    27420.39   22134.78     0.0    
   1100     10176.71    1.2427     1.237      0.1403     0.7169    27175.68   21930.34     0.0    
   1150     10643.14    1.1958     1.1889     0.1299     0.1599    26959.58   21761.99     0.0    
   1200     11109.52    1.1589     1.1505     0.1841     0.2009    26828.14   21652.13     0.0    
   1250     11575.81    1.1295     1.1201     0.1277     0.211     26698.37   21550.27     0.0    
   1300     12042.06    1.1053     1.0943     0.1701     0.0117    26587.32   21457.66     0.0    
   1350     12508.76    1.0844     1.0724     0.0931     0.0144    26512.74   21399.96     0.0    
   1400     12981.01    1.0663     1.055      0.1277     0.7244    26430.45   21339.93     0.0    
   1450     13456.83    1.0502     1.0378     0.1767     0.0469    26411.35   21311.5      0.0    
   1500     13930.88    1.0374     1.0262     0.1531     0.0745    26331.92   21251.26     0.0    
   1550     14400.19    1.0306     1.0173     0.1341     0.1234    26314.77   21240.03     0.0    
   1600     14866.27    1.0198     1.0058     0.2106     0.0105    26289.9    21209.69     0.0    
   1650     15332.06    1.0099     0.9967     0.1696     0.0864    26235.4    21177.99     0.0    
   1700     15797.93    1.002       0.99      0.0881     0.0205    26219.53   21163.72     0.0    
   1750     16263.75    0.9986     0.9859     0.1075     0.0097    26209.63   21147.72     0.0    
   1800     16729.7     0.9931     0.9794     0.1431     0.5522    26186.03   21139.45     0.0    
   1850     17195.39    0.9887     0.9763     0.1285     0.7403    26165.2    21112.07     0.0    
   1900     17661.26    0.9829     0.9689     0.1501     0.1819    26148.96   21094.61     0.0    
   1950     18126.95    0.9805     0.9667     0.0989     0.0378    26134.56   21090.92     0.0    
   2000     18592.96    0.9774     0.9641     0.0982     0.0156    26119.86   21077.87     0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       288.07     4.1241     4.1458     0.1034     4.4721   129078.61  208478.43     0.0    
   100       843.7      4.1237     4.1447     0.0555     2.4887   129184.77  208684.95     0.0    
   150      1403.28     4.1237     4.1447     0.0583     1.5748   129211.44  208738.51     0.0    
   200      1956.62     4.1233     4.1446     0.0539     1.1496   129221.14  208754.92     0.0    
   250      2510.22     4.1232     4.1447     0.0547     1.2058   129225.62  208763.63     0.0    
   300      3064.08     4.1229     4.1446     0.0548     1.1141   129234.04  208781.26     0.0    
   350      3622.11     4.1232     4.1444     0.0553     0.9857   129234.53  208784.42     0.0    
   400      4186.27     4.123      4.1442     0.0565     0.7427   129225.07  208770.53     0.0    
   450      4742.78     4.1226     4.1437     0.0528     0.5164    129210.3  208747.29     0.0    
   500      5295.92     4.1233     4.1436     0.0514     0.7884   129184.29  208706.42     0.0    
   550      5849.09     4.122      4.1437     0.0493     0.5382   129144.58  208642.75     0.0    
   600      6402.33     4.1218     4.1437     0.0489     0.6297   129087.23  208551.56     0.0    
   650       6955.9     4.1217     4.1428     0.0511     0.773    129002.61  208414.01     0.0    
   700      7509.13     4.1215     4.1421     0.0535     0.707    128884.91  208224.22     0.0    
   750      8062.34     4.1204     4.1412     0.0551     0.7134   128722.29  207961.16     0.0    
   800      8615.57     4.1193     4.1405     0.0598     1.0533   128504.46  207611.04     0.0    
   850      9168.96     4.1167     4.1381     0.0685     0.416    128199.45   207119.1     0.0    
   900      9721.74     4.115      4.1362     0.079      0.2389    127781.8  206444.78     0.0    
   950      10274.65    4.1118     4.1328     0.089      0.7555   127210.42  205523.04     0.0    
   1000     10827.45    4.1068     4.1284     0.0963     0.3679   126421.62  204249.69     0.0    
   1050     11380.29    4.1004     4.1219     0.1063     0.1087   125329.89  202489.17     0.0    
   1100     11933.45    4.0907     4.1126     0.119      0.4569   123821.58  200057.18     0.0    
   1150     12486.62    4.0776     4.0987     0.1218     0.1542   121727.52  196678.25     0.0    
   1200     13039.55    4.0579     4.0792     0.1472     0.4727   118840.56  192016.39     0.0    
   1250     13592.39    4.0308     4.0511     0.1494     0.2309   114893.59  185643.27     0.0    
   1300     14145.05    3.9904     4.011      0.1621     0.6786   109730.84  177310.33     0.0    
   1350     14697.15    3.9345     3.9552     0.1649     0.8205    103173.1  166726.11     0.0    
   1400     15248.87    3.8587     3.8795     0.1796     0.405     95394.57  154161.34     0.0    
   1450     15800.08    3.7623     3.7824     0.1824     0.3083    86796.94  140287.91     0.0    
   1500     16351.57    3.6409      3.66      0.1776     0.6728    77798.14  125746.42     0.0    
   1550     16902.51    3.498      3.518      0.1767     0.4945    69212.95  111874.87     0.0    
   1600     17452.81    3.3389     3.3569     0.1679     0.3956    61440.57   99316.74     0.0    
   1650     18002.47    3.1704     3.1878     0.1577     0.6407    54864.9    88690.48     0.0    
   1700     18551.66    2.9924     3.0073     0.1542     0.3799    49238.1    79592.39     0.0    
   1750     19100.8     2.8144     2.8289     0.1552     1.1595    44710.29   72268.89     0.0    
   1800     19650.0     2.6383     2.6519     0.1646     0.6974    41077.27   66385.17     0.0    
   1850     20198.83    2.4691     2.4806     0.1446     0.6835    38158.14   61674.55     0.0    
   1900     20747.29    2.3114     2.3212     0.1884     0.7493    35866.9    57975.03     0.0    
   1950     21295.33    2.1643     2.1732     0.1387     0.6486    34053.57   55037.85     0.0    
   2000     21843.3     2.0282     2.0341     0.1261     0.6514    32594.41   52679.77     0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       288.57     4.1245     4.1389     0.0793     4.4721    128928.4  311081.67     0.0    
   100       926.57     4.1235     4.1382     0.0227     2.4246   129020.47  311343.47     0.0    
   150      1563.23     4.1236     4.1377     0.0229     1.3966   129069.71  311481.08     0.0    
   200      2199.84     4.124      4.1379     0.0245     1.2614   129100.14  311560.12     0.0    
   250      2837.05     4.1238     4.1376     0.0224     1.5225   129135.85  311648.18     0.0    
   300      3473.39     4.1231     4.1374     0.0237     1.0377   129159.31  311706.51     0.0    
   350       4110.0     4.1228     4.1377     0.0259     0.9873   129173.46  311743.32     0.0    
   400      4746.03     4.1229     4.1373     0.0237     0.7316   129185.74  311778.32     0.0    
   450      5381.56     4.1223     4.1373     0.026      0.7022   129195.35  311802.31     0.0    
   500       6017.4     4.1234     4.1372     0.0249     0.8342   129202.11  311821.38     0.0    
   550      6653.66     4.1224     4.1371     0.0253     0.501    129207.36   311834.8     0.0    
   600      7288.88     4.1227     4.1374     0.0244     0.4374   129211.37  311846.78     0.0    
   650      7924.63     4.1225     4.1372     0.0247     0.8676   129212.09  311850.09     0.0    
   700       8559.9     4.123      4.1372     0.0243     0.8513   129214.75  311858.42     0.0    
   750      9194.79     4.1228     4.1372     0.025      1.3348   129219.36  311870.48     0.0    
   800      9829.66     4.1225     4.137      0.0255     0.7396   129217.81  311868.94     0.0    
   850      10464.44    4.1231     4.1371     0.0234     0.4651   129209.22  311848.35     0.0    
   900      11099.6     4.1228     4.1369     0.025      0.5097    129201.3  311830.17     0.0    
   950      11735.42    4.1224     4.1368     0.0248     0.0636   129187.07  311796.38     0.0    
   1000     12371.26    4.1226     4.1363     0.0245     0.5499   129170.38  311756.68     0.0    
   1050     13006.38    4.1223     4.1367     0.0249     0.7849   129150.02  311707.88     0.0    
   1100     13641.11    4.1224     4.1361     0.0252     0.023    129121.13  311638.54     0.0    
   1150     14276.83    4.1217     4.1364     0.0288     0.1206   129086.58  311555.95     0.0    
   1200     14911.59    4.1218     4.1359     0.0278     0.1141   129043.52  311451.85     0.0    
   1250     15546.6     4.1215     4.1356     0.0291     0.1883   128991.53  311326.99     0.0    
   1300     16181.59    4.1203     4.135      0.0321     0.6251    128928.7  311175.85     0.0    
   1350     16816.45    4.1208     4.1349     0.0327     0.2537   128852.16  310991.07     0.0    
   1400     17451.38    4.1203     4.1346     0.038      0.3541   128757.82  310762.79     0.0    
   1450     18087.04    4.1203     4.1337     0.0378     0.3502   128641.76  310484.18     0.0    
   1500     18722.75    4.1189     4.1326     0.0433     0.6647   128499.26  310141.58     0.0    
   1550     19358.1     4.1183     4.1315     0.0479     0.1824   128320.28   309710.6     0.0    
   1600     19993.17    4.1156     4.1309     0.0473     0.0205   128096.26  309170.94     0.0    
   1650     20628.08    4.1145     4.1291     0.0543     0.7456   127818.67  308501.31     0.0    
   1700     21262.71    4.1123     4.1269     0.0544     0.4477   127464.44  307648.87     0.0    
   1750     21900.14    4.1097     4.1243     0.0619     0.1369   127004.62  306541.58     0.0    
   1800     22541.72    4.1063     4.1208     0.0651     0.2108   126412.93  305116.86     0.0    
   1850     23180.22    4.1019     4.116      0.076      0.0636   125641.18  303256.86     0.0    
   1900     23820.02    4.095      4.1099     0.0771     0.3903   124627.82  300815.43     0.0    
   1950     24459.29    4.0868     4.1011     0.0881     0.1055   123290.26   297590.7     0.0    
   2000     25099.27    4.0751     4.0898     0.0902      0.06    121511.68  293303.53     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       291.59     4.123      4.1351     0.095      4.4721    128827.7  414292.39     0.0    
   100      1014.29     4.1231     4.1349     0.0241     2.6225   129011.12  414968.66     0.0    
   150      1735.18     4.1229     4.1348     0.0258     1.0694   129054.36   415135.0     0.0    
   200      2457.16     4.1219     4.1345     0.0272     1.8892   129086.29  415255.13     0.0    
   250      3178.65     4.1222     4.1343     0.0271     1.1004   129108.99   415346.2     0.0    
   300      3900.62     4.1222     4.1347     0.0266     0.5566   129133.81   415429.7     0.0    
   350      4620.88     4.1225     4.1344     0.0274     0.9766    129165.9  415538.17     0.0    
   400      5341.82     4.1224     4.1344     0.0285     0.6743   129173.88  415566.03     0.0    
   450      6062.87     4.1227     4.1344     0.0277     1.2157   129185.68  415603.71     0.0    
   500      6783.06     4.122      4.1344     0.0281     0.8299   129193.98  415633.35     0.0    
   550      7504.39     4.1224     4.1341     0.0287     0.7326   129205.12  415675.48     0.0    
   600      8224.79     4.1227     4.1344     0.027      0.8373    129209.6  415690.58     0.0    
   650      8944.55     4.122      4.1343     0.0268     0.5516   129210.79  415694.65     0.0    
   700       9665.2     4.1214     4.1344     0.0275     0.5906   129209.83  415690.83     0.0    
   750      10385.61    4.1221     4.1343     0.0276     0.281     129205.9   415678.2     0.0    
   800      11107.19    4.1225     4.1341     0.0261     0.151    129197.28  415650.39     0.0    
   850      11828.49    4.1223     4.134      0.0285     0.6781   129192.62  415635.83     0.0    
   900      12550.76    4.1226     4.1337     0.027      0.177    129180.45  415597.14     0.0    
   950      13272.22    4.1221     4.1341     0.0289     0.598    129166.03  415549.63     0.0    
   1000     13992.51    4.1221     4.1338     0.0247     0.5789   129145.55  415483.91     0.0    
   1050     14713.33    4.1214     4.1337     0.0272     0.0407   129119.16  415399.33     0.0    
   1100     15433.71    4.1214     4.1334     0.0282     0.4575   129093.48  415319.05     0.0    
   1150     16154.54    4.1218     4.1331     0.0271     0.5873   129054.16  415191.85     0.0    
   1200     16874.95    4.121      4.133      0.0292     0.4192   129002.76  415026.16     0.0    
   1250     17595.2     4.1205     4.1325     0.0313     0.0527   128937.02  414814.01     0.0    
   1300     18316.65    4.1205     4.1323     0.0326     0.2051   128858.79   414562.2     0.0    
   1350     19036.45    4.1198     4.1315     0.036      0.2239   128758.36  414238.51     0.0    
   1400     19756.84    4.1182     4.1307     0.0384     0.6234   128636.28  413846.77     0.0    
   1450     20477.66    4.118      4.1299     0.0421     0.0681   128481.32  413348.22     0.0    
   1500     21197.28    4.1172     4.1287     0.0455     0.097    128287.11  412724.87     0.0    
   1550     21918.51    4.1153     4.1275     0.0527     0.4148   128040.11  411928.82     0.0    
   1600     22638.32    4.1134     4.1256     0.0588     0.1739   127718.68  410893.91     0.0    
   1650     23359.27    4.111      4.1231     0.0622     0.668    127306.62  409570.53     0.0    
   1700     24081.09    4.1079     4.1198     0.0656     0.0393   126768.01  407837.98     0.0    
   1750     24801.04    4.1038     4.1157     0.0755     0.0672   126053.62  405538.12     0.0    
   1800     25522.43    4.0978     4.1097      0.08      0.0588   125104.24  402483.42     0.0    
   1850     26242.43    4.0896     4.1018     0.0921     0.3337   123829.08  398378.48     0.0    
   1900     26962.36    4.0789     4.0905     0.099      0.1026   122105.61  392828.74     0.0    
   1950     27683.29    4.0636     4.0748     0.1094     0.5613   119793.74  385381.53     0.0    
   2000     28403.06    4.0419     4.0535     0.1182     0.1567   116694.27  375400.44     0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  0.01  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       291.52     4.1252     4.1427     0.1141     4.4721   128839.89  519244.26     0.0    
   100       1098.0     4.1245     4.1424     0.0287     1.624    128940.23  519684.45     0.0    
   150      1903.56     4.1243     4.1421     0.0196     1.5128    129011.5  519987.73     0.0    
   200      2708.68     4.1244     4.1419     0.0174     0.8457   129072.13  520246.98     0.0    
   250      3514.94     4.1236     4.1421     0.023      0.7601   129090.76  520325.78     0.0    
   300      4320.18     4.1245     4.1417     0.0243     0.7332   129105.52   520386.0     0.0    
   350      5124.22     4.1238     4.1418     0.0188     0.3464    129118.9  520443.74     0.0    
   400      5944.78     4.1244     4.1418     0.0167     0.8491   129144.36  520543.35     0.0    
   450      6748.47     4.124      4.1416     0.0189     0.4685   129162.33  520621.27     0.0    
   500      7553.07     4.1237     4.1415     0.0189     0.6317   129177.21  520681.84     0.0    
   550      8356.57     4.1242     4.1417     0.0193     0.2248   129180.17  520694.89     0.0    
   600      9160.48     4.1241     4.1415     0.0204     0.2689   129185.54  520718.24     0.0    
   650      9963.17     4.1238     4.1412     0.0223     0.6842   129188.17  520727.97     0.0    
   700      10766.51    4.1236     4.1413     0.0182     0.1735   129190.25  520738.38     0.0    
   750      11569.65    4.1237     4.1415     0.023      0.1821   129196.61  520766.62     0.0    
   800      12371.99    4.1232     4.1414     0.019      0.2182   129199.62  520779.97     0.0    
   850      13173.81    4.1238     4.1415     0.0186     0.176    129198.53  520774.75     0.0    
   900      13970.91    4.1239     4.1416     0.0177      0.36    129198.02  520773.98     0.0    
   950      14768.02    4.1238     4.1419     0.0187     0.1246   129199.04   520778.4     0.0    
   1000     15565.17    4.1235     4.1415     0.0184     0.3165    129197.2  520771.28     0.0    
   1050     16362.19    4.1231     4.1413     0.0179     0.121    129196.18  520767.97     0.0    
   1100     17159.27    4.1234     4.1414     0.0198     0.4075   129192.43   520753.9     0.0    
   1150     17956.83    4.1235     4.1409     0.0204     0.6424   129186.15  520728.86     0.0    
   1200     18763.05    4.1236     4.1412     0.0174     0.1233   129177.61  520695.48     0.0    
   1250     19573.88    4.1236     4.1411     0.0179     0.0499   129166.01  520650.06     0.0    
   1300     20385.72    4.1234     4.1409     0.0173     0.1561   129151.54  520593.17     0.0    
   1350     21196.21    4.1229     4.1409     0.0196     0.156     129134.0  520522.77     0.0    
   1400     22006.75    4.1232     4.1406     0.0194     0.0841   129112.32  520436.24     0.0    
   1450     22817.65    4.1229     4.1407     0.0234     0.0656   129086.55  520333.34     0.0    
   1500     23628.68    4.1224     4.1405     0.0198     0.089     129056.5  520214.01     0.0    
   1550     24439.1     4.1224     4.1405     0.0248      0.11    129020.12  520069.25     0.0    
   1600     25249.39    4.1226     4.1401     0.0268     0.0662   128974.88  519888.38     0.0    
   1650     26062.05    4.1222     4.1396     0.0252     0.1011   128921.29  519674.36     0.0    
   1700     26873.18    4.1211     4.1395     0.0272     0.2076   128855.16  519410.75     0.0    
   1750     27686.02    4.1217     4.139      0.0313     0.1313   128776.36  519096.35     0.0    
   1800     28499.25    4.1204     4.1386     0.0326     0.0445   128680.23  518712.48     0.0    
   1850     29312.83    4.1198     4.1379     0.0339     0.064     128563.5  518247.43     0.0    
   1900     30125.09    4.1193     4.137      0.0365     0.1055   128416.24  517658.09     0.0    
   1950     30937.77    4.1189     4.136      0.0396     0.1497   128233.91  516928.99     0.0    
   2000     31749.82    4.117      4.1349     0.0445     0.5786   128007.57  516022.38     0.0    
