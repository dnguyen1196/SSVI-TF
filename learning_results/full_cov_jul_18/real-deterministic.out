Generating synthetic  real valued data ... 
Generating synthetic  real valued data took:  6.414243221282959
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       124.61    373.5064   373.3549    3.1623     4.4719   
   100       254.21    199.5149   199.6186    3.1622     0.2708   
   150       386.38    167.8248   167.6452    2.7498     0.1084   
   200       515.74    158.3946   158.0223    2.5942     0.1283   
   250       643.84    151.8615   151.5665    2.1371     0.0605   
   300       773.74    151.1766   150.5291    2.1959     0.051    
   350       901.74    150.1188   150.3603    2.1976     0.0245   
   400      1030.62    150.2048    148.86     1.8733     0.0427   
   450       1159.1    147.8019   147.6965    1.5427     0.0217   
   500      1287.74    148.5157   147.6753    1.7946     0.0204   
   550      1416.53    146.9539   146.9519    1.3895     0.0189   
   600      1545.71    146.9539   146.509     1.0484     0.0169   
   650       1674.6    147.738    147.4475    1.0764     0.0133   
   700      1802.47    147.9263   147.6512    1.3617     0.0091   
   750      1930.25    147.0425   147.1068    1.5843     0.0086   
   800      2059.18    147.6143   147.0574    1.1868     0.0099   
   850      2187.65    147.8044   147.3854    1.3762     0.0094   
   900      2315.58    148.5569   148.1819    1.2964     0.0053   
   950      2443.65    147.3967   147.1674    1.2407     0.0065   
   1000     2571.32    147.3769   146.938     1.0271     0.0056   
   1050      2699.6    146.6258   146.7706    1.1347     0.0045   
   1100     2827.47    146.0553   146.2499    0.9971     0.0037   
   1150     2955.12    147.4011   146.6587    1.2184     0.0039   
   1200     3083.03    146.8771   146.5284    1.1264     0.0042   
   1250     3211.29    146.3656   146.2022    0.9579     0.0034   
   1300     3339.78    146.6573   146.1644    0.9477     0.0027   
   1350      3467.8    147.5157   146.7896    1.2471     0.0034   
   1400     3596.06    147.1353   146.666     1.1721     0.0028   
   1450     3724.07    146.7549   146.3996    1.1356     0.0032   
   1500     3852.21    146.5983   146.0829    1.0155     0.0028   
   1550     3979.54    146.2753   145.7502    0.9318     0.0024   
   1600     4106.59    145.985    146.1629    0.9596     0.0022   
   1650     4234.18    146.548    145.9776    1.046      0.002    
   1700     4362.97    146.1604    145.91     0.8283     0.0022   
   1750     4491.16    146.7783   146.3806    0.9915     0.0024   
   1800     4620.64    146.1242   145.8964    1.0065     0.0019   
   1850     4749.69    146.2732   145.873     0.8027     0.0017   
   1900     4878.59    146.5091   146.2684    0.9541     0.0019   
   1950     5006.81    146.8481   146.055     0.9296     0.0016   
   2000     5133.78    145.7796   145.663     0.884      0.0013   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       121.42    297.5675   297.7026    3.0504     4.4679   
   100       250.08    175.4476   175.0753    2.8894     0.5663   
   150       378.71    161.2851   160.7733    2.2919     0.153    
   200       508.2     153.5491   153.285     2.2487     0.0821   
   250       636.33    152.0995   151.7791    1.8042     0.0397   
   300       765.26    149.7646   149.7208    1.8842     0.0308   
   350       894.22    150.1245   149.5433    1.7595     0.0201   
   400      1023.27    149.3658   148.9278    1.777      0.0186   
   450      1152.72    148.4844   148.1747    1.5466     0.0135   
   500      1282.21    148.1183   148.3371    1.4279     0.0125   
   550      1411.84    148.6447   147.9882    1.6187     0.009    
   600      1540.64    147.3644   147.4191    1.2919     0.008    
   650      1670.15    147.0408   146.8878    0.9886     0.0071   
   700       1799.0    147.6762   147.1605    1.1564     0.0062   
   750      1927.71    146.9027   146.8846    1.2683     0.005    
   800      2056.11    146.5746   146.4344    1.207      0.005    
   850      2185.15    146.7356   146.8146    0.771      0.0046   
   900      2314.38    147.3856   146.7834    1.076      0.0042   
   950      2443.13    146.5946   146.6598    1.113      0.0036   
   1000      2571.7    146.8126   146.7146    1.0964     0.0034   
   1050     2699.79    146.8227   146.6673    1.0467     0.0029   
   1100     2829.07    146.669    146.275     1.1159     0.0021   
   1150     2957.48    146.2239   146.1221    0.8516     0.0023   
   1200     3085.96    146.1411   145.8339    0.9975     0.0021   
   1250     3214.05    147.4575   146.6361    0.8363     0.0019   
   1300     3343.14    146.719    146.482     1.0821     0.002    
   1350     3471.14    147.3062   146.8093    1.0198     0.0018   
   1400     3599.57    146.572    146.1411    0.9818     0.0017   
   1450      3727.9    146.5181   146.0835    0.9023     0.0019   
   1500     3855.91    146.0591   146.0173    1.1156     0.0014   
   1550     3983.92    145.7711   145.6656    0.9338     0.0013   
   1600     4111.96    146.4972   145.9774    0.9971     0.0012   
   1650     4240.17    145.4633   145.4298    0.9149     0.0012   
   1700     4368.82    146.0314   145.6947    0.6249     0.0011   
   1750     4497.12    146.5396   146.0836    0.8863     0.0012   
   1800     4625.61    146.5703   146.2601    0.9232     0.001    
   1850      4754.6    146.8489   146.1476    0.9145     0.0009   
   1900     4883.74    146.6366   146.0589    0.8178     0.0009   
   1950     5013.14    145.6205   145.7196    0.8711     0.0007   
   2000      5142.9    146.1264   145.8869    0.8284     0.0008   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       122.95    289.9423   289.0708    2.8862     4.4665   
   100       252.83    175.8394   174.4561    2.8125     0.3347   
   150       382.16    157.9827   157.5502    1.6801     0.1291   
   200       511.6     151.9361   151.2544    1.3229     0.0654   
   250       641.24    149.3553   148.9351    1.2795     0.0481   
   300       771.78    147.9564   147.335     1.3071     0.034    
   350       902.14    148.5971   148.2818    1.4382     0.0236   
   400      1033.65    146.9097   146.6347    1.3969     0.0163   
   450      1165.82    146.7751   146.309     1.071      0.0155   
   500      1297.18    147.2482   147.0687    1.1901     0.0123   
   550      1428.12    146.7648   146.6804    1.4154     0.0099   
   600      1558.64    146.763    146.3434    1.1435     0.0094   
   650       1688.7    147.4541   147.3547    1.3455     0.0082   
   700      1818.86    147.2582   146.8591    1.2639     0.0074   
   750      1948.57    147.1695   146.9056    1.1291     0.0054   
   800      2078.46    146.4666   146.3174    0.9523     0.0049   
   850      2208.94    146.0531   145.8826    0.9794     0.0044   
   900      2339.46    146.9235   146.3174    1.0387     0.0043   
   950      2470.06    146.2699   145.8544    1.0626     0.0039   
   1000     2600.94    147.1603   146.8421    1.3486     0.0034   
   1050     2731.41    146.6163   146.1428    1.2628     0.0027   
   1100     2861.75    146.4979   145.9459    0.869      0.0024   
   1150     2992.66    147.222    146.7575    1.4965     0.0023   
   1200     3122.61    146.236    145.9625    1.2126     0.0024   
   1250     3252.24    146.3917   145.9856    0.8685     0.0022   
   1300     3381.66    145.8166   145.8932    1.0784     0.0019   
   1350     3511.32    146.0482   145.7286    0.9868     0.0019   
   1400     3641.51    146.3791   145.9825    0.847      0.0016   
   1450     3771.56    146.2391   145.9001    0.8086     0.0015   
   1500     3901.06    146.0483   145.6595    0.9224     0.0015   
   1550     4031.05    146.5312   145.816     0.9793     0.0014   
   1600     4160.96    145.554    145.3652    0.8778     0.0012   
   1650     4290.52    146.0952   145.3138    0.7261     0.0012   
   1700      4420.3    145.7796   145.1211    1.0178     0.0012   
   1750     4550.39    145.2001   144.8385    0.6242     0.0011   
   1800     4679.65    146.2602   145.5772    0.7889     0.0011   
   1850     4809.38    145.6384   145.2798    0.7186     0.001    
   1900     4938.98    146.0614   145.5286    0.8206     0.001    
   1950     5068.61    145.3927   145.3606    0.6651     0.0009   
   2000     5197.66    146.4614   145.8475    0.8863     0.0009   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       122.39    284.8412   284.3961    2.7542     4.4658   
   100       252.53    179.6317   178.2816    2.5107     0.2628   
   150       382.18    159.2861   158.7047    1.5816     0.1045   
   200       511.79    152.2047   151.8474    1.5371     0.0562   
   250       641.36    149.375    149.5646    1.3653      0.04    
   300       770.91    147.8707   147.8425    1.1444     0.0309   
   350       901.84    147.1163   147.1539    1.1254     0.0235   
   400      1032.33    146.5952   147.164     1.1628     0.0155   
   450      1162.41    147.4049   147.2216    1.3221     0.0147   
   500      1292.78    146.8163   147.1535    1.1612     0.011    
   550      1423.44    146.3533   146.231     1.2034     0.0098   
   600      1553.62    145.647    145.7965    1.0618     0.0081   
   650      1684.23    145.7415   145.7627    0.6274     0.0066   
   700      1814.76    145.7564   146.2905    1.0073     0.0059   
   750      1945.33    146.3634   146.4095    1.0515     0.0053   
   800      2076.79    145.5264   145.9107    1.0052     0.0046   
   850      2207.12    145.8655   146.0098    0.7618     0.0039   
   900      2337.62    145.3205   145.6539    0.786      0.0037   
   950      2468.13    146.2923   146.1346    0.9652     0.003    
   1000     2598.33    145.4605   145.8865     0.94      0.0031   
   1050     2728.72    145.4007   145.6775    0.7379     0.0026   
   1100     2859.06    145.8797   145.9842    0.8469     0.0026   
   1150     2989.61    145.7804   145.9401    0.9432     0.0021   
   1200     3120.21    145.9315   146.0824    1.0207     0.0019   
   1250     3250.83    145.1426   145.6245    0.9424     0.002    
   1300     3380.28    145.4405   145.7577    0.9608     0.0019   
   1350     3511.03    145.3766   145.4364    0.7954     0.0016   
   1400     3641.71    145.9029   146.263     1.0106     0.0014   
   1450     3771.78    145.7595   145.8339    1.0581     0.0016   
   1500     3902.69    145.5641   145.8487    0.8134     0.0014   
   1550     4033.47    146.1744   146.0587    0.831      0.0013   
   1600     4163.43    146.2711   146.5855    0.9633     0.0013   
   1650     4294.27     145.26    145.5223    0.7751     0.0011   
   1700     4425.37    146.1327   146.4021    1.0561     0.0011   
   1750     4556.24    145.9202   146.1147    0.9217     0.0011   
   1800     4685.97    145.7901   145.7252    0.7411     0.001    
   1850      4815.9    145.1926   145.5197    0.8478     0.0009   
   1900     4946.39    145.2433   145.2751    0.709      0.0009   
   1950     5076.77    145.2427   145.2098    0.6496     0.0009   
   2000     5206.68    145.7292   145.5773    0.5592     0.0008   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       122.86    286.4337   285.2802    2.6801     4.4653   
   100       253.16    186.312    184.7332    2.5058     0.4126   
   150       385.15    162.0426   161.5467    1.2132     0.1424   
   200       516.54    153.0361   152.3355    0.8285     0.0788   
   250       647.42    149.359    149.0708    0.6745     0.0414   
   300       778.22    147.6801   147.2026    0.965      0.0307   
   350       909.01    146.9272   146.6443    1.0241     0.0244   
   400       1040.0    146.3521   146.172     0.8621     0.0178   
   450      1171.17    146.2441   146.1762    0.8562     0.0122   
   500      1302.26    145.3587   145.255     0.7563     0.0135   
   550      1433.16    145.3029   145.3896    0.8505     0.0089   
   600      1565.93    145.243    145.148     0.8245     0.0082   
   650      1699.17    145.707    145.4028    0.7651     0.0069   
   700      1832.76    145.3541   145.5461    0.8851     0.0067   
   750      1966.62    146.0959   145.7618    0.8367     0.0055   
   800       2100.2    145.5203   145.7614    0.8158     0.0046   
   850      2233.39    145.1222   145.0178    0.7629     0.0043   
   900      2365.74    145.3108   145.1687    0.5325     0.0034   
   950      2496.82    145.7741   145.5191    0.697      0.0035   
   1000     2628.52    145.6048   145.5258    0.7133     0.003    
   1050     2760.07    145.7053   145.554     0.9927     0.0029   
   1100     2890.89    145.3406   145.3056    0.8743     0.0024   
   1150     3022.52    146.2814   146.0627    0.8509     0.0023   
   1200     3154.13    145.716    145.737     1.0231     0.0021   
   1250     3285.93    144.981    144.9721    0.7543     0.002    
   1300     3417.38    145.3722   145.4907    0.6579     0.002    
   1350     3548.81    145.2797   145.5097    0.7296     0.0017   
   1400     3681.69    145.9361   145.7451    0.7873     0.0017   
   1450      3815.1    145.1349   145.3855    0.9729     0.0014   
   1500     3948.97    145.6598   145.684     1.0601     0.0014   
   1550     4081.04    145.449    145.5491    0.7869     0.0013   
   1600     4211.79    144.9122   145.0694    0.5926     0.0012   
   1650     4344.06    145.017    145.0845    0.5862     0.0012   
   1700     4475.77    145.2047   145.2093    0.9659     0.0011   
   1750     4607.34    146.037    145.9212    1.0931     0.0011   
   1800      4739.9    145.6262   145.5714     1.02      0.0011   
   1850     4871.59    145.9984    145.88     1.0757     0.001    
   1900     5003.94    146.1075   145.9375    1.0727     0.001    
   1950     5134.87    145.3725   145.5801    0.9809     0.0008   
   2000     5266.45    145.159    145.268     0.8821     0.0008   
