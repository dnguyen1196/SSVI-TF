Generating synthetic count valued data ... 
Generating synthetic  count valued data took:  8.887744188308716
max_count =  16  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       107.14     3.8488     3.8781     0.2814     0.2277    57831.8    46705.72    0.0001  
   200       352.19     3.8903     3.9141     0.2194     0.156     56305.25   45462.49    0.0001  
   300       597.89     3.9174     3.9471     0.1983     0.1144    55282.78   44627.5      0.0    
   400       844.06     3.9486     3.9777     0.172      0.0953    54528.66   44011.34     0.0    
   500      1081.98     3.9671     4.0011     0.1648     0.0818    53950.82   43539.4      0.0    
   600      1315.04     3.9849     4.0151     0.1399     0.0677    53480.28   43155.94     0.0    
   700       1553.3     3.9983     4.0301     0.1405     0.0582    53095.14   42842.38     0.0    
   800      1784.21     4.0124     4.0418     0.1294     0.0519    52772.3    42580.21     0.0    
   900      2021.11     4.0234     4.0536     0.121      0.0451    52501.99   42360.91     0.0    
   1000     2264.85     4.0292     4.0628     0.1106     0.0392    52273.86   42176.06     0.0    
   1100     2506.39     4.0383     4.0691     0.1276     0.0366    52081.12   42020.16     0.0    
   1200     2749.73     4.0451     4.0772     0.1085     0.0328    51919.21   41889.33     0.0    
   1300     2994.66     4.0471     4.0767     0.1187     0.0315    51777.27   41774.9      0.0    
   1400     3239.29     4.0364     4.0656     0.128       0.03     51628.35   41655.24     0.0    
   1500     3483.82     4.0044     4.0346     0.1393     0.0268    51423.72   41491.22     0.0    
   1600      3728.7     3.9239     3.955      0.1668     0.0278    51119.88   41249.03     0.0    
   1700     3973.77     3.7888     3.8201     0.171      0.0256    50720.43   40933.59     0.0    
   1800     4218.72     3.5762     3.6028     0.1693     0.0241    50339.0    40634.64     0.0    
   1900     4463.32     3.2788     3.2987     0.1778     0.0237    50073.7    40424.3      0.0    
   2000     4707.57     2.8975     2.9158     0.1817     0.0222    49931.12   40301.37     0.0    
   2100     4952.22     2.5063     2.5237     0.1927     0.021     49796.35   40192.17     0.0    
   2200     5197.37     2.2212     2.2387     0.206      0.0216    49951.08   40343.03     0.0    
   2300     5442.54     2.2323     2.2447     0.1673     0.018     50682.91   40964.01     0.0    
   2400     5687.84     2.613      2.6268     0.1566     0.0175    51947.12   41991.1      0.0    
   2500     5933.23     3.2359     3.2623     0.1478     0.0157    53301.65   43076.75     0.0    
   2600     6178.78     4.0417     4.0628     0.238      0.0162    54937.98   44380.54     0.0    
   2700     6424.47     4.9367     4.9688     0.1854     0.0149    56612.67   45745.27     0.0    
   2800     6670.05     5.9043     5.9356     0.1774     0.0148    58159.62   47061.27     0.0    
   2900     6915.32     6.8236     6.8745     0.1393     0.0135    58893.44   47697.55     0.0    
   3000     7160.83     7.7812     7.8395     0.1291     0.0129    59018.63   47786.49     0.0    
   3100     7406.34     8.7527     8.794      0.1895     0.0128    58320.77   47198.24     0.0    
   3200     7651.55     9.6784     9.775      0.1216     0.0121    57150.02   46238.14     0.0    
   3300     7897.22    10.6421    10.6987     0.1439     0.0116    56442.76   45658.21     0.0    
   3400     8142.83    11.5998    11.6863     0.1917     0.0117    56258.6    45471.89     0.0    
   3500     8387.93    12.5172    12.6062     0.1142     0.0111    56909.67   45983.51     0.0    
   3600     8633.14    13.4129    13.5245     0.2292     0.0112    57990.96   46916.87     0.0    
   3700     8878.29    14.2119    14.3007     0.2185     0.0105    59539.96   48170.38     0.0    
   3800     9123.37    15.0315    15.1465     0.1453     0.0102    61456.97   49662.6      0.0    
   3900      9368.2    15.8409    15.9657     0.1553     0.0099    64019.4    51778.04     0.0    
   4000     9611.48    16.5921    16.7349     0.1413     0.0094    66666.68   53958.21     0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       106.4      3.8085     3.8274     0.2842     0.0846    59789.01   96745.74    0.0001  
   200       412.32     3.8227     3.8399     0.2198     0.0809    59078.74   95585.77     0.0    
   300       718.35     3.8448     3.855      0.1981     0.0714    58439.16   94540.15     0.0    
   400      1023.98     3.856      3.8728     0.1807     0.0704    57859.23   93591.0      0.0    
   500      1329.39     3.8683     3.8856     0.1549     0.061     57334.22   92731.32     0.0    
   600      1634.62     3.8824     3.9027     0.1476     0.0584    56853.99   91943.71     0.0    
   700      1939.77     3.8989     3.9128     0.146      0.0539    56417.23   91227.02     0.0    
   800      2244.84     3.908      3.9266     0.1287     0.0547    56018.96   90573.62     0.0    
   900      2550.01     3.9224     3.9353     0.1219     0.0468    55653.85   89974.19     0.0    
   1000     2855.09     3.9282     3.9519     0.1342     0.043     55318.23   89422.8      0.0    
   1100     3160.07      3.94      3.9621     0.108      0.0432    55009.0    88914.78     0.0    
   1200     3465.26     3.9476     3.9713     0.111      0.0374    54723.46   88445.83     0.0    
   1300     3769.93     3.962      3.979      0.1056     0.0399    54458.57   88010.82     0.0    
   1400     4074.88     3.9711     3.9905     0.1067     0.0389    54211.34   87604.6      0.0    
   1500     4379.63     3.977      3.998      0.0977     0.0338    53982.86   87229.76     0.0    
   1600     4684.93     3.9844     4.0063     0.1093     0.0324    53769.73   86880.21     0.0    
   1700     4989.81     3.9964     4.0131     0.0934     0.0312    53571.8    86555.52     0.0    
   1800     5294.68     4.0012     4.0216     0.0942     0.0292    53384.99   86249.43     0.0    
   1900     5596.81     4.0076     4.0292     0.0849     0.0286    53211.15   85964.52     0.0    
   2000     5894.04     4.0146     4.0342     0.0815     0.0259    53048.83   85698.68     0.0    
   2100     6191.47     4.0208     4.041      0.0873     0.0268    52895.41   85447.58     0.0    
   2200     6487.89     4.0256     4.0469     0.0841     0.0251    52751.32   85211.84     0.0    
   2300      6785.2     4.0316     4.0508     0.0786     0.0235    52616.78   84991.89     0.0    
   2400     7080.66     4.0376     4.0561     0.0812     0.0224    52489.81   84784.51     0.0    
   2500     7375.74     4.0383     4.0611     0.0808     0.0225    52368.18   84586.1      0.0    
   2600     7671.87     4.0403     4.059      0.0895     0.0229    52246.79   84388.34     0.0    
   2700     7967.69     4.0348     4.0538     0.0858     0.0204    52109.08   84165.36     0.0    
   2800     8264.02     4.016      4.038      0.0883     0.0188    51937.11   83888.61     0.0    
   2900     8557.84     3.9872     4.0107     0.0879     0.0191    51716.45   83535.12     0.0    
   3000     8851.82     3.9503     3.9699     0.0893     0.0187    51448.63   83107.27     0.0    
   3100     9142.17     3.8977     3.9164     0.0814     0.0177    51131.35   82601.6      0.0    
   3200     9425.62     3.8323     3.8505     0.0777     0.0176    50762.28   82013.94     0.0    
   3300     9708.84     3.758      3.7738     0.0772     0.0168    50345.22   81350.26     0.0    
   3400     9995.17     3.6672     3.6847     0.0758     0.0157    49883.78   80615.61     0.0    
   3500     10279.42    3.5713     3.5896     0.0719     0.0164    49390.15   79828.35     0.0    
   3600     10563.41    3.4642     3.4833     0.0663     0.0146    48861.57   78983.35     0.0    
   3700     10849.64    3.3531     3.3676     0.0623     0.0139    48320.16   78115.67     0.0    
   3800     11135.47    3.2296     3.2465     0.0573     0.0126    47757.55   77212.39     0.0    
   3900     11422.67    3.0997     3.1187     0.0638     0.0126    47199.88   76315.53     0.0    
   4000     11710.62    2.9786     2.9887     0.0652     0.0119    46657.11   75443.31     0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       100.29     3.8071     3.817      0.2731     0.0673    60001.26  145050.41     0.0    
   200       446.31     3.8144     3.8285     0.2255     0.0589    59463.48  143741.04     0.0    
   300       774.43     3.8336     3.8426     0.1951     0.0567    58957.84  142509.23     0.0    
   400      1095.14     3.8414     3.8546     0.1854     0.0524    58481.18  141348.23     0.0    
   500      1418.09     3.8547     3.8665     0.1709      0.05     58034.68  140258.81     0.0    
   600       1737.7     3.8611     3.8777     0.1532     0.0515    57617.26  139239.84     0.0    
   700      2060.09     3.8777     3.889      0.1548     0.0449    57225.52  138283.09     0.0    
   800      2383.94     3.8874     3.8979     0.1396     0.0456    56861.37   137392.8     0.0    
   900      2706.53     3.8934     3.9076     0.1368     0.0422    56515.19   136546.7     0.0    
   1000     3029.61     3.9061     3.917      0.1277     0.0404    56193.61  135760.38     0.0    
   1100     3352.58     3.9145     3.9296     0.1188     0.0394    55890.72  135019.29     0.0    
   1200     3670.58     3.9279     3.9363     0.1148     0.0387    55607.96   134327.7     0.0    
   1300     3988.68     3.9329     3.9436     0.1041     0.0359    55343.76  133681.07     0.0    
   1400     4306.81     3.9425     3.9562     0.1011     0.036     55092.0    133065.0     0.0    
   1500     4624.79     3.9485     3.9621     0.0974     0.0332    54854.68  132484.12     0.0    
   1600     4942.71     3.9583     3.9687     0.0965     0.0332    54629.85  131933.66     0.0    
   1700     5260.63     3.9629     3.979      0.1149     0.0291    54420.29   131420.9     0.0    
   1800     5578.58     3.9749     3.9864     0.0835     0.0317    54221.06  130934.05     0.0    
   1900     5896.59     3.9822     3.9917     0.0924     0.0282    54031.56  130470.78     0.0    
   2000     6214.47     3.9862     4.0005     0.0805     0.0273    53852.17  130032.39     0.0    
   2100     6532.37     3.9917     4.0052     0.0802     0.0272    53681.84  129615.95     0.0    
   2200     6850.31     3.9991     4.0138     0.0813     0.0251    53520.28  129221.64     0.0    
   2300     7168.33     4.0034     4.0166     0.0794     0.0239    53366.12  128845.43     0.0    
   2400     7486.31     4.0106     4.0245     0.0744     0.0235    53220.74  128490.75     0.0    
   2500     7804.39     4.0177     4.0314     0.0832     0.0219    53082.98  128154.57     0.0    
   2600     8122.35     4.022      4.0348     0.0677     0.0211    52950.9   127832.45     0.0    
   2700     8440.49     4.0275     4.0395     0.0717     0.0214    52825.07  127525.77     0.0    
   2800      8758.5     4.032      4.0461     0.0721     0.0208    52705.64  127234.69     0.0    
   2900      9076.5     4.0361     4.0509     0.0661     0.0195    52591.79  126957.45     0.0    
   3000     9394.61     4.0413     4.0547     0.0743     0.0189    52484.2   126695.54     0.0    
   3100     9712.53     4.0461     4.0582     0.0681     0.019     52381.84  126446.42     0.0    
   3200     10030.55    4.0505     4.0634     0.0601     0.0175    52285.76  126212.85     0.0    
   3300     10348.51    4.0539     4.0669     0.0691     0.0179    52194.29  125990.48     0.0    
   3400     10666.65    4.057      4.0707     0.0658     0.0182    52107.41  125779.13     0.0    
   3500     10984.76    4.062      4.0758     0.0564     0.0158    52025.8   125580.73     0.0    
   3600     11303.03    4.0628     4.0771     0.0674     0.016     51948.53  125392.78     0.0    
   3700     11621.15    4.0669     4.0829     0.0594     0.0164    51874.64  125213.15     0.0    
   3800     11939.29    4.0705     4.0854     0.0661     0.0153    51805.65  125045.49     0.0    
   3900     12257.46    4.0754     4.0898     0.0581     0.0154    51740.06  124885.95     0.0    
   4000     12575.59    4.0796     4.0919     0.0541     0.0149    51678.6   124736.53     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       92.33      3.8025     3.8138     0.2764     0.0514    60096.74  193848.84     0.0    
   200       465.03     3.8176     3.8225     0.218      0.0508    59636.74  192355.45     0.0    
   300       837.52     3.8228     3.8345     0.2032     0.048     59200.84  190940.42     0.0    
   400      1210.02     3.8412     3.843      0.1803     0.0479    58785.38  189589.85     0.0    
   500      1582.52     3.8492     3.8548     0.168      0.0444    58386.53  188291.77     0.0    
   600      1955.02     3.8562     3.8637     0.1578     0.0436    58006.4   187054.45     0.0    
   700      2327.47     3.8704     3.8747     0.1404     0.041     57645.06  185878.03     0.0    
   800      2699.64     3.878      3.8856     0.1332     0.0411    57305.94  184774.22     0.0    
   900      3071.85     3.8837     3.8946     0.1479     0.0386    56981.86  183718.59     0.0    
   1000     3444.18     3.8967     3.9013     0.1242     0.0368    56676.59  182723.63     0.0    
   1100     3816.62     3.9019     3.913      0.1154     0.0363    56387.91  181782.14     0.0    
   1200      4188.9     3.9113     3.9214     0.1061     0.0328    56113.96  180888.99     0.0    
   1300      4561.3     3.9181     3.928      0.1075     0.034     55854.34  180042.61     0.0    
   1400     4933.65     3.9286     3.9389     0.0998     0.0315    55607.81  179237.85     0.0    
   1500     5305.82     3.9363     3.946      0.0969     0.0314    55373.28  178472.69     0.0    
   1600     5678.14     3.9427     3.9538      0.09      0.0297    55149.9   177743.89     0.0    
   1700     6050.26     3.9516     3.9601     0.1009      0.03     54936.03   177046.0     0.0    
   1800     6422.21     3.9572     3.9699     0.091      0.0285    54733.62  176385.94     0.0    
   1900     6794.35     3.966      3.9742     0.098      0.027     54539.81  175753.93     0.0    
   2000     7166.39     3.9714     3.9802     0.0851     0.0262    54354.94  175151.31     0.0    
   2100     7538.83     3.9749     3.9877     0.0881     0.0251    54177.72  174573.69     0.0    
   2200     7911.18     3.9832     3.9944     0.0817     0.0239    54007.99  174020.81     0.0    
   2300     8283.47     3.9922     3.9987     0.0781     0.0245    53846.57  173494.71     0.0    
   2400      8655.7     3.993      4.0067     0.0779     0.023     53691.9   172990.98     0.0    
   2500     9027.86     3.9994     4.0109     0.0769     0.0229    53544.57  172510.89     0.0    
   2600     9400.14     4.0052     4.0183     0.0726     0.022     53403.46  172051.52     0.0    
   2700      9772.2     4.0113     4.0225     0.0727     0.0219    53267.84  171610.21     0.0    
   2800     10144.49    4.0149     4.0272     0.0769     0.0208    53139.06  171191.03     0.0    
   2900     10516.62    4.019      4.0331     0.0807     0.0196    53015.62  170789.43     0.0    
   3000     10888.76    4.0264     4.0376     0.0698     0.0193    52897.15  170404.35     0.0    
   3100     11263.0     4.0316     4.0435     0.0753     0.0187    52783.8   170035.91     0.0    
   3200     11635.19    4.0366     4.0454     0.0666     0.0195    52675.72  169684.79     0.0    
   3300     12007.67    4.039      4.0501     0.0646     0.0176    52572.04  169347.86     0.0    
   3400     12380.26    4.0431     4.0551     0.0608     0.0177    52473.33  169027.24     0.0    
   3500     12753.16    4.0489     4.0589     0.066      0.0165    52379.26  168721.86     0.0    
   3600     13125.83    4.0536     4.0631     0.062      0.0167    52289.15  168429.19     0.0    
   3700     13498.49    4.054      4.0679     0.0578     0.0167    52204.03  168152.93     0.0    
   3800     13871.44    4.0625     4.0707     0.0579     0.015     52122.56  167888.39     0.0    
   3900     14244.06    4.0642     4.076      0.0585     0.0158    52044.12  167633.78     0.0    
   4000     14616.88    4.0659     4.0774     0.0556     0.0153    51970.16  167393.53     0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
   100       92.37      3.8097     3.8198     0.2841     0.0458    60155.85   242621.3     0.0    
   200       517.6      3.8191     3.8288     0.2424     0.0406    59751.47  240982.04     0.0    
   300       942.69     3.8269     3.8354     0.1934     0.042     59361.67  239399.63     0.0    
   400      1367.69     3.8329     3.8486     0.1799     0.0404    58983.89   237867.4     0.0    
   500      1792.77     3.8459     3.8577     0.1728     0.0402    58622.03  236397.26     0.0    
   600      2217.49     3.8534     3.8658     0.1566     0.0411    58275.44   234988.3     0.0    
   700      2642.26     3.8626     3.8745     0.1404     0.0388    57944.72  233645.18     0.0    
   800      3066.98     3.8682     3.8852     0.1511     0.0344    57629.61  232363.93     0.0    
   900      3491.84     3.8793     3.8912     0.1308     0.0381    57326.83   231132.4     0.0    
   1000     3916.69     3.8849     3.8993     0.1189     0.0332    57038.83  229961.48     0.0    
   1100     4341.53     3.8958     3.9078     0.1141     0.0317    56762.45  228835.61     0.0    
   1200     4780.47     3.8982     3.9161     0.122      0.033     56498.27   227759.5     0.0    
   1300     5221.54     3.9134     3.9261     0.117      0.0307    56247.57   226738.6     0.0    
   1400     5664.64     3.915      3.9326     0.1138     0.0331    56006.09  225754.73     0.0    
   1500     6106.73     3.9235     3.9405     0.1028     0.0298    55776.46  224818.97     0.0    
   1600     6550.49     3.9289     3.9473     0.0933     0.0289    55557.67  223927.11     0.0    
   1700     6992.71     3.9383     3.9548     0.0916     0.029     55346.64  223067.08     0.0    
   1800     7432.89     3.9451     3.9608     0.0952     0.0276    55144.94  222244.69     0.0    
   1900     7864.75     3.9508     3.9672     0.094      0.026     54950.7   221453.44     0.0    
   2000     8289.32     3.9571     3.9742     0.0865     0.0252    54765.71  220699.38     0.0    
   2100     8714.01     3.964      3.9813     0.081      0.0245    54590.28  219984.75     0.0    
   2200     9138.41     3.9691     3.9866     0.0793     0.0247    54418.44   219284.7     0.0    
   2300     9562.93     3.9769     3.9931     0.092      0.0243    54255.3    218619.3     0.0    
   2400     9987.41     3.9817     3.9985     0.084      0.0216    54098.64  217981.07     0.0    
   2500     10412.21    3.9877     4.0043     0.0876     0.0223    53948.02   217368.1     0.0    
   2600     10836.79    3.9952     4.0103     0.0753     0.0221    53803.5   216780.08     0.0    
   2700     11275.12    3.9972     4.0147     0.0754     0.0208    53664.66  216214.46     0.0    
   2800     11720.42    4.0033     4.0221     0.0754     0.0213    53529.96  215666.27     0.0    
   2900     12163.59    4.0092     4.0255     0.0775     0.0204    53401.63   215144.0     0.0    
   3000     12606.64    4.0163     4.0294     0.0734     0.0205    53277.04  214637.17     0.0    
   3100     13049.3     4.0186     4.0362     0.0667     0.0203    53157.49  214151.09     0.0    
   3200     13498.98    4.0227     4.0403     0.0766     0.0188    53043.46  213687.66     0.0    
   3300     13954.68    4.0256     4.0455     0.0653     0.0177    52933.92   213242.4     0.0    
   3400     14414.8     4.0304     4.0478     0.0653     0.0177    52827.82  212811.27     0.0    
   3500     14872.85    4.036      4.0532     0.0625     0.0175    52726.32  212399.11     0.0    
   3600     15331.86    4.0381     4.0561     0.0687     0.0165    52628.79  212003.11     0.0    
   3700     15790.08    4.041      4.0603     0.0599     0.0166    52535.56  211624.54     0.0    
   3800     16248.84    4.0462     4.0638     0.0622     0.0163    52445.71  211260.17     0.0    
   3900     16709.56    4.0506     4.0689     0.0598     0.0158    52359.19  210908.93     0.0    
   4000     17169.78    4.0571     4.0718     0.0544     0.0155    52276.66  210574.18     0.0    
