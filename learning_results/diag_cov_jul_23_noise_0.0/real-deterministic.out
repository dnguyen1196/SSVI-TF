Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  6.272291660308838
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       67.85     175.8159   174.7383    3.1622     0.6944   
   200       136.63    125.9932   125.0859    2.5552     0.2375   
   300       205.27    115.6956   115.0591    2.537      0.1251   
   400       273.39    112.3995   111.8083    1.9782     0.0795   
   500       341.23    106.9002   106.7623    1.6141     0.0551   
   600       408.46    105.4799   105.673     1.1558     0.0418   
   700       476.41    105.4362   104.9075    1.0059     0.0328   
   800       545.13    105.7017   105.1437    0.8984     0.0261   
   900       613.93    106.1618   105.9256    1.0107     0.0213   
   1000      682.7     106.2179   105.7993    0.8877     0.0182   
   1100      751.35    105.8719   105.6132    0.8025     0.0156   
   1200      820.07    106.4877   106.1374    1.1778     0.0137   
   1300      888.76    105.9774   105.7489    1.0574     0.0121   
   1400      957.52    105.2717   105.0852    0.9041     0.0105   
   1500     1026.34    105.5454   104.9321    0.933      0.0095   
   1600     1095.12    105.1219   104.8345    0.7788     0.0086   
   1700     1163.86    106.1242   105.2348    0.8453     0.0079   
   1800     1232.66    105.5985   104.6608     0.77      0.0071   
   1900     1301.41    105.5364   105.0218    0.8457     0.0065   
   2000     1370.14    105.8964   105.2554    0.9702     0.006    
   2100     1438.84    105.115    104.5683    0.8551     0.0056   
   2200      1507.5    105.2654   104.5721    0.8638     0.0052   
   2300      1576.4    104.6108   104.439     0.8182     0.005    
   2400     1645.28    105.675    104.7997    0.6773     0.0046   
   2500     1714.06    105.2558   104.6355    0.898      0.0041   
   2600     1782.86    105.2027   104.8259    0.9334     0.0039   
   2700     1851.73    104.8852   104.4892    0.7936     0.0037   
   2800     1920.59    104.5819   103.984     0.6643     0.0035   
   2900     1989.44    104.5451   103.9891    0.6263     0.0033   
   3000      2058.3    104.9638   104.4301    0.7604     0.0032   
   3100     2127.11    105.2182   104.6556    0.8963     0.0031   
   3200     2195.99    104.9058   104.4877    0.8508     0.0029   
   3300     2264.73    104.8061   104.2062    0.6325     0.0027   
   3400     2332.95    104.5962   104.2948    0.7303     0.0026   
   3500     2400.94    104.6088   103.9304    0.5894     0.0025   
   3600     2468.38    104.9408   104.2438    0.876      0.0024   
   3700     2536.06    104.3887   103.8363    0.5375     0.0022   
   3800     2603.63    104.8485   104.3055    0.5223     0.0022   
   3900     2671.31    104.2145   103.6861    0.534      0.0021   
   4000     2739.44    104.8045   104.2535    0.5446     0.002    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       67.25     173.558    174.5277    3.1619     0.6336   
   200       135.95    126.4496   126.9397    2.582      0.3245   
   300       204.76    113.6962   113.9955    2.4574     0.2085   
   400       273.6     110.0079   109.7537    2.1056     0.1436   
   500       341.95    109.0872   108.719     1.594      0.1028   
   600       410.58    106.2217   105.8826    1.1736     0.0807   
   700       478.73    105.4542   105.0922    1.3598     0.0649   
   800       546.7     107.5779   106.8726    1.1336     0.0514   
   900       615.4     106.8823   106.2933    1.2316     0.0436   
   1000      681.84    106.1471   105.6445    0.9381     0.0363   
   1100      748.48    105.6842   105.1262    0.8371     0.0313   
   1200      815.83    105.7012   105.0378    1.0305     0.027    
   1300      884.95    105.945    105.6949    0.9488     0.0242   
   1400      954.03    106.2397   105.4735    0.8492     0.021    
   1500     1023.13    105.3099   104.616     0.7297     0.0189   
   1600     1092.34    105.2523   104.6613    0.6651     0.0164   
   1700      1161.5    105.6986   105.0132    0.9882     0.0151   
   1800     1230.74    105.2621   105.1613    0.8629     0.0137   
   1900     1299.92    105.8252   105.1088    0.7628     0.0129   
   2000     1369.12    105.2053   104.8754    0.7338     0.0118   
   2100     1438.27    105.5961   105.0175    0.9059     0.0108   
   2200     1507.45    104.8747   104.2376    0.6012     0.0098   
   2300     1576.61    105.9216   104.9282    0.7435     0.009    
   2400     1645.75    104.4402   103.9405    0.7982     0.0085   
   2500     1714.86    105.348    104.4018    0.6997     0.0079   
   2600     1783.83    105.4353   104.7862    0.7977     0.0074   
   2700     1852.81    104.7615   104.0915    0.6756     0.007    
   2800     1921.78    104.9662   104.3039    0.8029     0.0065   
   2900     1990.67    105.1298   104.5534    0.8249     0.0061   
   3000     2058.52    104.8158   104.2416    0.6481     0.0058   
   3100     2122.46    104.9304   104.357     0.7597     0.0054   
   3200     2183.13    104.4406   104.0343    0.5979     0.0052   
   3300     2251.27    104.9011   104.4148    0.6775     0.0052   
   3400     2320.93    105.0836   104.4703    0.7659     0.0046   
   3500     2390.49    105.0502   104.3996    0.8643     0.0045   
   3600     2459.91    104.5982   104.1739    0.6856     0.0044   
   3700     2529.21    105.1329   104.396     0.6778     0.0042   
   3800     2598.31    104.8503   104.3004    0.7071     0.0039   
   3900     2667.27    105.4019   104.7271    0.7162     0.0037   
   4000     2736.52    104.5499   103.9263    0.5787     0.0036   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100        67.7     164.9728   164.0188    3.162      0.518    
   200       137.72    125.206    125.4692    2.5951     0.3043   
   300       207.72    117.477    117.2175    2.2247     0.206    
   400       277.65    112.7354   112.6253    1.6884     0.1528   
   500       347.69    108.5034   107.9376    1.6062     0.1155   
   600       417.75    109.6314   108.9103    1.4496     0.0898   
   700       487.75    108.2094   108.2491    1.382      0.0732   
   800       557.81    107.2545   107.2317    1.1218     0.0626   
   900       627.89    105.6762   105.4268    0.9798     0.0527   
   1000      697.88    105.4456   105.2388    0.7825     0.0443   
   1100      767.8     106.0573   105.3759    1.0822     0.0384   
   1200      837.71    105.6687   105.2446    0.7995     0.0329   
   1300      907.64    105.1928   104.8214    0.7711     0.0297   
   1400      977.53    105.4536   105.4137    0.9543     0.0262   
   1500     1047.37    105.8059   105.3588    0.7854     0.0232   
   1600     1117.03    105.2708   104.6735    0.6768     0.022    
   1700     1186.67    105.9495   105.2425    0.9845     0.0197   
   1800      1256.3    105.2384   104.5976    0.813      0.0172   
   1900     1325.89    106.3885   105.635     0.8056     0.0157   
   2000     1395.48    105.5054   105.1253    0.7837     0.0145   
   2100     1465.11    104.8779   104.5175    0.6051     0.0135   
   2200     1534.77    105.261    104.8043    0.7739     0.0124   
   2300     1604.38    104.5141   104.2809    0.563      0.0115   
   2400     1674.03    105.2929   104.8574    0.5182     0.0106   
   2500      1743.7    104.8976   104.4593    0.9384     0.0099   
   2600     1813.29    105.0657   104.5797    0.6193     0.0094   
   2700     1882.91    104.6145   104.307     0.7009     0.0087   
   2800     1952.54    105.1347   104.6295    0.7237     0.0083   
   2900      2022.3    105.1428   104.6234    0.7525     0.0077   
   3000     2092.14    104.8584   104.4919    0.6741     0.0074   
   3100     2161.74    105.3443   104.8303    0.7252     0.0068   
   3200     2231.55    105.3286   104.9452    0.7552     0.0064   
   3300      2301.5    104.8393   104.5165     0.69      0.0062   
   3400     2371.36    104.605    104.3703    0.6771     0.0059   
   3500     2441.33    104.8012   104.2472    0.6483     0.0055   
   3600      2511.2    104.3457   104.1971    0.5501     0.0053   
   3700     2581.23    104.5646   104.1338    0.6374     0.0051   
   3800      2651.2    104.4614   104.1662    0.5581     0.0048   
   3900     2721.18    104.2907   104.0628     0.66      0.0047   
   4000     2791.07    104.7827   104.3838    0.6344     0.0044   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       67.45     164.6899   165.3657    3.1613     0.437    
   200       137.98    128.4711   128.3479    2.4125     0.2903   
   300       208.15    118.1314   117.882     2.5021     0.2058   
   400       277.26    109.6979    110.06     1.6565     0.1551   
   500       346.71    108.0415   108.3558    1.2114     0.1191   
   600       417.27    108.9018   108.7575     1.29      0.0977   
   700       487.8     106.7418   106.6641    1.2386     0.081    
   800       558.27    107.1917   106.8388    0.943      0.0657   
   900       628.66    106.4803   106.4929    1.2317     0.0564   
   1000      699.16    106.1417   106.1685    1.011      0.0482   
   1100      769.57    107.0918   106.9109    0.9495     0.042    
   1200      839.97    106.2509   106.0034    0.9377     0.0377   
   1300      905.84    105.6866   105.6159    0.9648     0.0332   
   1400      967.53    105.0959   104.7582    0.7579     0.0292   
   1500     1029.48    105.8395   105.5906    0.8035     0.0262   
   1600     1090.32    105.7146   105.6464    0.6702     0.0241   
   1700     1151.24    105.2099   105.4958    0.621      0.0221   
   1800     1212.29    104.9482   104.8691    0.5334     0.0206   
   1900      1273.8    105.1491   105.0184    0.815      0.0186   
   2000     1335.17    104.633    104.6607    0.5975     0.0174   
   2100     1396.72    105.2725   105.4247    0.794      0.0158   
   2200     1457.89    105.331    105.6431    0.757      0.0145   
   2300     1519.26    105.2516   104.9961    0.7076     0.0138   
   2400     1580.82    104.627    104.7792    0.6637     0.0126   
   2500     1641.69    105.288    105.5789    0.8518     0.0116   
   2600     1702.58    105.1833   105.1008    1.0219     0.0113   
   2700     1764.15    104.427    104.811     0.6932     0.0104   
   2800     1825.53    105.1825   105.3854    0.898      0.0094   
   2900      1886.5    104.8649   105.1291    0.6622     0.0091   
   3000     1947.43    104.8179   104.9134    0.6464     0.0086   
   3100     2009.03    105.2285   105.1486    0.6873     0.0081   
   3200     2071.03    104.8131   104.7787    0.6834     0.0077   
   3300     2132.01    104.8824   104.7948    0.5687     0.0072   
   3400      2193.4    104.547    104.6048    0.7035     0.007    
   3500     2254.93    104.6766   104.7111    0.6312     0.0068   
   3600     2315.98    104.4617   104.4452    0.5254     0.0062   
   3700     2377.55    105.1753   105.2376    0.8453     0.0059   
   3800     2438.91    104.737    104.7593    0.6756     0.0058   
   3900     2499.54    104.8755   105.0377    0.6579     0.0055   
   4000     2560.53    105.0482   104.8697    0.655      0.0052   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       58.41     171.4473   171.1335    3.161      0.3901   
   200       120.26    126.9527   127.0879    2.8483     0.2708   
   300       181.82    118.257    118.3387    2.4844     0.1969   
   400       243.45    112.3903   112.5199    2.1643     0.1537   
   500       305.09    109.5401   109.7567    1.7318     0.1239   
   600       366.47    107.4607   107.6759    1.0207     0.0987   
   700       428.79    107.6712   107.697     1.1569     0.0825   
   800       491.32    107.044    106.5578    1.1278     0.0696   
   900       552.97    107.1467   106.9461    1.1792     0.0603   
   1000      614.46    107.5655   107.4711    1.254      0.0528   
   1100      676.25    105.724    105.6449    0.8909     0.046    
   1200      738.35    106.0149   106.2366    0.8502     0.0399   
   1300      800.91    106.3339   106.2952    0.7246     0.0358   
   1400      863.8     105.9561   106.2038    0.9119     0.032    
   1500      925.94    105.172    105.3445    0.7061     0.0286   
   1600      987.66    105.1909   105.3771    0.8669     0.0264   
   1700      1050.2    105.515    105.6124    1.0395     0.024    
   1800     1111.62    106.0352   106.1408    0.8361     0.0216   
   1900     1173.76    104.956    105.2357    0.832      0.0203   
   2000     1237.01     105.73    105.9423    1.0439     0.0184   
   2100     1300.52    105.2575   105.4936    0.8534     0.017    
   2200     1364.34    105.0868   105.3289    0.7155     0.0161   
   2300     1435.55    105.3915   105.7203    0.7521     0.0154   
   2400     1506.67    105.6224   105.5519    0.9039     0.0138   
   2500     1577.84    104.857    104.8918    0.7142     0.0127   
   2600     1648.97    104.8449   104.9473    0.6494     0.0126   
   2700     1720.12    105.0178   105.3109    0.7732     0.0112   
   2800     1791.25    105.3722   105.1927    0.8123     0.0107   
   2900     1862.39    104.6882   104.9494    0.5199     0.0101   
   3000     1933.51    104.7677   104.8671    0.7047     0.0096   
   3100     2004.63    104.9854   105.2853    0.7075     0.0092   
   3200     2075.75    104.7904   104.8672    0.5634     0.0086   
   3300     2146.91    104.7489   104.7174    0.6551     0.0081   
   3400     2218.05    105.0461   104.987     0.8167     0.0076   
   3500     2289.15    103.9458   104.309     0.6646     0.0072   
   3600     2360.21    104.6416   104.8451    0.9233     0.0071   
   3700     2431.27    104.4991   104.7015    0.7303     0.0066   
   3800     2502.34    104.5328   104.6919    0.5686     0.0064   
   3900     2573.44    104.9599   105.1944    0.6665     0.006    
   4000      2644.5    104.5764   104.9269    0.5334     0.0058   
