Generating synthetic  count valued data ... 
Generating synthetic  count valued data took:  7.958353519439697
max_count =  19  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   | test_err | train_err|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       52.29      2.7137     2.7549     0.3162     0.2943    58906.35   47302.64     0.0    
   100       228.81     2.6932     2.7306     0.282      0.2261    57559.19   46222.16    0.0001  
   150       403.45     2.6702     2.7156     0.2456     0.1801    56569.5    45428.44     0.0    
   200       577.55     2.6593     2.701      0.225      0.152     55820.45   44827.9      0.0    
   250       751.64     2.6508     2.6915     0.2132     0.1313    55207.04   44336.58    0.0001  
   300       925.78     2.642      2.6826     0.2041     0.1153    54694.7    43926.86    0.0001  
   350      1099.91     2.6327     2.6765     0.1857     0.0977    54267.42   43585.64     0.0    
   400      1274.04     2.6274     2.6675     0.1713     0.0899    53893.38   43286.84    0.0001  
   450      1448.06     2.621      2.6622     0.1649     0.079     53564.28   43024.7      0.0    
   500      1622.06     2.6185     2.6563     0.1643     0.0757    53276.98   42795.98     0.0    
   550      1796.06     2.6171     2.656      0.1436     0.0652    53014.71   42587.8      0.0    
   600      1970.06     2.6134     2.6527     0.1452     0.0648    52779.31   42400.96     0.0    
   650      2144.04     2.6092     2.6483     0.1356     0.0589    52565.31   42231.33     0.0    
   700      2317.96     2.6068     2.6439     0.1348     0.0526    52370.03   42076.62     0.0    
   750      2491.89     2.6015     2.6466     0.142      0.0515    52191.68   41935.14     0.0    
   800      2665.83     2.5996     2.6414     0.1237     0.046     52030.72   41807.84     0.0    
   850       2839.8     2.5993     2.6391     0.1306     0.0434    51880.62   41689.37     0.0    
   900      3013.77     2.5964     2.6362     0.1148     0.0413    51742.64   41580.45     0.0    
   950       3187.6     2.593      2.6321     0.1271     0.0399    51613.68   41478.72     0.0    
   1000      3361.4     2.5929     2.6327     0.1199     0.0368    51494.7    41384.96     0.0    
   1050     3535.26     2.5912     2.628      0.1243     0.0369    51381.76   41295.94     0.0    
   1100     3709.04     2.5882     2.6304     0.1101     0.0341    51278.8    41214.86     0.0    
   1150     3882.97     2.5855     2.6276     0.1082     0.0325    51183.84   41140.12     0.0    
   1200     4056.85     2.5885     2.6284     0.1165     0.0319    51092.06   41067.94     0.0    
   1250      4230.7     2.5844     2.6253     0.103      0.0291    51008.25   41001.98     0.0    
   1300     4404.51     2.5838     2.6251     0.1012     0.0287    50930.22   40940.84     0.0    
   1350     4578.29     2.5808     2.6232     0.1031     0.0285    50858.98   40884.88     0.0    
   1400     4752.14     2.5803     2.6197     0.1005     0.0267    50790.95   40831.44     0.0    
   1450     4925.99     2.5775     2.6207     0.0915     0.0259    50727.61   40781.59     0.0    
   1500     5099.86     2.5783     2.6163     0.0971     0.0248    50671.47   40737.54     0.0    
   1550     5273.69     2.5775     2.6171     0.0997     0.0245    50618.02   40695.57     0.0    
   1600     5447.56     2.5754     2.6156     0.1039     0.0245    50569.81   40657.28     0.0    
   1650     5621.44     2.5707     2.6129     0.1018     0.0239    50526.81   40623.2      0.0    
   1700      5795.4     2.5707     2.6097     0.1102     0.0226    50488.39   40592.53     0.0    
   1750     5969.23     2.5644     2.6075     0.1214     0.0223    50454.85   40565.15     0.0    
   1800     6143.04     2.5556     2.597      0.1341     0.021     50426.42   40541.25     0.0    
   1850     6316.86     2.5442     2.5852     0.1443     0.0203    50401.5    40518.99     0.0    
   1900      6490.7     2.5274     2.5679     0.1628     0.0206    50381.69   40499.64     0.0    
   1950     6664.57     2.4987     2.5388     0.1871     0.0201    50373.37   40487.65     0.0    
   2000      6838.4     2.4574     2.4941     0.203      0.0193    50397.22   40499.31     0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   | test_err | train_err|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       51.83      2.7283     2.7567     0.2011     0.1877    59816.4    96196.4      0.0    
   100       281.33     2.7155     2.7419     0.1527     0.1597    58865.05   94666.21     0.0    
   150       509.59     2.6951     2.724      0.1625     0.1411    58072.77   93391.82     0.0    
   200       737.37     2.6874     2.7142     0.1443     0.1262    57393.25   92298.25     0.0    
   250       965.13     2.6738     2.703      0.1487     0.1138    56809.49   91357.07     0.0    
   300      1192.89     2.6657     2.6959     0.1446     0.0985    56300.23   90537.33     0.0    
   350      1420.68     2.6567     2.6895     0.1288     0.0942    55850.56   89813.63     0.0    
   400      1648.43     2.6519     2.685      0.123      0.0917    55448.17   89165.81     0.0    
   450      1876.14     2.6455     2.6766     0.1209     0.0797    55091.01   88591.42     0.0    
   500      2103.76     2.6389     2.6728     0.1213     0.0734    54765.73   88068.67     0.0    
   550      2331.41     2.6365     2.6665     0.1162     0.0653    54472.19   87597.28     0.0    
   600       2559.0     2.6331     2.6611     0.1216     0.0647    54202.21   87163.74     0.0    
   650       2786.6     2.6215     2.6586     0.1069     0.0671    53952.43   86762.94     0.0    
   700      3014.19     2.6184     2.6561     0.1089     0.0547    53719.14   86389.14     0.0    
   750      3241.75     2.6177     2.6543     0.1177     0.0524    53501.41   86040.66     0.0    
   800      3469.33     2.6162     2.6491     0.1089     0.0517    53301.56   85721.1      0.0    
   850      3696.86     2.6122     2.6444     0.1118     0.0496    53114.93   85422.62     0.0    
   900      3924.42     2.6102     2.6421     0.1013     0.0471    52940.02   85143.01     0.0    
   950      4151.86     2.6083     2.6401     0.0905     0.0416    52776.69   84881.73     0.0    
   1000     4379.44     2.6072     2.6353     0.0944     0.0411    52622.24   84634.93     0.0    
   1050     4606.88     2.6029     2.6374     0.0954     0.039     52477.02   84403.12     0.0    
   1100     4834.41     2.5988     2.634      0.0989     0.0378    52338.73   84182.4      0.0    
   1150     5061.97     2.5986     2.6319     0.1018     0.0375    52208.75   83975.29     0.0    
   1200     5289.57     2.5965     2.6279     0.0997     0.0344    52085.11   83778.0      0.0    
   1250     5517.19     2.5963     2.6274     0.0886     0.0332    51967.81   83590.89     0.0    
   1300      5744.8     2.5917     2.6259     0.0817     0.0317    51857.33   83415.1      0.0    
   1350     5972.28     2.5891     2.6234     0.0793     0.0304    51751.7    83247.03     0.0    
   1400     6199.88     2.5889     2.6245     0.0885     0.0294    51651.65   83087.94     0.0    
   1450     6427.42     2.5894     2.623      0.0817     0.0293    51555.73   82935.21     0.0    
   1500     6655.24     2.5863     2.6219     0.0797     0.0285    51464.01   82789.31     0.0    
   1550     6882.85     2.5864     2.6199     0.0798     0.0275    51377.02   82651.0      0.0    
   1600     7110.19     2.5839     2.6196     0.0738     0.025     51293.97   82519.01     0.0    
   1650     7337.64     2.5812     2.6163     0.0762     0.0262    51214.64   82393.07     0.0    
   1700      7565.1     2.5834     2.6161     0.0777     0.0246    51139.79   82274.13     0.0    
   1750     7792.58     2.5818     2.6158     0.0786     0.0232    51066.62   82158.1      0.0    
   1800     8019.87     2.5762     2.6132     0.0716     0.0237    50996.52   82046.82     0.0    
   1850     8247.56     2.5779     2.6137     0.076      0.026     50929.81   81941.14     0.0    
   1900     8475.23     2.5787     2.6108     0.0726     0.0233    50866.79   81841.18     0.0    
   1950     8702.78     2.576      2.6116     0.0745     0.0217    50806.46   81745.69     0.0    
   2000     8930.54     2.5763     2.6091     0.076      0.0216    50748.18   81653.43     0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   | test_err | train_err|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50        51.7      2.7289     2.7515     0.1374     0.1325    60148.08  145275.92     0.0    
   100       334.92     2.7163     2.7386     0.1284     0.1225    59417.99  143501.84     0.0    
   150       617.97     2.7062     2.7246     0.1339     0.1129    58774.38  141936.46     0.0    
   200       901.09     2.6917     2.7145     0.1243     0.1041    58202.8    140543.8     0.0    
   250      1184.16     2.6852     2.7078     0.1181     0.1038    57686.88   139285.9     0.0    
   300      1466.98     2.6807     2.6999     0.1315     0.0881    57224.45  138157.72     0.0    
   350      1749.94     2.6705      2.69      0.1127     0.0847    56803.59  137130.11     0.0    
   400      2032.83     2.6628     2.6871     0.117      0.0777    56421.62  136197.83     0.0    
   450      2315.29     2.6558     2.6798     0.1054     0.0726    56069.73  135337.88     0.0    
   500      2596.99     2.6519     2.675      0.1097     0.0683    55746.78  134549.19     0.0    
   550      2878.52     2.6477     2.6682     0.1069     0.066     55449.68  133824.55     0.0    
   600      3159.94     2.6411     2.662      0.1097     0.0603    55176.55  133158.01     0.0    
   650      3441.48     2.6372     2.6617     0.0933     0.0587    54919.47  132530.72     0.0    
   700       3722.9     2.6314     2.6569     0.0893     0.0542    54680.21  131948.26     0.0    
   750      4004.37     2.6289     2.6548     0.0897     0.0555    54454.38  131397.78     0.0    
   800      4285.69     2.6271     2.6499     0.0952     0.0545    54243.63  130885.05     0.0    
   850      4566.73     2.6224     2.6475     0.0948     0.0508    54042.79  130396.38     0.0    
   900      4847.75     2.6218     2.6443     0.0936     0.0455    53855.9   129941.61     0.0    
   950      5128.94     2.6177     2.6413     0.0912     0.0457    53679.23  129512.12     0.0    
   1000     5410.35     2.6124     2.639      0.0915     0.042     53513.1   129108.84     0.0    
   1050      5691.8     2.6122     2.6361     0.0877     0.0401    53356.76  128729.05     0.0    
   1100     5972.84     2.6085     2.6343     0.0886     0.0391    53205.0   128360.86     0.0    
   1150     6253.96     2.6076     2.6305     0.0846     0.037     53062.55  128015.49     0.0    
   1200     6535.39     2.6063     2.6298     0.0902     0.0368    52926.48  127685.61     0.0    
   1250      6816.8     2.6033     2.6253     0.0897     0.0361    52796.7   127371.19     0.0    
   1300      7098.3     2.6019     2.625      0.0778     0.0345    52672.63  127070.68     0.0    
   1350     7379.28     2.5975     2.6231     0.0691     0.0345    52554.29  126784.26     0.0    
   1400     7660.39     2.5961     2.622      0.0821     0.0315    52440.5   126508.94     0.0    
   1450     7941.45     2.5952     2.6193     0.085      0.0305    52332.79  126248.39     0.0    
   1500     8222.86     2.5942     2.6182     0.0734     0.0287    52228.38  125995.98     0.0    
   1550     8504.12     2.5926     2.618      0.0734     0.0283    52128.37  125754.52     0.0    
   1600     8785.47     2.5902     2.6161     0.0734     0.028     52032.03  125521.62     0.0    
   1650     9066.79     2.5904     2.6133     0.0763     0.0277    51940.26  125299.92     0.0    
   1700     9348.19     2.587      2.612      0.0723     0.0253    51851.52  125085.92     0.0    
   1750     9629.62     2.5892     2.6102     0.0733     0.0275    51766.38   124880.5     0.0    
   1800      9911.2     2.587      2.6106     0.0736     0.0249    51684.1   124682.06     0.0    
   1850     10192.63    2.5865     2.6088     0.0707     0.025     51605.33  124492.03     0.0    
   1900     10473.92    2.5818     2.609       0.07      0.0243    51528.89  124307.57     0.0    
   1950     10755.09    2.5818     2.6068     0.0707     0.0238    51455.33  124130.26     0.0    
   2000     11036.38    2.5834     2.6057     0.0688     0.0212    51384.35  123959.53     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   | test_err | train_err|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       51.43      2.7366     2.7399     0.121      0.1092    60324.13  193625.52     0.0    
   100       386.94     2.7217     2.7292     0.1154     0.103     59715.03  191664.17     0.0    
   150       722.43     2.7092     2.719      0.1109     0.0952    59169.26  189904.13     0.0    
   200      1057.92     2.7028     2.7089     0.1084     0.0943    58665.87  188278.05     0.0    
   250      1393.32     2.6935     2.7035     0.1032     0.0845    58212.26  186813.05     0.0    
   300      1728.59     2.6864     2.6955     0.1008     0.0782    57791.26  185452.14     0.0    
   350      2063.87     2.6789     2.6863     0.0984     0.0768    57403.07   184196.1     0.0    
   400      2399.09     2.6763     2.6794     0.1053     0.0717    57046.19  183041.23     0.0    
   450      2734.29     2.662      2.6726     0.1057     0.0627    56717.87  181978.13     0.0    
   500      3069.63     2.6615     2.671      0.1051     0.0715    56408.4   180977.98     0.0    
   550      3404.95     2.6579     2.6667     0.0969     0.0603    56120.91  180048.14     0.0    
   600       3740.3     2.6505     2.6581     0.0928     0.0564    55848.85  179167.84     0.0    
   650      4075.71     2.6487     2.6556     0.0956     0.0549    55594.94  178346.45     0.0    
   700      4411.09     2.6446     2.6519     0.0914     0.0527    55358.4   177581.51     0.0    
   750      4746.45     2.6355     2.6486     0.0898     0.0511    55134.15  176855.58     0.0    
   800       5081.8     2.634      2.6464     0.0851     0.0479    54921.55  176168.94     0.0    
   850      5417.16     2.6326     2.6429     0.0842     0.0458    54721.99  175524.52     0.0    
   900       5752.3     2.6258     2.6373     0.085      0.0461    54532.01  174911.15     0.0    
   950      6090.07     2.6264     2.6354     0.0754     0.0448    54349.44  174321.67     0.0    
   1000      6428.3     2.6229     2.6333     0.0906     0.0414    54177.85  173768.67     0.0    
   1050     6766.71     2.6202     2.6309     0.0774     0.0405    54014.24  173240.75     0.0    
   1100     7105.21     2.616      2.6269     0.0841     0.0372    53859.6   172742.71     0.0    
   1150      7447.3     2.6138     2.6254     0.0783     0.0398    53711.02  172263.46     0.0    
   1200     7785.92     2.6165     2.6221     0.0829     0.0349    53568.0   171803.27     0.0    
   1250     8124.33     2.6111     2.6205     0.0777     0.034     53431.63  171364.01     0.0    
   1300     8462.76     2.6087     2.6185     0.0706     0.034     53301.46  170945.03     0.0    
   1350      8801.1     2.6077     2.615      0.0776     0.0327    53176.86  170544.18     0.0    
   1400     9142.76     2.6047     2.6168     0.0793     0.031     53056.91  170158.21     0.0    
   1450     9481.36     2.6001     2.6123     0.0751     0.0301    52942.36  169789.64     0.0    
   1500     9819.95     2.6021     2.612      0.0728     0.031     52831.12  169431.76     0.0    
   1550     10158.52     2.6       2.6104     0.0705     0.0277    52724.47  169088.77     0.0    
   1600     10497.34    2.6008     2.6085     0.0675     0.0292    52621.58  168758.42     0.0    
   1650     10840.04    2.5991     2.6052     0.0697     0.0266    52522.94  168441.46     0.0    
   1700     11179.59    2.5964     2.6048     0.0802     0.0251    52427.89  168136.11     0.0    
   1750     11519.18    2.5934     2.6029     0.0723     0.0271    52335.44  167839.34     0.0    
   1800     11858.54    2.5901     2.6033     0.0723     0.0259    52246.3   167553.18     0.0    
   1850     12198.09    2.5901     2.6011     0.0671     0.0248    52159.81   167275.5     0.0    
   1900     12537.36    2.5928     2.5992     0.0677     0.0237    52076.45  167007.96     0.0    
   1950     12880.95    2.5892     2.5972     0.0611     0.0243    51995.93  166749.68     0.0    
   2000     13220.1     2.5891     2.598      0.0633     0.0225    51918.33  166500.82     0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   | test_err | train_err|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       52.09      2.7371     2.7363     0.1062     0.0971    60419.47   242722.3     0.0    
   100       446.77     2.7217     2.7233     0.1066     0.0891    59896.55  240610.49     0.0    
   150       842.03     2.7132     2.7168     0.1024     0.0822    59418.16  238675.26     0.0    
   200      1240.53     2.7035     2.7111     0.099      0.0794    58970.68  236863.49     0.0    
   250      1634.94     2.6999     2.7023     0.1042     0.0745    58560.09   235200.3     0.0    
   300      2029.35     2.6953     2.6943     0.0999     0.0667    58175.63  233642.98     0.0    
   350      2423.88     2.6859     2.6881     0.0948     0.0735    57817.37  232191.04     0.0    
   400      2823.01     2.6788     2.6816     0.0945     0.0631    57484.88  230842.59     0.0    
   450      3219.39     2.6712     2.6763     0.0924     0.0611    57167.55  229555.34     0.0    
   500      3615.68     2.6702     2.6725     0.0909     0.0609    56872.97  228360.76     0.0    
   550       4013.7     2.6624     2.6677     0.1026     0.0535    56598.04  227245.08     0.0    
   600      4411.92     2.6604     2.6611     0.0899     0.0549    56338.08  226189.53     0.0    
   650      4811.19     2.6543     2.6597     0.0802     0.0515    56088.91  225177.68     0.0    
   700       5209.4     2.6473     2.6524     0.0875     0.0499    55855.58  224231.07     0.0    
   750      5607.63     2.6464     2.6507     0.0785     0.0468    55638.6   223350.07     0.0    
   800      6005.98     2.6442     2.6481     0.0804     0.0453    55432.62  222513.23     0.0    
   850      6405.37     2.6389     2.6433      0.08      0.0448    55233.54  221705.94     0.0    
   900       6803.5     2.6391     2.6409     0.0758     0.0419    55043.43  220935.17     0.0    
   950      7201.71     2.6311     2.6363     0.0793     0.0392    54864.86  220211.04     0.0    
   1000      7600.0     2.6301     2.6349     0.0738     0.0403    54694.59  219520.36     0.0    
   1050     7997.94     2.6299     2.6305     0.0721     0.0396    54528.77  218847.53     0.0    
   1100     8397.78     2.6254     2.6289     0.0729     0.0378    54372.48  218213.89     0.0    
   1150     8795.56     2.6214     2.6255     0.0768     0.0356    54220.7   217599.31     0.0    
   1200     9193.31     2.6191     2.6238     0.0675     0.0374    54075.75  217012.46     0.0    
   1250      9591.2     2.6203     2.6217     0.0672     0.0329    53935.16  216442.97     0.0    
   1300     9990.54     2.6168     2.6212     0.0714     0.0329    53802.53  215906.23     0.0    
   1350     10388.64    2.6145     2.6183     0.072      0.0367    53672.69  215380.84     0.0    
   1400     10786.37    2.6121     2.6153     0.0642      0.03     53549.69  214883.39     0.0    
   1450     11184.38    2.6149     2.6144     0.0683     0.0319    53430.45  214401.09     0.0    
   1500     11582.39    2.6069     2.6124     0.0611     0.029     53317.82  213945.94     0.0    
   1550     11982.16    2.608      2.6093     0.0631     0.0282    53207.15  213498.37     0.0    
   1600     12380.17    2.6065     2.6095     0.0674     0.0284    53099.52  213063.23     0.0    
   1650     12778.31    2.6025     2.6093     0.0627     0.028     52996.2   212645.91     0.0    
   1700     13176.29    2.6008     2.6063     0.0687     0.0262    52897.06  212245.75     0.0    
   1750     13575.53     2.6       2.603      0.0646     0.026     52799.73  211852.51     0.0    
   1800     13973.52    2.5994     2.6029     0.0624     0.0268    52705.56   211472.2     0.0    
   1850     14371.8     2.5978     2.6022     0.0572     0.0246    52615.54  211108.39     0.0    
   1900     14770.05    2.5964     2.6002     0.0556     0.0237    52527.99  210755.36     0.0    
   1950     15168.51    2.5937     2.5987     0.0573     0.0244    52442.61  210410.45     0.0    
   2000     15567.65    2.596      2.596      0.0604     0.0227    52360.7   210079.59     0.0    
