Generating synthetic  real valued data ... 
Generating synthetic  real valued data took:  6.674018144607544
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       128.48    373.5064   373.3549    3.1623     4.4719   
   100       264.81    199.5149   199.6186    3.1622     0.2708   
   150       399.81    167.8248   167.6452    2.7498     0.1084   
   200       532.57    158.3946   158.0223    2.5942     0.1283   
   250       656.99    151.8615   151.5665    2.1371     0.0605   
   300       784.62    151.1766   150.5291    2.1959     0.051    
   350       916.77    150.1188   150.3603    2.1976     0.0245   
   400      1048.37    150.2048    148.86     1.8733     0.0427   
   450      1180.15    147.8019   147.6965    1.5427     0.0217   
   500      1312.25    148.5157   147.6753    1.7946     0.0204   
   550      1444.27    146.9539   146.9519    1.3895     0.0189   
   600       1576.5    146.9539   146.509     1.0484     0.0169   
   650      1709.08    147.738    147.4475    1.0764     0.0133   
   700      1840.52    147.9263   147.6512    1.3617     0.0091   
   750      1972.86    147.0425   147.1068    1.5843     0.0086   
   800      2105.14    147.6143   147.0574    1.1868     0.0099   
   850      2237.53    147.8044   147.3854    1.3762     0.0094   
   900      2370.06    148.5569   148.1819    1.2964     0.0053   
   950      2502.64    147.3967   147.1674    1.2407     0.0065   
   1000     2634.69    147.3769   146.938     1.0271     0.0056   
   1050     2766.72    146.6258   146.7706    1.1347     0.0045   
   1100     2898.74    146.0553   146.2499    0.9971     0.0037   
   1150     3031.25    147.4011   146.6587    1.2184     0.0039   
   1200     3163.13    146.8771   146.5284    1.1264     0.0042   
   1250     3295.37    146.3656   146.2022    0.9579     0.0034   
   1300     3427.28    146.6573   146.1644    0.9477     0.0027   
   1350      3559.6    147.5157   146.7896    1.2471     0.0034   
   1400      3691.9    147.1353   146.666     1.1721     0.0028   
   1450     3823.83    146.7549   146.3996    1.1356     0.0032   
   1500     3956.33    146.5983   146.0829    1.0155     0.0028   
   1550     4088.71    146.2753   145.7502    0.9318     0.0024   
   1600     4221.05    145.985    146.1629    0.9596     0.0022   
   1650     4353.45    146.548    145.9776    1.046      0.002    
   1700     4485.31    146.1604    145.91     0.8283     0.0022   
   1750     4617.14    146.7783   146.3806    0.9915     0.0024   
   1800     4749.33    146.1242   145.8964    1.0065     0.0019   
   1850     4881.47    146.2732   145.873     0.8027     0.0017   
   1900     5013.62    146.5091   146.2684    0.9541     0.0019   
   1950     5145.68    146.8481   146.055     0.9296     0.0016   
   2000     5278.04    145.7796   145.663     0.884      0.0013   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       126.59    297.5675   297.7026    3.0504     4.4679   
   100       259.31    175.4476   175.0753    2.8894     0.5663   
   150       392.75    161.2851   160.7733    2.2919     0.153    
   200       525.71    153.5491   153.285     2.2487     0.0821   
   250       658.71    152.0995   151.7791    1.8042     0.0397   
   300       791.57    149.7646   149.7208    1.8842     0.0308   
   350       924.38    150.1245   149.5433    1.7595     0.0201   
   400      1057.19    149.3658   148.9278    1.777      0.0186   
   450      1189.88    148.4844   148.1747    1.5466     0.0135   
   500      1322.39    148.1183   148.3371    1.4279     0.0125   
   550      1455.51    148.6447   147.9882    1.6187     0.009    
   600      1588.43    147.3644   147.4191    1.2919     0.008    
   650      1722.37    147.0408   146.8878    0.9886     0.0071   
   700      1854.86    147.6762   147.1605    1.1564     0.0062   
   750      1987.81    146.9027   146.8846    1.2683     0.005    
   800      2120.73    146.5746   146.4344    1.207      0.005    
   850       2254.0    146.7356   146.8146    0.771      0.0046   
   900      2386.99    147.3856   146.7834    1.076      0.0042   
   950      2520.12    146.5946   146.6598    1.113      0.0036   
   1000     2652.53    146.8126   146.7146    1.0964     0.0034   
   1050     2785.08    146.8227   146.6673    1.0467     0.0029   
   1100     2918.68    146.669    146.275     1.1159     0.0021   
   1150     3051.91    146.2239   146.1221    0.8516     0.0023   
   1200     3185.32    146.1411   145.8339    0.9975     0.0021   
   1250      3319.2    147.4575   146.6361    0.8363     0.0019   
   1300     3452.22    146.719    146.482     1.0821     0.002    
   1350     3585.35    147.3062   146.8093    1.0198     0.0018   
   1400     3719.09    146.572    146.1411    0.9818     0.0017   
   1450     3852.85    146.5181   146.0835    0.9023     0.0019   
   1500      3987.1    146.0591   146.0173    1.1156     0.0014   
   1550     4120.76    145.7711   145.6656    0.9338     0.0013   
   1600      4254.0    146.4972   145.9774    0.9971     0.0012   
   1650     4387.51    145.4633   145.4298    0.9149     0.0012   
   1700     4521.28    146.0314   145.6947    0.6249     0.0011   
   1750     4654.83    146.5396   146.0836    0.8863     0.0012   
   1800     4788.33    146.5703   146.2601    0.9232     0.001    
   1850     4922.19    146.8489   146.1476    0.9145     0.0009   
   1900     5055.06    146.6366   146.0589    0.8178     0.0009   
   1950      5188.5    145.6205   145.7196    0.8711     0.0007   
   2000     5321.38    146.1264   145.8869    0.8284     0.0008   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       127.69    289.9423   289.0708    2.8862     4.4665   
   100       262.48    175.8394   174.4561    2.8125     0.3347   
   150       397.87    157.9827   157.5502    1.6801     0.1291   
   200       532.79    151.9361   151.2544    1.3229     0.0654   
   250       667.81    149.3553   148.9351    1.2795     0.0481   
   300       803.19    147.9564   147.335     1.3071     0.034    
   350       937.71    148.5971   148.2818    1.4382     0.0236   
   400      1072.84    146.9097   146.6347    1.3969     0.0163   
   450      1207.54    146.7751   146.309     1.071      0.0155   
   500      1342.48    147.2482   147.0687    1.1901     0.0123   
   550      1477.28    146.7648   146.6804    1.4154     0.0099   
   600      1612.02    146.763    146.3434    1.1435     0.0094   
   650      1747.14    147.4541   147.3547    1.3455     0.0082   
   700      1881.42    147.2582   146.8591    1.2639     0.0074   
   750      2016.36    147.1695   146.9056    1.1291     0.0054   
   800       2151.8    146.4666   146.3174    0.9523     0.0049   
   850      2286.72    146.0531   145.8826    0.9794     0.0044   
   900      2421.05    146.9235   146.3174    1.0387     0.0043   
   950      2556.01    146.2699   145.8544    1.0626     0.0039   
   1000     2690.26    147.1603   146.8421    1.3486     0.0034   
   1050     2824.84    146.6163   146.1428    1.2628     0.0027   
   1100      2959.5    146.4979   145.9459    0.869      0.0024   
   1150     3094.51    147.222    146.7575    1.4965     0.0023   
   1200     3228.78    146.236    145.9625    1.2126     0.0024   
   1250     3363.09    146.3917   145.9856    0.8685     0.0022   
   1300     3497.77    145.8166   145.8932    1.0784     0.0019   
   1350     3632.12    146.0482   145.7286    0.9868     0.0019   
   1400     3767.08    146.3791   145.9825    0.847      0.0016   
   1450     3901.55    146.2391   145.9001    0.8086     0.0015   
   1500      4036.6    146.0483   145.6595    0.9224     0.0015   
   1550      4171.7    146.5312   145.816     0.9793     0.0014   
   1600     4307.03    145.554    145.3652    0.8778     0.0012   
   1650     4441.43    146.0952   145.3138    0.7261     0.0012   
   1700     4575.82    145.7796   145.1211    1.0178     0.0012   
   1750      4710.1    145.2001   144.8385    0.6242     0.0011   
   1800     4845.02    146.2602   145.5772    0.7889     0.0011   
   1850     4980.18    145.6384   145.2798    0.7186     0.001    
   1900     5115.01    146.0614   145.5286    0.8206     0.001    
   1950     5249.24    145.3927   145.3606    0.6651     0.0009   
   2000     5383.88    146.4614   145.8475    0.8863     0.0009   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       127.84    284.8412   284.3961    2.7542     4.4658   
   100       262.85    179.6317   178.2816    2.5107     0.2628   
   150       398.35    159.2861   158.7047    1.5816     0.1045   
   200       534.36    152.2047   151.8474    1.5371     0.0562   
   250       669.83    149.375    149.5646    1.3653      0.04    
   300       805.13    147.8707   147.8425    1.1444     0.0309   
   350       941.18    147.1163   147.1539    1.1254     0.0235   
   400      1076.75    146.5952   147.164     1.1628     0.0155   
   450      1211.89    147.4049   147.2216    1.3221     0.0147   
   500      1346.94    146.8163   147.1535    1.1612     0.011    
   550      1482.32    146.3533   146.231     1.2034     0.0098   
   600       1618.0    145.647    145.7965    1.0618     0.0081   
   650      1753.22    145.7415   145.7627    0.6274     0.0066   
   700      1888.55    145.7564   146.2905    1.0073     0.0059   
   750      2024.14    146.3634   146.4095    1.0515     0.0053   
   800      2159.96    145.5264   145.9107    1.0052     0.0046   
   850      2297.45    145.8655   146.0098    0.7618     0.0039   
   900      2433.85    145.3205   145.6539    0.786      0.0037   
   950      2569.42    146.2923   146.1346    0.9652     0.003    
   1000     2704.31    145.4605   145.8865     0.94      0.0031   
   1050     2840.58    145.4007   145.6775    0.7379     0.0026   
   1100     2976.14    145.8797   145.9842    0.8469     0.0026   
   1150     3111.69    145.7804   145.9401    0.9432     0.0021   
   1200     3247.28    145.9315   146.0824    1.0207     0.0019   
   1250     3383.01    145.1426   145.6245    0.9424     0.002    
   1300     3518.11    145.4405   145.7577    0.9608     0.0019   
   1350     3653.69    145.3766   145.4364    0.7954     0.0016   
   1400     3789.05    145.9029   146.263     1.0106     0.0014   
   1450     3924.47    145.7595   145.8339    1.0581     0.0016   
   1500     4060.45    145.5641   145.8487    0.8134     0.0014   
   1550     4195.98    146.1744   146.0587    0.831      0.0013   
   1600      4331.6    146.2711   146.5855    0.9633     0.0013   
   1650     4466.36     145.26    145.5223    0.7751     0.0011   
   1700     4601.98    146.1327   146.4021    1.0561     0.0011   
   1750     4736.84    145.9202   146.1147    0.9217     0.0011   
   1800     4872.82    145.7901   145.7252    0.7411     0.001    
   1850     5008.73    145.1926   145.5197    0.8478     0.0009   
   1900     5144.76    145.2433   145.2751    0.709      0.0009   
   1950     5280.45    145.2427   145.2098    0.6496     0.0009   
   2000      5416.5    145.7292   145.5773    0.5592     0.0008   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
    50       127.7     286.4337   285.2802    2.6801     4.4653   
   100       263.78    186.312    184.7332    2.5058     0.4126   
   150       400.27    162.0426   161.5467    1.2132     0.1424   
   200       536.72    153.0361   152.3355    0.8285     0.0788   
   250       672.97    149.359    149.0708    0.6745     0.0414   
   300       808.66    147.6801   147.2026    0.965      0.0307   
   350       944.91    146.9272   146.6443    1.0241     0.0244   
   400       1080.5    146.3521   146.172     0.8621     0.0178   
   450      1216.79    146.2441   146.1762    0.8562     0.0122   
   500      1352.46    145.3587   145.255     0.7563     0.0135   
   550      1488.57    145.3029   145.3896    0.8505     0.0089   
   600       1625.0    145.243    145.148     0.8245     0.0082   
   650      1761.13    145.707    145.4028    0.7651     0.0069   
   700      1896.71    145.3541   145.5461    0.8851     0.0067   
   750       2032.6    146.0959   145.7618    0.8367     0.0055   
   800      2167.86    145.5203   145.7614    0.8158     0.0046   
   850      2303.93    145.1222   145.0178    0.7629     0.0043   
   900      2440.35    145.3108   145.1687    0.5325     0.0034   
   950      2576.32    145.7741   145.5191    0.697      0.0035   
   1000     2712.48    145.6048   145.5258    0.7133     0.003    
   1050     2848.71    145.7053   145.554     0.9927     0.0029   
   1100     2984.55    145.3406   145.3056    0.8743     0.0024   
   1150      3120.3    146.2814   146.0627    0.8509     0.0023   
   1200     3256.91    145.716    145.737     1.0231     0.0021   
   1250     3392.74    144.981    144.9721    0.7543     0.002    
   1300      3528.6    145.3722   145.4907    0.6579     0.002    
   1350     3664.75    145.2797   145.5097    0.7296     0.0017   
   1400      3800.6    145.9361   145.7451    0.7873     0.0017   
   1450     3936.79    145.1349   145.3855    0.9729     0.0014   
   1500      4073.7    145.6598   145.684     1.0601     0.0014   
   1550      4209.6    145.449    145.5491    0.7869     0.0013   
   1600     4344.81    144.9122   145.0694    0.5926     0.0012   
   1650     4480.44    145.017    145.0845    0.5862     0.0012   
   1700     4615.76    145.2047   145.2093    0.9659     0.0011   
   1750     4751.81    146.037    145.9212    1.0931     0.0011   
   1800     4887.31    145.6262   145.5714     1.02      0.0011   
   1850     5023.07    145.9984    145.88     1.0757     0.001    
   1900     5158.61    146.1075   145.9375    1.0727     0.001    
   1950     5294.94    145.3725   145.5801    0.9809     0.0008   
   2000     5430.08    145.159    145.268     0.8821     0.0008   
