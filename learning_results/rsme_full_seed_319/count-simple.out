Generating synthetic  count valued data ... 
Generating synthetic  count valued data took:  8.804458856582642
max_count =  16  min count =  0
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       128.66     4.2006     4.234      0.3162     4.415    128771.61  104392.11    0.0006  
   100       464.81     4.2029     4.2363     0.3135     0.292    127948.21  103718.84    0.0001  
   150       800.56     4.1895     4.2224     0.3004     0.0587   125123.62  101412.42     0.0    
   200       1136.6     4.1542     4.1867     0.296      0.0258   119180.64   96565.21     0.0    
   250      1472.03     4.0833     4.1152     0.2852     0.0273   109562.55   88743.7      0.0    
   300      1806.81     3.9661     3.9972     0.285      0.0238    97300.28   78785.95     0.0    
   350      2141.37     3.7947     3.8246     0.281      0.0206    83853.91   67873.27     0.0    
   400      2477.08     3.5726     3.6002     0.2648     0.017     70961.93   57433.29     0.0    
   450      2813.91     3.3151     3.3407     0.2502     0.0137    59844.76   48425.82     0.0    
   500      3149.06     3.0483     3.0723     0.2289     0.0103    51095.52   41344.93     0.0    
   550      3484.52     2.7959     2.8169      0.22      0.0107    44703.91   36167.58     0.0    
   600      3819.88     2.5662     2.584      0.1977     0.0115    40097.87   32439.76     0.0    
   650      4155.15     2.3632     2.3776     0.2115     0.0114    36799.33   29758.51    0.0001  
   700      4491.31     2.1841     2.1947     0.1714     0.0114    34397.88   27808.3     0.0001  
   750      4827.98     2.022      2.0323     0.1696     0.0112    32592.08   26340.63    0.0001  
   800      5164.54     1.8833     1.8899     0.2075     0.0113    31240.12   25246.47     0.0    
   850      5500.05     1.7614     1.7681     0.1015     0.011     30228.95   24430.72     0.0    
   900      5835.85     1.6588     1.661      0.1615     0.0106    29449.57   23788.94     0.0    
   950       6171.5     1.5715     1.5733     0.1183     0.0105    28870.55   23314.86     0.0    
   1000     6506.79     1.4935     1.4942     0.1297     0.0107    28399.72   22941.5      0.0    
   1050     6842.56     1.4248     1.4253     0.1478     0.0094    28021.32   22627.48     0.0    
   1100      7178.4     1.3698     1.3657     0.1003     0.0092    27728.82   22385.35     0.0    
   1150     7514.06     1.3182     1.3148     0.0942     0.009     27487.78   22187.1      0.0    
   1200     7848.32     1.2784     1.273      0.0925     0.0087    27302.5    22040.88     0.0    
   1250      8184.1     1.2432     1.2367     0.1126     0.0088    27149.6    21919.19     0.0    
   1300     8520.22     1.2104     1.2035     0.1275     0.0083    27027.8    21813.93     0.0    
   1350     8854.95     1.1841     1.1765     0.0717     0.0081    26922.71   21730.64     0.0    
   1400     9190.34     1.1593     1.1512     0.1323     0.008     26826.43   21656.99     0.0    
   1450     9525.89     1.1374     1.1298     0.096      0.0077    26732.58   21578.51     0.0    
   1500     9860.67     1.122      1.1121     0.1076     0.0074    26691.19   21544.19     0.0    
   1550     10195.13    1.1035     1.0938     0.1134     0.0071    26620.69   21481.83     0.0    
   1600     10530.83    1.0919     1.0796     0.1366     0.0073    26591.04   21457.09     0.0    
   1650     10865.27    1.0806     1.0694     0.1631     0.0067    26555.99   21431.08     0.0    
   1700     11200.05    1.0723     1.0614     0.1784     0.0066    26527.83   21417.15     0.0    
   1750     11535.34    1.0606     1.0515     0.1161     0.0063    26506.01   21402.14     0.0    
   1800     11871.69    1.0543     1.0436     0.0929     0.0063    26478.6    21369.8      0.0    
   1850     12206.79    1.0489     1.0376     0.0852     0.0062    26468.1    21365.06     0.0    
   1900     12542.17    1.0388     1.0279     0.097      0.0058    26415.98   21329.14     0.0    
   1950     12877.56    1.0321     1.0198     0.1672     0.006     26393.92   21305.12     0.0    
   2000     13212.71    1.0265     1.0137     0.0884     0.0055    26367.2    21281.54     0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       130.17     4.1406     4.1621     0.0697     3.5915    84681.83  136802.09    0.0001  
   100       556.61     4.1752     4.1957     0.0324     0.7941   107068.28  173055.89    0.0001  
   150       982.12     4.1827     4.2042     0.0276     0.3862   115327.83   186392.1    0.0001  
   200      1406.47     4.1873     4.2096     0.0239     0.2536   119262.26  192740.72    0.0001  
   250      1832.58     4.1904     4.2127     0.0251     0.1891   121470.73  196301.44    0.0001  
   300      2256.67     4.1935     4.2156     0.0263     0.1469   122887.28  198584.28    0.0001  
   350      2682.23     4.1957     4.2178     0.0286     0.1163   123854.42  200142.11     0.0    
   400      3107.87     4.1976     4.2199     0.0281     0.0962   124556.68  201272.72     0.0    
   450       3533.1     4.1995     4.2213     0.0313     0.0814   125085.09  202123.62     0.0    
   500      3957.79     4.2007     4.2228     0.0322     0.0697   125496.77  202786.16     0.0    
   550      4382.99     4.2022     4.2243     0.0341     0.0611   125827.43  203318.28     0.0    
   600      4808.16     4.2031     4.2258     0.0334     0.0544   126096.15  203750.76     0.0    
   650      5232.74     4.2043     4.2263     0.034      0.0482   126318.38  204108.38     0.0    
   700       5657.8     4.2053     4.2275     0.0316     0.0439   126504.77  204408.31     0.0    
   750      6083.82     4.2064     4.2285     0.0353     0.039    126660.07  204658.11     0.0    
   800      6508.84     4.2067     4.2289     0.0367     0.0355   126791.94  204870.14     0.0    
   850       6932.5     4.2073     4.2299     0.0355     0.0328   126903.88  205050.15     0.0    
   900      7356.48     4.2083     4.2303     0.0357     0.0299   126997.14  205200.12     0.0    
   950      7781.17     4.2085     4.2311     0.0351     0.0279   127075.25   205325.7     0.0    
   1000     8205.92     4.2092     4.2315     0.0363     0.026    127138.85  205427.82     0.0    
   1050     8629.49     4.2097     4.2319     0.0367     0.0237   127188.05  205506.79     0.0    
   1100     9054.28     4.2101     4.2322     0.0395     0.0222   127223.13  205562.83     0.0    
   1150     9479.38     4.2103     4.2327     0.0405     0.0209   127243.41  205595.05     0.0    
   1200     9903.61     4.2104     4.2328     0.043      0.0194   127247.91  205601.81     0.0    
   1250     10328.24    4.2104     4.2329     0.0402     0.0182   127233.73  205578.53     0.0    
   1300     10752.98    4.2105     4.2328     0.0451     0.0171   127196.82  205518.33     0.0    
   1350     11178.02    4.2103     4.2327     0.048      0.0162    127133.7  205415.83     0.0    
   1400     11601.87    4.2102     4.2324     0.0539     0.0152   127038.34  205261.45     0.0    
   1450     12026.24    4.2097     4.2321     0.0559     0.0144   126900.13  205037.38     0.0    
   1500     12451.85    4.2086     4.2312     0.0605     0.0135   126706.78  204724.96     0.0    
   1550     12876.96    4.2075      4.23      0.0648     0.0132   126436.45  204287.62     0.0    
   1600     13300.81    4.2058     4.2283     0.0686     0.0125   126064.83  203686.32     0.0    
   1650     13726.12    4.2032     4.2257     0.0784     0.0121   125548.93  202852.16     0.0    
   1700     14151.52    4.1995     4.2218     0.0825     0.0118   124833.05  201695.13     0.0    
   1750     14575.97    4.1939     4.216      0.1014     0.0112   123797.99  200022.85     0.0    
   1800     14999.43    4.1861     4.208      0.1129     0.0112   122365.83  197707.12     0.0    
   1850     15422.55    4.1734     4.1953     0.1205     0.0113   120247.75  194290.45     0.0    
   1900     15847.94    4.154      4.1761     0.1444     0.0117   117273.31  189484.62     0.0    
   1950     16271.84    4.1248     4.1466     0.1611     0.0126   113062.39  182671.42     0.0    
   2000     16695.46    4.0819     4.1031     0.1717     0.0144   107493.98  173680.96     0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       129.51     4.1512     4.166      0.0743     3.4291    78521.5    189644.1     0.0    
   100       646.19     4.2003     4.2154     0.0412     0.8903   102029.04  246442.86     0.0    
   150       1162.3     4.2094     4.2242     0.0268     0.409    112024.95  270548.06     0.0    
   200      1678.29     4.2127     4.2275     0.0248     0.2706   116912.86  282313.06     0.0    
   250      2193.56     4.2143     4.2291     0.0275     0.1938   119730.54  289091.08     0.0    
   300      2708.67     4.2153      4.23      0.0263      0.15    121528.51  293416.15     0.0    
   350      3226.16     4.2158     4.2308     0.0218     0.1198   122762.94  296383.71     0.0    
   400      3742.78     4.2161     4.2314     0.0274     0.0997   123653.34  298524.65     0.0    
   450      4258.32     4.217      4.2319     0.0247     0.0832   124328.94  300148.52     0.0    
   500       4772.9     4.2175     4.2321     0.0281     0.073     124855.9  301414.93     0.0    
   550      5288.61     4.2177     4.2327     0.0294     0.063    125275.35  302423.29     0.0    
   600      5804.46     4.2179     4.2331     0.0304     0.0555   125620.55   303252.9     0.0    
   650      6320.44     4.2182     4.2335     0.0273     0.0499   125906.15  303939.17     0.0    
   700      6834.97     4.2185     4.2336     0.0284     0.0448   126146.45  304516.58     0.0    
   750      7349.58     4.2189     4.2341     0.0281     0.041    126350.39  305006.61     0.0    
   800       7863.2     4.2192     4.2342     0.0306     0.037     126525.8  305428.02     0.0    
   850      8378.42     4.2194     4.2344     0.0287     0.0341    126678.1  305793.82     0.0    
   900      8894.53     4.2198     4.2347     0.0284     0.0315   126810.77  306112.33     0.0    
   950      9410.32      4.22      4.2348     0.0285     0.0289   126926.25  306389.69     0.0    
   1000     9926.29      4.22      4.2351     0.034      0.0271   127027.26  306632.19     0.0    
   1050     10441.13    4.2202     4.2352     0.0298     0.0254   127115.17   306843.4     0.0    
   1100     10955.16    4.2205     4.2352     0.0298     0.0236   127190.36  307023.92     0.0    
   1150     11468.83    4.2205     4.2355     0.0327     0.0221   127253.78  307176.16     0.0    
   1200     11984.96    4.2204     4.2356     0.0325     0.0209   127307.05  307303.97     0.0    
   1250     12500.47    4.2205     4.2356     0.0321     0.0197   127349.27  307405.13     0.0    
   1300     13015.5     4.2207     4.2357     0.0302     0.0188   127379.84  307478.27     0.0    
   1350     13531.0     4.2207     4.2358     0.0338     0.0176   127398.49  307522.67     0.0    
   1400     14046.25    4.2205     4.2357     0.0333     0.0167   127403.37  307533.93     0.0    
   1450     14560.75    4.2206     4.2356     0.0347     0.0161   127391.77  307505.49     0.0    
   1500     15075.51    4.2202     4.2353     0.0371     0.0153   127359.24  307426.85     0.0    
   1550     15589.28     4.22      4.235      0.0401     0.0146   127301.65  307287.73     0.0    
   1600     16104.21    4.2195     4.2346     0.0462     0.014    127211.33  307069.44     0.0    
   1650     16620.49    4.2187     4.2339     0.0488     0.0135   127074.17   306738.5     0.0    
   1700     17136.43    4.2178     4.2328     0.0535     0.0129   126872.01  306250.76     0.0    
   1750     17652.14    4.2163     4.2314     0.0625     0.0127   126579.83   305546.1     0.0    
   1800     18168.87    4.214      4.229      0.072      0.0123    126143.3  304493.06     0.0    
   1850     18686.12    4.2102     4.2257     0.0786     0.0121   125495.45  302930.44     0.0    
   1900     19203.42    4.2052     4.2201     0.098      0.012    124509.49  300552.89     0.0    
   1950     19720.03    4.1963     4.2115     0.1075     0.0121   122993.64  296896.16     0.0    
   2000     20234.54    4.1824     4.1977     0.1278     0.0126   120666.05  291284.55     0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       130.2      4.1463     4.1591     0.0866     3.3464    76097.59  244975.22     0.0    
   100       736.48     4.2036     4.2159     0.0476     0.9942    99457.62  320207.58     0.0    
   150      1343.07     4.2143     4.2272     0.0359     0.4126   110280.96  355014.82     0.0    
   200      1950.16     4.2185     4.2307     0.0312     0.2679   115691.24  372392.61     0.0    
   250      2557.74     4.2197     4.2326     0.0281     0.1956   118804.36  382383.01     0.0    
   300      3164.22     4.2215     4.2336     0.026      0.153    120797.07  388777.16     0.0    
   350      3768.35     4.2216     4.2342     0.0257     0.1228   122175.25  393196.06     0.0    
   400      4375.07     4.2222     4.2348     0.0257     0.1007   123175.18  396401.75     0.0    
   450      4980.17     4.2228     4.2353     0.0243     0.0857   123924.78  398804.59     0.0    
   500      5584.68     4.2227     4.2355     0.0269     0.0735   124509.68  400679.03     0.0    
   550       6190.5     4.223      4.236      0.0253     0.0647   124979.18  402183.12     0.0    
   600      6794.98     4.2236     4.236      0.0287     0.0569   125361.64  403407.83     0.0    
   650      7400.75     4.2235     4.2364     0.0259     0.0507   125680.58  404429.63     0.0    
   700      8004.96     4.2238     4.2365     0.0239     0.0451   125948.74  405288.53     0.0    
   750      8610.73     4.2241     4.2367     0.0262     0.0417   126178.48  406024.39     0.0    
   800      9215.02     4.2241     4.2369     0.024      0.0378   126376.31  406657.99     0.0    
   850      9819.96     4.2243     4.2372     0.026      0.0344   126548.69  407210.15     0.0    
   900      10424.09    4.2243     4.2371     0.0236     0.032    126698.94  407691.01     0.0    
   950      11028.46    4.2244     4.2372     0.0274     0.0295   126830.76  408113.05     0.0    
   1000     11632.09    4.2245     4.2373     0.0266     0.0279   126946.92  408484.87     0.0    
   1050     12236.28    4.2246     4.2375     0.032      0.0259   127049.32  408812.49     0.0    
   1100     12841.51    4.2248     4.2375     0.027      0.024    127140.02  409102.63     0.0    
   1150     13444.6     4.2248     4.2377     0.0285     0.0225   127219.78   409357.7     0.0    
   1200     14049.66    4.2248     4.2377     0.0286     0.0213   127289.46  409580.57     0.0    
   1250     14652.55    4.2249     4.2378     0.0277     0.0203   127349.55  409772.73     0.0    
   1300     15256.01    4.2251     4.2378     0.0296     0.0191   127399.87   409933.4     0.0    
   1350     15860.18    4.2249     4.2378     0.0301     0.0184    127440.1  410061.57     0.0    
   1400     16464.36    4.2251     4.2378     0.0287     0.0173   127469.02  410153.57     0.0    
   1450     17068.62    4.2249     4.2378     0.0301     0.0166   127487.05  410210.54     0.0    
   1500     17670.79    4.2249     4.2376     0.0308     0.0157   127491.09  410222.75     0.0    
   1550     18273.16    4.2248     4.2375     0.0328     0.0151   127480.18  410186.56     0.0    
   1600     18876.51    4.2245     4.2373     0.0362     0.0146   127448.11  410082.18     0.0    
   1650     19481.63    4.2242     4.2369     0.0383     0.0139   127390.44  409895.52     0.0    
   1700     20084.98    4.2235     4.2363     0.0422     0.0135   127294.69  409585.74     0.0    
   1750     20689.51    4.2226     4.2356     0.0475     0.013    127149.71  409117.06     0.0    
   1800     21292.12    4.2217     4.2344     0.0555     0.0125   126929.99  408408.06     0.0    
   1850     21896.15    4.2199     4.2325     0.0664     0.0125   126589.65  407310.66     0.0    
   1900     22501.06    4.2169     4.2297     0.0774     0.0121   126060.13   405606.5     0.0    
   1950     23104.9     4.2127     4.2254     0.0899     0.0121   125254.07  403007.75     0.0    
   2000     23711.49    4.2055     4.2182     0.1099     0.0123   123973.68  398881.99     0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | test_nll | train_nll     dw   
    50       129.26     4.1449     4.1627     0.0975     3.2686    74895.97  301860.71     0.0    
   100       822.91     4.2054     4.2236     0.0686     0.9339    98074.33  395407.51     0.0    
   150       1517.3     4.2166     4.2359     0.0454     0.4358   109262.42   440511.7     0.0    
   200      2210.38     4.2206     4.2397     0.0337     0.2804   114972.77  463510.09     0.0    
   250      2904.62     4.2227     4.2418     0.0289     0.201    118275.85  476821.35     0.0    
   300      3597.22     4.2239     4.243      0.0301     0.1554   120389.19  485333.32     0.0    
   350      4290.45     4.2249     4.2437     0.0314     0.1261   121843.73  491192.06     0.0    
   400      4984.78     4.2254     4.2442     0.0246     0.1021   122901.67  495453.71     0.0    
   450       5678.0     4.2256     4.2445     0.0255     0.086    123691.83  498634.92     0.0    
   500      6371.49     4.2258     4.245      0.0284     0.0749    124315.1  501143.71     0.0    
   550      7066.58     4.2261     4.2451     0.0263     0.065    124814.35  503153.38     0.0    
   600      7759.05     4.2263     4.2453     0.026      0.0576   125218.54  504780.92     0.0    
   650       8451.2     4.2264     4.2456     0.0246     0.0515   125556.69  506141.71     0.0    
   700      9144.23     4.2267     4.2456     0.0259     0.0456   125841.35  507287.56     0.0    
   750      9834.82     4.2267     4.2458     0.0244     0.0418   126085.35  508269.62     0.0    
   800      10528.2     4.2269     4.2459     0.0235     0.0381   126295.01  509113.13     0.0    
   850      11220.49    4.2269     4.246      0.0242     0.0352   126477.17  509845.79     0.0    
   900      11912.5     4.2271     4.2461     0.0247     0.0327    126636.5  510486.82     0.0    
   950      12605.22    4.2272     4.2462     0.0244     0.0301   126776.66  511050.87     0.0    
   1000     13297.8     4.2272     4.2463     0.026      0.0279   126900.88  511550.53     0.0    
   1050     13991.27    4.2274     4.2463     0.0232     0.0262   127010.75  511992.46     0.0    
   1100     14684.35    4.2272     4.2465     0.0309     0.0246   127107.93  512383.28     0.0    
   1150     15378.28    4.2272     4.2465     0.0222     0.0231   127193.74  512728.24     0.0    
   1200     16072.28    4.2274     4.2466     0.0247     0.0217   127269.41  513032.37     0.0    
   1250     16765.42    4.2273     4.2466     0.0261     0.0205   127335.91  513299.56     0.0    
   1300     17459.05    4.2273     4.2467     0.0287     0.0194   127393.44  513530.82     0.0    
   1350     18151.46    4.2275     4.2466     0.0246     0.0184   127441.93  513725.58     0.0    
   1400     18844.67    4.2275     4.2465     0.0264     0.0175   127479.03  513874.56     0.0    
   1450     19536.9     4.2273     4.2466     0.0269     0.0168   127505.38  513979.94     0.0    
   1500     20232.34    4.2274     4.2464     0.0279     0.0161   127518.97  514034.16     0.0    
   1550     20925.08    4.2272     4.2463     0.0306     0.0153   127518.01  514029.57     0.0    
   1600     21616.98    4.2269     4.2461     0.0351     0.0147   127499.82  513955.79     0.0    
   1650     22311.01    4.2267     4.2458     0.0359     0.0141   127453.79  513769.65     0.0    
   1700     23004.5     4.2262     4.2452     0.0409     0.0136   127375.75  513453.98     0.0    
   1750     23697.37    4.2254     4.2445     0.0456     0.0132   127246.84  512932.82     0.0    
   1800     24390.99    4.2245     4.2434     0.0546     0.013    127039.44  512093.97     0.0    
   1850     25083.66    4.2225     4.2416     0.0655     0.0127   126713.32  510779.53     0.0    
   1900     25775.28    4.2196     4.2388     0.0798     0.0127   126181.39  508633.55     0.0    
   1950     26468.21    4.2151     4.2341     0.0957     0.0125   125308.96   505114.4     0.0    
   2000     27160.7     4.207      4.2258     0.1111     0.0129   123853.72  499247.94     0.0    
