Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  8.510809659957886
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       69.12     445.4442   446.0911    3.1614     0.6974   
   200       139.14    427.7135   428.393     2.8184     0.2336   
   300       209.15    425.4892   424.0374    2.8878     0.1232   
   400       279.18    423.386    422.4209    2.227      0.0798   
   500       349.27    424.7696   423.2585    2.3262     0.0553   
   600       419.3     422.189    421.3235    1.654      0.0421   
   700       489.28    420.5135   421.7624    1.6602     0.0321   
   800       559.3     422.9018   421.7823    1.7642     0.0266   
   900       629.34    421.8039   422.1582    2.3102     0.0217   
   1000      699.45    420.276    420.6041    1.6654     0.0182   
   1100      769.54    420.1768    420.75     1.6034     0.0159   
   1200      839.66    420.7587   420.7319    1.4982     0.0136   
   1300      909.57    420.9779   420.108     1.5582     0.0121   
   1400      979.01    421.0556   421.2659    1.2454     0.0106   
   1500     1048.35    419.2674   419.7333    1.446      0.0095   
   1600     1117.65    418.6465   420.1334    1.6569     0.0088   
   1700     1187.12    419.5942   419.8592    1.099      0.0078   
   1800     1256.48    418.8147   419.5194    1.2002     0.0072   
   1900     1325.91    418.7761   419.6246    1.3855     0.0067   
   2000     1395.19    418.3228   419.1685    1.379      0.006    
   2100      1464.4    419.6941   420.0863    1.4235     0.0056   
   2200     1533.63    418.642    419.0678    1.2444     0.0052   
   2300      1602.8    417.848    419.6232    1.4613     0.0048   
   2400     1672.08    419.1183   419.3443    1.2942     0.0047   
   2500     1741.37    417.9591   418.7372    1.4204     0.0043   
   2600     1810.58    418.4288   418.9658    1.2176     0.0041   
   2700     1879.82    418.7718   419.0317    1.0916     0.0038   
   2800      1949.1    418.2465   418.7835    0.9387     0.0037   
   2900     2018.41    418.4256   419.4129    1.2066     0.0034   
   3000     2087.73    418.9563   419.2469    1.1697     0.0033   
   3100     2157.07    419.3927   419.3672    1.2176     0.0031   
   3200     2226.27    418.0856   418.5225    0.8692     0.0029   
   3300     2295.43    417.741    418.8659    1.0268     0.0028   
   3400     2364.57    418.0269   418.6844    1.149      0.0027   
   3500     2433.63    418.6045   418.9037    1.2026     0.0025   
   3600     2502.61    418.1966   418.4368    1.0405     0.0024   
   3700      2571.5    418.3949   419.2488    1.3748     0.0023   
   3800     2640.26    418.4264   418.8922    0.9411     0.0022   
   3900     2708.69    418.4884   418.7923    1.0407     0.0021   
   4000     2777.22    418.1897   418.6168    1.124      0.0021   
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       68.88     440.1995   440.967     3.1621     0.6248   
   200       139.49    429.6871   429.6253    2.9277     0.3182   
   300       210.04    423.4234   424.5355    2.4599     0.2052   
   400       280.59    421.821    423.5138    2.5235     0.1436   
   500       351.19    422.1567   423.5267    2.0736     0.1071   
   600       421.72    421.0302   422.8416    2.0017     0.0815   
   700       492.25    421.3501   423.6248    2.093      0.0648   
   800       562.76    422.0134   423.0178    1.7309     0.0539   
   900       633.28    420.2879   421.6817    1.8198     0.0437   
   1000      703.86    420.123    422.1683    1.6638     0.0374   
   1100      774.45    419.1607   420.9753    1.611      0.0325   
   1200      845.06    419.3186   420.8417    1.9026     0.0277   
   1300      915.79    420.8779   421.3803    1.6488     0.0245   
   1400      986.47     419.85    420.7965    1.8332     0.0215   
   1500     1057.16    420.3484   420.3925    1.2558     0.0197   
   1600     1128.07    419.6791   420.5362    1.2672     0.0175   
   1700     1198.97    418.5799   420.5423    1.6326     0.0155   
   1800      1269.9    419.4684   420.6516    1.3959     0.0143   
   1900      1340.9    419.6582   420.6767    1.5211     0.0132   
   2000     1411.92    420.0076   420.8685    1.6044     0.0121   
   2100     1482.89    419.1081   420.4386    1.1215     0.0109   
   2200     1553.98    419.4353   420.3185    1.4094      0.01    
   2300     1625.18    418.9417   420.444     1.1721     0.0093   
   2400     1696.27    419.6991   420.2336    1.1826     0.0086   
   2500     1767.28    418.0589   420.0567    1.4957     0.008    
   2600     1838.22    419.0456   420.0827    1.1788     0.0076   
   2700     1909.11    418.4724   420.3765    1.3257     0.007    
   2800     1980.06     419.29    420.1031    1.2564     0.0066   
   2900     2050.86    418.3917   419.5435    1.4247     0.0062   
   3000     2121.58    418.0066   419.5531    0.9955     0.0059   
   3100     2192.85    418.2283   420.0154    1.0603     0.0055   
   3200     2264.11    418.6162   419.115     1.1103     0.0051   
   3300     2335.43    418.9434   420.2933    1.1759     0.005    
   3400     2406.64    417.8914   420.2705    1.3783     0.0048   
   3500     2477.92    417.9543   419.6688    0.9707     0.0047   
   3600     2549.06    417.6504   419.002     1.0407     0.0042   
   3700     2620.41    417.708    418.8279    1.2345     0.0041   
   3800     2691.72    418.2324   419.9454    0.9482     0.0038   
   3900     2763.01    418.9682   419.4599    0.9994     0.0038   
   4000     2834.31    417.3819   418.8792    1.0679     0.0035   
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100        69.6     438.4384   441.2018    3.1621     0.5109   
   200       141.57    426.2279   427.0579    2.9227     0.3083   
   300       213.62    424.1716   424.6182    2.5454     0.2116   
   400       285.73    423.3125   424.5345     2.08      0.1546   
   500       357.73    420.6812   422.8069    2.1331     0.1168   
   600       429.85    422.6939   423.3999    1.7899     0.0915   
   700       501.77    420.6569   421.8946    1.7139     0.0745   
   800       573.61     421.04    421.969     1.749      0.0638   
   900       645.39    420.3143   423.1879    2.0377     0.0508   
   1000      717.17    419.3952   421.0628    1.7782     0.044    
   1100      788.86    419.9541   422.2359    1.3441     0.0388   
   1200      860.68    419.2009   420.5192    1.4589     0.0338   
   1300      932.41     420.17    421.5915    1.5315     0.0297   
   1400     1004.27    418.6024   420.5145    1.8024     0.0264   
   1500     1076.08    419.5078   420.746     1.7147     0.024    
   1600     1147.74    418.2267   420.8096    1.2841     0.0211   
   1700     1219.39    419.9449   421.1467    1.4348     0.0195   
   1800     1291.02    419.1802   421.4271    1.362      0.0175   
   1900     1362.65    418.3852   420.1908    1.262      0.0157   
   2000     1434.38    418.7768   419.905     1.4822     0.0151   
   2100     1505.94    418.9387   420.7444    1.4278     0.0132   
   2200     1577.79    418.3806   420.1177    1.464      0.0122   
   2300      1649.6    419.9291   420.7277    1.1934     0.0115   
   2400     1721.38    418.8982   419.5028    1.2479     0.0105   
   2500      1793.1    416.988    419.0476    1.4029     0.0102   
   2600      1864.8    418.8413   420.5768    1.5429     0.0093   
   2700     1936.65    418.0028   420.2756    1.2524     0.0089   
   2800     2008.36    416.9584   419.111     1.2836     0.0085   
   2900     2080.31    417.8695   420.0711    1.1489     0.0083   
   3000     2152.19    418.0088   420.1996    1.2138     0.0076   
   3100     2224.16    417.6621   419.3085    1.1475     0.0071   
   3200     2296.09    418.7446   419.7148    1.0784     0.0068   
   3300      2368.1    417.9786   419.0133    1.1236     0.0063   
   3400     2440.09    418.7942   419.3677    1.3681     0.0058   
   3500     2512.25    418.4975   419.8804    0.9061     0.0057   
   3600     2584.57    416.7343   418.9683    0.9774     0.0054   
   3700      2656.5    416.5328   419.6499    1.0654     0.0051   
   3800     2728.47    417.922    419.2111    1.0202     0.0048   
   3900     2800.44    417.5877   418.5223    1.205      0.0046   
   4000     2872.27    416.7813   418.7079    0.9762     0.0044   
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       69.55     440.5667   441.6761    3.1619     0.4377   
   200       142.31    426.3789   427.8087    3.0036     0.2924   
   300       215.08    423.1106   425.3997    2.7379     0.2032   
   400       287.89    422.2539   424.303     2.3827     0.1583   
   500       360.66    422.7408   424.4068    2.2532     0.1205   
   600       433.34    420.6181   421.6358    2.0967     0.0979   
   700       505.86    420.7253   423.5161    1.7607     0.0792   
   800       578.36    421.5178   422.9783    1.4314     0.0695   
   900       650.66    420.1131   421.7283    1.5189     0.0598   
   1000      723.0     420.0253   421.8836    1.7505     0.0512   
   1100      795.35    418.8871   421.7436    2.0109     0.0434   
   1200      867.59    419.2759   421.7449    1.4348     0.0384   
   1300      939.8     418.5138   421.1071    1.5539     0.0351   
   1400     1011.99    418.6693   420.2648    1.3762     0.0298   
   1500     1084.16    419.3423   422.0008    1.6398     0.0272   
   1600     1156.41    419.9542   421.6619    1.4068     0.0241   
   1700     1228.55    419.1566   421.1066    1.7279     0.0221   
   1800     1300.66    419.4289   421.5929    1.5542     0.0202   
   1900     1372.83    420.5787   421.5964    1.4992     0.0183   
   2000      1445.0    418.5184   420.6915    1.7216     0.0169   
   2100     1517.15    417.9825   420.414     1.4537     0.0156   
   2200     1589.33    417.2222   420.2358    1.4379     0.0144   
   2300     1661.42    419.0731   421.5748    1.0397     0.0133   
   2400     1733.47    418.1523   420.0874    1.5458     0.0126   
   2500     1805.53    417.5629   419.8672    1.1055     0.012    
   2600     1877.65    418.0211   420.1644    1.1339     0.0109   
   2700      1949.9    417.6306   419.8369    1.0201     0.0102   
   2800     2022.05    417.6482   419.7963    1.3006     0.0096   
   2900     2094.22    419.3272   420.309     1.2018     0.0091   
   3000     2166.47    417.285    419.1781    1.0446     0.0085   
   3100     2238.66    418.2097   420.4497    1.249      0.0082   
   3200     2310.89    418.2166   420.1604    1.1354     0.0076   
   3300     2383.17    417.6112   419.7092    0.979      0.0073   
   3400     2455.39    418.9239   420.1642    1.2828     0.007    
   3500     2527.63    417.0789   419.302     1.3638     0.0065   
   3600     2599.78    417.1322   419.9032    1.2527     0.0062   
   3700     2671.96    417.2206   419.2693    0.988      0.006    
   3800     2744.23    417.3587   419.3594    1.2343     0.0056   
   3900     2816.42    418.1939   420.3089    1.0486     0.0054   
   4000     2888.62    417.1167   419.7489    0.9975     0.0052   
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  | 
   100       69.43     436.1291   438.205     3.162      0.4063   
   200       142.59    426.0355   427.8776     2.84      0.2663   
   300       215.75    426.5818   427.252     2.9026     0.2001   
   400       289.02    424.0646   424.7847    2.1263     0.1525   
   500       362.3     423.1227   424.4436    2.056      0.1215   
   600       435.43    423.1751   424.2565    2.5914     0.1016   
   700       508.64    420.798    422.3752    2.0789     0.0823   
   800       581.77    420.0635   421.4018    1.9399     0.0701   
   900       654.88    418.4578   421.1233    1.8652     0.0619   
   1000      727.98    419.6198   422.1515    1.616      0.0539   
   1100      801.12    420.1189   421.7362    1.6754     0.0482   
   1200      874.24    419.6949   421.5254    1.809      0.0403   
   1300      947.36    419.0186   420.9472    1.6844     0.037    
   1400     1020.48    419.4015   421.1915    1.5946     0.0319   
   1500     1093.63    420.7376   422.5865    1.5455     0.0291   
   1600     1166.79    418.9159   421.1035    1.3831     0.0257   
   1700     1239.99    418.744    421.0696    1.7279     0.0237   
   1800     1313.11    418.523    420.1618    1.2518     0.022    
   1900     1386.33    419.6024   421.3786    1.4847      0.02    
   2000     1459.57    418.8302   419.9574    1.235      0.0187   
   2100     1532.84    418.6019   420.3576    1.4029     0.0172   
   2200     1606.09    418.4495   420.086     1.4549     0.0161   
   2300     1679.28    417.2585   419.9486    1.2001     0.0148   
   2400     1752.39    417.8961   420.2451    1.7058     0.0137   
   2500     1825.57    418.6383   420.2376    1.2279     0.0129   
   2600     1898.72    418.2132   419.7246     1.07      0.0122   
   2700      1971.9    417.9483   420.217     1.2914     0.0114   
   2800     2045.14    418.1202    419.85     1.1667     0.0109   
   2900     2118.21    418.6741   420.0015    1.307      0.0103   
   3000      2191.3    418.8867   420.7373    1.455      0.0097   
   3100      2264.5    418.699    420.2369    1.0798     0.0091   
   3200     2337.56    417.917    419.5371    1.1495     0.0085   
   3300     2410.67    418.2126   420.0729    1.0422     0.0079   
   3400     2483.83    416.9825   418.836     1.1849     0.0077   
   3500     2556.88    417.5895   419.3186    1.1526     0.0073   
   3600     2629.83    417.876    419.8702    1.2422     0.0069   
   3700     2702.76    417.5546   419.1479    1.0178     0.0067   
   3800     2775.76    417.4719   419.1649    1.4488     0.0064   
   3900     2848.74    418.2583   419.3913    0.9907     0.006    
   4000     2921.74     417.1     419.0104    1.1476     0.0057   
