Generating synthetic real valued data ... 
Generating synthetic  real valued data took:  8.093226909637451
Using  0.2  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       211.49    436.4008   437.9687    3.1622     0.7484      0.0    
   200       422.58    424.9692   425.5803    2.8316     0.3243      0.0    
   300       633.67    421.6131   422.1593    2.5258     0.191       0.0    
   400       844.75     420.82    420.839     2.1053     0.1349      0.0    
   500      1055.96    420.7644   420.8368    2.1427     0.1324      0.0    
   600      1267.18    421.0872   420.964     2.1538     0.1367      0.0    
   700      1478.37    419.1868   419.7129    1.5922     0.0811      0.0    
   800      1689.74    420.5953   420.6271    2.1453     0.0638      0.0    
   900      1900.82    419.5111   419.5031    1.6604     0.0666      0.0    
   1000     2111.97    420.0701   419.3454    1.465      0.0568      0.0    
   1100     2322.38    420.0249   420.5245    1.3566     0.0442      0.0    
   1200     2532.45    420.0097   420.1016    1.3732     0.0424      0.0    
   1300     2741.04    418.992    419.6578    1.2532     0.0339      0.0    
   1400     2951.49    419.2741   419.6851    1.454      0.0313      0.0    
   1500     3161.84    418.8691   419.3189    1.6432     0.0285      0.0    
   1600     3372.53    419.8764   420.0045    1.0885     0.0284      0.0    
   1700     3582.86    419.086    419.4212     1.22      0.0211      0.0    
   1800     3793.66    418.9852   419.0278    1.4577     0.0217      0.0    
   1900     4004.42    418.8873   419.2658    1.2703     0.0224      0.0    
   2000     4215.31    417.9721   418.8887    1.1548     0.0218      0.0    
   2100     4426.11    418.4118   418.8943    1.4425     0.0192      0.0    
   2200     4636.84    417.5989   419.0547    1.0229     0.0172      0.0    
   2300     4847.27    417.5495   418.8825    1.079      0.0187      0.0    
   2400     5057.99    418.2127   418.5488    0.9554     0.0163      0.0    
   2500     5269.41    418.488    419.1897    1.6003     0.0174      0.0    
   2600      5480.4    418.9072   418.6428    1.1737     0.0139      0.0    
   2700      5691.5    417.7022   418.6235    1.1814     0.0161      0.0    
   2800      5902.5    419.1747   418.7487    1.0669     0.0147      0.0    
   2900     6113.44    418.8034   418.9718    1.0411     0.0138      0.0    
   3000     6324.44    417.4939   418.4684    0.9393     0.012       0.0    
   3100     6535.24    418.1843   418.3104    0.9905     0.0129      0.0    
   3200     6745.97    417.836    418.4922    1.2036     0.013       0.0    
   3300     6956.66    417.6322   417.9823    1.0792     0.0129      0.0    
   3400     7167.73    418.0488   418.0596    1.0498     0.0117      0.0    
   3500     7378.73    417.7857   418.2084    0.9888     0.0094      0.0    
   3600     7589.79    417.8034   418.4123    1.0288     0.0103      0.0    
   3700     7801.12    417.4724   418.0235    0.9527     0.0123      0.0    
   3800     8012.22    418.407    417.684     1.265      0.0101      0.0    
   3900     8223.13    417.9813   418.1224    0.9219     0.0097      0.0    
   4000      8434.1    417.3561   418.0224    1.2261     0.011       0.0    
Using  0.4  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       211.97    439.1199   441.4788    3.1622     1.061       0.0    
   200       423.98    428.1546   427.5914    2.6992     0.3865      0.0    
   300       635.74    423.972    424.5714    2.7141     0.2511      0.0    
   400       847.28    421.9292   423.2421    2.1891     0.1833      0.0    
   500       1058.3    420.5041   422.6779    1.7004     0.2042      0.0    
   600      1269.26    421.2476   422.8026    2.0713     0.1373      0.0    
   700      1480.38    420.3578   421.4515    1.6826     0.0918      0.0    
   800      1688.93    420.5812   421.442     1.9682     0.0678      0.0    
   900      1897.43    418.5817   420.185     1.7947     0.0775      0.0    
   1000     2105.99    418.3583   420.1354    1.5497     0.079       0.0    
   1100     2314.31    418.8011   420.4698    1.6887     0.0667      0.0    
   1200     2522.95    418.852    419.7032    1.8081     0.0733      0.0    
   1300     2732.82    420.2231   420.8774    1.4033     0.045       0.0    
   1400     2942.85    418.345    420.8496    1.3225     0.0485      0.0    
   1500     3153.21    418.8033   419.8593    1.1409     0.0366      0.0    
   1600     3363.36    417.2644   419.6389    1.5697     0.0368      0.0    
   1700     3573.61    418.7666   419.2903    1.1279     0.0353      0.0    
   1800     3783.79    419.613    419.8099    1.2881     0.0356      0.0    
   1900     3993.98    418.474    420.0263    1.3552     0.0321      0.0    
   2000     4204.18    417.8618   419.9929    1.2585     0.0317      0.0    
   2100      4414.4    418.1913   419.2713    1.3366     0.0241      0.0    
   2200     4624.69    417.5934   419.4919    1.2303     0.0246      0.0    
   2300     4835.19    418.8868   419.9626    1.1818     0.0225      0.0    
   2400     5045.55    418.0347   419.1348    1.1843     0.0176      0.0    
   2500     5255.72    417.7895   419.9953    1.1416     0.0233      0.0    
   2600     5465.59    417.6479   419.3076    0.9885     0.0204      0.0    
   2700     5675.66    417.9276   419.1465    0.951      0.0169      0.0    
   2800     5884.35    418.0702    419.23     0.9931     0.0173      0.0    
   2900     6092.77    418.3088   419.2997    0.9954     0.0159      0.0    
   3000     6301.17    417.3213   419.2914    1.276      0.0152      0.0    
   3100     6509.38    418.6364   419.391     1.0609     0.0124      0.0    
   3200     6718.06    417.6103   419.6936    1.0365     0.0149      0.0    
   3300     6921.64    417.7346   418.563      0.99      0.0112      0.0    
   3400      7117.9    418.1267   419.0527    1.0341     0.0153      0.0    
   3500     7309.54    416.7958   419.0105    0.9987     0.0119      0.0    
   3600     7500.38    418.2362   419.4399    1.0936     0.0139      0.0    
   3700     7691.79    417.8396   419.248     1.4355     0.0116      0.0    
   3800     7882.94    417.2864   418.822     0.9646     0.012       0.0    
   3900     8072.87    417.5797   418.8531    0.7394     0.0103      0.0    
   4000     8263.78    416.4273   418.2971    1.1653     0.0108      0.0    
Using  0.6  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       190.2     441.1286   441.836     3.1608     1.1933      0.0    
   200       381.91    427.8383   428.0177    2.9653     0.3995      0.0    
   300       571.41    425.9517   425.9007    2.2734     0.2607      0.0    
   400       762.32    421.562    423.481     2.0136     0.308       0.0    
   500       953.69    420.2797   422.4423    2.4289     0.2009      0.0    
   600       1145.3    420.4249   421.4436    1.7264     0.1678      0.0    
   700      1335.55    419.2163    420.67     1.6818     0.1054      0.0    
   800       1525.6    419.4968   420.6294    1.9781     0.1549      0.0    
   900      1717.58    418.593    419.8787    1.4178     0.0869      0.0    
   1000     1908.89    418.5054   420.5527    1.402      0.0836      0.0    
   1100     2099.37    419.1014   421.1063    1.6775     0.0762      0.0    
   1200     2287.48    417.8344   420.0814    1.5358     0.0563      0.0    
   1300     2475.82    419.418    420.9532    1.5934     0.0599      0.0    
   1400      2663.8    418.4206   420.2538    1.4502     0.0516      0.0    
   1500     2851.98    418.8313   420.0267    1.4411     0.0543      0.0    
   1600     3040.17    417.8458   419.6925    1.3565     0.0589      0.0    
   1700     3228.31    418.6435   419.7422    1.3371     0.0324      0.0    
   1800     3416.49    418.8194   420.1455    1.265      0.031       0.0    
   1900     3604.67    417.9601   419.7392    1.3189     0.037       0.0    
   2000     3792.84    417.7726   419.4912    1.2347     0.0289      0.0    
   2100     3980.99    417.7536   419.458     1.2822     0.0368      0.0    
   2200     4173.81    417.6387   419.4136    1.5999     0.0223      0.0    
   2300      4363.5    417.8021   418.9369    1.1493     0.0229      0.0    
   2400     4551.59    417.5006   419.0701    1.2717     0.0246      0.0    
   2500     4739.86    417.3025   419.2364    1.0525     0.0176      0.0    
   2600     4927.93    417.4971   419.0986    0.9032     0.0203      0.0    
   2700     5120.05    416.5818   419.122     1.2293     0.0224      0.0    
   2800     5312.31    417.8323   419.3083    1.278      0.021       0.0    
   2900     5505.26    417.2294   419.1332    0.8726     0.0175      0.0    
   3000     5698.18    417.0498   419.4922    1.0483     0.0196      0.0    
   3100     5889.89    418.5972   420.099     1.0198     0.0161      0.0    
   3200     6082.25    418.005    419.8271    0.9171     0.0128      0.0    
   3300     6274.63    417.1295   418.796     1.1143     0.0172      0.0    
   3400     6466.65    416.8921   418.5272    0.9383     0.0166      0.0    
   3500     6659.35    417.723    419.4878    1.1041     0.0162      0.0    
   3600     6851.42    417.8695   418.9226    0.994      0.0123      0.0    
   3700     7043.29    417.3792   418.6627    0.8956     0.0122      0.0    
   3800     7235.99    417.3813   419.0636    1.1624     0.012       0.0    
   3900     7429.03    417.3694   418.6947    1.0081     0.0119      0.0    
   4000     7621.49    417.6644   418.588     0.9417     0.0095      0.0    
Using  0.8  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       192.7     439.8216   442.5925    3.1618     1.1348      0.0    
   200       387.3     423.8735   424.7943    2.7132     0.4157      0.0    
   300       582.07    423.7759   424.0614    2.8939     0.3447      0.0    
   400       777.75    424.0772   425.6275    2.248      0.3155      0.0    
   500       973.89    421.7293   423.8188    1.7684     0.174       0.0    
   600       1170.0    420.0376   421.7419    1.871      0.1745      0.0    
   700       1365.4    418.7866   421.3353    1.8152     0.1143      0.0    
   800      1561.21    419.7363   421.761     1.695      0.1117      0.0    
   900      1756.66    418.3577   420.6444    1.6491     0.0918      0.0    
   1000     1951.48    419.4817   421.7974    1.7314     0.075       0.0    
   1100     2146.23    418.8059   420.7904    1.566      0.0709      0.0    
   1200     2340.99    418.8797   421.0037    1.9663     0.0546      0.0    
   1300     2535.67    417.8881   420.2531    1.6044     0.0626      0.0    
   1400     2730.19    418.5264   420.1501    1.5881      0.06       0.0    
   1500     2924.78    418.3641   419.7683    1.5865     0.0595      0.0    
   1600     3119.35    418.2576   419.5844    1.0973     0.0412      0.0    
   1700     3314.02    418.873    420.9793    1.4867     0.0648      0.0    
   1800     3508.26    417.9499   419.6782    1.0557     0.0386      0.0    
   1900     3702.52    418.3549   419.485     1.5277     0.0396      0.0    
   2000     3896.77    418.9655   420.4663    1.4417     0.0287      0.0    
   2100     4090.79    418.2374   420.3852    1.1794     0.0273      0.0    
   2200     4285.37    417.9194   420.295     1.1696     0.0534      0.0    
   2300     4480.79    418.5054   420.6731    1.5916     0.0318      0.0    
   2400     4676.26    417.7072   419.545     1.0428     0.0331      0.0    
   2500     4871.45    417.6543   419.5463    1.3352     0.0243      0.0    
   2600     5066.51    417.9558   419.6319    0.9953     0.0303      0.0    
   2700     5261.63    418.0971   419.8085    1.188      0.0206      0.0    
   2800     5456.72    418.3437   420.4707    1.1973     0.022       0.0    
   2900     5651.62    417.8887   420.0811    1.1276     0.0214      0.0    
   3000     5846.46    417.7809   419.4672    0.9457     0.0219      0.0    
   3100     6041.65    416.8071   418.8664    1.2614     0.019       0.0    
   3200     6235.65    416.2675   419.1223    0.8672     0.0298      0.0    
   3300     6424.79    417.192    419.4458    0.8753     0.0157      0.0    
   3400     6613.93    417.163    419.4063    0.9882     0.0171      0.0    
   3500     6803.05    418.2089   419.8765    1.4552     0.0122      0.0    
   3600     6992.19    417.2396   419.4366    1.2214     0.0133      0.0    
   3700     7181.27    417.7417   419.4913    1.1452     0.0144      0.0    
   3800     7370.39    416.9596   419.0389    1.0062     0.0181      0.0    
   3900     7559.55    417.0818   419.1308    1.0785     0.012       0.0    
   4000     7748.65    417.078    419.4233    0.8488     0.0118      0.0    
Using  1  of training data 
Tensor dimensions:  [50, 50, 50]
Optimization metrics: 
Using Ada Grad
Mean update scheme:  S
Covariance update :  N
k1 samples =  64  k2 samples =  64
eta =  1  cov eta =  1  sigma eta =  1
iteration |   time   |test_rsme |train_rsme|  d_mean  |   d_cov  |    dw   
   100       187.61    439.4653   440.5727    3.1622     1.1844      0.0    
   200       380.48    427.4606   428.4342    3.0907     0.4977      0.0    
   300       573.68    421.5636   423.8443    2.5504     0.2844      0.0    
   400       768.02    420.4882   423.882     2.3221     0.2008      0.0    
   500       972.74    422.3318   422.8154    2.2764     0.1932      0.0    
   600      1168.48    420.9899   422.094     1.9263     0.1789      0.0    
   700      1363.04    420.2907    421.23     1.7188     0.1102      0.0    
   800      1553.35    419.4923   420.7837    1.7143     0.1214      0.0    
   900      1742.73    420.9844   422.3496    1.8042     0.0897      0.0    
   1000      1932.3    418.9871   420.8158    1.8933     0.0929      0.0    
   1100     2122.43    417.9906   420.5389    1.7969     0.0593      0.0    
   1200     2311.92    419.3851   420.9225    1.824      0.0776      0.0    
   1300     2501.29    418.4696   420.5043    1.3939     0.0603      0.0    
   1400     2690.67    418.6911   420.2692    1.4664     0.0643      0.0    
   1500     2880.03    419.0214   420.8439    1.2206     0.0711      0.0    
   1600     3069.21    417.1462   419.3456    1.2725     0.0548      0.0    
   1700     3258.35    418.5104   420.3345    1.3798     0.063       0.0    
   1800     3447.48    418.9162   419.9323    1.1846     0.038       0.0    
   1900     3636.64    418.4398   419.9944    1.5167     0.0553      0.0    
   2000     3827.37    418.958    420.0846    1.1436     0.0339      0.0    
   2100     4017.15    418.1228   419.8767    1.4158     0.0481      0.0    
   2200     4206.68    417.9154   419.7293    1.2397     0.0303      0.0    
   2300     4395.86    418.3195   419.6656    1.2552     0.0339      0.0    
   2400     4584.98    417.159    419.6798    1.2643     0.0346      0.0    
   2500     4774.08    417.3217   419.1553    1.0181     0.0231      0.0    
   2600     4963.23    417.245    419.5146    1.3696     0.027       0.0    
   2700     5152.42    417.5862   419.5847    1.2209     0.0248      0.0    
   2800     5341.64    417.2999   419.2024    0.7735     0.0241      0.0    
   2900     5530.93    417.0897   418.7422    1.0703     0.0235      0.0    
   3000     5720.22    417.3199   419.2279    1.1324     0.021       0.0    
   3100     5909.47    417.6436   419.4655    1.025      0.0284      0.0    
   3200     6098.74    418.3972   419.2842    1.0899     0.0191      0.0    
   3300     6287.98    417.0085   419.2401    1.1802     0.0197      0.0    
   3400     6477.23    417.8083   419.2518    1.0491     0.0231      0.0    
   3500      6666.5    417.0293   418.9925    1.1395     0.0214      0.0    
   3600     6855.79    417.3991   418.9464    0.9385     0.0269      0.0    
   3700     7045.05    417.0644   419.0953    0.942      0.0165      0.0    
   3800      7234.3    417.3348   419.1428    1.0619     0.0157      0.0    
   3900     7423.58    417.4937   419.132     1.2143     0.0173      0.0    
   4000     7612.74    417.3509   418.8348    0.8828     0.0179      0.0    
